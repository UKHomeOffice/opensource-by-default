[{"name":"UKHomeOffice/puppet-skeleton","private":false,"url":"https://github.com/UKHomeOffice/puppet-skeleton","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# puppet-skeleton\n\nThis is a skeleton project for Web Operations teams using Puppet. It ties\ntogether a suite of sensible defaults, best current practices, and re-usable\ncode. The intentions of which are two-fold:\n\n- New projects can get started and bootstrapped faster without needing to\n  collate or re-writing this material themselves.\n\n- The standardisation and modularisation of these materials makes it easier\n  for ongoing improvements to be shared, in both directions, between\n  different teams.\n\nIt is suggested that you fork or clone this repository when starting out.\nImprovements can be submitted back with pull requests. Any significant\nportions of code should be modularised to a more appropriate distribution\nmechanism, such as Ruby gems or Vagrant plugins.\n\n## Batteries included\n\nHere are the headline details of what's inside.\n\n### Module management\n\n[librarian-puppet](https://github.com/rodjek/librarian-puppet) is used to\npull in external modules. Externalising modules makes them more re-usable.\n\nAs sample `Puppetfile` and `Puppetfile.lock` is included which contains\n[puppetlabs-stdlib](https://github.com/puppetlabs/puppetlabs-stdlib).\n\n### Tests\n\nA modularised `Rakefile` will call the following test suites, in order:\n\n- [puppet-syntax](https://github.com/alphagov/puppet-syntax) for syntax\n  checking Puppet manifests and templates.\n- [puppet-lint](https://github.com/rodjek/puppet-lint) to check manifests\n  against PuppetLabs style guide.\n- [rspec-puppet](https://github.com/rodjek/rspec-puppet) to run behaviour\n  tests against Puppet manifests, types and providers.\n\n### Vagrant\n\nA simple `Vagrantfile` demonstrating the use of a mutli-VM setup with a\nPuppet provisioner.\n\n## Requirements\n\n- [Ruby](http://www.ruby-lang.org/) and [Bundler](http://gembundler.com/) -- ideally with [rbenv](https://github.com/sstephenson/rbenv)\n- [Vagrant](http://www.vagrantup.com/) -- version >= 1.1\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/puppetlabs-haproxy","private":false,"url":"https://github.com/UKHomeOffice/puppetlabs-haproxy","license":{"key":"apache-2.0","name":"Apache License 2.0","spdxId":"Apache-2.0","url":"https://api.github.com/licenses/apache-2.0","featured":true},"readme":"PuppetLabs Module for haproxy\n=============================\n\n[![Build Status](https://travis-ci.org/puppetlabs/puppetlabs-haproxy.svg?branch=master)](https://travis-ci.org/puppetlabs/puppetlabs-haproxy)\n\nHAProxy is an HA proxying daemon for load-balancing to clustered services. It\ncan proxy TCP directly, or other kinds of traffic such as HTTP.\n\nBasic Usage\n-----------\n\nThis haproxy uses storeconfigs to collect and realize balancer member servers\non a load balancer server. Currently Redhat family OSes are supported.\n\n*To install and configure HAProxy server listening on port 8140*\n\n```puppet\nnode 'haproxy-server' {\n  class { 'haproxy': }\n  haproxy::listen { 'puppet00':\n    ipaddress => $::ipaddress,\n    ports     => '8140',\n  }\n}\n```\n\n*To add backend loadbalance members*\n\n```puppet\nnode 'webserver01' {\n  @@haproxy::balancermember { $fqdn:\n    listening_service => 'puppet00',\n    server_names      => $::hostname,\n    ipaddresses       => $::ipaddress,\n    ports             => '8140',\n    options           => 'check'\n  }\n}\n```\n\nConfiguring haproxy options\n---------------------------\n\nThe base `haproxy` class can accept two parameters which will configure basic\nbehaviour of the haproxy server daemon:\n\n- `global_options` to configure the `global` section in `haproxy.cfg`\n- `defaults_options` to configure the `defaults` section in `haproxy.cfg`\n\nConfiguring haproxy daemon listener\n-----------------------------------\n\nOne `haproxy::listen` defined resource should be defined for each HAProxy loadbalanced set of backend servers. The title of the `haproxy::listen` resource is the key to which balancer members will be proxied to. The `ipaddress` field should be the public ip address which the loadbalancer will be contacted on. The `ports` attribute can accept an array or comma-separated list of ports which should be proxied to the `haproxy::balancermember` nodes.\n\nConfiguring haproxy daemon frontend\n-----------------------------------\n\nOne `haproxy::frontend` defined resource should be defined for each HAProxy front end you wish to set up. The `ipaddress` field should be the public ip address which the loadbalancer will be contacted on. The `ports` attribute can accept an array or comma-separated list of ports which should be proxied to the `haproxy::backend` resources.\n\nConfiguring haproxy daemon backend\n----------------------------------\n\nOne `haproxy::backend` defined resource should be defined for each HAProxy loadbalanced set of backend servers. The title of the `haproxy::backend` resource is the key to which balancer members will be proxied to. Note that an `haproxy::listen` resource and `haproxy::backend` resource *can* have the same name, and any balancermembers exported to that name will show up in both places. This is likely to have unsatisfactory results, but there's nothing preventing this from happening.\n\nConfiguring haproxy loadbalanced member nodes\n---------------------------------------------\n\nThe `haproxy::balancermember` defined resource should be exported from each node\nwhich is serving loadbalanced traffic. the `listening_service` attribute will\nassociate it with `haproxy::listen` directives on the haproxy node.\n`ipaddresses` and `ports` will be assigned to the member to be contacted on. If an array of `ipaddresses` and `server_names` are provided then they will be added to the config in lock-step.\n\nConfiguring haproxy daemon userlist\n-----------------------------------\n\nOne `haproxy::userlist` defined resource should be defined for each HAProxy userlist.\nThe users and groups for the userlist are supplied to the resource via an array.\n\nDependencies\n------------\n\nTested and built on Ubuntu and CentOS\n\nCopyright and License\n---------------------\n\nCopyright (C) 2012 [Puppet Labs](https://www.puppetlabs.com/) Inc\n\nPuppet Labs can be contacted at: info@puppetlabs.com\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n  http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/swappr","private":false,"url":"https://github.com/UKHomeOffice/swappr","license":null,"readme":"swappr\n======\n\nClient / Server app for managing shift swaps\n\n## Running the app\n\nSwappr uses MySQL. Before running for the first time, ensure the database and user exist and have appropriate \npermissions. E.g. by executing the contents of [schema.sql](web/src/db/schema.sql).\n\nStart the MySQL server:\n\n```\nmysql.server start\n```\n\nThen set up the db:\n\n```\nmysql -u root < schema.sql\n```\n\nand run the seed:\n\n```\nmysql -u root < seed.sql\n```\n\n## Smoke tests\n### Requirements\nInstall [PhantomJS](http://phantomjs.org/download.html) eg. using Homebrew on Mac:\n\n```\nbrew update && brew install phantomjs\n```\n\nNavigate to /integration/smoke_tests and run\n\n```\nbundle install\n```\n\n### Running\nTo run the tests locally, ie localhost:8080, use:\n\n```\nrake smoke_test\n```\n\nThis will reset the database and seed it with 2 users, bill and ben, before running the test suite.\n\nTo run the test suite against another instance of the app, pass the hostname of that server as an argument:\n\n```\nrake \"smoke_test['http://www.google.com']\"\n```\n\n### Writing\nThe tests are written in [Capybara](https://github.com/jnicklas/capybara).\n\nShared code for steps is in step_definitions/common_steps.rb\n\n### Debugging\n\nTo aid debugging of tests, open integration/smoke_tests/spec/spec_helper.rb and set\n\n```\nCapybara.default_driver = :selenium\n```\n\nThis will run the tests in Firefox by default so you can see what's going on.\n\nTo set a breakpoint in a test, insert this line into your step definition:\n\n```\nbinding.pry\n```\n\nThis will pause execution in the command prompt and let you examine variables, run Capybara queries etc. You can also step through the test using next / continue. See [pry-nav](https://github.com/nixme/pry-nav)","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/cts-pentaho","private":false,"url":"https://github.com/UKHomeOffice/cts-pentaho","license":null,"readme":"cts-alfresco-tomcat\n===================\n\nAlfresco tailored tomcat\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/finch","private":false,"url":"https://github.com/UKHomeOffice/finch","license":{"key":"apache-2.0","name":"Apache License 2.0","spdxId":"Apache-2.0","url":"https://api.github.com/licenses/apache-2.0","featured":true},"readme":"![logo](https://raw.github.com/finagle/finch/master/finch-logo.png) \n\n**Finch.io** is a thin layer of purely functional basic blocks atop of [Finagle](http://twitter.github.io/finagle) for \nbuilding composable REST APIs. Its mission is to provide the developers simple and robust REST API building blocks \nbeing as close as possible to the Finagle bare metal API.\n\nQuickstart\n----------\n\n```scala\nresolvers += \"Finch.io\" at \"http://repo.konfettin.ru\"\n\nlibraryDependencies ++= Seq(\n  \"io\" %% \"finch\" % \"0.1.6\"\n)\n```\n\n```scala\ndef hello(name: String) = new Service[HttpRequest, HttpResponse] = {\n  def apply(req: HttpRequest) = for {\n    title <- OptionalParam(\"title\")(req)\n  } yield Ok(s\"Hello, ${title.getOrElse(\"\")} $name!\")\n}\n\nval endpoint = new Endpoint[HttpRequest, HttpResponse] {\n  def route = {\n    // routes requests like '/hello/Bob?title=Mr.'\n    case Method.Get -> Root / \"hello\" / name => hello(name)\n  }\n}\n```\n\nDocumentation\n-------------\nDocumentation may be found in the [`docs.md`](docs.md) file in the root directory.\n\nAdopters\n--------\n* [Konfettin](http://konfettin.ru)\n* [JusBrasil](http://www.jusbrasil.com.br)\n* *Submit a pull-request to include your company/project into the list*\n\nLicense\n-------\n\nLicensed under the **[Apache License, Version 2.0](http://www.apache.org/licenses/LICENSE-2.0)** (the \"License\");\nyou may not use this software except in compliance with the License.\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n----\n[![Build Status](https://secure.travis-ci.org/finagle/finch.png)](http://travis-ci.org/finagle/finch)\n[![Coverage Status](https://coveralls.io/repos/finagle/finch/badge.png)](https://coveralls.io/r/finagle/finch)\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/vcloud-start_stop","private":false,"url":"https://github.com/UKHomeOffice/vcloud-start_stop","license":{"key":"apache-2.0","name":"Apache License 2.0","spdxId":"Apache-2.0","url":"https://api.github.com/licenses/apache-2.0","featured":true},"readme":"# Vcloud::StartStop\n\nTODO: Write a gem description\n\n## Installation\n\nAdd this line to your application's Gemfile:\n\n    gem 'vcloud-start_stop'\n\nAnd then execute:\n\n    $ bundle\n\nOr install it yourself as:\n\n    $ gem install vcloud-start_stop\n\n## Usage\n\nTODO: Write usage instructions here\n\n## Contributing\n\n1. Fork it ( https://github.com/[my-github-username]/vcloud-start_stop/fork )\n2. Create your feature branch (`git checkout -b my-new-feature`)\n3. Commit your changes (`git commit -am 'Add some feature'`)\n4. Push to the branch (`git push origin my-new-feature`)\n5. Create a new Pull Request\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/puppet-hosts","private":false,"url":"https://github.com/UKHomeOffice/puppet-hosts","license":{"key":"other","name":"Other","spdxId":null,"url":null,"featured":false},"readme":"# Puppet module: hosts\n\nThis is a Puppet module to manage /etc/hosts\n\nIt allows its population in different ways, either static or dynamic\n\nWritten by Alessandro Franceschi / Lab42\n\nOfficial site: http://www.example42.com\n\nOfficial git repository: http://github.com/example42/puppet-hosts\n\nReleased under the terms of Apache 2 License.\n\nThis module requires the presence of Example42 Puppi module in your modulepath.\n\n\n## USAGE\n\nThis module provide different options for managing /etc/hosts\n\n1 -  Use custom static sources for hosts file (also an array)\n\n        class { 'hosts':\n          source => [ \"puppet:///modules/example42/hosts/hosts.conf-${hostname}\" ,\n                      \"puppet:///modules/example42/hosts/hosts.conf\" ], \n        }\n\n\n2 - Use custom template for hosts file. Note that template and source arguments are alternative. \n\n        class { 'hosts':\n          template => 'example42/hosts/hosts.conf.erb',\n        }\n\n3 - Dynamically populate /etc/hosts with all the nodes of your Puppet infrastructure\n\n        class { 'hosts':\n          dynamic_mode => true,\n        }\n\n\n## DYNAMIC MODE USAGE\n\nIn dynamic mode you have various options that allows you to fine tune the automatic\ncollection of host entries in /etc/hosts:\n\n* To add a common header to /etc/hosts (by default the existing entries are not modified):\n\n        class { 'hosts':\n          dynamic_mode     => true,\n          dynamic_template => 'example42/hosts/header.erb',\n        }\n\n(The above adds an header taken from $MODULEPATH/example42/templates/hosts/header.erb)\n\n* To collect on /etc/hosts only nodes that share the same value for a given variable:\n\n        class { 'hosts':\n          dynamic_mode     => true,\n          dynamic_magicvar => 'environment',\n        }\n\n(Here you'll find in /etc/hosts only the nodes that share the same $environment)\n\n* To exclude a specific host from automatic collection on other nodes\n\n        class { 'hosts':\n          dynamic_mode     => true,\n          dynamic_exclude  => $::role ? {\n            puppetmaster => true,\n            default      => false,\n          }\n        }\n\n(In the above example the puppetmaster's host entry won't be automatically added to the other nodes (you might force it in the header template). Note that the puppetmaster\nitself will continue to populate its /etc/hosts dynamically as the other nodes.)\n\n* To specify custom variables to use for IP or alias entries:\n\n        class { 'hosts':\n          dynamic_mode => true,\n          dynamic_ip    => $::ec2_public_ipv4,\n          dynamic_alias => [ $::hostname , $::ec2_hostname ],\n        }\n\n(By default $::ipaddress and [ $::hostname ] are used.\n\n\n## CONTINUOUS TESTING\n\nTravis {<img src=\"https://travis-ci.org/example42/puppet-hosts.png?branch=master\" alt=\"Build Status\" />}[https://travis-ci.org/example42/puppet-hosts]\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/puppet-php","private":false,"url":"https://github.com/UKHomeOffice/puppet-php","license":{"key":"other","name":"Other","spdxId":null,"url":null,"featured":false},"readme":"# Puppet module: php\n\nThis is a Puppet module for php based on the second generation layout (\"NextGen\") of Example42 Puppet Modules.\n\nMade by ALessandro Franceschi / Lab42\n\nOfficial site: http://www.example42.com\n\nOfficial git repository: http://github.com/example42/puppet-php\n\nReleased under the terms of Apache 2 License.\n\nThis module requires functions provided by the Example42 Puppi module (you need it even if you don't use and install Puppi)\n\nFor detailed info about the logic and usage patterns of Example42 modules check the DOCS directory on Example42 main modules set.\n\n## USAGE - Basic management\n\n* Install php with default settings\n\n        class { 'php': }\n\n* Install a specific version of php package\n\n        class { 'php':\n          version => '1.0.1',\n        }\n\n* Remove php package\n\n        class { 'php':\n          absent => true\n        }\n\n* Enable auditing without without making changes on existing php configuration files\n\n        class { 'php':\n          audit_only => true\n        }\n\n* Install php in an nginx environment\n\n        class { 'php':\n          service => 'nginx'\n        }\n\n## USAGE - Module installation\n\n* Install a new module\n\n        php::module { \"imagick\": }\n\n* Install a specific version of a module:\n\n        php::module { \"imagick\":\n          version => '1.0.1';\n        }\n\n* Remove php module\n\n        php::module { \"imagick\":\n            absent => true,\n        }\n\n* By default module package name is php-$title for RedHat and php5-$title . You can override this prefix.\n\n        php::module { \"apc\":\n          module_prefix => \"php-\"\n        }\n\n\n## USAGE - Pear Management\n\n* Install a pear package\n\n        php::pear::module { \"XML_Util\": }\n\n* Install a pear package from a remote repository\n\n        php::pear::module { 'PHPUnit':\n          repository  => 'pear.phpunit.de',\n          use_package => 'no',\n        }\n\n* Install a pear package will all dependencies (--alldeps)\n\n        php::pear::module { 'PHPUnit':\n          repository  => 'pear.phpunit.de',\n          alldeps => 'true',\n        }\n\n* Set a config option\n\n        php::pear::config { http_proxy: value => \"myproxy:8080\" }\n\n\n## USAGE - Pecl Management\n\n* Install a pecl package\n\n        php::pecl::module { \"XML_Util\": }\n\n* Install a pecl package from source specifying the preferred state (note that you must have the package 'make' installed on your system)\n\n        php::pecl::module { \"xhprof\":\n          use_package     => 'false',\n          preferred_state => 'beta',\n        }\n\n* Set a config option\n\n        php::pecl::config { http_proxy: value => \"myproxy:8080\" }\n\n\n## USAGE - Overrides and Customizations\n* Use custom sources for main config file.\n\n        class { 'php':\n          source => [ \"puppet:///modules/lab42/php/php.conf-${hostname}\" , \"puppet:///modules/lab42/php/php.conf\" ],\n        }\n\n* Manage php.ini files on Debian and Suse derivatives. Here the main config file path (managed with the source/template params) defaults to /etc/php5/apache2/php.ini. To manage other files, either set a different path in config_file or use the php::conf define.\n\n        class { 'php':\n          config_file => '/etc/php5/apache2/php.ini',      # Default value on Ubuntu/Suse\n          template    => 'example42/php/php.ini-apache2.erb',\n        }\n\n        php::conf { 'php.ini-cli':\n          path     => '/etc/php5/cli/php.ini',\n          template => 'example42/php/php.ini-cli.erb',\n        }\n\n* Use custom source directory for the whole configuration dir\n\n        class { 'php':\n          source_dir       => 'puppet:///modules/lab42/php/conf/',\n          source_dir_purge => false, # Set to true to purge any existing file not present in $source_dir\n        }\n\n* Use custom template for main config file. Note that template and source arguments are alternative.\n\n        class { 'php':\n          template => 'example42/php/php.conf.erb',\n        }\n\n* Automatically include a custom subclass\n\n        class { 'php':\n          my_class => 'php::example42',\n        }\n\n\n\n\n\n[![Build Status](https://travis-ci.org/example42/puppet-php.png?branch=master)](https://travis-ci.org/example42/puppet-php)\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/puppet-apache","private":false,"url":"https://github.com/UKHomeOffice/puppet-apache","license":{"key":"other","name":"Other","spdxId":null,"url":null,"featured":false},"readme":"# Puppet module: apache\n\nThis is a Puppet apache module from the second generation of Example42 Puppet Modules.\n\nMade by Alessandro Franceschi / Lab42\n\nOfficial site: http://www.example42.com\n\nOfficial git repository: http://github.com/example42/puppet-apache\n\nReleased under the terms of Apache 2 License.\n\nThis module requires functions provided by the Example42 Puppi module.\n\nFor detailed info about the logic and usage patterns of Example42 modules read README.usage on Example42 main modules set.\n\n## USAGE - Module specific usage\n\n* Install apache with a custom httpd.conf template and some virtual hosts\n\n         class { 'apache':\n           template => 'example42/apache/httpd.conf.erb',\n         }\n\n         apache::vhost { 'mysite':\n           docroot  => '/path/to/docroot',\n           template => 'example42/apache/vhost/mysite.com.erb',\n         }\n\n\n* Install mod ssl\n\n        include apache::ssl\n\n\n* Manage basic auth users (Here user joe is created with the $crypt_password on the defined htpasswd_file\n\n        apache::htpasswd { 'joe':\n          crypt_password => 'B5dPQYYjf.jjA',\n          htpasswd_file  => '/etc/httpd/users.passwd',\n        }\n\n\n* Manage custom configuration files (created in conf.d, source or content can be defined)\n\n        apache::dotconf { 'trac':\n          content => template(\"site/trac/apache.conf.erb\")\n        }\n\n\n* Add other listening ports (a relevant NameVirtualHost directive is automatically created)\n\n        apache::listen { '8080': }\n\n\n* Add other listening ports without creating a relevant NameVirtualHost directive\n\n        apache::listen { '8080':\n          $namevirtualhost = false,\n        }\n\n\n* Add an apache module and manage its configuraton\n\n        apache::module { 'proxy':\n          templatefile => 'site/apache/module/proxy.conf.erb',\n        }\n\n\n* Install mod passenger\n\n        include apache::passenger\n\n\n## USAGE - Basic management\n\n* Install apache with default settings\n\n        class { \"apache\": }\n\n* Disable apache service.\n\n        class { \"apache\":\n          disable => true\n        }\n\n* Disable apache service at boot time, but don't stop if is running.\n\n        class { \"apache\":\n          disableboot => true\n        }\n\n* Remove apache package\n\n        class { \"apache\":\n          absent => true\n        }\n\n* Enable auditing without making changes on existing apache configuration files\n\n        class { \"apache\":\n          audit_only => true\n        }\n\n* Install apache with a specific version\n\n        class { \"apache\":\n          version =>  '2.2.22'\n        }\n\n\n## USAGE - Default server management\n\n* Simple way to manage default apache configuration\n\n        apache::vhost { 'default':\n            docroot             => '/var/www/document_root',\n            server_name         => false,\n            priority            => '',\n            template            => 'apache/virtualhost/vhost.conf.erb',\n        }\n\n* Using a source file to create the vhost\n\n        apache::vhost { 'default':\n\t        source \t\t=> 'puppet:///files/web/default.conf'\n\t        template\t=> '',\n        }\n\n\n## USAGE - Overrides and Customizations\n\n* Use custom sources for main config file\n\n        class { \"apache\":\n          source => [ \"puppet:///modules/lab42/apache/apache.conf-${hostname}\" , \"puppet:///modules/lab42/apache/apache.conf\" ],\n        }\n\n\n* Use custom source directory for the whole configuration dir\n\n        class { \"apache\":\n          source_dir       => \"puppet:///modules/lab42/apache/conf/\",\n          source_dir_purge => false, # Set to true to purge any existing file not present in $source_dir\n        }\n\n* Use custom template for main config file \n\n        class { \"apache\":\n          template => \"example42/apache/apache.conf.erb\",      \n        }\n\n* Define custom options that can be used in a custom template without the\n  need to add parameters to the apache class\n\n        class { \"apache\":\n          template => \"example42/apache/apache.conf.erb\",    \n          options  => {\n            'LogLevel' => 'INFO',\n            'UsePAM'   => 'yes',\n          },\n        }\n\n* Automaticallly include a custom subclass\n\n        class { \"apache:\"\n          my_class => 'apache::example42',\n        }\n\n\n## USAGE - Example42 extensions management \n* Activate puppi (recommended, but disabled by default)\n  Note that this option requires the usage of Example42 puppi module\n\n        class { \"apache\": \n          puppi    => true,\n        }\n\n* Activate puppi and use a custom puppi_helper template (to be provided separately with\n  a puppi::helper define ) to customize the output of puppi commands \n\n        class { \"apache\":\n          puppi        => true,\n          puppi_helper => \"myhelper\", \n        }\n\n* Activate automatic monitoring (recommended, but disabled by default)\n  This option requires the usage of Example42 monitor and relevant monitor tools modules\n\n        class { \"apache\":\n          monitor      => true,\n          monitor_tool => [ \"nagios\" , \"monit\" , \"munin\" ],\n        }\n\n* Activate automatic firewalling \n  This option requires the usage of Example42 firewall and relevant firewall tools modules\n\n        class { \"apache\":       \n          firewall      => true,\n          firewall_tool => \"iptables\",\n          firewall_src  => \"10.42.0.0/24\",\n          firewall_dst  => \"$ipaddress_eth0\",\n        }\n\n\n[![Build Status](https://travis-ci.org/example42/puppet-apache.png?branch=master)](https://travis-ci.org/example42/puppet-apache)\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/puppet-common","private":false,"url":"https://github.com/UKHomeOffice/puppet-common","license":{"key":"apache-2.0","name":"Apache License 2.0","spdxId":"Apache-2.0","url":"https://api.github.com/licenses/apache-2.0","featured":true},"readme":"ext_stdlibs\n===========\n\nThis module contains \"extra\" resources useful for Puppet modules\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/puppet-ntp","private":false,"url":"https://github.com/UKHomeOffice/puppet-ntp","license":{"key":"apache-2.0","name":"Apache License 2.0","spdxId":"Apache-2.0","url":"https://api.github.com/licenses/apache-2.0","featured":true},"readme":"ntp\n===\n\nThis module installs and manages ntp.\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/puppet-postgresql","private":false,"url":"https://github.com/UKHomeOffice/puppet-postgresql","license":{"key":"other","name":"Other","spdxId":null,"url":null,"featured":false},"readme":"# Puppet module: postgresql\n\nThis is a Puppet module for postgresql based on the second generation layout (\"NextGen\") of Example42 Puppet Modules.\n\nMade by Alessandro Franceschi / Lab42\n\nOfficial site: http://www.example42.com\n\nOfficial git repository: http://github.com/example42/puppet-postgresql\n\nReleased under the terms of Apache 2 License.\n\nThis module requires functions provided by the Example42 Puppi module (you need it even if you don't use and install Puppi)\n\nFor detailed info about the logic and usage patterns of Example42 modules check the DOCS directory on Example42 main modules set.\n\n## USAGE - Basic management\n\n* Install postgresql with default settings\n\n        class { 'postgresql': }\n\n* Install a specific version of postgresql package\n\n        class { 'postgresql':\n          version => '1.0.1',\n        }\n\n* Disable postgresql service.\n\n        class { 'postgresql':\n          disable => true\n        }\n\n* Remove postgresql package\n\n        class { 'postgresql':\n          absent => true\n        }\n\n* Enable auditing without without making changes on existing postgresql configuration files\n\n        class { 'postgresql':\n          audit_only => true\n        }\n\n\n## USAGE - Overrides and Customizations\n* Use custom sources for main config file \n\n        class { 'postgresql':\n          source => [ \"puppet:///modules/lab42/postgresql/postgresql.conf-${hostname}\" , \"puppet:///modules/lab42/postgresql/postgresql.conf\" ], \n        }\n\n\n* Use custom source directory for the whole configuration dir\n\n        class { 'postgresql':\n          source_dir       => 'puppet:///modules/lab42/postgresql/conf/',\n          source_dir_purge => false, # Set to true to purge any existing file not present in $source_dir\n        }\n\n* Use custom template for main config file. Note that template and source arguments are alternative. \n\n        class { 'postgresql':\n          template => 'example42/postgresql/postgresql.conf.erb',\n        }\n\n* Automatically include a custom subclass\n\n        class { 'postgresql':\n          my_class => 'postgresql::example42',\n        }\n\n\n## USAGE - Example42 extensions management \n* Activate puppi (recommended, but disabled by default)\n\n        class { 'postgresql':\n          puppi    => true,\n        }\n\n* Activate puppi and use a custom puppi_helper template (to be provided separately with a puppi::helper define ) to customize the output of puppi commands \n\n        class { 'postgresql':\n          puppi        => true,\n          puppi_helper => 'myhelper', \n        }\n\n* Activate automatic monitoring (recommended, but disabled by default). This option requires the usage of Example42 monitor and relevant monitor tools modules\n\n        class { 'postgresql':\n          monitor      => true,\n          monitor_tool => [ 'nagios' , 'monit' , 'munin' ],\n        }\n\n* Activate automatic firewalling. This option requires the usage of Example42 firewall and relevant firewall tools modules\n\n        class { 'postgresql':       \n          firewall      => true,\n          firewall_tool => 'iptables',\n          firewall_src  => '10.42.0.0/24',\n          firewall_dst  => $ipaddress_eth0,\n        }\n\n\n[![Build Status](https://travis-ci.org/example42/puppet-postgresql.png?branch=master)](https://travis-ci.org/example42/puppet-postgresql)\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/puppet-puppet","private":false,"url":"https://github.com/UKHomeOffice/puppet-puppet","license":{"key":"other","name":"Other","spdxId":null,"url":null,"featured":false},"readme":"# Puppet module: puppet\n\nThis is a Puppet module for puppet based on the second generation layout (\"NextGen\") of Example42 Puppet Modules.\n\nMade by Alessandro Franceschi / Lab42\n\nOfficial site: http://www.example42.com\n\nOfficial git repository: http://github.com/example42/puppet-puppet\n\nReleased under the terms of Apache 2 License.\n\nThis module requires functions provided by the Example42 Puppi module (you need it even if you don't use and install Puppi)\n\nFor detailed info about the logic and usage patterns of Example42 modules check the DOCS directory on Example42 main modules set.\n\n## USAGE - Basic management\n\n* Install puppet with default settings\n\n        class { 'puppet': }\n\n* Install a specific version of puppet package\n\n        class { 'puppet':\n          version => '1.0.1',\n        }\n\n* Disable puppet service.\n\n        class { 'puppet':\n          disable => true\n        }\n\n* Remove puppet package\n\n        class { 'puppet':\n          absent => true\n        }\n\n* Enable auditing without without making changes on existing puppet configuration files\n\n        class { 'puppet':\n          audit_only => true\n        }\n\n\n## USAGE - Overrides and Customizations\n* Use custom sources for main config file (you have to explicitely disable the default template)\n\n        class { 'puppet':\n          source   => [ \"puppet:///modules/lab42/puppet/puppet.conf-${hostname}\" , \"puppet:///modules/lab42/puppet/puppet.conf\" ], \n          template => absent,\n        }\n\n\n* Use custom source directory for the whole configuration dir (you have to explicitely disable the default template) \n\n        class { 'puppet':\n          source_dir       => 'puppet:///modules/lab42/puppet/conf/',\n          source_dir_purge => false, # Set to true to purge any existing file not present in $source_dir\n          template         => absent,\n        }\n\n* Use custom template for main config file. Note that template and source arguments are alternative. \n\n        class { 'puppet':\n          template => 'example42/puppet/puppet.conf.erb',\n        }\n\n* Automatically include a custom subclass\n\n        class { 'puppet':\n          my_class => 'puppet::example42',\n        }\n\n\n## USAGE - Example42 extensions management \n* Activate puppi (recommended, but disabled by default)\n\n        class { 'puppet':\n          puppi    => true,\n        }\n\n* Activate puppi and use a custom puppi_helper template (to be provided separately with a puppi::helper define ) to customize the output of puppi commands \n\n        class { 'puppet':\n          puppi        => true,\n          puppi_helper => 'myhelper', \n        }\n\n* Activate automatic monitoring (recommended, but disabled by default). This option requires the usage of Example42 monitor and relevant monitor tools modules\n\n        class { 'puppet':\n          monitor      => true,\n          monitor_tool => [ 'nagios' , 'monit' , 'munin' ],\n        }\n\n* Activate automatic firewalling. This option requires the usage of Example42 firewall and relevant firewall tools modules\n\n        class { 'puppet':       \n          firewall      => true,\n          firewall_tool => 'iptables',\n          firewall_src  => '10.42.0.0/24',\n          firewall_dst  => $ipaddress_eth0,\n        }\n\n\n[![Build Status](https://travis-ci.org/example42/puppet-puppet.png?branch=master)](https://travis-ci.org/example42/puppet-puppet)\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/puppet-puppetdb","private":false,"url":"https://github.com/UKHomeOffice/puppet-puppetdb","license":{"key":"other","name":"Other","spdxId":null,"url":null,"featured":false},"readme":"# Puppet module: puppetdb\n\nThis is a Puppet module for puppetdb based on the second generation layout (\"NextGen\") of Example42 Puppet Modules.\n\nMade by Alessandro Franceschi / Lab42\n\nOfficial site: http://www.example42.com\n\nOfficial git repository: http://github.com/example42/puppet-puppetdb\n\nReleased under the terms of Apache 2 License.\n\nThis module requires functions provided by the Example42 Puppi module (you need it even if you don't use and install Puppi)\n\nFor detailed info about the logic and usage patterns of Example42 modules check the DOCS directory on Example42 main modules set.\n\n## USAGE - Module's specific parameters\n\n* Install PuppetDb with local postgresql backend (Note: default credentials with a random password are used)\n\n        class { 'puppetdb':\n          db_type => 'postgresql',\n        }\n\n* Install PuppetDb with postgresql backend and custom credentials\n\n        class { 'puppetdb':\n          db_type     => 'postgresql',\n          db_host     => 'data.example42.com',\n          db_port     => '12345',\n          db_name     => 'puppetdb',\n          db_user     => 'puppetdbuser',\n          db_password => 's0rt0fP4ssW0rd!',\n        }\n\n\n## USAGE - Basic management\n\n* Install puppetdb with default settings (hsqldb backend)\n\n        class { 'puppetdb': }\n\n* Install a specific version of puppetdb package\n\n        class { 'puppetdb':\n          version => '1.0.1',\n        }\n\n* Disable puppetdb service.\n\n        class { 'puppetdb':\n          disable => true\n        }\n\n* Remove puppetdb package\n\n        class { 'puppetdb':\n          absent => true\n        }\n\n* Enable auditing without without making changes on existing puppetdb configuration files\n\n        class { 'puppetdb':\n          audit_only => true\n        }\n\n\n## USAGE - Overrides and Customizations\n* Use custom sources for main config file \n\n        class { 'puppetdb':\n          source => [ \"puppet:///modules/lab42/puppetdb/puppetdb.conf-${hostname}\" , \"puppet:///modules/lab42/puppetdb/puppetdb.conf\" ], \n        }\n\n\n* Use custom source directory for the whole configuration dir\n\n        class { 'puppetdb':\n          source_dir       => 'puppet:///modules/lab42/puppetdb/conf/',\n          source_dir_purge => false, # Set to true to purge any existing file not present in $source_dir\n        }\n\n* Use custom template for main config file. Note that template and source arguments are alternative. \n\n        class { 'puppetdb':\n          template => 'example42/puppetdb/puppetdb.conf.erb',\n        }\n\n* Automatically include a custom subclass\n\n        class { 'puppetdb':\n          my_class => 'puppetdb::example42',\n        }\n\n\n## USAGE - Example42 extensions management \n* Activate puppi (recommended, but disabled by default)\n\n        class { 'puppetdb':\n          puppi    => true,\n        }\n\n* Activate puppi and use a custom puppi_helper template (to be provided separately with a puppi::helper define ) to customize the output of puppi commands \n\n        class { 'puppetdb':\n          puppi        => true,\n          puppi_helper => 'myhelper', \n        }\n\n* Activate automatic monitoring (recommended, but disabled by default). This option requires the usage of Example42 monitor and relevant monitor tools modules\n\n        class { 'puppetdb':\n          monitor      => true,\n          monitor_tool => [ 'nagios' , 'monit' , 'munin' ],\n        }\n\n* Activate automatic firewalling. This option requires the usage of Example42 firewall and relevant firewall tools modules\n\n        class { 'puppetdb':       \n          firewall      => true,\n          firewall_tool => 'iptables',\n          firewall_src  => '10.42.0.0/24',\n          firewall_dst  => $ipaddress_eth0,\n        }\n\n\n[![Build Status](https://travis-ci.org/example42/puppet-puppetdb.png?branch=master)](https://travis-ci.org/example42/puppet-puppetdb)\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/puppet-snmpd","private":false,"url":"https://github.com/UKHomeOffice/puppet-snmpd","license":null,"readme":"# Puppet module: snmpd\n\nThis is a Puppet module for snmpd.\nIt manages its installation, configuration and service.\n\n## USAGE - Basic management\n\n* Install snmpd with default settings (package installed, service started, default configuration files)\n\n        class { 'snmpd': }\n\n* Remove snmpd package and purge all the managed files\n\n        class { 'snmpd':\n          ensure => absent,\n        }\n\n* Install a specific version of snmpd package\n\n        class { 'snmpd':\n          version => '1.0.1',\n        }\n\n* Install the latest version of snmpd package\n\n        class { 'snmpd':\n          version => 'latest',\n        }\n\n* Enable snmpd service. This is default.\n\n        class { 'snmpd':\n          service_ensure => 'running',\n        }\n\n* Enable snmpd service at boot. This is default.\n\n        class { 'snmpd':\n          service_status => 'enabled',\n        }\n\n\n* Do not automatically restart services when configuration files change (Default: Class['snmpd::config']).\n\n        class { 'snmpd':\n          service_subscribe => false,\n        }\n\n* Enable auditing (on all the arguments)  without making changes on existing snmpd configuration *files*\n\n        class { 'snmpd':\n          audit => 'all',\n        }\n\n* Module dry-run: Do not make any change on *all* the resources provided by the module\n\n        class { 'snmpd':\n          noop => true,\n        }\n\n\n## USAGE - Overrides and Customizations\n## Some of these options have not been implemented\n* Use custom source for main configuration file \n\n        class { 'snmpd':\n          file_source => \"puppet:///modules/snmpd/snmpd.conf-${hostname}\" ,\n                         \n        }\n\n\n* Use custom source directory for the whole configuration dir.\n\n        class { 'snmpd':\n          dir_source  => 'puppet:///modules/snmpd/conf/',\n        }\n\n* Use custom source directory for the whole configuration dir purging all the local files that are not on the dir.\n  Note: This option can be used to be sure that the content of a directory is exactly the same you expect, but it is desctructive and may remove files.\n\n        class { 'snmpd':\n          dir_source => 'puppet:///modules/snmpd/conf/',\n          dir_purge  => true, # Default: false.\n        }\n\n* Use custom source directory for the whole configuration dir and define recursing policy.\n\n        class { 'snmpd':\n          dir_source    => 'puppet:///modules/snmpd/conf/',\n          dir_recursion => false, # Default: true.\n        }\n\n* Use custom template for main config file. Note that template and source arguments are alternative.\n\n        class { 'snmpd':\n          file_template => 'snmpd/snmpd.conf.erb',\n        }\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/puppet-yum","private":false,"url":"https://github.com/UKHomeOffice/puppet-yum","license":{"key":"other","name":"Other","spdxId":null,"url":null,"featured":false},"readme":"# Puppet module: yum\n\nThis is a Puppet module that manages Yum repositories for Centos RedHat and Scientific Linux\n\nMade by Alessandro Franceschi / Lab42\n\nInspired by the Yum Immerda module: https://git.puppet.immerda.ch\n\nOfficial site: http://www.example42.com\n\nOfficial git repository: http://github.com/example42/puppet-yum\n\nReleased under the terms of Apache 2 License.\n\nThis module requires functions provided by the Example42 Puppi module.\n\n## USAGE \n\n* Just leave the default options: Automatic detection of Operating System (RedHat, Centos, Scientific supported) Epel repo installation, keeping of local yum files, automatic updates disabled.\n\n        class { 'yum':\n        }\n\n* Enable automatic updates via cron (updatesd is supported only on 5)\n\n        class { 'yum':\n          update => 'cron',\n        }\n\n\n* Purge local /etc/yum.repos.d/ and enforce its contents only via a custom source\n\n        class { 'yum':\n          source_repo_dir => 'puppet:///modules/example42/yum/conf/',\n          clean_repos     => true,\n        }\n\n* Enable EPEL and PuppetLabs repos\n\n        class { 'yum':\n          extrarepo => [ 'epel' , 'puppetlabs' ],\n        }\n\n\n* Do not include any extra repo (By default EPEL is added)\n\n        class { 'yum':\n          extrarepo => '' ,\n        }\n\n* Automatically copy in /etc/pki/rpm-gpg  all the rpm-gpg keys known by the yum module (this was the \"old\" and intrusive behaviour, now each rpm-gpg key may be individually provided by the yum::manages_repos' gpgkey_source parameter)\n\n        class { 'yum':\n          install_all_keys => true ,\n        }\n\n* Include a selected extra repo\n\n        include yum::repo::puppetlabs\n\n\n## USAGE - Overrides and Customizations\n* Enable auditing without without making changes on existing yum configuration files\n\n        class { 'yum':\n          audit_only => true\n        }\n\n\n* Use custom sources for main config file\n\n        class { 'yum':\n          source => [ \"puppet:///modules/lab42/yum/yum.conf-${hostname}\" , \"puppet:///modules/lab42/yum/yum.conf\" ],\n        }\n\n\n* Use custom source directory for the whole configuration dir\n\n        class { 'yum':\n          source_dir       => 'puppet:///modules/lab42/yum/conf/',\n          source_dir_purge => false, # Set to true to purge any existing file not present in $source_dir\n        }\n\n* Use custom template for main config file. Note that template and source arguments are alternative.\n\n        class { 'yum':\n          template => 'example42/yum/yum.conf.erb',\n        }\n\n* Automatically include a custom subclass\n\n        class { 'yum':\n          my_class => 'yum::example42',\n        }\n\n\n## USAGE - Example42 extensions management\n* Activate puppi (recommended, but disabled by default)\n\n        class { 'yum':\n          puppi    => true,\n        }\n\n* Activate puppi and use a custom puppi_helper template (to be provided separately with a puppi::helper define ) to customize the output of puppi commands\n\n        class { 'yum':\n          puppi        => true,\n          puppi_helper => 'myhelper',\n        }\n\n\n## OPERATING SYSTEMS SUPPORT\n\nREDHAT 6 - Full\n\nREDHAT 5 - Full\n\nREDHAT 4 - Partial\n\nCENTOS 6 - Full\n\nCENTOS 5 - Full\n\nCENTOS 4 - Partial\n\nSCIENTIFIC 6 - Full\n\nSCIENTIFIC 5 - Full\n\nAMAZON LINUX 3 (Sigh) - Partial\n\n[![Build Status](https://travis-ci.org/example42/puppet-yum.png?branch=master)](https://travis-ci.org/example42/puppet-yum)\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/puppet-ipa","private":false,"url":"https://github.com/UKHomeOffice/puppet-ipa","license":null,"readme":"# IPA Puppet module\n[![Build Status](https://travis-ci.org/huit/puppet-ipa.png?branch=master)](https://travis-ci.org/huit/puppet-ipa)\n\n## Overview\n\nPuppet module that can manage an IPA master, replicas and clients.\n\nhuit/puppet-ipa aims at the management and configuration of a complete IPA environment under Puppet control.\n\nTo start, an IPA master will be required as the beginning of the LDAP/Kerberos environment. IPA replicas can\nthen be added for additional resiliancy.\n\nThe IPA primary master server will take a minimum of two Puppet runs to fully configure. This is because the ipa_adminhomedir,\nipa_adminuidnumber and ipa_replicascheme facts are not available until the IPA primary master is installed and operational.\nThese facts are necessary to automatically configure clients and replicas.\n\nIPA replica servers will be automatically configured with a replication agreement on the IPA primary master server.\n\nAll Puppet nodes added as clients will automatically be added to the IPA domain through exported resources.\n\nMultiple IPA domains are supported.\n\nA cleanup parameter has been included to remove the IPA server or client packages from nodes.\n\n## Dependencies\n\nThe ability to use [Exported resources](http://docs.puppetlabs.com/guides/exported_resources.html) and \n[Stored Configuration](http://projects.puppetlabs.com/projects/1/wiki/Using_Stored_Configuration) enabled on the Puppet master.\n\n[puppetlabs/puppetlabs-firewall](https://forge.puppetlabs.com/puppetlabs/firewall) module.\n\n[puppetlabs/stdlib](https://forge.puppetlabs.com/puppetlabs/stdlib) module.\n\n## Usage\n\nAvailable parameters.\n\n####`master`\n\nConfigures a server to be an IPA master LDAP/Kerberos node.\n\nDefaults to 'false'.\n\n####`replica`\n\nConfigures a server to be an IPA replica LDAP/Kerberos node.\n\nDefaults to 'false'.\n\n####`client`\n\nConfigures a server to be an IPA client.\n\nDefaults to 'false'.\n\n####`cleanup`\n\nRemoves IPA specific packages.\n\nDefaults to 'false'.\n\n####`domain`\n\nDefines the LDAP domain.\n\nDefaults to 'undef'.\n\n####`realm`\n\nDefines the Kerberos realm.\n\nDefaults to 'undef'.\n\n####`adminpw`\n\nDefines the IPA administrative user password.\n\nDefaults to 'undef'.\n\n####`dspw`\n\nDefines the IPA directory services password.\n\nDefaults to 'undef'.\n\n####`otp`\n\nDefines an IPA client one-time-password.\n\nDefaults to 'undef'.\n\n####`dns`\n\nControls the option to configure a DNS zone with the IPA master setup.\n\nDefaults to 'false'.\n\n####`fixedprimary`\n\nConfigure sssd to use a fixed server as the primary IPA server.\n\nDefaults to 'false'.\n\n####`forwarders`\n\nDefines an array of DNS forwarders to use when DNS is setup. An empty list will use the Root Nameservers.\n\nDefaults to '[]'.\n\n####`extca`\n\nControls the option to configure an external CA.\n\nDefaults to 'false'\n\n####`extcertpath`\n\nDefines a file path to the external certificate file. Somewhere under /root is recommended.\n\nDefaults to 'undef'\n\n####`extcert`\n\nThe X.509 certificate in base64 encoded format.\n\nDefaults to 'undef'\n\n####`extcapath`\n\nDefines a file path to the external CA certificate file. Somewhere under /root is recommended.\n\nDefaults ro 'undef'\n\n####`extcacert`\n\nThe X.509 CA certificate in base64 encoded format.\n\nDefaults to 'undef'\n\n####`dirsrv_pkcs12`\n\nPKCS#12 file containing the Directory Server SSL Certificate, also corresponds to the Puppet fileserver path under fileserverconfig for $confdir/files/ipa\n\nDefaults to 'undef'\n\n####`http_pkcs12`\n\nThe PKCS#12 file containing the Apache Server SSL Certificate, also corresponds to the Puppet fileserver path under fileserverconfig for $confdir/files/ipa\n\nDefaults to 'undef'\n\n####`dirsrv_pin`\n\nThe password of the Directory Server PKCS#12 file.\n\nDefaults to 'undef'\n\n####`http_pin`\n\nThe password of the Apache Server PKCS#12 file.\n\nDefaults to 'undef'\n\n####`subject`\n\nThe certificate subject base.\n\nDefaults to 'undef'\n\n####`selfsign`\n\nConfigure a self-signed CA instance for issuing server certificates instead of using dogtag for certificates.\n\nDefaults to 'false'\n\n####`loadbalance`\n\nControls the option to include any additional hostnames to be used in a load balanced IPA client configuration.\n\nDefaults to 'false'.\n\n####`ipaservers`\n\nDefines an array of additional hostnames to be used in a load balanced IPA client configuration.\n\nDefaults to '[]'\n\n####`mkhomedir`\n\nControls the option to create user home directories on first login.\n\nDefaults to 'false'.\n\n####`ntp`\n\nControls the option to configure NTP on a client.\n\nDefaults to 'false'.\n\n####`kstart`\n\nControls the installation of kstart.\n\nDefaults to 'true'.\n\n####`desc`\n\nControls the description entry of an IPA client.\n\nDefaults to ''.\n\n####`locality`\n\nControls the locality entry of an IPA client.\n\nDefaults to ''.\n\n####`location`\n\nControls the location entry of an IPA client.\n\nDefaults to ''.\n\n####`sssdtools`\n\nControls the installation of the SSSD tools package.\n\nDefaults to 'true'.\n\n####`sssdtoolspkg`\n\nSSSD tools package name.\n\nDefaults to 'sssd-tools'\n\n####`sssd`\n\nControls the option to start the SSSD service if its not defined elsewhere. Note: Set to false if the SSSD service is defined in your site specific modules.\n\nDefaults to 'true'.\n\n####`sudo`\n\nControls the option to configure sudo in LDAP.\n\nDefaults to 'false'.\n\n####`sudopw`\n\nDefines the sudo user bind password.\n\nDefaults to 'undef'.\n\n####`debiansudopkg`\n\nControls the installation of the Debian sudo-ldap package.\n\nDefaults to 'true'.\n\n####`automount`\n\nControls the option to configure automounter maps in LDAP.\n\nDefaults to 'false'.\n\n####`autofs`\n\nControls the option to start the autofs service and install the autofs package.\n\nDefaults to 'false'.\n\n####`svrpkg`\n\nIPA server package name.\n\nDefaults to 'ipa-server'.\n\n####`clntpkg`\n\nIPA client package name.\n\nDefaults to 'ipa-client'.\n\n####`ldaputils`\n\nControls the instalation of the LDAP utilities package.\n\nDefaults to 'true'.\n\n####`ldaputilspkg`\n\nLDAP utilities package name.\n\nDefaults to 'openldap-clients'.\n\n## Usage examples\n\nHere are a few simple usage examples. If you don't want to put your passwords in the clear, then use hiera/gpg.\n\nIPA master:\n\n```puppet\n    node 'ipamaster.domain.name' {\n      class { 'ipa':\n        master  => true, # Only one master per Puppet master\n        domain  => 'domain.name',\n        realm   => 'DOMAIN.NAME',\n        adminpw => 'somepasswd', # Cleartext example\n        dspw    => hiera('some_passwd') # Using hiera\n      }\n    }\n```\n\nIPA replica:\n\n```puppet\n    node 'ipareplica1.domain.name' {\n      class { 'ipa':\n        replica => true, # Multiple replicas can be setup.\n        domain  => 'domain.name',\n        realm   => 'DOMAIN.NAME',\n        adminpw => 'somepasswd',\n        dspw    => 'somepasswd',\n        otp     => 'onetimepasswd'\n      }\n    }\n```\n\nAnother IPA replica:\n\n```puppet\n    node 'ipareplica2.domain.name' {\n      class { 'ipa':\n        replica => true,\n        domain  => 'domain.name',\n        realm   => 'DOMAIN.NAME',\n        adminpw => hiera('some_passwd'),\n        dspw    => hiera('some_passwd'), \n        otp     => hiera('one_time_passwd')\n      }\n    }\n```\n\nIPA client:\n\n```puppet\n    node 'ipaclient.domain.name' {\n      class { 'ipa':\n        client      => true,\n        domain      => 'domain.name',\n        realm       => 'DOMAIN.NAME',\n        loadbalance => true,\n        ipaservers  => ['ipaloadbalanceddnsname.domain.name','ipamaster.domain.name','ipareplica1.domain.name','ipareplica2.domain.name'],\n        desc        => 'This is an IPA client', # This string will show up the the description attribute of the computer account.\n        otp         => hiera('one_time_passwd')\n      }\n    }\n```\n\nCleanup parameter:\n\n```puppet\n    node 'ipawhatever.domain.name' {\n      class { 'ipa':\n        cleanup => true # Removes IPA completely. Mutually exclusive from master, replica and client parameters.\n      }\n    }\n```\n\n## Limitations\n\nIPA master and replicas require a RedHat family OS.\n\nClient configuration does not work with Ubuntu 8.04 and Ubuntu 10.04\n\n## License\n\n    huit/puppet-ipa - Puppet module that can manage an IPA master, replicas and clients.\n\n    Copyright (C) 2013 Harvard University Information Technology\n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation, either version 3 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\n## Support\n\nPlease report issues [here](https://github.com/huit/puppet-ipa/issues).\n\nFor more information see [https://github.com/huit/puppet-ipa.git](https://github.com/huit/puppet-ipa.git)\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/puppet-resolver","private":false,"url":"https://github.com/UKHomeOffice/puppet-resolver","license":{"key":"other","name":"Other","spdxId":null,"url":null,"featured":false},"readme":"# Puppet module: resolver\n\nThis is a Puppet module for resolver based on the second generation layout (\"NextGen\") of Example42 Puppet Modules.\n\nMade by Alessandro Franceschi / Lab42\n\nOfficial site: http://www.example42.com\n\nOfficial git repository: http://github.com/example42/puppet-resolver\n\nReleased under the terms of Apache 2 License.\n\nThis module requires functions provided by the Example42 Puppi module (you need it even if you don't use and install Puppi)\n\nFor detailed info about the logic and usage patterns of Example42 modules check the DOCS directory on Example42 main modules set.\n\n## USAGE - Basic management\n\n* Configure /etc/resolv.conf with custom dns servers and search paths\n\n        class { 'resolver': \n          dns_servers => [ '8.8.8.8' , '8.8.4.4' ],\n          search      => [ 'example42.com' , 'example42.lan' ],\n        }\n\n* Configure /etc/resolv.conf with specific dns server and custom options (provide them as an hash)\n\n        class { 'resolver':\n          dns_servers => [ '8.8.8.8' , '8.8.4.4' ],\n          search      => [ 'example42.com' , 'example42.lan' ],\n          options     => {\n            'rotate'  => '',\n            'timeout' => '2',\n          },\n        }\n\n* Enable auditing without without making changes on existing resolver configuration files\n\n        class { 'resolver':\n          audit_only => true\n        }\n\n\n## USAGE - Overrides and Customizations\n* Use static custom sources to populate resolv.conf\n\n        class { 'resolver':\n          source => [ \"puppet:///modules/lab42/resolver/resolv.conf-${hostname}\" , \"puppet:///modules/lab42/resolver/resolv.conf\" ], \n        }\n\n\n* Use custom template for main config file. Note that template and source arguments are alternative. \n\n        class { 'resolver':\n          template => 'example42/resolver/resolver.conf.erb',\n        }\n\n* Automatically include a custom subclass\n\n        class { 'resolver':\n          my_class => 'resolver::example42',\n        }\n\n\n## USAGE - Example42 extensions management \n* Activate puppi (recommended, but disabled by default)\n\n        class { 'resolver':\n          dns_servers => '8.8.8.8',\n          puppi       => true,\n        }\n\n* Activate puppi and use a custom puppi_helper template (to be provided separately with a puppi::helper define ) to customize the output of puppi commands \n\n        class { 'resolver':\n          dns_servers  => '8.8.8.8',\n          puppi        => true,\n          puppi_helper => 'myhelper', \n        }\n\n* Activate automatic monitoring (recommended, but disabled by default). This option requires the usage of Example42 monitor and relevant monitor tools modules\n\n        class { 'resolver':\n          dns_servers  => [ '8.8.8.8' , '8.8.4.4' ],\n          monitor      => true,\n          monitor_tool => [ 'nagios' , 'puppi' ],\n        }\n\n* Activate automatic firewalling. This option requires the usage of Example42 firewall and relevant firewall tools modules. Note that firewall rules are automatically applied outbound for port udp/53 to the specified dns_servers.\n\n        class { 'resolver':     \n          dns_servers   => [ '8.8.8.8' , '8.8.4.4' ],\n          firewall      => true,\n          firewall_tool => 'iptables',\n        }\n\n\n[![Build Status](https://travis-ci.org/example42/puppet-resolver.png?branch=master)](https://travis-ci.org/example42/puppet-resolver)\n>>>>>>> 83dd1f430703b4399372b38a36e521226a4d764b\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/vcloud-core","private":false,"url":"https://github.com/UKHomeOffice/vcloud-core","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# vCloud Core\n\nvCloud Core is a gem that supports automatated provisioning of VMWare vCloud Director. It uses Fog under the hood. Primarily developed to support [vCloud Walker](https://github.com/gds-operations/vcloud-walker) and [vCloud Tools](https://github.com/gds-operations/vcloud-tools).\n\nvCloud Core includes vCloud Query and a command-line wrapper for vCloud Query.\n\n## Installation\n\nAdd this line to your application's Gemfile:\n\n    gem 'vcloud-core'\n\nAnd then execute:\n\n    $ bundle\n\nOr install it yourself as:\n\n    $ gem install vcloud-core\n\n## Credentials\n\nPlease see the [vcloud-tools usage documentation](http://gds-operations.github.io/vcloud-tools/usage/).\n\n## vCloud Query\n\n### Get results from the vCloud Query API\n\nvCloud Query is a light wrapper around the vCloud Query API.\n\nAny, or all, records of a particular 'type' can be returned. These types map to \nentities in the vCloud system itself, eg: 'vm', 'vApp', 'orgVdc', 'edgeGateway'.\n\nFilters can be applied, using a simple query syntax. See below for basic usage and\nexamples.\n\nRun with no arguments, it outputs a list of potential entity types to query, along\nwith the potential record types to display (default 'records')\n\n#### Usage:\n\n    vcloud-query [options] [queriable type]\n\n    where [queriable type] maps to a vcloud entity type, eg: vApp, vm, orgVdc\n\n#### Examples:\n\nNB: examples assume FOG_CREDENTIAL or FOG_VCLOUD_TOKEN has been set accordingly.\n\n    # Get a list of vApps, in YAML\n    vcloud-query -o yaml vApp\n\n    # Get general usage info\n    vcloud-query --help\n\n    # Get a list of all queriable entity types\n    vcloud-query\n\n    # Get all VMs with VMware Tools less than 9282, that are not a vApp Template:\n    vcloud-query --filter 'vmToolsVersion=lt=9282;isVAppTemplate==false' vm\n\n#### Supports:\n\n* Returning a list of queriable types (eg vm, vApp, edgeGateway) from the API\n* Displaying all vCloud entities of a given type\n* Filtering the results of the query based on common parameters such as:\n  * entity name\n  * metadata values\n  * key entity parameters\n* Limiting the output to certain fields (eg: name, vmToolsVersion)\n* Returning results in TSV, CSV, and YAML\n\n#### Query Syntax:\n\nSummary of filter query syntax:\n\n    attribute==value                      # == to check equality\n    attribute!=value                      # != to check inequality\n    attribute=lt=value                    # =lt= less than (=le= for <=)\n    attribute=gt=value                    # =gt= greater than (=ge= for >=)\n    attribute==value;attribute2==value2   # ; == AND\n    attribute==value,attribute2==value2   # , == OR\n\nParentheses can be used to group sub-queries.\n\n**Do not use spaces in the query**\n\nEntity metadata queries have their own subsyntax incorporating the value types:\n\n    metadata:key1==STRING:value1\n    metadata:key1=le=NUMBER:15\n    metadata:key1=gt=DATETIME:2012-06-18T12:00:00-05:00\n\nSee http://pubs.vmware.com/vcd-51/topic/com.vmware.vcloud.api.doc_51/GUID-4FD71B6D-6797-4B8E-B9F0-618F4ACBEFAC.html for details.\n\n## The vCloud API\n\nvCloud Tools currently use version 5.1 of the [vCloud API](http://pubs.vmware.com/vcd-51/index.jsp?topic=%2Fcom.vmware.vcloud.api.doc_51%2FGUID-F4BF9D5D-EF66-4D36-A6EB-2086703F6E37.html). Version 5.5 may work but is not currently supported. You should be able to access the 5.1 API in a 5.5 environment, and this *is* currently supported.\n\nThe default version is defined in [Fog](https://github.com/fog/fog/blob/244a049918604eadbcebd3a8eaaf433424fe4617/lib/fog/vcloud_director/compute.rb#L32).\n\nIf you want to be sure you are pinning to 5.1, or use 5.5, you can set the API version to use in your fog file, e.g.\n\n`vcloud_director_api_version: 5.1`\n\n## Working with Independent Disks\n\nvCloud Core now supports the management of Independent Disks -- block devices\nstored and managed separately from the VMs they are attached to. We have\nnoticed that this bring some limitations/caveats into play that API users\nshould be aware of:\n\n* It is not possible to move the VM from one Storage Profile to another with\n  Vm#update_storage_profile if an Independent Disk is attached. This appears to\n  be a limitation in vCloud Director itself. To work around this, detach the\n  disks before updating, and reattach afterwards.\n\n* It is not possible to add additional *local* disks via Vm#add_extra_disks\n  when Independent Disks are attached to a VM. This appears to be a limitation with\n  Fog, as the vCD UI permits it. See https://github.com/fog/fog/issues/3179\n  for progress on this issue.\n\n* Extreme care should be taken when detaching Independent Disks from a VM, as\n  vCloud Director will detach them without warning from running VMs, and hence\n  with no notification to the running OS. It is recommended to simply use them for\n  persistence across VM delete/recreate operations.\n\n## Debugging\n\n`export EXCON_DEBUG=true` - this will print out the API requests and responses.\n\n`export DEBUG=true` - this will show you the stack trace when there is an exception instead of just the message.\n\n## Testing\n\nRun the default suite of tests (e.g. lint, unit, features):\n\n    bundle exec rake\n\nRun the integration tests (slower and requires a real environment):\n\n    bundle exec rake integration\n\nYou need access to a suitable vCloud Director organization to run the\nintegration tests. See the [integration tests README](/spec/integration/README.md) for\nfurther details.\n\n## Contributing\n\n1. Fork it\n2. Create your feature branch (`git checkout -b my-new-feature`)\n3. Commit your changes (`git commit -am 'Add some feature'`)\n4. Push to the branch (`git push origin my-new-feature`)\n5. Create new Pull Request\n","travis":false,"contributing":"# Contributing to vCloud Core\n\nWe really welcome contributions.\n\n## Issues list\n\nIssues we know about are [listed here](https://github.com/gds-operations/vcloud-core/issues). We have a [`newcomer-friendly label`](https://github.com/gds-operations/vcloud-core/labels/newcomer-friendly) for issues that we feel would be a good place to start, because they do not touch a lot of other vCloud Tools code and do not require an environment to work on. This label is just a suggestion.\n\n## A quick guide on how to contribute\n\n1. Clone the repo:\n\n        git clone git@github.com:gds-operations/vcloud-core.git\n\n2. Run `bundle` to get the required dependecies\n\n3. Run the tests. Pull requests that add features must include unit tests,\n   so it is good to ensure you've got them passing to begin with.\n\n        bundle exec rake\n\n   If you have access to a live environment for testing, it would be great\n   if you could run the integration tests too - for more details on the\n   set-up for that, please see the [integration tests README]\n   (https://github.com/gds-operations/vcloud-core/blob/master/spec/integration/README.md)\n\n4. Add your functionality or bug fix and a test for your change. Only refactoring and\n   documentation changes do not require tests. If the functionality is at all complicated\n   then it is likely that more than one test will be required. If you would like help\n   with writing tests please do ask us.\n\n5. Make sure all the tests pass, including the integration tests if possible.\n\n6. Update the [CHANGELOG](https://github.com/gds-operations/vcloud-core/blob/master/CHANGELOG.md)\n   with a short description of what the change is. This may be a feature, a bugfix, or an\n   API change. If your change is documenation or refactoring, you do not need to add a line\n   to the CHANGELOG.\n\n7. Fork the repo, push to your fork, and submit a pull request.\n\n## How soon will we respond?\n\nWe will comment on your pull request within two working days. However, we might not be able to review it immediately.\n\nWe may come back to you with comments and suggestions, and if we would like you to make changes, we will close the pull request as well as adding details of the changes we'd like you to make.\n\nIf you feel your pull request has been outstanding too long, please feel free to bump it by making a comment on it.\n\n## Guidelines for making a pull request\n\n    The key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\", \"SHALL NOT\", \"SHOULD\",\n    \"SHOULD NOT\", \"RECOMMENDED\",  \"MAY\", and \"OPTIONAL\" in this document are to be\n    interpreted as described in RFC 2119.\n\n## In order for a pull request to be accepted, it MUST\n\n- Include at least one test (unless it is documentation or refactoring). If you have any questions about how to write tests, please ask us, we will be happy to help\n- Follow our [Git style guide](https://github.com/alphagov/styleguides/blob/master/git.md)\n- Include a clear summary in the pull request comments as to what the change is and why\n  you are making it\n- Be readable - we might ask you to change unclear variable names or obscure syntactic sugar\n- Have [good commit messages](http://robots.thoughtbot.com/5-useful-tips-for-a-better-commit-message)\n  that explain the change being made in that commit. Don't be afraid to write a lot in the\n  detail.\n\n## In order for a pull request to be accepted, it SHOULD\n\n- Include a line in the CHANGELOG unless it is a refactoring or documentation change\n- If it is code, follow our [Ruby style guide](https://github.com/alphagov/styleguides/blob/master/ruby.md)\n- If it is documentation, follow the [GDS content style guide](https://www.gov.uk/design-principles/style-guide/style-points)\n","masterBranchProtection":false},{"name":"UKHomeOffice/puppet-runstatus","private":false,"url":"https://github.com/UKHomeOffice/puppet-runstatus","license":{"key":"other","name":"Other","spdxId":null,"url":null,"featured":false},"readme":"# Puppet::Runstatus\n\nTODO: Write a gem description\n\n## Installation\n\nAdd this line to your application's Gemfile:\n\n```ruby\ngem 'puppet-runstatus'\n```\n\nAnd then execute:\n\n    $ bundle\n\nOr install it yourself as:\n\n    $ gem install puppet-runstatus\n\n## Usage\n\nTODO: Write usage instructions here\n\n## Contributing\n\n1. Fork it ( https://github.com/[my-github-username]/puppet-runstatus/fork )\n2. Create your feature branch (`git checkout -b my-new-feature`)\n3. Commit your changes (`git commit -am 'Add some feature'`)\n4. Push to the branch (`git push origin my-new-feature`)\n5. Create a new Pull Request\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/adegnanCfTest-","private":false,"url":"https://github.com/UKHomeOffice/adegnanCfTest-","license":null,"readme":"# adegnanCfTest-\nCloud Foundry Testing\n\n## Getting started \n\nAssuming you've already received the email with your credentials in it, you'll want to install the cloudfoundry-cli package; This can be found here https://github.com/cloudfoundry/cli, there are pre-compiled binaries if you scroll down slightly.  Following that, as suggested, login and change your password using the following two commands:-\n\n- cf login\n- cf passwd\n\n## starting an app\n\n- will fill this out later\n\n## Notes on Crippledness\n\nI don't have permission to do the following commands\n- cf create-service-broker -  This, I believe, is how we add more services, We'd need this if we want to actually give people the ability to make their own services\n\n\n## Questions\n\nCF is a PaaS system; it is unclear that we'd get any access to the infrastructure beyond what the APIs give us access to.  \n\n### Security\n\nWe need to know whether our infrastructure is using shared resources and how this affects our security.  Follow up questions may be needed depending on these answers.\n\n- What platform is CF running on?  \n- Is the CF software shared between clients?\n- Are the physical nodes shared?\n- Are the underlying virtual machines shared?\n- Is the compute platform shared?\n- Are any of the storage platforms shared?\n- Are any network components shared?\n- Where is our entry point to said network?\n- Do we have any kind of separation on the network layer?\n- Where do our external SSL connections terminate?\n- Are there any shared resources beyond this point?\n\nWe need to ask any questions about the underlying platform.  This is probably something VMware related and thus it could be useful to ask the similar questions we'd ask regarding the IaaS platform provided by skyscape:\n\n- What are you running on the underlying platform\n- Is there a dedicated security team working on the platform?\n- What hardware is the platform running on.  Switches, routers, servers, etc?\n- How is the underlying platform components patched?\n- How and what is monitored on the platform?\n\nWe need to ask any CF specific questions, particularly on how this pertains to any shared resources which have been disclosed above.\n\n- What's the process on packaging and patch CF itself?\n- How are processed isolated?  Is it possible to isolate at VM level?  CGroup?  User?\n- How does CF persist data?\n- How are process created, destroyed, etc?\n- How are the router end points protected?  How is the router itself protected?\n- Does NATS communication have any encryption?  Does it need it.\n- Are services bound over SSL or isolated someway?\n- Is the blobstore locked down?\n- Lucid is out of support in April; What's happening here?\n- Are we using the recommended VLAN setup from CF docs?  Unsure how this protects from internal shared-server threats?  \n- If VMs themselves are VLANd, are they shared?  If so, what exactly stops an app from snooping the network?\n- How is the BOSH firewall manifest setup?\n- How to connections between host and containers work? Documentation is vague.  http://docs.cloudfoundry.org/concepts/security.html\n- What kind of SSL is used by BOSH, UAA and the router connections?\n- Is BOSH data encrypted?  CF doesn't do this by default.\n- Who has BOSH access?\n- How does the Cloud Controller lock down access?\n- What stops me from attempting to escaping my container when using a ruby command line app?  \n- Is the jumpbox secure?\n- Are VLANS configured as stated.  Does this drill down to container level?  How are these distrubuted, so only nodes needing access to the VLAN get access, or do all nodes get access to all VLANs?\n- What's stopping promiscious interfaces?\n- Application and Datastores connections are over SSL?\n\n\n### Scalability\n\nIt's important to know how CF is scaled in general and in this specific install. http://docs.cloudfoundry.org/concepts/high-availability.html\n\n- How many AZs are there and in how many datacentres?\n- What will our quotas be?\n- We actually going to get org, space, roles and permission control?\n- How exactly are the service-brokers setup?  Do they support HA?  How do we do this?\n\n\n### Features\n\nWe need to have an outline on what the platform offers and where the manual tasks lie.  Specifically I want to figure out which tasks will require us to log a ticket and wait.\n\n- Docs suggests that you have to terminate SSL outwith the platform.  Is this still the case?  If so, how do we setup our own SSLs?\n- How does it handle new versions of an app deploy.  Does it achieve zero-downtime?\n- How do we manage performance?  Does it have a profiler?  \n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/puppet-os-hardening","private":false,"url":"https://github.com/UKHomeOffice/puppet-os-hardening","license":null,"readme":"# os_hardening (Puppet module)\n\n## Description\n\nThis module provides secure configuration of your base OS with hardening.\n\n## Requirements\n\n* Puppet\n\n## Parameters\n\n* `system_environment = default`\n  define the context in which the system runs. Some options don't work for `docker`/`lxc`\n* `desktop_enabled = false`\n  true if this is a desktop system, ie Xorg, KDE/GNOME/Unity/etc\n* `enable_ipv4_forwarding   = false`\n  true if this system requires packet forwarding in IPv4 (eg Router), false otherwise\n* `enable_ipv6_forwarding   = false`\n  true if this system requires packet forwarding in IPv6 (eg Router), false otherwise\n* `enable_ipv6 = false`\n* `arp_restricted = true`\n  true if you want the behavior of announcing and replying to ARP to be restricted, false otherwise\n* `extra_user_paths = []`\n  add additional paths to the user's `PATH` variable (default is empty).\n* `umask = \"027\"`\n* `password_max_age = 60`\n  maximum password age\n* `password_min_age = 7`\n  minimum password age (before allowing any other password change)\n* `auth_retries = 5`\n  the maximum number of authentication attempts, before the account is locked for some time\n* `auth_lockout_time = 600`\n  time in seconds that needs to pass, if the account was locked due to too many failed authentication attempts\n* `login_timeout = 60`\n  authentication timeout in seconds, so login will exit if this time passes\n* `allow_login_without_home = false`\n  true if to allow users without home to login\n* `passwdqc_enabled = true`\n  true if you want to use strong password checking in PAM using passwdqc\n* `passwdqc_options = \"min=disabled,disabled,16,12,8\"`\n  set to any option line (as a string) that you want to pass to passwdqc\n* `allow_change_user = false`\n  if a user may use `su` to change his login\n* `enable_module_loading = true`\n  true if you want to allowed to change kernel modules once the system is running (eg `modprobe`, `rmmod`)\n* `load_modules = []`\n  load this modules via initramfs if enable_module_loading is false\n* `enable_sysrq = false`\n* `enable_core_dump = false`\n* `cpu_vendor = 'intel'`\n  only required if `enable_module_loading = false`: set the CPU vendor for modules to load\n* `root_ttys = [\"console\",\"tty1\",\"tty2\",\"tty3\",\"tty4\",\"tty5\",\"tty6\"]`\n  registered TTYs for root\n* `whitelist = []`\n  all files which should keep their SUID/SGID bits if set (will be combined with pre-defined whiteliste of files)\n* `blacklist = []`\n  all files which should have their SUID/SGID bits removed if set (will be combined with pre-defined blacklist of files)\n* `remove_from_unknown = false`\n  `true` if you want to remove SUID/SGID bits from any file, that is not explicitly configured in a `blacklist`. This will make every Chef run search through the mounted filesystems looking for SUID/SGID bits that are not configured in the default and user blacklist. If it finds an SUID/SGID bit, it will be removed, unless this file is in your `whitelist`.\n* `dry_run_on_unknown = false`\n  like `remove_from_unknown` above, only that SUID/SGID bits aren't removed. It will still search the filesystems to look for SUID/SGID bits but it will only print them in your log. This option is only ever recommended, when you first configure `remove_from_unkown` for SUID/SGID bits, so that you can see the files that are being changed and make adjustments to your `whitelist` and `blacklist`.\n\n## Usage\n\nAfter adding this module, you can use the class:\n\n    class { 'os_hardening': }\n\n## Contributors + Kudos\n\n* Dominik Richter [arlimus](https://github.com/arlimus)\n* Edmund Haselwanter [ehaselwanter](https://github.com/ehaselwanter)\n* Christoph Hartmann [chris-rock](https://github.com/chris-rock)\n* Artem Sidorenko [artem-sidorenko](https://github.com/artem-sidorenko)\n* Patrick Meier [atomic111](https://github.com/atomic111)\n* Kurt Huwig [kurthuwig](https://github.com/kurthuwig)\n* Daniel Dreier [danieldreier](https://github.com/danieldreier)\n* Matthew Haughton [3flex](https://github.com/3flex)\n* Reik Keutterling [spielkind](https://github.com/spielkind)\n* Tristan Helmich [fadenb](https://github.com/fadenb)\n\nFor the original port of `chef-os-hardening` to puppet:\n\n* Artem Sidorenko [artem-sidorenko](https://github.com/artem-sidorenko)\n* Frank Kloeker [eumel8](https://github.com/eumel8)\n\nThank you all!!\n\n## License and Author\n\n* Author:: Dominik Richter <dominik.richter@gmail.com>\n* Author:: Deutsche Telekom AG\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/govuk-template-compiler","private":false,"url":"https://github.com/UKHomeOffice/govuk-template-compiler","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# hmpo-govuk-template\n\nCompiles govuk mustache template into a more usable format and provide middleware for use in apps.\n\nExisting [govuk mustache template](https://www.npmjs.com/package/govuk_template_mustache) has simple mustache placeholders for content sections, which necessitates a two step compile process where sections are compiled individually and then again into the parent template.\n\nCompiling the template to replace these placeholders with variables allows for templates to implement the govuk template as a parent partial.\n\n## Example\n\n```\n{{< govuk-template}}\n\n    {{$main}}\n        <h1>Page Content</h1>\n    {{/main}}\n\n{{/ govuk-template}}\n```\n\n## Installation\n\n```\nnpm install [--save] hmpo-govuk-template\n```\n\n## Usage\n\nThe compilation of the template is performed automatically as an npm postinstall hook.\n\nWhen used as part of an express app, a setup method is provided which will add a static-middleware (using [serve-static](https://www.npmjs.com/package/serve-static)) to serve the template assets without needing to copy them to any other location.\n\nIt will also add the template as a mustache partial with a name of \"govuk-template\".\n\n### To configure express middleware\n```\nrequire('hmpo-govuk-template').setup(app[, { ... options ...}]);\n```\n\n### To use the mustache partial\n```\n{{< govuk-template}}\n    {{$pageTitle}}An example page{{/pageTitle}}\n    {{$main}}\n        <h1>Page Content</h1>\n    {{/main}}\n{{/ govuk-template}}\n```\n\n## Options\n\nA number of options can be passed with the app into the setup method:\n\n* `path` - Sets the base path for the location of static assets - Default: `/govuk-assets`\n\nOther options are passed onto the [serve-static](https://www.npmjs.com/package/serve-static) configuration, and more details can be found in [the serve-static documentation](https://www.npmjs.com/package/serve-static)\n\n## Example\n\nThere is an example implmentation in '/example'. To run:\n\n```\ncd example\nnpm install\nnpm start\n```","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/express-partial-templates","private":false,"url":"https://github.com/UKHomeOffice/express-partial-templates","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# express-partial-templates\n\nA middleware that will use the `views` path and the `view engine` string that are stored against an [Express](http://expressjs.com) `app` object to generate a key-value object that identifies and makes accessible the file paths of partial templates against `res.locals.partials` on execution.\n\n## Installation\n\n```\nnpm install [--save] express-partial-templates;\n```\n\n## Usage\n\n```\nvar app = require('express')();\n\napp.set('view engine', 'html');\napp.set('views', path.join(__dirname, '/views'));\napp.use(require('express-partial-templates')(app));\n\napp.use(function (req, res, next) {\n    // res.locals.partials has been set.\n\n    next();\n});\n```\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/passports-form-controller","private":false,"url":"https://github.com/UKHomeOffice/passports-form-controller","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# passports-form-controller\n\nImplements a request pipeline for GET and POST of forms, with input cleaning/formatting and validation.\n\n## Usage\n\nBasic usage:\n\n```javascript\nvar Form = require('hmpo-form-controller');\n\nvar form = new Form({\n    template: 'form',\n    fields: {\n        name: {\n            validate: 'required'\n        }\n    }\n});\n\napp.use('/', form.requestHandler());\n```\n\nThis won't really be very useful though, since all it will do is render the \"form\" template on `/` and respond to GET and POST requests.\n\nFor real-world usage you will probably want to extend the Form class to create your own controllers.\n\n```javascript\nvar Form = require('hmpo-form-controller'),\n    util = require('util');\n\nvar MyForm = function (options) {\n    Form.call(this, options);\n};\n\nutil.inherits(MyForm, Form);\n\nmodule.exports = MyForm;\n```\n\nThe Form class allows for a number of insertion points for extended functionality:\n\n* `process`     Allows for custom formatting and processing of input prior to validation\n* `validate`    Allows for custom input validation\n* `getValues`   To define what values the fields are populated with on GET\n* `saveValues`  To define what is done with successful form submissions\n\nAll of these methods take three arguments of the request, the response and a callback. In all cases the callback should be called with a first argument representing an error.\n\n* `getErrors/setErrors` Define how errors are persisted between the POST and subsequent GET of a form step.\n* `locals` Define what additional variables a controller exposes to its template\n\nThese methods are synchronous and take only the request and response obejct as arguments.\n\n### Validators\n\nThe library [supports a number of validators](https://github.com/UKHomeOffice/passports-form-controller/blob/master/lib/validation/validators.js).\n\nBy default the application of a validator is optional on empty strings. If you need to ensure a field is validated as being 9 characters long and exists then you need to use both an `exactlength` and a `required` validator.\n\n#### Custom Validators\n\nCustom validator functions can be passed in field config. These must be named functions and the name is used as the error.type for looking up validation error messages.\n\nfields.js\n```js\n{\n    'field-1': {\n        validate: ['required', function isTrue(val) {\n            return val === true;\n        }]\n    }\n}\n```\n\n### steps config\n\n#### Handles journey forking\n\nEach step definition accepts a `next` property, the value of which is the next route in the journey. By default, when the form is successfully submitted, the next steps will load. However, there are times when it is necessary to fork from the current journey based on a users response to certain questions in a form. For such circumstances there exists the `forks` property.\n\nIn this example, when the submits the form, if the field called 'example-radio' has the value 'superman', the page at '/fork-page' will load, otherwise '/next-page' will be loaded.\n\n```js\n\n'/my-page': {\n    next: '/next-page',\n    forks: [{\n        target: '/fork-page',\n        condition: {\n            field: 'example-radio',\n            value: 'superman'\n        }\n    }]\n}\n```\n\nThe condition property can also take a function. In the following example, if the field called 'name' is more than 30 characters in length, the page at '/fork-page' will be loaded.\n\n```js\n\n'/my-page': {\n    next: '/next-page',\n    forks: [{\n        target: '/fork-page',\n        condition: function (req, res) {\n            return req.form.values['name'].length > 30;\n        }\n    }]\n}\n```\n\nForks is an array and therefore each fork is interrogated in order from top to bottom. The last fork whose condition is met will assign its target to the next page variable.\n\nIn this example, if the last condition resolves to true - even if the others also resolve to true - then the page at '/fork-page-three' will be loaded. The last condition to be met is always the fork used to determine the next step.\n\n```js\n\n'/my-page': {\n    next: '/next-page',\n    forks: [{\n        target: '/fork-page-one',\n        condition: function (req, res) {\n            return req.form.values['name'].length > 30;\n        }\n    }, {\n        target: '/fork-page-two',\n        condition: {\n            field: 'example-radio',\n            value: 'superman'\n        }\n    }, {\n        target: '/fork-page-three',\n        condition: function (req, res) {\n            return typeof req.form.values['email'] === 'undefined';\n        }\n    }]\n}\n```\n\n### The FormError class\n\nFormError can be used as a façade to normalise different types of error one may receive / trigger, and to be subsequently returned from a controller.\nIts constructor takes a series of options. `title` and `message` have both getters and public methods to define default values.\n\n\n```js\n\nlet error = new ErrorClass(this.missingDoB, {\n    key: this.missingDob,\n    type: 'required',\n    redirect: '/missingData',\n    title: 'Something went wrong',\n    message: 'Please supply a valid date of birth'});\n```\n\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/passports-model","private":false,"url":"https://github.com/UKHomeOffice/passports-model","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# hmpo-model\nSimple model for interacting with http/rest apis.\n\n## Usage\n\nNormally this would be used as an abstract class and extended with your own implementation.\n\nImplementations would normally define at least a `url` method to define the target of API calls.\n\nThere are three methods for API interaction corresponding to GET, POST, and DELETE http methods:\n\n### `fetch`\n\n```javascript\nvar model = new Model();\nmodel.fetch(function (err, data, responseTime) {\n    console.log(data);\n});\n```\n\n### `save`\n\n```javascript\nvar model = new Model();\nmodel.set({\n    property: 'properties are sent as JSON request body by default'\n});\nmodel.save(function (err, data, responseTime) {\n    console.log(data);\n});\n```\n\nThe method can also be overwritten by passing options\n\n```javascript\nvar model = new Model();\nmodel.set({\n    property: 'this will be sent as a PUT request'\n});\nmodel.save({ method: 'PUT' }, function (err, data, responseTime) {\n    console.log(data);\n});\n```\n\n### `delete`\n\n```javascript\nvar model = new Model();\nmodel.delete(function (err, data) {\n    console.log(data);\n});\n```\n\nIf no `url` method is defined then the model will use the options parameter and [Node's url.format method](https://nodejs.org/api/url.html#url_url_format_urlobj) to construct a URL.\n\n```javascript\nvar model = new Model();\n\n// make a GET request to http://example.com:3000/foo/bar\nmodel.fetch({\n    protocol: 'http',\n    hostname: 'example.com',\n    port: 3000,\n    path: '/foo/bar'\n}, function (err, data, responseTime) {\n    console.log(data);\n});\n```\n\n## Events\n\nAPI requests will emit events as part of their lifecycle.\n\n`sync` is emitted when an API request is sent\n```javascript\nmodel.on('sync', function (settings) { });\n```\n\n`success` is emitted when an API request successfully completes\n```javascript\nmodel.on('success', function (data, settings, statusCode, responseTime) { });\n```\n\n`fail` is emitted when an API request fails\n```javascript\nmodel.on('fail', function (err, data, settings, statusCode, responseTime) { });\n```\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/passports-template-mixins","private":false,"url":"https://github.com/UKHomeOffice/passports-template-mixins","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# passports-template-mixins\nA middleware that exposes a series of Mustache mixins on `res.locals` to ease usage of forms, translations, and some other things.\n\nIt takes in two arguments, a `fields` object containing field configuration, and an [options object](#options).\n\n## Installation\n\n```javascript\nnpm install [--save] hmpo-template-mixins;\n```\n\n## Usage\n\n```javascript\nvar express = require('express');\n\nvar i18n = require('i18n-future');\n\nvar fields = require('./routes/renew-your-passport/fields');\n\napp.set('view engine', 'html');\napp.set('views', path.join(__dirname, '/views'));\n\napp.use(i18n.middleware());\napp.use(require('hmpo-template-mixins')(fields, { sharedTranslationsKey: 'passport.renew' }));\n\napp.use(function (req, res) {\n    // NOTE: res.locals.partials has been set.\n\n    res.render('example-template');\n});\n```\n\n## Translation\n\nBy default any function set to `req.translate` will be used for translation if it exists. For example, that generated using [i18n-future](https://npmjs.com/package/i18n-future) middleware.\n\n## Options\n\n### viewsDirectory\n\nAllows you override the directory that the module checks for partials in - Default: the root of this project\n\n### viewEngine\n\nAllows you to alter the file extension of the templates - Default: 'html'\n\n### sharedTranslationsKey\n\nPrefixes keys for translation - Default: ''\n\n### translate\n\nDefines a custom translation method - Default: `req.translate`\n\n## Mustache mixins available\n\n```\nt\ntime\nselected\nlowercase\nuppercase\nhyphenate\ndate\ncurrency\nselect\ninput-text\ninput-date\ninput-text-compound\ninput-text-code\ninput-number\ninput-phone\nradio-group\ncheckbox\ncheckbox-compound\ncheckbox-required\ninput-submit\ntextarea\n```\n\n## Options\n\n- `className`: A string or array of string class names.\n- `label`: The intended value of the HTML `label` attribute.\n- `type`: The value of the HTML input `type` attribute.\n- `required`: Value applied to `aria-required` HTML attribute.\n- `hint`: This adds context to the label, which it is a part of, for input text, radio groups and textarea. It is used within the input by aria-describedby for screen readers.\n- `maxlength`: Applicable to text-based fields and mapped to the `maxlength` HTML attribute.\n- `options`: Applicable to HTML `select` and `radio` controls and used to generate the items of either HTML element.\n- `selected`: Applicable to `select`, `checkbox`, and `radio` controls. Will render the selected HTML option/element selected or checked.\n- `legend`: Applicable to `radio` button controls, which are wrapped in a HTML `fieldset` with a `legend` element.\n- `legendClassName`: Applied as a class name to HTML `legend` attribute.\n- `toggle`: Can be used to toggle the display of the HTML element with a matching `id`. See [passports-frontend-toolkit](https://github.com/UKHomeOffice/passports-frontend-toolkit/blob/master/assets/javascript/progressive-reveal.js) for details.\n- `attributes`: A hash of key/value pairs applicable to a HTML `textarea` field. Each key/value is assigned as an attribute of the `textarea`. For example `spellcheck=\"true\"`.\n- `child`: Render a child partial beneath each option in an `optionGroup`. Accepts a custom mustache template string, a custom partial in the format `partials/{your-partial-name}` or a template mixin key which will be rendered within a panel element partial.\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/payments-service","private":false,"url":"https://github.com/UKHomeOffice/payments-service","license":{"key":"other","name":"Other","spdxId":null,"url":null,"featured":false},"readme":"## Synopsis\n\nThis project separates the concern of handling a payment gateway from the client requiring the integration.\n\nBenefits include ease of financial transaction reporting, payment event and type handling.\n \nFurthermore, although WorldPay is the only current payment gateway implemented the abstraction makes implementing alternative providers easier from the client perspective. \n\n## Code Example\n\nTo learn the features implemented in this project the suggested starting place is the controller tests you can find [here](payments/test/controller/), specifically PaymentControllerSpec, PaymentEventControllerSpec and WorldPayTransactionReportControllerSpec.\n\n## Motivation\n\nThis project exists because it is useful for the Home Office Visa exemplar and payment gateway integration is common to many government projects.\n\n## Installation\n\nThis project is implemented in Scala and uses Mongo for data persistence.\n\nTo build the project execute `./build.sh`, and likewise to run execute `./run.sh` from the project root folder.\n\n## API Reference\n\nThis project is a web application exposing RESTful web services. The expected content-type is `application/json` except from endpoints specific for WorldPay.\n\n### `GET /payment-types/:region`\n\n#### Description\n\nReturns a list of payment types for a given `region`.\n\n#### Header attributes\n\n`X-CLIENT-ID` - to define client id\n\n#### Parameters\n\n* `region` - a `string` parameter for a region name; it has to match one of regions specified in the configuration.\n\n#### Response\n\nA json representing set of payment types.\n\n\n### `POST /payment/start`\n\n#### Description\n\nStarts a new payment by initializing it on both Payments and the WorldPay side and returns a response json with a redirect `url`.\n\n#### Header attributes\n\n`X-CLIENT-ID` - to define client id\n\n#### Payload\n\nA json structure containing all required data.\n\nExample:\n\n```\n{\n  \"externalReference\": \"pnn\",\n  \"internalReference\": \"appId\",\n  \"payee\": {\n    \"title\": \"Mr\",\n    \"givenName\": \"givenName\",\n    \"familyName\": \"familyName\",\n    \"email\": \"lincolnshire.poacher@example.com\",\n    \"phoneNumber\": \"0123456789\",\n    \"billingAddress\": {\n      \"line1\": \"line1\",\n      \"line2\": \"line2\",\n      \"line3\": \"line3\",\n      \"townCity\": \"London\",\n      \"postCode\": \"EC2 2CE\",\n      \"countryCode\": \"CHN\"\n    }\n  },\n  \"description\": \"I am a product\",\n  \"profile\": {\n    \"paymentType\": \"VISA-SSL\",\n    \"region\": \"uk\"\n  },\n  \"paymentItems\": [{\n     \"description\": \"6 months\",\n     \"price\": 234.0\n  }\n  ],\n  \"total\": 234.0,\n  \"currency\": \"GBP\",\n  \"locale\": \"\",\n  \"additionalInformation\": {\n      \"GWF\": \"123\"\n   }\n}\n```\n\n#### Response\n\nA json containing `url` to be used to redirect to payment pages along with payment `externalReference`.\n\n\n### `GET /payment/perform-inquiry/:internalReference`\n\n#### Description\n\nForces to perform inquiry on the WorldPay to check the current status of the latest payment for the given `internalReference`.\n\nAs a result the service may asynchronously send a notification to the client system informing about the change in payment status.\n\n#### Parameters\n\n* `internalReference` - a `string` parameter for internal payment reference.\n\n#### Response\n\nNo specific response body.\n\n\n### `GET /payment-submission/confirmation`\n\n#### Description\n\nAn endpoint to handle synchronous WorldPay callbacks on payment submission. There is number of query parameters WorldPay adds to the query, however the service takes into account only `status` and `externalReference`.\n\nThis main purpose of this endpoint it to handle *APM* payments as the `status` query parameter is added only for them.\n\nAs a result the service may asynchronously send a notification to the client system informing about the change in payment status.\n\n#### Parameters\n\n* `externalReference` - a `string` parameter for external payment reference;\n* `status` - a `string` representing current payment status; there is a set of possible values for that field.\n\n#### Response\n\nResponse body required by WorldPay: `[OK]`\n\n\n### `GET /notify`\n\n#### Description\n\nAn endpoint to receive asynchronous WorldPay notifications about a payment. There is number of query parameters WorldPay adds to the query to both identify the payment and to give information about its current status.\n\nAs a result the service may asynchronously send a notification to the client system informing about the change in payment status.\n\n#### Parameters\n\n* `PaymentCurrency` - a `string` parameter for currency used on the payment;\n* `PaymentStatus` - a `string` representing current payment status;\n* `OrderCode` - a `string` parameter for the payment external reference;\n* `PaymentMethod` - a `string` parameter for payment method used on the payment;\n* `PaymentAmount` - a `number` parameter with the paid amount; value multiplied by 100; contains no commas.\n\n#### Response\n\nResponse body required by WorldPay: `[OK]`\n\n\n### `POST /report`\n\n#### Description\n\nAn endpoint to receive reports from WorldPay. It generates two reports and sends them as email attachments to recipients specified in the config file.\n\nThe endpoint payload is in XML format.\n\n#### Response\n\nResponse body required by WorldPay: `<html> <head>Report Response</head> <body> [OK] </body> </html>`\n\n\n### `POST /migration/payment`\n\n#### Description\n\nThis endpoint creates initial payment data on the service side. It does not initializes payment on WorldPay side, though.\n\nThe endpoint is for a parallel phase when a client system was already integrated with WorldPay and is moving to use the new gateway system.\n\n#### Header attributes\n\n`X-CLIENT-ID` - to define client id\n\n#### Response\n\nNo specific response body.\n\n\n### `GET /healthcheck`\n\n#### Description\n\nAn endpoint to check service's health.\n\n#### Response\n\nReturns `healthy!` along with build number if everything is fine.\n\n\n### Callback urls\n\nThe service requires defining several urls in order to interact with client systems.\n\n#### `payment.report.url`\n\nA client url where generated reports are sent.\n\n#### `payment.notification.url`\n\nA client url where notifications about payment status change are sent.\n\n#### `pending.url`\n\nA client url where payment journey gets redirected for pending payment.\n\n#### `cancel.url`\n\nA client url where payment journey gets redirected in case of payment being cancelled.\n\n\n## Tests\n\nAll tests are executed in the build process.\n\nHowever if you are learning how the service works through running individual tests, this is best done in an IDE such as IntelliJ.\n\n## Contributors\n\nIf you want to contribute to the project you can do it by creating a pull request.\n\n\n## Known issues\n\nThere is no validation of the string fields within the JSON payload which, if not correctly protected by the calling client, could leave the potential for a XML injection attack.\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/removals_integration","private":false,"url":"https://github.com/UKHomeOffice/removals_integration","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Removals Integration API\n\n[![Build](https://travis-ci.org/UKHomeOffice/removals_integration.png)](https://travis-ci.org/UKHomeOffice/removals_integration)\n[![Coverage Status](https://coveralls.io/repos/github/UKHomeOffice/removals_integration/badge.svg)](https://coveralls.io/github/UKHomeOffice/removals_integration)\n[![Quality](https://codeclimate.com/github/UKHomeOffice/removals_integration.png)](https://codeclimate.com/github/UKHomeOffice/removals_integration)\n[![Dependencies](https://david-dm.org/UKHomeOffice/removals_integration.png)](https://david-dm.org/UKHomeOffice/removals_integration)\n## Quickstart:\n\n Get [NodeJS](https://nodejs.org) via [nvm](https://github.com/creationix/nvm)\n```sh\n$ curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.31.0/install.sh | bash\n```\n\n#### Install NodeJS 4 LTS\n```sh\n$ nvm install 4\n$ nvm use 4\n```\n### Build:\n```sh\n$ npm install\n```\n### Test:\n```sh\n$ npm test\n```\n### CI Test:\n```sh\n$ npm test\n```\n### Start single-threaded unmanaged server:\n```sh\n$ npm start\n```\n### Start in production mode with MySQL server and Redis server:\n\n(set environment variables to whatever you've configured)\n```sh\nNODE_ENV=productionAlter \\\nDBHOST=localhost \\\nDBPORT=3306 \\\nDBUSER=root \\\nDBPASS=root \\\nDBNAME=sails \\\nREDIS_SERVICE_HOST=localhost \\\nREDIS_SERVICE_PORT=6379 \\\nPORT=8080 \\\nnpm start\n```\n\n## Environment variables\n\n| VAR | OPTION | RESULT |\n| --- | ------ | ------ |\n| NODE_ENV | production | start in a production mode, use a mysql db, use redis, no fixtures, **do not run** migrations |\n| NODE_ENV | productionAlter | start in a production mode, use a mysql db, use redis, no fixtures, **do run** migrations |\n| NODE_ENV | development | start in a development mode, use a local in-memory database, no fixtures, no redis |\n| PORT | [integer] | port to run node server on |\n| DBHOST | [string] | mysql db host |\n| DBPORT | [string] | mysql db port |\n| DBUSER | [string] | mysql db user |\n| DBPASS | [string] | mysql db password |\n| REDIS_SERVICE_HOST | [string] | redis host |\n| REDIS_SERVICE_PORT | [string] | redis port |\n\n## Docker\nCan be built and run in the same way with docker for example:\n```sh\n$ docker build -t ibm-backend .\n$ docker run -i -e \"NODE_ENV=development\" ibm-backend\n```\n","travis":true,"contributing":"# Contribution guidelines\n\nWe welcome patches!\n\n## Commit hygiene\n\nWe like to follow the recommendations set out in the GDS [git style guide][gitstyle]\nwhich describes how we prefer git history and commit messages to read.\n\n[gitstyle]: https://github.com/alphagov/styleguides/blob/master/git.md\n\n## Visual changes\n\nFor visual changes, it can be helpful to provide images in your pull-request\nshowing before and after to highlight the differences.\n","masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/removals_integration/branches/master/protection","requiredStatusChecks":{"url":"https://api.github.com/repos/UKHomeOffice/removals_integration/branches/master/protection/required_status_checks","strict":true,"includeAdmins":false,"contextsUrl":"https://api.github.com/repos/UKHomeOffice/removals_integration/branches/master/protection/required_status_checks/contexts"}}},{"name":"UKHomeOffice/passports-frontend-toolkit","private":false,"url":"https://github.com/UKHomeOffice/passports-frontend-toolkit","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# passports-frontend-toolkit\nSet of common UI patterns/styles for hmpo projects\n\n## Images\nCopy `assets/images/hmpo` to your image directory. Images are loaded by using the `file-url` function provided by [GOV.UK frontend toolkit](https://github.com/alphagov/govuk_frontend_toolkit). The `file-url` function uses the `$path` variable which is set before the toolkit's modules are loaded.\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/puppet-galera","private":false,"url":"https://github.com/UKHomeOffice/puppet-galera","license":{"key":"apache-2.0","name":"Apache License 2.0","spdxId":"Apache-2.0","url":"https://api.github.com/licenses/apache-2.0","featured":true},"readme":"# puppet-galera module\n\n[![Build Status](https://travis-ci.org/michaeltchapman/puppet-galera.png?branch=master)](https://travis-ci.org/michaeltchapman/puppet-galera)\n\nThis module will massage puppetlabs-mysql into creating a mysql galera cluster. It will try to recover from failures by bootstrapping on a node designated as the master if no other nodes appear to be running mysql, but if the cluster goes down and the master is permanently taken out, another node will need to be specified as the 'master' that can bootstrap the cluster.\n\n## Requirements\n\nThis module was build against master of the following repos in early 2014, which corresponds to the listed version:\n\n    puppetlabs-mysql    2.2.0\n    puppetlabs-stdlib   4.1.0\n\n    # If you're on debian and need the repo to be set\n    puppetlabs-apt      1.4.1\n\n    # If you want the firewall to be configured for you\n    puppetlabs-firewall 1.0.0\n## Structure\n\nThis module was created to work in tandem with the mysql module, rather than replacing it. As the stages in the mysql module are quite strictly laid out in the mysql::server class, this module places its own resources in the gaps between them. Of note is an exec that will start the mysql service with the parameter --wsrep_address=gcomm:// which will start a new cluster, but only if it cannot open the comms port to any other node in the provided list. This is done with a simple nc command and should not be considered terribly reliable.\n\n## Usage\n\nBasic usage requires only the fqdn of the master node, and a list of IP addresses of other nodes:\n\n    class { 'galera':\n        galera_servers => ['192.168.99.101', '192.168.99.102'],\n        galera_master  => 'control1.domain.name'\n    }\n\nA number of simple options are available:\n\n    class { 'galera':\n        galera_servers => ['192.168.99.101', '192.168.99.102'],\n        galera_master  => 'control1.domain.name',\n\n        vendor_type => 'mariadb', # default is 'percona'\n\n        # These options are only used for the firewall - \n        # to change the my.cnf settings, use the override options\n        # described below\n\n        $mysql_port = 3306, \n        $wsrep_state_transfer_port = 4444,\n        $wsrep_inc_state_transfer_port = 4568,\n\n        # this is used for the firewall + for status checks\n        # when deciding whether to bootstrap\n        $wsrep_group_comm_port = 4567,\n\n        local_ip => $::ipaddress_eth0, # This will be used to populate my.cnf values that control where wsrep binds, advertises, and listens\n        root_password => 'myrootpassword', # This will be set when the cluster is bootstrapped\n        configure_repo => true, # Disable this if you are managing your own repos and mirrors\n        configure_firewall => true, # Disable this if you don't want firewall rules to be set\n    }\n\nA catch-all parameter can be used to populate my.cnf in the same way as the puppetlabs-mysql module:\n\n    class { 'galera':\n        galera_servers => ['192.168.99.101', '192.168.99.102'],\n        galera_master  => 'control1.domain.name',\n\n        override_options = {\n            'mysqld' => {\n                'bind_address' => '0.0.0.0',\n            }\n        }\n    }\n\n## Testing\n\nA vagrant file is provided. Control1 is set as the master and control2 as the slave. It will read environment variables for http_proxy and http_mirror, but these only work on Debian. The module has been tested on Ubuntu 12.04 and Centos 6.4, both 64 bit.\n\n    vagrant up control1\n    vagrant up control2\n\n## Contributions\n\nPull requests most welcome :)\n\n# Authors\n\n- Michael Chapman\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/mcollective-haproxyctl","private":false,"url":"https://github.com/UKHomeOffice/mcollective-haproxyctl","license":{"key":"gpl-3.0","name":"GNU General Public License v3.0","spdxId":"GPL-3.0","url":"https://api.github.com/licenses/gpl-3.0","featured":true},"readme":"mcollective-haproxyctl\n======================\n\nsimpleRPC agent to manage haproxy using haproxyctl\n\nAssumptions\n-----------\n\nThe agent assumes install locations of\n\nhaproxy at /usr/sbin/haproxy (default for yum install haproxy)\n\nand\n\nhaproxyctl at /usr/bin/haproxyctl \n\nAlternate installation locations will require updates within the ../agent/haproxyctl.rb file\n\nInstallation\n-----------\n\nCopy the haproxyctl.rb and haproxyctl.ddl to the mcollective agent directory.\n\nRestart the mcollective service to load it in.\n\nUsage\n-----------\n\n### Viewing backends/health/stat/info/errors\n\nmco rpc haproxyctl show mode=*health|backends|stat|errors|info*\n\ne.g.\n\nmco rpc haproxyctl show mode=backends\n\nwill do the equivalent to...\n\n./haproxyctl show backends\n\n### Enabling/disabling servers\n\nmco rpc haproxyctl *enable|enable_all|enable_all_except|disable|disable_all|disable_all_except* SERVER\n\ne.g.\n\nmco rpc haproxyctl enable_all app1\n\nwill do the equivalent to...\n\n./haproxyctl enable all app1\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/vcloud_packer_images","private":false,"url":"https://github.com/UKHomeOffice/vcloud_packer_images","license":null,"readme":"## vcloud_packer_images\nHelps you generates an image from an iso ( currently tested using ubuntu 14.04 but should be pretty portable) which we can upload as a skyscape template.  \n\n## Intended use\n### General form \nBuild a new template:\n```./createimage [-p,-u,-o,-t] [build|upload] <template name>```\n\nThe createimage script will upload the template to Skyscape or a vCenter compatible provider.\n\n** Required Fields for upload**\n* -d distro\n* -u username\n* -o org\n* -c catalog\n\nThe upload options will build an ovftool command and the ovftool will in turn prompt you for a password. For the sake of security specifying the\npassword for image uploading is not allowed.\n\n\n### Examples\n```\ngit clone git@github.com:UKHomeOffice/vcloud_packer_images.git\ncd vcloud_packer_images\n./createimage -p p4ssw0rd build centos-66-x64 #_for Centos 66_\n./createimage -p p4ssw0rd build ubuntu-1404-x64 #_for Ubuntu 14.04_\n./createimage -u 123.456.789 -o 1234-456-223a -t centos -c CentOS  upload centos-66-x64\n./createimage build #_you will be prompted for options (distro, vm type, password) during the build run\n```\n\n### Skyscape translation\nTo get API details for skyscape you need to login to the (portal)[https://portal.skyscapecloud.com] and click on your username and then (API)[https://portal.skyscapecloud.com/user/api] . \nThis will give you the API details requried to run the createimage tool. **Note** however that the username as specified by Skyscape is actually your username and the organisation \nseperated by an **@** symbol.\n\n## TODO\n\n- Add to the build command so it runs a fix on any json configs before proceeding.\n- Figure out how to run this without infecting host system. (If you have vagrant running with something else other than virtualbox, you _should_ be able to vagrant up) \n- Double check ruby dependancies are correct.\n- Integrate with local or remote vagrant store to upload vagrant images\n- Move puppet scripts to a share directory used by all images\n- Make the packer build files an ERB template\n- Add PACKER_CACHE_DIR env variable to keep centralised iso cache, if not already.\n\n## Requirements\n\nThe following is what you'll need on a fairly recent debian / ubuntu system.\n\n# Ubuntu\n- aptitude install unzip qemu libxtst6 libxcursor1 libxinerama1 libxi6 wget ruby -y\n- wget -O packer.zip https://dl.bintray.com/mitchellh/packer/packer_0.7.5_linux_amd64.zip && unzip packer.zip && rm packer.zip && cp packer* /usr/local/bin\n- wget -O vmware.bundle https://download3.vmware.com/software/wkst/file/VMware-Workstation-Full-11.0.0-2305329.x86_64.bundle && bash vmware.bundle --required --eulas-agreed --console\n\n# Mac os X\n- Use brew to install the dependencies above i.e. ruby etc. \n- Brew's version of packer isn't updated enough and doesn't understand the hardware version for the vmware-iso \n- wget -O packer.zip https://dl.bintray.com/mitchellh/packer/packer_0.7.5_darwin_amd64.zip && unzip packer.zip && rm packer.zip && sudo cp packer* /usr/local/bin\n- Download VMWARE Fusion for MAC\n\nYou'll also need ovftool if it isn't insalled with vmware-workstation / vmware fusion (MAC).  Currently, this is only available on the vmware website after you signup.\novftool can be downloaded from: [VMWare](https://my.vmware.com/web/vmware/details?downloadGroup=OVFTOOL400&productId=353)\n\n_You'll need to do some work if you want to run this on another type of host._\n\n## Would be nice\n- If this feature request ever happens, we'll update the Vagrantfile so this all works within vbox.\n- [https://www.virtualbox.org/ticket/4032]\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/passports-form-wizard","private":false,"url":"https://github.com/UKHomeOffice/passports-form-wizard","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# hmpo-form-wizard\n\nCreates routing and request handling for a multi-step form process.\n\nGiven a set of form steps and field definitions, the wizard function will create an express router with routing bound to each step of the form and input validation applied as configured.\n\nAdditional checks are also applied to ensure a user completes the form in the correct order.\n\n## Usage\n\nDefine a set of steps:\n\n```javascript\n// steps.js\nmodule.exports = {\n  '/step1': {\n    next: '/step2'\n  },\n  '/step2': {\n    next: '/step3',\n    fields: ['name']\n  },\n  '/step3': {\n    next: '/step4',\n    fields: ['age']\n  },\n  '/step4': {}\n}\n```\n\nDefine field rules:\n\n```javascript\n// fields.js\nmodule.exports = {\n  'name': {\n    validate: 'required'\n  },\n  'age': {\n    validate: 'required'\n  }\n}\n```\n\nCreate a wizard and bind it as middleware to an app:\n\n```javascript\nvar wizard = require('hmpo-form-wizard'),\n    steps = require('./steps'),\n    fields = require('./fields');\n\napp.use(wizard(steps, fields));\n```\n\n## Sessions\n\nThe wizard expects some kind of session to have been created in previous middleware layers.\n\nFor production use a database backed session store is recommended - such as [connect-redis](https://github.com/tj/connect-redis).\n\n### Additional step options\n\nThe minimum amount of configuration for a wizard step is the `next` property to determine where the user should be taken after completing a step. A number of additional properties can be defined.\n\n* `fields` - specifies which of the fields from the field definition list are applied to this step. Form inputs which are not named on this list will not be processed. Default: `[]`\n* `template` - Specifies the template to render for GET requests to this step. Defaults to the route (without trailing slash)\n* `backLink` - Specifies the location of the step previous to this one. If not specified then an algorithm is applied which checks the previously visited steps which have the current step set as `next`.\n* `controller` - The constructor for the controller to be used for this step's request handling. The default is an extension of the [hmpo-form-controller](https://www.npmjs.com/package/hmpo-form-controller), which is exported as a `Controller` property of this module. If custom behaviour is required for a particular form step then custom extensions can be defined - see [Custom Controllers](#custom-controllers)\n* `forks` - Specifies a list of forks that can be taken depending on a particular field value or conditional function - See  [handling forking journeys](https://github.com/UKHomeOffice/passports-form-controller#handles-journey-forking) in hmpo-form-controller.\n\n### Additional field options\n\n* `invalidates` - an array of field names that will be 'invalidated' when this field value is set or changed. Any fields specified in the `invalidates` array will be removed from the `sessionModel`. Further to this any future steps from the invalidating step field will be removed from the `sessionModel`.\n\nRemaining field options documentation can be found in the hmpo-template-mixins [README](https://github.com/UKHomeOffice/passports-template-mixins#options-1).\n\n### Additional wizard options\n\nA number of options can be passed to the wizard as a third argument to customise aspects of the behaviour for all steps.\n\n`translate` - provide a function for translating validation error codes into usable messages. Previous implementations have used [i18next](https://www.npmjs.com/package/i18next) to do translations.\n`templatePath` - provides the location within `app.get('views')` that templates are stored. Default `pages`.\n`controller` - override the [default controller](./lib/controller.js) for steps without a controller specified.\n`params` - define a suffix for the routes for supporting additional URL parameters.\n\n### Custom Controllers\n\nCreating a custom controller:\n\n```javascript\n// controller.js\nvar util = require('util'),\n    Controller = require('hmpo-form-wizard').Controller;\n\nfunction CustomController() {\n  Controller.apply(this, arguments);\n  // extra middleware to log the request\n  this.use(function (req, res, next) {\n    console.log(req.method, req.url);\n    next();\n  });\n}\n\nutil.inherits(CustomController)\n\nmodule.exports = CustomController\n```\n\nExamples of custom controllers can be found in the [example app](./example/controllers)\n\n## Example app\n\nAn example application can be found in [the ./example directory](./example). To run this, follow the instructions in the [README](./example/README.md).\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/i18n-lookup","private":false,"url":"https://github.com/UKHomeOffice/i18n-lookup","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# i18n-lookup\nUtility node module for doing lookups from translation documents\n\n## Install\n\n```\nnpm install [--save] i18n-lookup\n```\n\n## Usage\n\nA lookup function is returned by passing in the translation method as an argument. We normally use [i18next](https://www.npmjs.com/package/i18next).\n\n```javascript\n/**\nLocale: {\n    another: {\n        translation: {\n            key: 'Text'\n        }\n    }\n}\n**/\nvar t = require('i18next').t;\n\nvar lookup = require('i18n-lookup')(t);\n\nvar translated = lookup([\n    'a.translation.key',\n    'another.translation.key'\n]);\n\nconsole.log(translated);\n// This will output the first key which has a corresponding translation defined.\n// => \"Text\"\n```\n\nAdditionally, a template compilation method can be provided for cases where the translated key also includes template syntax.\n\n```javascript\n/**\nLocale: {\n    greeting: 'Hello {{name}}'\n}\n**/\nvar t = require('i18next').t,\n    Mustache = require('mustache');\n\nvar lookup = require('i18n-lookup')(t, Mustache.render);\n\nvar translated = lookup([\n    'greeting'\n], {\n    name: 'John'\n});\n\nconsole.log(translated);\n// This will output the returned lookup compiled with the provided context\n// \"Hello John\"\n```\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/cloud-costs","private":false,"url":"https://github.com/UKHomeOffice/cloud-costs","license":null,"readme":"You will need to log into vcloud before you can use this script. It appears that, as long as you run this frequently, there is no need to keep logging in.\n\nFor this script to work, you will also need to install the vcloud-walk gem. I used rbenv for this, but you could also install it system-wide\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/heiraupdater","private":false,"url":"https://github.com/UKHomeOffice/heiraupdater","license":null,"readme":"# Heiraupdater\n\nTODO: Write a gem description\n\n## Installation\n\nAdd this line to your application's Gemfile:\n\n```ruby\ngem 'heiraupdater'\n```\n\nAnd then execute:\n\n    $ bundle\n\nOr install it yourself as:\n\n    $ gem install heiraupdater\n\n## Usage\n\nTODO: Write usage instructions here\n\n## Contributing\n\n1. Fork it ( https://github.com/[my-github-username]/heiraupdater/fork )\n2. Create your feature branch (`git checkout -b my-new-feature`)\n3. Commit your changes (`git commit -am 'Add some feature'`)\n4. Push to the branch (`git push origin my-new-feature`)\n5. Create a new Pull Request\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/HODHackMicroServices","private":false,"url":"https://github.com/UKHomeOffice/HODHackMicroServices","license":null,"readme":"# HODHackMicroServices\nProduce a micro service proof of concept\n\nhod.hacker@gmail.com    hodhacker1\n\nhttps://twitter.com/HodHacker hodhacker1\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/openid","private":false,"url":"https://github.com/UKHomeOffice/openid","license":null,"readme":"# openid\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/mrz","private":false,"url":"https://github.com/UKHomeOffice/mrz","license":null,"readme":"You will need to create the following folder where you will put your passport image files\n\nsrc/test/resources/passport-images","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/immigration-status-check","private":false,"url":"https://github.com/UKHomeOffice/immigration-status-check","license":{"key":"other","name":"Other","spdxId":null,"url":null,"featured":false},"readme":"This is your new Play application\n=================================\n\nThis file will be packaged with your application, when using `activator dist`.\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/rtp-io-lib","private":false,"url":"https://github.com/UKHomeOffice/rtp-io-lib","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"Scala library for IO functionality\n==================================\nGeneral Scala IO functionality such as JSON schema validation\n\nProject built with the following (main) technologies:\n\n- Scala\n\n- SBT\n\n- Json4s\n\nIntroduction\n------------\nTODO\n\nBuild and Deploy\n----------------\nThe project is built with SBT. On a Mac (sorry everyone else) do:\n> brew install sbt\n\nIt is also a good idea to install Typesafe Activator (which sits on top of SBT) for when you need to create new projects - it also has some SBT extras, so running an application with Activator instead of SBT can be useful. On Mac do:\n> brew install typesafe-activator\n\nTo compile:\n> sbt compile\n\nor\n> activator compile\n\nTo run the specs:\n> sbt test\n\nTo run integration specs:\n> sbt it:test\n\nPublishing\n----------\nTo publish the jar to artifactory you will need to \n\n1. Copy the .credentials file into your <home directory>/.ivy2/\n2. Edit this .credentials file to fill in the artifactory security credentials (amend the realm name and host where necessary)\n\n> sbt publish\n\nNote that initially this project refers to some libraries held within a private Artifactory. However, those libraries have been open sourced under https://github.com/UKHomeOffice.\n\nExample Usage\n-------------\n- Validate JSON against a JSON schema:\n```scala\n  val json: JValue = getYourJson()\n  val schema: JValue = getYourSchema()\n  \n  val Good(result) = JsonSchema(schema).validate(json) // Assuming successful validation\n```\n\n- Transform JSON from one structure to another:\n```scala\n  val yourJsonTransformer = new JsonTransformer {\n    def transform(json: JValue): JValue Or JsonError = {\n      val JsonTransformation(oldJson, newJson) = (\n        map(\"name\" -> \"superName\") ~\n        mapArray(\"fee\" -> \"payment.feeInPence\", field => JInt(BigInt(field.extract[String])))\n      )(json)\n      \n      Good(newJson)\n    }\n  }\n  \n  val flatJson = parse(\"\"\"\n  {\n    \"name\": \"Batman\",\n    \"fee_1\": \"12\",\n    \"fee_2\": \"15\",\n    \"fee_3\": 18\n  }\"\"\")\n\n  val json = parse(\"\"\"\n  {\n    \"superName\": \"Batman\",\n    \"payment\": [\n      { \"feeInPence\": 12 },\n      { \"feeInPence\": 15 },\n      { \"feeInPence\": 18 }\n    ]\n  }\"\"\")\n\n  // Assuming successful transformation\n  transform(flatJson) mustEqual Good(json) \n```\n\nNote - if required (though not advised) the EmptyJsonSchema can be used to all JSON to be validated successfully.\n\nJSON Schema Validation\n----------------------\nThere are several online JSON schema validation tools such as [JSON Schema Validator](http://www.jsonschemavalidator.net/)\n\nAlternatively, a JSON schema can be validated from the Scala REPL by doing the following:\n\n> sbt\n\n> console\n\n> import uk.gov.homeoffice.json._\n\n> import uk.gov.homeoffice.json.Json._\n\n> jsonFromFilepath(\"src/test/resources/schema-test.json\") map { JsonSchema(_) }\n\nIf you've given a valid file path and the schema is valid, the result will be something like:\n\nres3: scala.util.Try[uk.gov.homeoffice.json.JsonSchema] = Success(uk.gov.homeoffice.json.JsonSchema@7568db95)","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/rtp-rabbit-lib","private":false,"url":"https://github.com/UKHomeOffice/rtp-rabbit-lib","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"Scala publish/subscribe JSON API for RabbitMQ\n=============================================\nScala general functionality to interface with RabbitMQ via JSON protocol.\n\nProject built with the following (main) technologies:\n\n- Scala\n\n- SBT\n\n- Akka\n\n- RabbitMQ\n\n- Specs2\n\nIntroduction\n------------\nTODO\n\nBuild and Deploy\n----------------\nThe project is built with SBT. On a Mac (sorry everyone else) do:\n> brew install sbt\n\nIt is also a good idea to install Typesafe Activator (which sits on top of SBT) for when you need to create new projects - it also has some SBT extras, so running an application with Activator instead of SBT can be useful. On Mac do:\n> brew install typesafe-activator\n\nTo compile:\n> sbt compile\n\nor\n> activator compile\n\nTo run the specs:\n> sbt test\n\nTo run integration specs:\n> sbt it:test\n\nPublishing\n----------\nTo publish the jar to artifactory you will need to \n\n1. Copy the .credentials file into your <home directory>/.ivy2/\n2. Edit this .credentials file to fill in the artifactory user and password\n\n> sbt publish\n\nNote that initially this project refers to some libraries held within a private Artifactory. However, those libraries have been open sourced under https://github.com/UKHomeOffice.\n\nExample Usage\n-------------\n```scala\n  object ExampleBoot extends App with HasConfig {\n    implicit val json4sFormats = DefaultFormats\n  \n    val system = ActorSystem(\"example-actor-system\", config)\n  \n    // Consume\n    system.actorOf {\n      Props {\n        new ConsumerActor with Consumer[String] with DefaultErrorPolicy with NoJsonValidator with ExampleQueue with Rabbit {\n          def consume(json: JValue) = Future {\n            val message = (json \\ \"message\").extract[String]\n            debug(s\"Congratulations, consumed message '$message'\")\n            message\n          }\n        }\n      }\n    }\n  \n    // Publish\n    val publisher = new Publisher with ExampleQueue with Rabbit\n    publisher.publish(\"message\" -> \"hello world!\")\n  }\n  \n  trait ExampleQueue extends Queue {\n    def queueName = \"rabbit-example\"\n  }\n```\n\nNoting that a \"configuration\" such as application.conf must be provided e.g.\n```scala\n  amqp {\n    addresses = [{\n      host = \"127.0.0.1\"\n      port = 5672\n    }]\n  \n    automatic-recovery = on\n  }\n```\n\nWriting specs (tests) against Rabbit is very easy (integration tests are so easy, they can be regarded as unit tests). Upon running the specs, the SBT build will attempt to start Rabbit (but it is easier to start Rabbit yourself and keep it running, as all specs will create unique, temporary queues, which are removed when examples have finished, and all connections are automatically closed, closing all Rabbit channels).\n\nA spec that consumes valid and error messages, upon publication of said messages. All the plumbing is handled automatically, allowing you to concentrate on writing specs to build your API and subsequently your code.\n\n```scala\nclass WithConsumerSpec(implicit ev: ExecutionEnv) extends Specification with RabbitSpec {\n  \"Consumer\" should {\n    \"consume valid message\" in {\n      val validMessageConsumed = Promise[Boolean]()\n\n      val publisher = new Publisher with WithQueue.Consumer with WithRabbit {\n        def json(json: JValue) = validMessageConsumed success true\n      }\n\n      publisher.publish(JObject())\n\n      validMessageConsumed.future must beTrue.await\n    }\n\n    \"consume error message\" in {\n      val errorMessageConsumed = Promise[Boolean]()\n\n      val publisher = new Publisher with WithQueue.ErrorConsumer with WithRabbit {\n        def jsonError(jsonError: JsonError) = errorMessageConsumed success true\n      }\n\n      publisher.publish(JsonError())\n\n      errorMessageConsumed.future must beTrue.await\n    }\n  }\n}\n```\n\nRabbit MQ\n---------\nWorking on a Mac:\n> brew install rabbitmq\n\nTo enable the Management UI:\n> rabbitmq-plugins enable rabbitmq_management\n\nTo run Rabbit (server)\n> rabbitmq-server\n\nView Management UI in browser at http://localhost:15672\nand login as guest/guest\n\nEven though this is a Scala library to easy test against and use RabbitMQ, underneath it uses the Java RabbitMQ driver.\nTo use Rabbit with other drivers, there is plenty of good documentation at https://www.rabbitmq.com, where the following are a couple of extracts.\n\nExample of connecting to Rabbit to publish to a queue using a Java driver:\n\nhttps://www.rabbitmq.com/api-guide.html\n```java\nConnectionFactory factory = new ConnectionFactory();\nfactory.setUri(\"amqp://userName:password@hostName:portNumber/virtualHost\");\nConnection conn = factory.newConnection();\n\nChannel channel = conn.createChannel();\n\nbyte[] messageBodyBytes = \"Hello, world!\".getBytes();\nchannel.basicPublish(exchangeName, routingKey, null, messageBodyBytes);\n```\n\nExample of using Ruby (maybe for Cucumber testing):\n\nhttps://www.rabbitmq.com/tutorials/tutorial-one-ruby.html\n> gem install bunny --version \">= 1.6.0\"\n\n```ruby\nrequire \"bunny\"\n\nconn = Bunny.new\nconn.start\n\nch = conn.create_channel\n\nq = ch.queue(\"hello\")\nch.default_exchange.publish(\"Hello World!\", :routing_key => q.name)\nputs \" [x] Sent 'Hello World!'\"\n```","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/rtp-akka-lib","private":false,"url":"https://github.com/UKHomeOffice/rtp-akka-lib","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"Akka - Reusable functionality\n=============================\nAkka reusable functionality and Scala Spray functionality/template for general use.\n\nProject built with the following (main) technologies:\n\n- Scala\n\n- SBT\n\n- Akka\n\n- Spray\n\n- Specs2\n\nIntroduction\n------------\nBoot a microservice utilising functionality built on top of Spray.\n\nCreate an application and include \"routes\" to expose an API to access via HTTP.\nBuild up your own routes, noting that \"service-statistics\" route is automatically exposed for you and can be accessed as (for example):\n```bash\nhttp://localhost:9100/service-statistics\n```\nwhich would give you something like:\n```javascript\n{\n  statistics: {\n    uptime: \"36663930295 nanoseconds\"\n    total-requests: \"2\"\n    open-requests: \"1\"\n    maximum-open-requests: \"1\"\n    total-connections: \"1\"\n    open-connections: \"1\"\n    max-open-connections: \"1\"\n    request-timeouts: \"0\"\n  }\n}\n```\n\nBuild and Deploy\n----------------\nThe project is built with SBT. On a Mac (sorry everyone else) do:\n> brew install sbt\n\nIt is also a good idea to install Typesafe Activator (which sits on top of SBT) for when you need to create new projects - it also has some SBT extras, so running an application with Activator instead of SBT can be useful. On Mac do:\n> brew install typesafe-activator\n\nTo compile:\n> sbt compile\n\nor\n> activator compile\n\nTo run the specs:\n> sbt test\n\nTo run integration specs:\n> sbt it:test\n\nTo run integration specs:\n> sbt it:test \n\nConfiguration\n-------------\nTODO\n\nThe project utilises Artifactory to resolve in-house modules. Do the following:\n1. Copy the .credentials file into your <home directory>/.ivy2/\n2. Edit this .credentials file to fill in the artifactory security credentials (amend the realm name and host where necessary)\n\n> sbt publish\n\nNote that initially this project refers to some libraries held within a private Artifactory. However, those libraries have been open sourced under https://github.com/UKHomeOffice.\n\nTesting\n-------\nNote regarding testing of application that utilises Spray.\nAt the time of writing this, Spray was in maintenance mode because of its migration to Akka HTTP.\nUnfortunately, Spray uses a now out of date Specs2 library. This can be resolved by adding the following class into the package \"spray.testkit\" within the \"test\" directory of your application:\n```scala\npackage spray.testkit\n\nimport org.specs2.execute.{ Failure, FailureException }\nimport org.specs2.specification.core.{ Fragments, SpecificationStructure }\nimport org.specs2.specification.create.DefaultFragmentFactory\n\n/**\n * Spray's built-in support for specs2 is built against specs2 2.x, not 3.x.\n * So you cannot use the Specs2Interface from spray but need to compile one yourself (against specs2 3.x).\n * That is what this code does, taken from https://gist.github.com/gmalouf/51a8722b50f6a9d30404\n * Note that the build has to exclude Specs2 as a transitive dependency from the Spray testkit.\n */\ntrait Specs2Interface extends TestFrameworkInterface with SpecificationStructure {\n  def failTest(msg: String) = {\n    val trace = new Exception().getStackTrace.toList\n    val fixedTrace = trace.drop(trace.indexWhere(_.getClassName.startsWith(\"org.specs2\")) - 1)\n    throw new FailureException(Failure(msg, stackTrace = fixedTrace))\n  }\n\n  override def map(fs: ⇒ Fragments) = super.map(fs).append(DefaultFragmentFactory.step(cleanUp()))\n}\n\ntrait NoAutoHtmlLinkFragments extends org.specs2.specification.dsl.ReferenceDsl {\n  override def linkFragment(alias: String) = super.linkFragment(alias)\n\n  override def seeFragment(alias: String) = super.seeFragment(alias)\n}\n```\n\nSBT - Revolver\n--------------\nsbt-revolver is a plugin for SBT enabling a super-fast development turnaround for your Scala applications:\n\nSee https://github.com/spray/sbt-revolver\n\nFor development, you can use ~re-start to go into \"triggered restart\" mode.\nYour application starts up and SBT watches for changes in your source (or resource) files.\nIf a change is detected SBT recompiles the required classes and sbt-revolver automatically restarts your application. \nWhen you press &lt;ENTER&gt; SBT leaves \"triggered restart\" and returns to the normal prompt keeping your application running.\n\nExample Usage\n-------------\n- Actor scheduling:\n```scala\n  class SchedulerSpec extends Specification {\n    \"Actor\" should {\n      \"be scheduled to act as a poller\" in new ActorSystemContext {\n        val exampleSchedulerActor = system.actorOf(Props(new ExampleSchedulerActor), \"exampleSchedulerActor\")\n        exampleSchedulerActor ! Scheduled\n        expectMsg(Scheduled)\n      }\n  \n      \"not be scheduled to act as a poller\" in new ActorSystemContext {\n        val exampleSchedulerActor = system.actorOf(Props(new ExampleSchedulerActor with NoSchedule), \"exampleNoSchedulerActor\")\n        exampleSchedulerActor ! Scheduled\n        expectMsg(NotScheduled)\n      }\n    }\n  }\n  \n  class ExampleSchedulerActor extends Actor with Scheduler {\n    val schedule: Cancellable = schedule(initialDelay = 1 second, interval = 5 seconds, receiver = self, message = Wakeup)\n  \n    def receive = LoggingReceive {\n      case Wakeup => println(\"Hello World!\")\n    }\n  }\n```\n\n- Create some Spray routings - HTTP contract/gateway to your microservice:\n```scala\n  object ExampleRouting1 extends ExampleRouting1\n  \n  trait ExampleRouting1 extends Routing {\n   val route =\n     pathPrefix(\"example1\") {\n       pathEndOrSingleSlash {\n         get {\n           complete { JObject(\"status\" -> JString(\"Congratulations 1\")) }\n         }\n       }\n     }\n  }\n  \n  object ExampleRouting2 extends ExampleRouting2\n    \n  trait ExampleRouting2 extends Routing {\n   val route =\n     pathPrefix(\"example2\") {\n       pathEndOrSingleSlash {\n         get {\n           complete { JObject(\"status\" -> JString(\"Congratulations 2\")) }\n         }\n       }\n     }\n  }\n```\n\n- Create your application (App) utilitising your routings (as well as anything else e.g. booting/wiring Akka actors):\n```scala\n  object ExampleBoot extends App with SprayBoot with ExampleConfig {\n    // You must provide an ActorSystem for Spray.\n    implicit lazy val sprayActorSystem = ActorSystem(\"example-boot-actor-system\")\n  \n    bootRoutings(ExampleRouting1 ~ ExampleRouting2 ~ ExampleRoutingError)(FailureHandling.exceptionHandler)\n  }\n```\n\nNoting that a \"configuration\" such as application.conf must be provided e.g.\n```scala\n  spray.can.server {\n    name = \"example-spray-can\"\n    host = \"0.0.0.0\"\n    port = 9100\n    request-timeout = 1s\n    service = \"example-http-routing-service\"\n    remote-address-header = on\n  }\n```\n\nTo run ExampleBoot:\n```bash\nsbt test:run\n```\n\nAkka Clustering\n---------------\nCluster Singleton:\n\nActors can be managed in a cluster to run as a singleton - an actor will be distributed on multiple nodes, but only one will be running.\n\nYour application.conf for a Cluster Singleton, can use the following template:\n```javascript\nakka {\n  actor {\n    provider = \"akka.cluster.ClusterActorRefProvider\"\n  }\n\n  remote {\n    enabled-transports = [\"akka.remote.netty.tcp\"]\n\n    netty.tcp {\n      hostname = \"127.0.0.1\"\n      port = 0 # To be overridden in code for each running node in a cluster\n    }\n  }\n\n  cluster {\n    seed-nodes = [\n      \"akka.tcp://your-actor-system@127.0.0.1:2551\",\n      \"akka.tcp://your-actor-system@127.0.0.1:2552\",\n      \"akka.tcp://your-actor-system@127.0.0.1:2553\"\n    ]\n\n    roles = [\"your-service\"]\n    min-nr-of-members = 2\n    auto-down-unreachable-after = 30 seconds\n  }\n}\n```\n\nEach node that starts up on the same box would need a different port e.g. 2551, 2552 etc.\nIn production, the nodes would be on different boxes and so can all have the same ports and said port could then also be declared for akka.actor.remote.netty.tcp.port.\n\nThere is an example app showing a makeshift cluster of 3 nodes:\n```scala\nobject ClusterActorSystemExampleApp extends App with Network {\n  withConfig {\n    // Imagine we are starting up 3 nodes on 3 separate boxes (here we will have simply utilise 3 separately configured ports).\n    val actorSystem1 = ClusterActorSystem(1)\n    val actorSystem2 = ClusterActorSystem(2)\n    val actorSystem3 = ClusterActorSystem(3)\n    ...\n  }\n}    \n```","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/rtp-test-lib","private":false,"url":"https://github.com/UKHomeOffice/rtp-test-lib","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"Test - Scala testing functionality\n==================================\nScala testing functionality for general use (originally written for Registered Traveller UK).\n\nProject built with the following (main) technologies:\n\n- Scala\n\n- SBT\n\n- Specs2\n\nIntroduction\n------------\nTODO\n\nBuild and Deploy\n----------------\nThe project is built with SBT. On a Mac (sorry everyone else) do:\n> brew install sbt\n\nIt is also a good idea to install Typesafe Activator (which sits on top of SBT) for when you need to create new projects - it also has some SBT extras, so running an application with Activator instead of SBT can be useful. On Mac do:\n> brew install typesafe-activator\n\nTo compile:\n> sbt compile\n\nor\n> activator compile\n\nTo run the specs:\n> sbt test\n\nTo run integration specs:\n> sbt it:test\n\nPublishing\n----------\nTo publish the jar to artifactory you will need to \n\n1. Copy the .credentials file into your <home directory>/.ivy2/\n2. Edit this .credentials file to fill in the artifactory security credentials (amend the realm name and host where necessary)\n\nSBT - Revolver\n--------------\nsbt-revolver is a plugin for SBT enabling a super-fast development turnaround for your Scala applications:\n\nSee https://github.com/spray/sbt-revolver\n\nFor development, you can use ~re-start to go into \"triggered restart\" mode.\nYour application starts up and SBT watches for changes in your source (or resource) files.\nIf a change is detected SBT recompiles the required classes and sbt-revolver automatically restarts your application. \nWhen you press &lt;ENTER&gt; SBT leaves \"triggered restart\" and returns to the normal prompt keeping your application running.\n\nExample Usage\n-------------\nTODO","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/certificate-service-enquiry-form","private":false,"url":"https://github.com/UKHomeOffice/certificate-service-enquiry-form","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Certificate service prototype\n\nPrototype created (using the [Express](http://expressjs.com/) [Prototype Kit](https://github.com/tombye/express_prototype)) by Home Office Digital's Service Optimisation team to test improvements to:\n\n- [Order a copy of a birth, death or marriage certificate](https://www.gov.uk/order-copy-birth-death-marriage-certificate)\n","travis":false,"contributing":"# Contribution guidelines\n\nWe really like contributions and bug reports, in fact the project wouldn't have got to this stage without them. \nWe do have a few guidelines to bear in mind.\n\n## GOV.UK Elements\n\nThe project contains code taken from the [GOV.UK Elements](https://github.com/alphagov/govuk_elements/) project.\nPlease check that any issues related to that code are raised with that project, not this one.\n\n## Raising bugs\n\nWhen raising bugs please explain the issue in good detail and provide a guide to how to replicate it. \nWhen describing the bug it's useful to follow the format:\n\n- what you did\n- what you expected to happen\n- what happened\n\n## Suggesting features\n\nPlease raise feature requests as issues before contributing any code.\nThis is just to ensure they are discussed properly before any time is spent on them.\n\n## Contributing code\n\n### Indentation and whitespace\n\n2-space, soft-tabs only please. No trailing whitespace.\n\n### Versioning\n\nWe use [semantic versioning](http://semver.org/), and bump the version\non master only. Please don't submit your own proposed version numbers.\n\n### Commit hygiene\n\nPlease see our [git style guide](https://github.com/alphagov/styleguides/blob/master/git.md)\nwhich describes how we prefer git history and commit messages to read.\n","masterBranchProtection":false},{"name":"UKHomeOffice/vcloud-launcher","private":false,"url":"https://github.com/UKHomeOffice/vcloud-launcher","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"vCloud Launcher\n===============\nA tool that takes a YAML or JSON configuration file describing a vDC, and\nprovisions the vApps and VMs contained within.\n\n### Supports\n\n- Configuration of multiple vApps/VMs with:\n  - multiple NICs\n  - custom CPU and memory size\n  - multiple additional disks\n  - custom VM metadata\n- Basic idempotent operation - vApps that already exist are skipped.\n\n### Limitations\n\n- Source vApp Template must contain a single VM. This is VMware's recommended\n'simple' method of vApp creation. Complex multi-VM vApps are not supported.\n- Org vDC Networks must be precreated.\n- vCloud has some interesting ideas about the size of potential 'guest\ncustomisation scripts' (aka preambles). You may need to use an external minify\ntool to reduce the size, or speak to your provider to up the limit. 2048 bytes\nseems to be a practical default maximum.\n\n## Installation\n\nAdd this line to your application's Gemfile:\n\n    gem 'vcloud-launcher'\n\nAnd then execute:\n\n    $ bundle\n\nOr install it yourself as:\n\n    $ gem install vcloud-launcher\n\n\n## Usage\n\n`vcloud-launch node.yaml`\n\n## Configuration schemas\n\nConfiguration schemas can be found in [`lib/vcloud/launcher/schema/`][schema].\n\n[schema]: /lib/vcloud/launcher/schema\n\n## Credentials\n\nPlease see the [vcloud-tools usage documentation](http://gds-operations.github.io/vcloud-tools/usage/).\n\n## Contributing\n\n1. Fork it\n2. Create your feature branch (`git checkout -b my-new-feature`)\n3. Commit your changes (`git commit -am 'Add some feature'`)\n4. Push to the branch (`git push origin my-new-feature`)\n5. Create new Pull Request\n\n## Other settings\n\nvCloud Launcher uses vCloud Core. If you want to use the latest version of\nvCloud Core, or a local version, you can export some variables. See the Gemfile\nfor details.\n\n## The vCloud API\n\nvCloud Tools currently use version 5.1 of the [vCloud API](http://pubs.vmware.com/vcd-51/index.jsp?topic=%2Fcom.vmware.vcloud.api.doc_51%2FGUID-F4BF9D5D-EF66-4D36-A6EB-2086703F6E37.html). Version 5.5 may work but is not currently supported. You should be able to access the 5.1 API in a 5.5 environment, and this *is* currently supported.\n\nThe default version is defined in [Fog](https://github.com/fog/fog/blob/244a049918604eadbcebd3a8eaaf433424fe4617/lib/fog/vcloud_director/compute.rb#L32).\n\nIf you want to be sure you are pinning to 5.1, or use 5.5, you can set the API version to use in your fog file, e.g.\n\n`vcloud_director_api_version: 5.1`\n\n## Debugging\n\n`export EXCON_DEBUG=true` - this will print out the API requests and responses.\n\n## Testing\n\nRun the default suite of tests (e.g. lint, unit, features):\n\n    bundle exec rake\n\nThere are also integration tests. These are slower and require a real environment.\nSee the [vCloud Tools website](http://gds-operations.github.io/vcloud-tools/testing/) for details of how to set up and run the integration tests.\n\nThe parameters required to run the vCloud Launcher integration tests are:\n\n````\ndefault: # This is the fog credential that refers to your testing environment, e.g. `test_credential`\n  vdc_1_name: # The name of a VDC\n  vdc_2_name: # The name of another VDC - you need two in your organisation to run these tests\n  catalog: # A catalog\n  vapp_template: # A vApp Template within that catalog\n  network_1: # The name of the primary network\n  network_1_ip: # The IP address of the primary network\n  network_2: # The name of a secondary network\n  network_2_ip: # The IP address of the secondary network\n  storage_profile: # The name of a storage profile (not the default)\n  default_storage_profile_name: # The name of the default storage profile\n  default_storage_profile_href: # The href of the default storage profile\n  vdc_1_storage_profile_href: # The href of `storage_profile` in `vdc_1`\n  vdc_2_storage_profile_href: # The href of `storage_profile` in `vdc_2`\n````\n\nThere is an additional rake task on vCloud Launcher that runs the integration tests minus some that are very slow:\n\n    bundle exec rake integration:quick\n","travis":false,"contributing":"# Contributing to vCloud Launcher\n\nWe really welcome contributions.\n\n## A quick guide on how to contribute\n\n1. Clone the repo:\n\n        git clone git@github.com:gds-operations/vcloud-launcher.git\n\n2. Run `bundle` to get the required dependecies\n\n3. Run the tests. Pull requests that add features must include unit tests,\n   so it is good to ensure you've got them passing to begin with.\n\n        bundle exec rake\n\n   If you have access to a live environment for testing, it would be great\n   if you could run the integration tests too - for more details on the\n   set-up for that, please see the [integration tests README]\n   (https://github.com/gds-operations/vcloud-launcher/blob/master/spec/integration/README.md)\n\n4. Add your functionality or bug fix and a test for your change. Only refactoring and\n   documentation changes do not require tests. If the functionality is at all complicated\n   then it is likely that more than one test will be required. If you would like help\n   with writing tests please do ask us.\n\n5. Make sure all the tests pass, including the integration tests if possible.\n\n6. Update the [CHANGELOG](https://github.com/gds-operations/vcloud-launcher/blob/master/CHANGELOG.md)\n   with a short description of what the change is. This may be a feature, a bugfix, or an\n   API change. If your change is documenation or refactoring, you do not need to add a line\n   to the CHANGELOG.\n\n7. Fork the repo, push to your fork, and submit a pull request.\n\n## How soon will we respond?\n\nWe will comment on your pull request within two working days. However, we might not be able to review it immediately.\n\nWe may come back to you with comments and suggestions, and if we would like you to make changes, we will close the pull request as well as adding details of the changes we'd like you to make.\n\nIf you feel your pull request has been outstanding too long, please feel free to bump it by making a comment on it.\n\n## Guidelines for making a pull request\n\n    The key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\", \"SHALL NOT\", \"SHOULD\",\n    \"SHOULD NOT\", \"RECOMMENDED\",  \"MAY\", and \"OPTIONAL\" in this document are to be\n    interpreted as described in RFC 2119.\n\n## In order for a pull request to be accepted, it MUST\n\n- Include at least one test (unless it is documentation or refactoring). If you have any questions about how to write tests, please ask us, we will be happy to help\n- Follow our [Git style guide](https://github.com/alphagov/styleguides/blob/master/git.md)\n- Include a clear summary in the pull request comments as to what the change is and why\n  you are making it\n- Be readable - we might ask you to change unclear variable names or obscure syntactic sugar\n- Have [good commit messages](http://robots.thoughtbot.com/5-useful-tips-for-a-better-commit-message)\n  that explain the change being made in that commit. Don't be afraid to write a lot in the\n  detail.\n\n## In order for a pull request to be accepted, it SHOULD\n\n- Include a line in the CHANGELOG unless it is a refactoring or documentation change\n- If it is code, follow our [Ruby style guide](https://github.com/alphagov/styleguides/blob/master/ruby.md)\n- If it is documentation, follow the [GDS content style guide](https://www.gov.uk/design-principles/style-guide/style-points)\n","masterBranchProtection":false},{"name":"UKHomeOffice/brp_app","private":false,"url":"https://github.com/UKHomeOffice/brp_app","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# BRP Application project for nodejs\n\n[![Docker Repository on Quay.io](https://quay.io/repository/ukhomeofficedigital/brpapp/status \"Docker Repository on Quay.io\")](https://quay.io/repository/ukhomeofficedigital/brpapp) [![Build Status](https://travis-ci.org/UKHomeOffice/brp_app.svg)](https://travis-ci.org/UKHomeOffice/brp_app)\n\n## Quick start\n\nInstall the dependencies and build the project resources\n```bash\n$ npm install\n```\n\nInstall `Redis` and make sure you have a running redis instance in the background.\n\nInitiate the server in development mode (Express is used to serve the static resources in development).\n```bash\n$ npm run dev\n```\n\nThen select one of the following journeys to see the applcation in action\n\n- [Collection](http://localhost:8080/collection)\n- [Someone else](http://localhost:8080/someone-else)\n- [Not arrived](http://localhost:8080/not-arrived)\n- [Correct mistakes](http://localhost:8080/correct-mistakes)\n- [Lost or stolen](http://localhost:8080/lost-stolen)\n\nSee the [development documentation](./documentation/DEVELOPMENT.MD) for a complete description of the application and how to maintain and support BRP.\n\n\n## NPM scripts\n\nStart the application in default mode (production).\nWe use Nginx to serve our static resources in production and ci.\n```bash\n$ npm start\n```\n\nStart the application with [Nodemon](https://www.npmjs.com/package/nodemon) in development mode.\nDebug is switched on and the server restarts when the JS or Sass are recompiled.\n```bash\n$ npm run dev\n```\n\nRun the unit tests\n```bash\n$ npm run test\n```\n\nRun the EcmaScript (ES) linter.  Rules are defined in [.eslintrc](./.eslintrc)\n```bash\n$ npm run lint\n```\n\nRun the jscs style checker. Rules are defined in [.jscsrc.json](./.jscsrc.json)\n```bash\n$ npm run style\n```\n\nAnalyse the quality of the codebase (for results - open [./reports/plato/index.html](./reports/plato/index.html))\n```bash\n$ npm run quality\n```\n\nCompile the Sass to CSS\n```bash\n$ npm run sass\n```\n\n_____________________________________________________________\n\n- For details on [Acceptance tests](https://github.com/UKHomeOffice/brp_app/tree/master/acceptance_tests)\n\n- See the [package.json](./package.json) for a full list of scripts.\n\n- Full list of [environment variables](./documentation/ENVIRONMENT_VARIABLES.md)\n\n","travis":true,"contributing":"# Contribution guidelines\n\nWe welcome patches!\n\n## Commit hygiene\n\nWe like to follow the recommendations set out in the GDS [git style guide][gitstyle]\nwhich describes how we prefer git history and commit messages to read.\n\n[gitstyle]: https://github.com/alphagov/styleguides/blob/master/git.md\n\n## JavaScript\n\nWe have a JavaScript style checker `npm run style`\n\nAll our styles are defined in our [JavaScript style config][jsstyle]\n\nWe follow the [Google JavaScript style guide](https://google.github.io/styleguide/javascriptguide.xml)\n\nWe also lint our code `npm run lint`.\n\n[jsstyle]: https://github.com/UKHomeOffice/brp_app/blob/master/.jscsrc.json\n\nA pre commit hook is run as part of the project which runs the above checks and our tests (`npm run test`).\n\n## Visual changes\n\nFor visual changes, it can be helpful to provide images in your pull-request\nshowing before and after to highlight the differences.","masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/brp_app/branches/master/protection","restrictions":{"url":"https://api.github.com/repos/UKHomeOffice/brp_app/branches/master/protection/restrictions","users":[{"login":"easternbloc","id":92585,"avatarUrl":"https://avatars.githubusercontent.com/u/92585?v=3","gravatarId":"","url":"https://api.github.com/users/easternbloc","htmlUrl":"https://github.com/easternbloc","followersUrl":"https://api.github.com/users/easternbloc/followers","subscriptionsUrl":"https://api.github.com/users/easternbloc/subscriptions","organizationsUrl":"https://api.github.com/users/easternbloc/orgs","reposUrl":"https://api.github.com/users/easternbloc/repos","receivedEventsUrl":"https://api.github.com/users/easternbloc/received_events","type":"User"}],"usersUrl":"https://api.github.com/repos/UKHomeOffice/brp_app/branches/master/protection/restrictions/users","teams":[],"teamsUrl":"https://api.github.com/repos/UKHomeOffice/brp_app/branches/master/protection/restrictions/teams"}}},{"name":"UKHomeOffice/performanceplatform-js-style-configs","private":false,"url":"https://github.com/UKHomeOffice/performanceplatform-js-style-configs","license":null,"readme":"# Performance Platform - Javascript style configs\n\nCentralised configs for JSHint and JSCS style-checking.\n\nJSHint is focussed around code correctness more logic-based checks.\n\nJSCS is about code style, eg use of braces whitespace and indentation.\n\nTo install these configs as an NPM module in your own project:\n\n```\nnpm install performanceplatform-js-style-configs\n```\n\n## JSHint\n\nThere are two separate JSHint config files:\n- .jshintrc-node - for Node projects so the list of assumed globals doesn't include those for a browser environment eg window, document\n- .jshint-browser - allows browser globals\n\nTo install JSHint globally:\n\n```\nnpm install jshint -g\n```\n\nTo run JSHint from the root of the host project:\n\n```\njshint --config ./node_modules/performanceplatform-js-style-configs/.jshintrc-browser.json\n```\n\n## JSCS\n\nJavascript code style checking.\n- .jscrc\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/platform_email_service","private":false,"url":"https://github.com/UKHomeOffice/platform_email_service","license":null,"readme":"# platform_email_service\nEmail Microservice in NodeJS\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/platform_email_service.svg)](https://travis-ci.org/UKHomeOffice/platform_email_service)\n\nGetting started\n\nIf you need a development mail server I suggest [Fake SMTP](https://nilhcem.github.io/FakeSMTP/) no setup, just follow the instructions.\n\nEdit `config/smtp.json` to point to your smtp server (if using FakeSMTP bind this to port 8082 and set that as your port in this file)\nEdit `config/template.json` to point to your template path\n\n`$ npm install`\n\n`$ node app.js`\n\n\n\n## Template API End points\nThese will be deprecated in the future\n\nBoth of the GET methods can take an optional header paramter of templatepath to specify an non standard path\n\nGET template/list to retrieve a list of templates returns 200 or 404\n \nGET template/get/<templateName> to retrieve a specific template returns 200 or 404\n\nPOST template/add with the following body parameters creates a new template returns 201 or 400\n\n```\n  templatePath: <optional>\n  body: <raw html of the template>\n  name: <the templates name for on the filesystem>\n```\n\nPUT template/update/<templatename> with the following body parameters creates a new template returns 200 or 400\n\n```\n  templatePath: <optional>\n  body: <raw html of the template>\n  name: <the templates name for on the filesystem>\n```\n\nDELETE template/delete/<templatename> removes a template from the filesystem returns 204 or 400 with an empty body\n\n## Email API End points\n\nThese will be deprecated in the future\n\nPOST email/send with the following payload as a JSON string to send an email will return a 201 or 400 \n\n```\n  dataModel = {\n    \"sender\": \"test@localhost\", \n    \"recipient\": \"recipient@localhost\",\n    \"subject\": \"<message subject>\",\n    \"template\": \"<template name>\",\n    \"data\": {\n      //Template data in key value pairs                     \n    }\n```\n\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/platform_queue_service","private":false,"url":"https://github.com/UKHomeOffice/platform_queue_service","license":null,"readme":"# platform_queue_service\nQueuing Micro Service in Node.js\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/platform_queue_service.svg)](https://travis-ci.org/UKHomeOffice/platform_queue_service)\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/vcloud_ipsec-vpn","private":false,"url":"https://github.com/UKHomeOffice/vcloud_ipsec-vpn","license":{"key":"apache-2.0","name":"Apache License 2.0","spdxId":"Apache-2.0","url":"https://api.github.com/licenses/apache-2.0","featured":true},"readme":"# Vpnconfig\nA command line tool to allow use of a yaml VPN configuration file to push this config to Skyscape\n\n## Installation\nAdd this line to your application's Gemfile:\n\n```ruby\ngem 'vcloud_ipsec-vpn'\n```\n\nAnd then execute:\n\n    $ bundle install\n\nOr install it yourself as:\n\n    $ gem install vcloud_ipsec-vpn\n    \nRequire it in your ruby code using:\nrequire 'vcloud_ipsec-vpn'\n\n## Usage\nRun with option --help to show command line help.\n\nExample command line with gem installed:\nvcloud_ipsec-vpn -d DataCentre1 -u JohnSmith -w vpn-configuration.yaml\n\nExample command line if you have cloned the repository without installing as a gem:\nbundle exec ./bin/vcloud_ipsec-vpn -d DataCentre1 -u JohnSmith -w vpn-configuration.yaml\n\nExample yaml input is provided in test/vpn-configuration-example.yaml\n\nThe yaml schema is provided in lib/vpn-configuration-schema.yaml\n\n## Development\n\nAfter checking out the repo, run `bin/setup` to install dependencies. Then, run `bin/console` for an interactive prompt that will allow you to experiment.\n\nTo install this gem onto your local machine, run `bundle exec rake install`. To release a new version, update the version number in `version.rb`, and then run `bundle exec rake release` to create a git tag for the version, push git commits and tags, and push the `.gem` file to [rubygems.org](https://rubygems.org).\n\n## Contributing\n\n1. Fork it ( https://github.com/UKHomeOffice/vcloud_ipec-vpn/fork )\n2. Create your feature branch (`git checkout -b my-new-feature`)\n3. Commit your changes (`git commit -am 'Add some feature'`)\n4. Push to the branch (`git push origin my-new-feature`)\n5. Create a new Pull Request\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/vcloudToolsGenerator","private":false,"url":"https://github.com/UKHomeOffice/vcloudToolsGenerator","license":null,"readme":"# vcloudToolsGenerator\nAn attempt at abstracting the vcloud-tools format to quickly generate and launch a cluster.  Has some coreos/kubernetes stuff in here, but you don't need to be using that for this to be useful.\n\nwhat works.\n==\n- vapps\n- networks\n- uploading iso's\n- lanching everything (assuming you don't need nat, firewall or vpn rules first)\n\nwhat doesn't work\n==\n- vpn\n- firewall\n- nat\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/lev-rpm-builder-ords","private":false,"url":"https://github.com/UKHomeOffice/lev-rpm-builder-ords","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Docker Oracle REST Data Services RPM Builder\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/lev-rpm-builder-ords.svg?branch=master)](https://travis-ci.org/UKHomeOffice/lev-rpm-builder-ords)\n\nThis project contains a Dockerfile for a container that will build an Oracle REST Data Service RPM package with SystemV script.\n\n## Getting Started\n\nThese instructions will tell you how to use this container to build an RPM.\n\n### Prerequisities\n\nYou'll need some form of docker that can have a volume mounted where it'll put the RPM. \n\n[Boot2docker](http://boot2docker.io/) works if you want to test it on your local machine. The following commands once you run boot2docker will get it up an running. It mounts the \"/Users\" directory in the VM, we'll use this as the output path for the RPM to get it on our hosts directory.  \n\n```\nboot2docker init \nboot2docker up \neval \"$(boot2docker shellinit)\"\n```\n\nFor licensing reasons we can't distribute the ORDs zip file. [Download it](http://www.oracle.com/technetwork/developer-tools/rest-data-services/ords-30-downloads-2373781.html) and store it somewhere wget-able before we start.\n\n### Running\n\nAssuming you have a docker instance to communicate with\n\n```shell\ndocker build -t rpm-builder-ords . && docker run -e \"ORDS_ZIP=http://example.com/path/to/zip\" -v $(pwd):/rpmbuild rpm-builder-ords \n```\n\nWill cause an RPM to fall out at ```$(pwd)``` named ```ords-3.0.0.121.10.23-1.x86_64.rpm```\n\nYou can customise the RPM output directory in the container by setting the ```$RPM_OUTPUT_DIR``` environment variable.\n\n## RPM Details\n\n* The RPM will install to `/opt/ords.3.0.0/`\n* The RPM comes with a SystemV script\n* The SystemV script will configure ORDs from the `/opt/ords.3.0.0/params/ords_params.properties`. If this file is updated ORDs will be reconfigured when restarted. \n* The config file can have the parameters defined in the [documentation for ORDs](https://docs.oracle.com/cd/E56351_01/doc.30/e56293/config_file.htm#AELIG7204).\n\n## Testing the RPM\n\nThere is bundled a [vagrant](https://www.vagrantup.com/) file that starts a CentOS 6 machine, that can be used for testing the RPM.\n\nIt has a base image for [VirtualBox](https://www.virtualbox.org/).\n\n## Built With\n\n* [ORDs](http://www.oracle.com/technetwork/developer-tools/rest-data-services) - Great for avoiding connecting to Oracle directly.\n* [FPM](https://github.com/jordansissel/fpm) - Makes making RPMs very easy.\n* [Docker](https://www.docker.com) - So we can statically link to RedHat compatible binaries even if we're not running on RedHat.\n\n# Find us\n\n##  Docker repository\n[ukhomeofficedigital/lev-rpm-builder-ords](https://registry.hub.docker.com/u/ukhomeofficedigital/lev-rpm-builder-ords)\n\n## GitHub\n[UKHomeOffice/lev-rpm-builder-ords](https://github.com/UKHomeOffice/lev-rpm-builder-ords)\n\n\n## Contributing\n\nFeel free to submit pull requests and issues. If it's a particularly large PR, you may wish to discuss it in an issue first.\n\nPlease note that this project is released with a [Contributor Code of Conduct](https://github.com/UKHomeOffice/lev-rpm-builder-ords/blob/master/code_of_conduct.md). By participating in this project you agree to abide by its terms.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for the version tags available See the tags on this repository. \n\n## Authors\n\n* **Billie Thompson** - *Developer* - [PurpleBooth](https://github.com/PurpleBooth)\n\nSee also the list of [contributors](https://github.com/UKHomeOffice/lev-rpm-builder-ords/contributors) who participated in this project.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](https://github.com/UKHomeOffice/lev-rpm-builder-ords/blob/master/LICENSE.md) file for details\n\n## Acknowledgments\n\n* jordansissel for writing FPM and saving my santity trying to build RPMs\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/lev-rpm-builder-openresty","private":false,"url":"https://github.com/UKHomeOffice/lev-rpm-builder-openresty","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Docker Centos 6 OpenResty with Naxsi RPM Builder\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/lev-rpm-builder-openresty.svg?branch=master)](https://travis-ci.org/UKHomeOffice/lev-rpm-builder-openresty)\n\nThis project contains a Dockerfile for a container that will build an OpenResty RPM package with Naxsi and Lua included, statically linked to CentOS 6 packages.\n\n## Getting Started\n\nThese instructions will tell you how to use this container to build an RPM.\n\n### Prerequisities\n\nYou'll need some form of docker that can have a volume mounted where it'll put the RPM. \n\n[Boot2docker](http://boot2docker.io/) works if you want to test it on your local machine. The following commands once you run boot2docker will get it up an running. It mounts the \"/Users\" directory in the VM, we'll use this as the output path for the RPM to get it on our hosts directory.  \n\n```\nboot2docker init \nboot2docker up \neval \"$(boot2docker shellinit)\"\n```\n\n### Running\n\nAssuming you have a docker instance to communicate with\n\n```shell\ndocker build -t rpm-builder-waf . && docker run -v $(pwd):/rpmbuild rpm-builder-waf  \n```\n\nWill cause an RPM to fall out at ```$(pwd)``` named ```ngx_openresty-1.7.10.1-1.x86_64.rpm```\n\nYou can customise the RPM output directory in the container by setting the ```$RPM_OUTPUT_DIR``` environment variable.\n\n## RPM Details\n\n* The RPM will install to `/usr/local/openresty/`\n* The RPM comes with a SystemV script\n* The RPM will install example HTTPS certificate at ```/usr/local/openresty/nginx/conf/example.crt``` and ```/usr/local/openresty/nginx/conf/example.key```\n* The nginx configuration file to set which servers it connects to can be found at ```/usr/local/openresty/nginx/conf/nginx.conf```\n\n## Testing the RPM\n\nThere is bundled a [vagrant](https://www.vagrantup.com/) file that starts a CentOS 6 machine, that can be used for testing the RPM.\n\nIt has a base image for [VirtualBox](https://www.virtualbox.org/).\n\n## Built With\n\n* [OpenResty](http://openresty.org/) - It's very suitable for making WAF firewalls.\n* [FPM](https://github.com/jordansissel/fpm) - Makes making RPMs very easy.\n* [Docker](https://www.docker.com) - So we can statically link to RedHat compatible binaries even if we're not running on RedHat.\n* [Naxsi](https://github.com/nbs-system/naxsi) - Framework for writing Web Application Firewalls\n\n# Find us\n\n##  Docker repository\n[ukhomeofficedigital/lev-rpm-builder-openresty](https://registry.hub.docker.com/u/ukhomeofficedigital/lev-rpm-builder-openresty)\n\n## GitHub\n[UKHomeOffice/lev-rpm-builder-openresty](https://github.com/UKHomeOffice/lev-rpm-builder-openresty)\n\n\n## Contributing\n\nFeel free to submit pull requests and issues. If it's a particularly large PR, you may wish to discuss it in an issue first.\n\nPlease note that this project is released with a [Contributor Code of Conduct](https://github.com/UKHomeOffice/lev-rpm-builder-openresty/blob/master/code_of_conduct.md). By participating in this project you agree to abide by its terms.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for the version tags available See the tags on this repository. \n\n## Authors\n\n* **Billie Thompson** - *Developer* - [PurpleBooth](https://github.com/PurpleBooth)\n\nSee also the list of [contributors](https://github.com/UKHomeOffice/lev-rpm-builder-openresty/contributors) who participated in this project.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](https://github.com/UKHomeOffice/lev-rpm-builder-openresty/blob/master/LICENSE.md) file for details\n\n## Acknowledgments\n\n* jordansissel for writing FPM and saving my santity trying to build RPMs\n* The Naxsi team for writing an awesome module\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/kb8or","private":false,"url":"https://github.com/UKHomeOffice/kb8or","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# kb8or\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/kb8or.svg?branch=master)](https://travis-ci.org/UKHomeOffice/kb8or)\n\nContinuous Deployment Tool for deploying with [Kubernetes](http://kubernetes.io/).\n\n## Features\n1. Will deploy any Kubernetes YAML files by creating / re-creating or do rolling update as required\n2. Monitors for success (including restarts) of applications (where [kubectl client](http://kubernetes.io/v1.0/docs/getting-started-guides/aws/kubectl.html) doesn't). \n3. Reports on failures and display logs and errors for failing resources\n3. Container images AND resource version management\n4. Application environment specific variables (for deployments to dev, pre-prod, production)\n\n## Pre-requisites\n1. A running Kubernetes cluster\n2. Either  \n   1. [Ruby](https://www.ruby-lang.org/en/documentation/installation/) 2.x, bundler, [kubectl client](http://kubernetes.io/v1.0/docs/getting-started-guides/aws/kubectl.html) client.  \n   2. [Docker](#docker-prerequisites).\n\n## Install (if not using Docker)\n   \n1. Download the [kubectl client](http://kubernetes.io/v1.0/docs/getting-started-guides/aws/kubectl.html).\n2. `bundle install`\n   \n## Usage\n\n### Schema\n\nAll features and configurable options are described in the [Schema Documentation](./docs/schema.md).\n\n### As a container:\n`docker run -it --rm -v ${PWD}:/var/lib/deploy quay.io/ukhomeofficedigital/kb8or --help`\n\n### Locally:\n`./kb8or.rb --help`\n\n### Deploy an 'environment':\n\nDeploy to \"default\" environment (usually vagrant):\n`./kb8or.rb mydeploy.yaml`\n\nDeploy to specific environment:\n`./kb8or.rb mydeploy.yaml --env pre-production`\n\nA deployment will do the following:\n\n1. Any (defaults.yaml) will be loaded (from the same directory as the deployment)\n2. Any environment data will then be parsed (based on EnvFileGlobPath set in config)\n3. Each deploy will be loaded and settings will be updated\n4. kubectl will be used to setup the Kb8or specific context settings (typically set per environment)\n4. Any Kubernetes .yaml files in the path specified will be parsed and deployed / updated as required.\n\n### Examples:\n\n* For a walk through of features see [docs/example/Example.md](docs/example/Example.md).\n* Example of creation of multiple ResourceControllers from a [templated Elasticsearch](docs/example/elasticsearch/Example.md) resource.\n\n## Docker-prerequisites\n\nIn order to run this in a container you'll need docker installed:\n\n* [Windows](https://docs.docker.com/windows/started)\n* [OS X](https://docs.docker.com/mac/started/)\n* [Linux](https://docs.docker.com/linux/started/)\n\nIt is currently hosted here: https://quay.io/repository/ukhomeofficedigital/kb8or\n\n## Contributing\n\nFeel free to submit pull requests and issues. If it's a particularly large PR, you may wish to discuss it in an issue first.\n\nPlease note that this project is released with a [Contributor Code of Conduct](CONTRIBUTING.md). \nBy participating in this project you agree to abide by its terms.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the [tags on this repository](https://github.com/your/project/tags).\n\nTo create a new version:\n\n1. update the [version](version) file.\n2. Push a tag of the same version name to build Docker image at https://quay.io/repository/ukhomeofficedigital/kb8or\n\n## Authors\n\n* **Lewis Marshall** - *Initial work* - [Lewis Marshall](https://github.com/lewismarshall)\n\nSee also the list of [contributors](https://github.com/UKHomeOffice/kb8or/contributors) who participated in this project.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details\n\n## Acknowledgments\n\n* [Kubernetes](http://kubernetes.io/)\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/docker-oracle-database-express-edition-11g","private":false,"url":"https://github.com/UKHomeOffice/docker-oracle-database-express-edition-11g","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Oracle Database Express Edition 11g Container\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-oracle-database-express-edition-11g.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-oracle-database-express-edition-11g)\n\nThis provides a docker container for Oracle XE 11g.\n\n## Usage\n\n### Basic Usage\n\nDue to licensing problems we cannot distribute the oracle RPM.\n\nHowever this doesn't mean the setup process has to be horribly complicated. Simply create a new docker file that extends this docker file, place the [zip from oracle with the RPM in](http://www.oracle.com/technetwork/database/database-technologies/express-edition/downloads/index.html) a ```docker_files``` directory, and build it.\n\nYour Dockerfile will be tiny and look like this:\n\n```Dockerfile\nFROM ukhomeofficedigital/oracle-xe-11g:2.0.2\n```\n\nSee [/example](https://github.com/UKHomeOffice/docker-oracle-database-express-edition-11g/tree/master/example) if you're not sure what I mean.\n\n### Volumes\n\nData is stored to the volume ```/u01/app/oracle```\n \n### Customise the database on first run\n\nThe container will try to run ```/init_only.sh``` before running Oracle XE if there aren't any data files. You can use this script to initialise your database, simply add it in the container you have created which extends this one.\n\n## Version Compatibility\n\nThis was built for oracle-xe-11.2.0-1.0, however with minor tweaks it would probably work for other versions.\n\n# Docker tags\n\nWe use [SemVer](http://semver.org/) for the version tags available See the tags on this repository. \n\n# Find us\n\n##  Docker repository\n[ukhomeofficedigital/oracle-xe-11g](https://registry.hub.docker.com/u/ukhomeofficedigital/oracle-xe-11g)\n\n## GitHub\n[UKHomeOffice/docker-oracle-database-express-edition-11g](https://github.com/UKHomeOffice/docker-oracle-database-express-edition-11g)\n\n\n# Contributing\n\nFeel free to create pull requests or issues. \n\nPlease note that this project is released with a [Contributor Code of Conduct](https://github.com/UKHomeOffice/docker-oracle-database-express-edition-11g/blob/master/code_of_conduct.md). By participating in this project you agree to abide by its terms.\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/Office365-PowerShellScripts","private":false,"url":"https://github.com/UKHomeOffice/Office365-PowerShellScripts","license":null,"readme":"# Office 365 Powershell Scripts \nUse this repo for powershell scripts for user provisioning and reporting etc.\n\nDocument scritps in terms of functionality in this readme, but ideally scripts should contian comments so this page only needs to act as an index.\n\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-aws-drupal","private":false,"url":"https://github.com/UKHomeOffice/docker-aws-drupal","license":null,"readme":"","travis":"","contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-nginx-gateway","private":false,"url":"https://github.com/UKHomeOffice/docker-nginx-gateway","license":{"key":"apache-2.0","name":"Apache License 2.0","spdxId":"Apache-2.0","url":"https://api.github.com/licenses/apache-2.0","featured":true},"readme":"\n\n##### **NGINX Gateway**\n\nThe NGINX Gateway (version 1.9.2 with stream module) is a small container service used to provision TCP and HTTP[S] service from kubernetes (tested on version 0.18.2). Essetially we're not running in proper cloud provider but needed a dynamic means of provisioning external load balanced / exposed services. The data, i.e. services and minions is consumed the etcd cluster kubernetes is running via confd (note: confd is purely being used as a trigger to pull down the data and push into json arrays of services: [] and minions: [], the reason being that templating in go is hideous. \n\n    [template]\n    src   = \"nginx.conf.tmpl\"\n    dest  = \"/etc/nginx/config.json\"\n    keys  = [ \n      \"/registry/services/specs/\",\n      \"/registry/minions\",\n    ]\n    owner = \"root\"\n    mode  = \"0444\"\n    \n    reload_cmd = \"/usr/sbin/nginx -s reload\"\n    check_cmd  = \"/bin/nginx_check {{ .src }}\"\n\nOnce the data is in the config file: /bin/nginx_check is used to generate the nginx config, with in ruby erb. At the moment the container is pushed out via fleet and mapped to the docker host network (--net=host) so we don't have to preconfigure ports. \n\n##### **Services**\n\nThe load balancer config is store in the annontation of the service descriptor. Note, due to the fact that kubernetes wont allow complex types in annotation, i.e. will only support simple key values, I encode the content as a yaml string.\n\n    apiVersion: v1beta3\n    kind: Service\n    metadata:\n      labels:\n        name: gitlab-redis\n        role: service\n      name: gitlab-redis\n      annotations:\n        loadbalancer: |\n          6379:\n            # port: PORT  \n            type: tcp  \n    spec:\n      portalIP: 10.101.100.100\n      ports:\n        - port: 6379\n          targetPort: 6379\n      selector:\n        name: gitlab-redis\n\nBy default services use 'port' from the spec as the externally exposed spec, though this can be override using 'port' in the loadbalacer section. For websites\n  \n    apiVersion: v1beta3\n    kind: Service\n    metadata:\n      labels:\n        name: gitlab-web\n      name: gitlab-web\n      annotations:\n        loadbalancer: |\n          80:\n            type: http\n            vhost: gitlab.example.com\n            # paths: [] # optional nginx locations\n          443:\n            type: http\n            vhost: gitlab.example.com\n            ssl:\n              key: <filename>\n              cert: <filename>\n\nNote: at the moment the virtualhost on the same port are not consolidated, i.e say you have site X and you have Y backends which you wish to serve on different locations | url's; so / goes to default, /admin goes to backend 1 etc etc. At the moment, i'm not preprocessing the vhosts to perform this, a hash of vhost:port is maintained to ensure you dont try and add the same vhost on the same port.\n\n##### **Flannel & Service Ports** \n \nBy passing the -e FLANNEL_ENABLED=true flag into the container, the config generated assumed the docker host it's running on is a member or at the very least mapped into the flannel network and will thus use the portalIP / clusterIP to access the services. If the flag is not enabled we assume the service is being exposed via the NodePort or PublicIPs and use the minion ip addresses at the upstream backends in nginx.\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/monologue.js","private":false,"url":"https://github.com/UKHomeOffice/monologue.js","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# monologue.js\n\n### What is it?\nmonologue provides 'event-emitting' functionality - commonly referred to as \"pub/sub\" - that can be mixed into/inherited by your JavaScript objects.\n\n##### Philosophy\nmonologue's pub/sub implementation uses the observer pattern - meaning that subscribers should have a direct reference to the 'monologue-ized' object emitting the events.  This is in contrast to monologue's sister library, [postal.js](https://github.com/postaljs/postal.js), which uses the mediator pattern to relieve publishers and subscribers from the need to have a direct reference to each other.  Putting a monologue instance in the prototype chain of an object turns  it into an \"event emitter\". This is incredibly useful in organizing how other *local* (within a limited scope/module) instances are notified of something the object wants to publish. monologue is designed to be bridged with [postal.js](https://github.com/postaljs/postal.js) if you want to 'promote' an event into an app-level message - and the [monopost](https://github.com/postaljs/monopost.js) add-on exists to do just that.\n\n##### Really? Another Event Emitter?\nI know, right?!  There are a number of EventEmitter implementations that are very useful (and compact) - my favorite of which is [EventEmitter2](https://github.com/hij1nx/EventEmitter2). So why did I write monologue? Three main reasons:\n\n* **I wanted postal/AMQP-like wildcard binding semantics.**  The \"*\" wildcard matches exactly one word in a topic, while the \"#\" wildcard matches 0-n words.\n* **I prefer an \"envelope\" payload in an event vs passing 0-n arguments to a subscriber callback.**  This means we get a consistent callback signature everywhere. Consistency causes kittens to turn into angels and get their wings.\n* **I wanted to have a choice to opt-into safe invocation of subscriber callbacks.** Most Event Emitter style implementations (that I've seen) blindly fire the subscriber callback - and if the callback throws an uncaught exception, the entire event-emit breaks. \"But won't a try/catch slow things down?\" Yes, there is a performance hit, that's why it's something you opt-into. (I've asked myself these two questions: How many times has an event emitter been the bottleneck in my app? And how many times has a subscriber callback been guilty of tanking the app? In my experience, the latter happens **far more often** than the former.)\n\n### Why should I use it?\nIf you want to extend your objects with the ability to trigger custom events, take advantage of the wildcard binding options, trust that subscriber callbacks can't tank the emitter while it's triggering events, and/or have consistent callback signatures, then monologue might be for you.\n\n### How do I use it?\n##### Adding monologue functionality to an instance\n\nYou can use the `mixInto` helper function, which mixes Monologue into the prototype of your object:\n\n\tvar Worker = function(name) {\n\t    this.name = name;\n\t};\n\tWorker.prototype.doWork = function() {\n\t    this.emit(\"work.done\", { who: this.name });\n\t};\n\tMonologue.mixInto(Worker);\n\n\nYou can also manually put a monologue instance in the prototype chain of an object:\n\n\tvar Worker = function(name) {\n\t    this.name = name;\n\t};\n\tWorker.prototype = Monologue.prototype;\n\tWorker.prototype.doWork = function() {\n\t    this.emit(\"work.done\", { who: this.name });\n\t};\n\nAn alternative approach would be to 'mix-in' to an existing instance via a helper like [lodash's](http://lodash.com/) [assign](http://lodash.com/docs#assign) call:\n\n\t_.assign(\n\t    plainJane,\n\t    {\n\t        doWork: function() {\n\t            this.emit(\"work.done\", { who: this.name });\n\t        }\n\t    },\n\t    Monologue.prototype);\n\nmonologue uses [riveter](https://github.com/ifandelse/riveter) for it's inheritance/mixin capabilities. There's a *lot* you can do with riveter, so check it out.\n\n##### Adding an event listener\nAny object that has monologue's behavior has an `on` method which can be used to subscribe to events.  The first argument of `on()` is the `topic` (just a string event name, which can optionally be a period-delimited string for hierarchical use).  The second argument of `on()` is the `callback` which should be invoked when the event occurs. Calling `on` returns a `SubscriptionDefinition` - giving you a convenient way to unsubscribe or apply additional options (discussed below) to the subscription.\n\n\tvar instance = new Worker(); // get an instance of something that has monologue's behavior\n\n\t// subscribe to listen for 'some.event'\n\tvar subscription = instance.on(\"some.event\", function(data, envelope){\n\t    console.log(\"Something happened thanks to \" + data.name);\n\t});\n\nAs you can see in the example above, the subscription callback takes two arguments: `data` and `envelope`.  Like many facets of monologue, this matches the behavior of postal.js.  The `data`\nargument is simply the data published when the event was emitted.  The `envelope` provides additional metadata about the event, and can be customized to fit your needs.  By default, the envelope has three members: `data`, `topic` and `timeStamp`.  For example:\n\n\t// pretending we're inside of a monologue-ized object:\n\tthis.emit(\"some.event\", { foo: 'bar', baz: 'bacon' });\n\n\t// pretending we're somewhere else setting up the subscriber:\n\tvar subscription = instance.on(\"some.event\", function(data, envelope){\n\t\t/*\n\t\t  data would look like:\n\t\t\t{\n\t\t\t\tfoo: 'bar',\n\t\t\t\tbaz: 'bacon'\n\t\t\t}\n\n\t\t  envelope would look like:\n\t\t  \t{\n\t\t  \t\ttopic: 'some.event',\n\t\t  \t\ttimeStamp: '2012-10-21T02:53:10.287Z',\n\t\t  \t    data: {\n\t\t\t\t\tfoo: 'bar',\n\t\t\t\t\tbaz: 'bacon'\n\t\t\t\t}\n\t\t\t}\n\t\t*/\n\t});\n\n##### Wildcard Subscriptions\nAs mentioned above, the `*` and `#` characters represent wildcards available when you subscribe to events. Topics are string values, and are often period-delimited. The part of the topic delimited by a period is called a 'word'. Using a `*` represents exactly one word in a topic, while the `#` character matches 0-n words.  For example:\n\n\t// The topic binding below will match \"name.changed\" and \"city.changed\"\n\t// but it will not match \"changed\" or \"user.location.changed\"\n\tvar subscription = instance.on(\"*.changed\", function(data, envelope){\n\t\t// handle event data here….\n\t});\n\n\t// The topic binding below will match \"name.changed\", \"city.changed\"\n\t// \"changed\" and \"user.location.changed\"\n\tvar subscription = instance.on(\"#.changed\", function(data, envelope){\n\t\t// handle event data here….\n\t});\n\n\t// Also - you can use the wildcards together:\n\t// this binding will match user.email.validation.failed, user.zip.validation.success\n\t// as well as password.validation.success, but NOT customer.order.validation.retry.cancel\n\tvar subscription = instance.on(\"#.validation.*\", function(data, envelope){\n\t\t// handle event data here….\n\t});\n\n##### Unsubscribing\nYou have four possible ways to remove event listeners in monologue:\n\n###### Removing a specific listener\nWhen you use `on` to subscribe to an event, it returns a `SubscriptionDefinition` object. This object contains several helper methods, one of which is `unsubscribe`:\n\n\tvar subscription = instance.on(\"#.changed\", function(data, envelope){\n\t\t// handle event data here….\n\t});\n\n\tsubscription.unsubscribe();\n\n###### Removing all listeners for a topic\nHowever, you can also call the `off` method on the monlogue-ized event emitter object:\n\n\tvar subscription = instance.on(\"#.changed\", function(data, envelope){\n\t\t// handle event data here….\n\t});\n\n\t// remove just this one subscription\n\tinstance.off(subscription);\n\n\t// remove all subscriptions for a topic\n\tinstance.off(\"#.changed\");\n\n###### Removing all listeners for a topic/context combination\nOne of the SubscriptionDefinition helper methods is `withContext` - which allows you to specifiy the `this` context you want to apply to the subscription callback when it is invoked. Because of this, it's possible to remove all listeners for a specific topic that are using a particular 'context':\n\n\tvar subscription = instance.on(\"#.changed\", function(data, envelope){\n\t\t// handle event data here….\n\t}).withContext(someObject);\n\n\t// remove just this one subscription\n\tinstance.off(subscription);\n\n\t// remove all subscriptions for the topic + context combination\n\tinstance.off(\"#.changed\", someObject);\n\n###### Removing ALL listeners, period.\nThis is the 'nuke it from orbit' option. Simply call `off` with no arguments, and all subscriptions will be removed from the object.\n\n\tvar subscriptionA = instance.on(\"#.changed\", function(data, envelope){\n\t\t// handle event data here….\n\t}).withContext(someObject);\n\n\tvar subscriptionB = instance.on(\"*.moar\", function(data, envelope){\n\t\t// handle event data here….\n\t}).withContext(someOtherObject);\n\n\t// buh-bye all subscriptions...\n\tinstance.off();\n\n##### Subscription Options\nAs mentioned above - the `SubscriptionDefinition` object returned from a call to the `on` method provides some additional fluent configuration options:\n\n* **`withContext(object)`** - the provided argument becomes the `this` context inside the subscription callback.\n* **`defer`** - delays the invocation of the callback until the event loop is free (via setTimeout of 0 milliseconds).\n* **`disposeAfter(count)`** - automatically unsubscribes the subscription after the number of invocations specified.\n* **`once`** - a shortcut to disposeAfter(1).\n* **`distinctUntilChanged`** - keeps track of the last data published with an event and only invokes the callback if the new data differs from the old data.\n* **`distnct`** - keeps track of the data published with an event and only invokes the callback if it's different from anything published previously.\n* **`withConstraint(predicateFn)`** - the predicateFn argument is a function with the same signature as the subscriber callback (data,envelope).  Returning true from this function will cause the subscription callback to be invoked, returning false will prevent it from firing.\n* **`withConstraints([predicateFns])`** - same as `withConstraint`, but it takes an array of predicates instead of one.\n* **`withDebounce(milliseconds)`** - uses underscore's debounce function to cause the subscription callback to only be invoked a minimum of {x} milliseconds after the events cease being published.\n* **`withDelay(milliseconds)`** - delays invocation of the subscriber callback for the number of milliseconds specified.\n* **`withThrottle(milliseconds)`** - causes the subscriber callback to be invoked at most once per {x} milliseconds interval.\n\n##### Other Monologue Options\n###### Customizing the Envelope\nAny object that has been extended with Monologue's behavior will have a `getEnvelope` method which you can override to customize how the envelope is created. The default implementation looks like this:\n\n\n\t// The default implementation just marks the envelope with a time stamp.\n\t// The topic and data are attached to the envelope just before it's published\n\tgetEnvelope: function(topic, data) {\n\t\treturn {\n\t\t\ttimeStamp: new Date()\n\t\t};\n\t}\n\n\nNote that the topic and data being published are passed in for optional use - allowing you to configure envelope data at run time, based on the event in progress.\n\n###### Error Tracking\nOne of the core features of monologue is that subscriber callbacks won't be able to crash the event emitter with uncaught exceptions. While developers **should** be cleaning up after themselves (and not crashing things with uncaught exceptions), they don't always do so. We don't want to simply swallow those exceptions, so by default monologue will store them in an aptly named `_yuno` member - which is an array of objects, where each object contains the subscription definition instance that threw the uncaught exception, as well as the envelope being published at the time of the event.  You can turn error tracking off by setting the `_trackErrors` member to `false`:\n\n\n\n\tvar Worker = function(name) {\n\t    this.name = name;\n\t};\n\tWorker.prototype = Monologue.prototype;\n\tvar instance = new Worker();\n\tinstance._trackErrors = false;\n\n\n##### Customizing Wildcard Bindings\nJust like it's sister library postal.js, monologue's bindingsResolver object can be overridden with your own implementation. Don't like how AMQP's wildcards work? Want to create something that uses different characters, or logic in matching topics? All you have to do is create an object that implements a `compare(binding, topic)` method (where `binding` is the topic value used when a subscriber was added and `topic` is the actual topic of the event being published).  This function should return true for a match, or false otherwise.  Simply create your own resolver and replace the existing resolver with your own:\n\n\n\tMonologue.resolver = {\n\t    compare: function(binding, topic) {\n\t         // The magic happens here….\n\t    }\n\t}\n\n## Build, Dependencies, etc.\n\n* monologue depends on [lodash.js](http://lodash.com/) and a fork of [riveter](https://github.com/ifandelse/riveter/tree/0cffebb92117c88543cb4359fb9fd69c2d65dd22)\n* monologue uses [gulp.js](http://gulpjs.com/) for building, running tests and examples.\n    * To build\n        * run `npm install` (to install all deps)\n        * run `bower install` (yep, we're using at least one thing only found on bower in the local project runner)\n        * run `gulp` then check the lib folder for the output\n    * To run tests & examples\n        * Tests are node-based: `gulp test`\n        * To run browser-based examples:\n            * run `gulp server`\n            * navigate in your browser to <http://localhost:3080/>\n            * if you want to see test coverage or plato reports be sure to run `gulp coverage` and `gulp report` (respectively) in order to generate them, as they are not stored with the repo.\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/wascally","private":false,"url":"https://github.com/UKHomeOffice/wascally","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Wascally\nThis is a very opinionated abstraction over amqplib to help simplify certain common tasks and (hopefully) reduce the effort required to use RabbitMQ in your Node services.\n\n### Features:\n\n * Gracefully handle re-connections\n * Automatically re-define all topology on re-connection\n * Automatically re-send any unconfirmed messages on re-connection\n * Support the majority of RabbitMQ's extensions\n * Handle batching of acknowledgements and rejections\n * Topology & configuration via the JSON configuration method (thanks to @JohnDMathis!)\n\n### Assumptions & Defaults:\n\n * Fault-tolerance/resilience over throughput\n * Default to publish confirmation\n * Default to ack mode on consumers\n * Heterogenous services that include statically typed languages\n * JSON as the only serialization provider\n\n### Demos\n\n * [pubsub](https://github.com/LeanKit-Labs/wascally/blob/master/demo/pubsub/README.md)\n\n# API Reference\nThis library implements promises for many of the calls via when.js.\n\n## Sending & Receiving Messages\n\n### Publish\nThe publish call returns a promise that is only resolved once the broker has accepted responsibility for the message (see [Publisher Acknowledgments](https://www.rabbitmq.com/confirms.html) for more details). In the rare event that the broker rejects the message, the promise will be rejected. More commonly, the connection to the broker could be lost before the message is confirmed and you end up with a message in \"limbo\". Wascally keeps a list of unconfirmed messages that have been published _in memory only_. Once a connection is re-established and the topology is in place, Wascally will prioritize re-sending these messages before sending anything else.\n\nIn the event of a disconnect, all publish promises that have not been resolved are rejected. __This behavior is a problematic over-simplification and subject to change in a future release.__\n\n### publish( exchangeName, options, [connectionName] )\nThis syntax uses an options object rather than arguments, here's an example showing all of the available properties:\n\n```javascript\nrabbit.publish( 'exchange.name', {\n\t\troutingKey: 'hi',\n\t\ttype: 'company.project.messages.textMessage',\n\t\tcorrelationId: 'one',\n\t\tbody: { text: 'hello!' },\n\t\tmessageId: '100',\n\t\texpiresAfter: 1000 // TTL in ms, in this example 1 second\n\t\ttimestamp: // posix timestamp (long)\n\t\theaders: {\n\t\t\t'random': 'application specific value'\n\t\t}\n\t},\n\tconnectionName: '' // another optional way to provide connection name if needed\n);\n```\n\n### publish( exchangeName, typeName, messageBody, [routingKey], [correlationId], [connectionName] )\nMessages bodies are simple objects. A type specifier is required for the message which will be used to set AMQP's properties.type. If no routing key is provided, the type specifier will be used. A routing key of '' will prevent the type specifier from being used.\n\n```javascript\n// the first 3 arguments are required\n// routing key is optional and defaults to the value of typeName\n// connectionName is only needed if you have multiple connections to different servers or vhosts\n\nrabbit.publish( 'log.entries', 'company.project.messages.logEntry', {\n\t\tdate: Date.now(),\n\t\tlevel: logLevel,\n\t\tmessage: message\n\t}, 'log.' + logLevel, someValueToCorrelateBy );\n```\n\n### request( exchangeName, options, [connectionName] )\nThis works just like a publish except that the promise returned provides the response (or responses) from the other side.\n\n```javascript\n// when multiple responses are provided, all but the last will be provided via the .progress callback.\n// the last/only reply will always be provided to the .then callback\nrabbit.request( 'request.exchange', {\n\t\t// see publish example to see options for the outgoing message\n\t} )\n\t.progress( function( reply ) {\n\t\t// if multiple replies are provided, all but the last will be sent via the progress callback\n\t} )\n\t.then( function( final ) {\n\t\t// the last message in a series OR the only reply will be sent to this callback\n\t} );\n```\n\n### handle( typeName, handler, [context] )\n\n> Handle calls should happen __before__ starting subscriptions.\n\nMessage handlers are registered to handle a message based on the typeName. Calling handle will return a reference to the handler that can later be removed. The message that is passed to the handler is the raw Rabbit payload. The body property contains the message body published. The message has `ack`, `nack` (requeue the message) and `reject` (don't requeue the message) methods control what Rabbit does with the message.\n\n#### Explicit Error Handling\nIn this example, any possible error is caught in an explicit try/catch:\n\n```javascript\nvar handler = rabbit.handle( 'company.project.messages.logEntry', function( message ) {\n\ttry {\n\t\t// do something meaningful?\n\t\tconsole.log( message.body );\n\t\tmessage.ack();\n\t} catch( err ) {\n\t\tmessage.nack();\n\t}\n} );\n\nhandler.remove();\n```\n\n#### Automatically Nack On Error\nThis example shows how to have wascally wrap all handlers with a try catch that:\n\n * nacks the message on error\n * console.log that an error has occurred in a handle\n\n```javascript\n// after this call, any new callbacks attached via handle will be wrapped in a try/catch\n// that nacks the message on an error\nrabbit.nackOnError();\n\nvar handler = rabbit.handle( 'company.project.messages.logEntry', function( message ) {\n\tconsole.log( message.body );\n\tmessage.ack();\n} );\n\nhandler.remove();\n\n// after this call, new callbacks attached via handle will *not* be wrapped in a try/catch\nrabbit.ignoreHandlerErrors();\n```\n\n#### Late-bound Error Handling\nProvide a strategy for handling errors to multiple handles or attach an error handler after the fact.\n\n```javascript\nvar handler = rabbit.handle( 'company.project.messages.logEntry', function( message ) {\n\tconsole.log( message.body );\n\tmessage.ack();\n} );\n\nhandler.catch( function( err, msg ) {\n\t// do something with the error & message\n\tmsg.nack();\n} );\n```\n\n#### !!! IMPORTANT !!! ####\nFailure to handle errors will result in silent failures and lost messages.\n\n### Unhandled Messages\nIn previous versions, if a subscription was started in ack mode (the default) without a handler to process the message, the message would get lost in limbo until the connection (or channel) was closed and then the messages would be returned to the queue. This is very confusing and undesirable behavior. To help protect against this, the new default behavior is that any message received that doesn't have any elligible handlers will get `nack`'d and sent back to the queue immediately.\n\nThis is _still_ problematic because it can create churn on the client and server as the message will be redelivered indefinitely.\n\nTo change this behavior, use one of the following calls:\n\n> Note: only one of these strategies can be activated at a time\n\n#### onUnhandled( handler )\n```javascript\nrabbit.onUnhandled( function( message ) {\n\t // handle the message here\n} );\n```\n\n#### nackUnhandled() - default\nSends all unhandled messages back to the queue.\n```javascript\nrabbit.nackUnhandled();\n```\n\n#### rejectUnhandled()\nRejects unhandled messages so that will will _not_ be requeued. **DO NOT** use this unless there are dead letter exchanges for all queues.\n```javascript\nrabbit.rejectUnhandled();\n```\n\n### startSubscription( queueName, [connectionName] )\n\n> Recommendation: set handlers for anticipated types up before starting subscriptions.\n\nStarts a consumer on the queue specified. `connectionName` is optional and only required if subscribing to a queue on a connection other than the default one.\n\n## Message Format\nThe following structure shows and briefly explains the format of the message that is passed to the handle callback:\n\n```javascript\n{\n\t// metadata specific to routing & delivery\n\tfields: {\n\t\tconsumerTag: \"\", // identifies the consumer to rabbit\n\t\tdeliveryTag: #, // identifies the message delivered for rabbit\n\t\tredelivered: true|false, // indicates if the message was previously nacked or returned to the queue\n\t\texchange: \"\" // name of exchange the message was published to,\n\t\troutingKey: \"\" // the routing key (if any) used when published\n\t},\n\tproperties:{\n\t\tcontentType: \"application/json\", // wascally's default\n\t\tcontentEncoding: \"utf8\", // wascally's default\n\t\theaders: {}, // any user provided headers\n\t\tcorrelationId: \"\", // the correlation id if provided\n\t\treplyTo: \"\", // the reply queue would go here\n\t\tmessageId: \"\", // message id if provided\n\t\ttype: \"\", // the type of the message published\n\t\tappId: \"\" // not used by wascally\n\t},\n\tcontent: { \"type\": \"Buffer\", \"data\": [ ... ] }, // raw buffer of message body\n\tbody: , // this could be an object, string, etc - whatever was published\n\ttype: \"\" // this also contains the type of the message published\n}\n```\n\n## Message API\nWascally defaults to (and assumes) queues are in ack mode. It batches ack and nack operations in order to improve total throughput. Ack/Nack calls do not take effect immediately.\n\n### message.ack()\nEnqueues the message for acknowledgement.\n\n### message.nack()\nEnqueues the message for rejection. This will re-enqueue the message.\n\n### message.reject()\nRejects the message without re-queueing it. Please use with caution and consider having a dead-letter-exchange assigned to the queue before using this feature.\n\n### message.reply( message, [more], [replyType] )\nAcknowledges the messages and sends the message back to the requestor. The `message` is only the body of the reply. Providing true to `more` will cause the message to get sent to the .progress callback of the request promise so that you can send multiple replies. The `replyType` argument sets the type of the reply message. (important when messaging with statically typed languages)\n\n### Queues in `noBatch` mode\nWascally now supports the ability to put queues into non-batching behavior. This causes ack, nack and reject calls to take place against the channel immediately. This feature is ideal when processing messages are long-running and consumer limits are in place. Be aware that this feature does have a significant impact on message throughput.\n\n## Reply Queues\nBy default, wascally creates a unique reply queue for each connection which is automatically subscribed to and deleted on connection close. This can be modified or turned off altogether.\n\nChanging the behavior is done by passing one of three values to the `replyQueue` property on the connection hash:\n\n> !!! IMPORTANT !!! wascally cannot prevent queue naming collisions across services instances or connections when using the first two options.\n\n### Custom Name\nOnly changes the name of the reply queue that wascally creates - `autoDelete` and `subscribe` will be set to `true`.\n\n```javascript\nrabbit.addConnection( {\n\tname: 'default',\n\treplyQueue: 'myOwnQueue',\n\tuser: 'guest',\n\tpass: 'guest',\n\tserver: '127.0.0.1',\n\tport: 5672,\n\ttimeout: 2000,\n\tvhost: '%2f'\n} );\n```\n\n### Custom Behavior\nTo take full control of the queue name and behavior, provide a queue definition in place of the name.\n\n> wascally provides no defaults - it will only use the definition provided\n\n```javascript\nrabbit.addConnection( {\n\tname: 'default',\n\treplyQueue: {\n\t\tname: 'myOwnQueue',\n\t\tsubscribe: 'true',\n\t\tdurable: true\n\t},\n\tuser: 'guest',\n\tpass: 'guest',\n\tserver: '127.0.0.1',\n\tport: 5672,\n\ttimeout: 2000,\n\tvhost: '%2f'\n} );\n```\n\n### No Automatic Reply Queue\n> Only pick this option if request/response isn't in use or when providing a custom overall strategy\n\n```javascript\nrabbit.addConnection( {\n\tname: 'default',\n\treplyQueue: false,\n\tuser: 'guest',\n\tpass: 'guest',\n\tserver: '127.0.0.1',\n\tport: 5672,\n\ttimeout: 2000,\n\tvhost: '%2f'\n} );\n```\n\n## Managing Topology\n\n### addExchange( exchangeName, exchangeType, [options], [connectionName] )\nThe call returns a promise that can be used to determine when the exchange has been created on the server.\n\nValid exchangeTypes:\n * 'direct'\n * 'fanout'\n * 'topic'\n\nOptions is a hash that can contain the following:\n * autoDelete\t\ttrue|false\t\tdelete when consumer count goes to 0\n * durable \t\t\ttrue|false\t\tsurvive broker restarts\n * persistent \t\ttrue|false\t\ta.k.a. persistent delivery, messages saved to disk\n * alternate \t\t'alt.exchange'\tdefine an alternate exchange\n\n### addQueue( queueName, [options], [connectionName] )\nThe call returns a promise that can be used to determine when the queue has been created on the server.\n\nOptions is a hash that can contain the following:\n * autoDelete\t\ttrue|false\t\tdelete when consumer count goes to 0\n * durable \t\t\ttrue|false\t\tsurvive broker restarts\n * exclusive\t\ttrue|false\t\tlimits queue to the current connection only (danger)\n * subscribe\t\ttrue|false\t\tauto-start the subscription\n * limit \t\t\t2^16\t\t\tmax number of unacked messages allowed for consumer\n * noAck\t\t\ttrue|false \t\tthe server will remove messages from the queue as soon as they are delivered\n * noBatch\t\t\ttrue|false \t\tcauses ack, nack & reject to take place immediately\n * queueLimit\t\t2^32\t\t\tmax number of ready messages a queue can hold\n * messageTtl\t\t2^32\t\t\ttime in ms before a message expires on the queue\n * expires\t\t\t2^32\t\t\ttime in ms before a queue with 0 consumers expires\n * deadLetter \t\t'dlx.exchange'\tthe exchange to dead-letter messages to\n\n### bindExchange( sourceExchange, targetExchange, [routingKeys], [connectionName] )\nBinds the target exchange to the source exchange. Messages flow from source to target.\n\n### bindQueue( sourceExchange, targetQueue, [routingKeys], [connectionName] )\nBinds the target queue to the source exchange. Messages flow from source to target.\n\n## Configuration via JSON\n\n> Note: setting subscribe to true will result in subscriptions starting immediately upon queue creation.\n\nThis example shows most of the available options described above.\n```javascript\n\tvar settings = {\n\t\tconnection: {\n\t\t\tuser: 'guest',\n\t\t\tpass: 'guest',\n\t\t\tserver: '127.0.0.1',\n\t\t\tport: 5672,\n\t\t\ttimeout: 2000,\n\t\t\tvhost: '%2fmyhost'\n\t\t\t},\n\t\texchanges:[\n\t\t\t{ name: 'config-ex.1', type: 'fanout'  },\n\t\t\t{ name: 'config-ex.2', type: 'topic', alternate: 'alternate-ex.2', persistent: true },\n\t\t\t{ name: 'dead-letter-ex.2', type: 'fanout' }\n\t\t\t],\n\t\tqueues:[\n\t\t\t{ name:'config-q.1', limit: 100, queueLimit: 1000 },\n\t\t\t{ name:'config-q.2', subscribe: true, deadLetter: 'dead-letter-ex.2' }\n\t\t\t],\n\t\tbindings:[\n\t\t\t{ exchange: 'config-ex.1', target: 'config-q.1', keys: [ 'bob','fred' ] },\n\t\t\t{ exchange: 'config-ex.2', target: 'config-q.2', keys: 'test1' }\n\t\t]\n\t};\n```\n\nTo establish a connection with all settings in place and ready to go call configure:\n```javascript\n\tvar rabbit = require( 'wascally' );\n\n\trabbit.configure( settings ).done( function() {\n\t\t// ready to go!\n\t} );\n```\n\n## Closing Connections\nWascally will attempt to resolve all outstanding publishes and recieved messages (ack/nack/reject) before closing the channels and connection. If you would like to defer certain actions until after everything has been safely resolved, then use the promise returned from either close call.\n\n> !!! CAUTION !!! - using reset is dangerous. All topology associated with the connection will be removed meaning wasclly will not be able to re-establish it all should you decide to reconnect.\n\n### close( [connectionName], [reset] )\nCloses the connection, optionall resetting all previously defined topology for the connection. The `connectionName` uses `default` if one is not provided.\n\n### closeAll( [reset] )\nCloses __all__ connections, optionally resetting the topology for all of them.\n\n## AMQPS, SSL/TLS Support\nProviding the following configuration options setting the related environment varibles will cause wascally to attempt connecting via AMQPS. For more details about which settings perform what role, refer to the amqplib's page on [SSL](http://www.squaremobius.net/amqp.node/doc/ssl.html).\n\n```javascript\n\tconnection: { \t\t// sample connection hash\n\t\tcaPath: '', \t// comma delimited paths to CA files. RABBIT_CA\n\t\tcertPath: '', \t// path to cert file. RABBIT_CERT\n\t\tkeyPath: '',\t// path to key file. RABBIT_KEY\n\t\tpassphrase: '', // passphrase associated with cert/pfx. RABBIT_PASSPHRASE\n\t\tpfxPath: ''\t\t// path to pfx file. RABBIT_PFX\n\t}\n```\n\n## Channel Prefetch Limits\n\nWascally mostly hides the notion of a channel behind the scenes, but still allows you to specify channel options such as the channel prefetch limit. Rather than specifying\nthis on a channel object, however, it is specified as a `limit` on a queue defintion.\n\n```js\nqueues: [{\n  // ...\n\n  limit: 5\n}]\n\n// or\n\nrabbit.addQueue(\"some.q\", {\n  // ...\n\n  limit: 5\n});\n```\n\nThis queue configuration will set a prefetch limit of 5 on the channel that is used for consuming this queue.\n\n**Note:** The queue `limit` is not the same as the `queueLimit` option - the latter of which sets the maximum number of messages allowed in the queue.\n\n## Additional Learning Resources\n\n### Watch Me Code\nThanks to Derick Bailey's input, the API and documentation for wascally have improved a lot. You can learn from Derick's hands-on experience in his [Watch Me Code](https://sub.watchmecode.net/categories/rabbitmq/) series.\n\n### RabbitMQ In Action\nAlvaro Vidella and Jason Williams literally wrote the book on [RabbitMQ](http://www.manning.com/videla/).\n\n### Enterprise Integration Patterns\nGregor Hophe and Bobby Woolf's definitive work on messaging. The [site](http://www.enterpriseintegrationpatterns.com/) provides basic descriptions of the patterns and the [book](http://www.amazon.com/Enterprise-Integration-Patterns-Designing-Deploying/dp/0321200683) goes into a lot of detail.\n\nI can't recommend this book highly enough; understanding the patterns will provide you with the conceptual tools need to be successful.\n\n## Contributing\nPRs with insufficient coverage, broken tests or deviation from the style will not be accepted.\n\n### Behavior & Integration Tests\nPRs should include modified or additional test coverage in both integration and behavioral specs. Integration tests assume RabbitMQ is running on localhost with guest/guest credentials and the consistent hash exchange plugin enabled. You can enable the plugin with the following command:\n\n```bash\nrabbitmq-plugins enable rabbitmq_consistent_hash_exchange\n```\n\nRunning gulp will run both sets after every file change and display a coverage summary. To view a detailed report, run gulp coverage once to bring up the browser.\n\n### Vagrant\n\nWascally now provides a sample `Vagrantfile` that will set up a virtual machine that runs RabbitMQ. Under the hood, it uses the official RabbitMQ Docker image. It will forward RabbitMQ's default ports to `localhost`.\n\n**First, you will need to copy the sample file to a usable file:**\n\n```bash\n$ cp Vagrantfile.sample Vagrantfile\n```\n\nAdjust any necessary settings. Then, from the root of the project, run:\n\n```bash\n$ vagrant up\n```\n\nThis will create your box. Right now, it only supports the `vmware_fusion` plugin. To access the box, run:\n\n```bash\n$ vagrant ssh\n```\n\nOnce inside, you can view the RabbitMQ logs by executing:\n\n```bash\n$ docker logs rabbitmq\n```\n\nWhen the Vagrant box is running, RabbitMQ can be accessed at `localhost:5673` and the management console at `http://localhost:15673`. This project uses non-standard ports to avoid conflicting with an existing RabbitMQ install.\n\nClick here for more information on [Vagrant](http://vagrantup.com), [Docker](http://docker.com), and [official RabbitMQ Docker image](https://registry.hub.docker.com/_/rabbitmq/).\n\n*To run tests using Vagrant:*\n\nExecute from the **host machine:**\n\n```bash\n$ vagrant up\n$ gulp\n```\n### Style\nThis project has both an `.editorconfig` and `.esformatter` file to help keep adherance to style simple. Please also take advantage of the `.jshintrc` file and avoid linter warnings.\n\n## Roadmap\n * additional test coverage\n * support RabbitMQ backpressure mechanisms\n * (configurable) limits & behavior when publishing during connectivity issues\n * ability to capture/log unpublished messages on shutdown\n * add support for Rabbit's HTTP API\n * enable better cluster utilization by spreading connections out over all nodes in cluster\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-gradle","private":false,"url":"https://github.com/UKHomeOffice/docker-gradle","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Docker Gradle\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-gradle.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-gradle)\n\nGradle in a docker image, the version of the image / tag will match the version of gradle\n\n## Getting Started\n\nThis is to provide the gradle tool as part of a CI pipeline / local delivery development pipeline\nfor a service. It's to make sure that CI can operate in a complete containerised world.\n\nCode is mounted into the container under /code where that becomes the WORKDIR and then gradle is run\nfrom that directory on the code\n\n### Environment Variables\n\n* `GRADLE_VERSION` - the version of gradle to pull down and install into the docker image\n* `GRADLE_ROOT` - the root of gradle\n* `GRADLE_HOME` - the home directory for gradle\n* `GRADLE_BIN`  - the bin directory for gradle\n\n### Volumes\n\n*  `/root/.gradle/caches` - this is where gradle is holding the cached files\n* `/code` - This is where the code is mounted and is also the WORKDIR\n\n### Other\n\n## Contributing\n\nContributions are most certainly welcome. If you want to introduce a breaking\nchange or any other major change, please raise an issue first to discuss.\n\n## License\n\n[MIT](LICENSE)\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/s3secrets","private":false,"url":"https://github.com/UKHomeOffice/s3secrets","license":null,"readme":"### **S3SECRETS**\n\nIs a command line utility for retrieving, uploading and view files encryted via the AWS KMS service.\n\n```shell\n[jest@starfury s3secrets]$ bin/s3secrets help\nNAME:\n   s3secrets - is a utility for interacting to s3 and kms encrypted files\n\nUSAGE:\n   s3secrets [global options] command [command options] [arguments...]\n   \nVERSION:\n   v0.0.1\n   \nAUTHOR(S):\n   Rohith <gambol99@gmail.com> \n   \nCOMMANDS:\n    kms\t\tprovide a listing of the kms key presently available to us\n    buckets\tprovides a list of the buckets available to you\n    list\tproviding a file listing of the files currently in there\n    get\t\tretrieve one or more files from the s3 bucket\n    cat\t\tretrieves and displays the contents of one or more files to the stdout\n    put\t\tupload one of more files, encrypt and place into the bucket\n    edit\tperform an inline edit of a file either locally or from s3 bucket\n\nGLOBAL OPTIONS:\n   -p, --profile \t\t\t\t\tthe aws profile to use for static credentials [$AWS_DEFAULT_PROFILE]\n   -c, --credentials \"/home/jest/.aws/credentials\"\tthe path to the credentials file container the aws profiles [$AWS_SHARED_CREDENTIALS_FILE]\n   --access-key \t\t\t\t\tthe aws access key to use to access the resources [$AWS_ACCESS_KEY_ID]\n   --secret-key \t\t\t\t\tthe aws secret key to use when accessing the resources [$AWS_SECRET_ACCESS_KEY]\n   -o, --output-dir \"./secrets\"\t\t\t\tthe path to the directory in which to save the files [$KMSCTL_OUTPUT_DIR]\n   --session-token \t\t\t\t\tthe aws session token to use when accessing the resources [$AWS_SESSION_TOKEN]\n   -r, --region \"eu-west-1\"\t\t\t\tthe aws region where the resources are located [$AWS_DEFAULT_REGION]\n   -f, --format \"text\"\t\t\t\t\tthe format of the output to generate (accepts json, yaml or default text)\n   --help, -h\t\t\t\t\t\tshow help\n   --version, -v\t\t\t\t\tprint the version\n```\n\n- **Viewing the KMS keys**\n\n```shell\n[jest@starfury s3secrets]$ bin/s3secrets -p profile_name kms\n74cc9f02-7795-4fe4-888e-2aae97e3eff5     alias/aws/ebs           \n62c6abc6-d1d7-4203-ac3e-5733580dd4eb     alias/dev-kms-eu-west-1\n75430871-d667-4fa5-bfb1-54c832f1d973     alias/prod-kms-eu-west-1\n```\n\n- **Create a bucket and upload the files**\n\n```shell\n[jest@starfury s3secrets]$ export AWS_DEFAULT_PROFILE=profile_name\n[jest@starfury s3secrets]$ bin/s3secrets buckets create -n this-is-my-test-bucket-11991\nsuccessfully created the bucket: this-is-my-test-bucket-11991\n\n[jest@starfury s3secrets]$ ls\nbin  buckets.go  cmd.go  doc.go  files.go  formater.go  Godeps  keys.go  kmscli.iml  LICENSE  main.go  Makefile  release  utils.go\n\n[jest@starfury s3secrets]$ bin/s3secrets put -k 62c6abc6-d1d7-4203-ac3e-5733580dd4eb -b this-is-my-test-bucket-11991 *.go\nsuccessfully pushed the file: buckets.go to s3://this-is-my-test-bucket-11991/buckets.go\nsuccessfully pushed the file: cmd.go to s3://this-is-my-test-bucket-11991/cmd.go\nsuccessfully pushed the file: doc.go to s3://this-is-my-test-bucket-11991/doc.go\nsuccessfully pushed the file: files.go to s3://this-is-my-test-bucket-11991/files.go\nsuccessfully pushed the file: formater.go to s3://this-is-my-test-bucket-11991/formater.go\nsuccessfully pushed the file: keys.go to s3://this-is-my-test-bucket-11991/keys.go\nsuccessfully pushed the file: main.go to s3://this-is-my-test-bucket-11991/main.go\nsuccessfully pushed the file: utils.go to s3://this-is-my-test-bucket-11991/utils.go\n\n[jest@starfury s3secrets]$ bin/s3secrets ls -b this-is-my-test-bucket-11991 -l \nsome.user 2793       26 Apr 16 13:50 UTC  buckets.go\nsome.user 10237      26 Apr 16 13:50 UTC  cmd.go\nsome.user 687        26 Apr 16 13:50 UTC  doc.go\nsome.user 9610       26 Apr 16 13:50 UTC  files.go\nsome.user 1614       26 Apr 16 13:50 UTC  formater.go\nsome.user 1452       26 Apr 16 13:50 UTC  keys.go\nsome.user 661        26 Apr 16 13:50 UTC  main.go\nsome.user 1445       26 Apr 16 13:50 UTC  utils.go\n\n[jest@starfury s3secrets]$ bin/s3secrets cat -b this-is-my-test-bucket-11991 buckets.go | head\n/*\nCopyright 2015 All rights reserved.\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\n\n[jest@starfury s3secrets]$ bin/s3secrets buckets delete -n this-is-my-test-bucket-11991 \n[error] operation failed, error: the bucket is not empty, either force (--force) deletion or empty the bucket\n\n[jest@starfury s3secrets]$ bin/s3secrets buckets delete -n this-is-my-test-bucket-11991 --force\nsuccessfully deleted the bucket: this-is-my-test-bucket-11991\n```\n* **Retrieve the files from the bucket**\n\n```shell\n[jest@starfury s3secrets]$ bin/s3secrets get -b this-is-my-test-bucket-11991 -r -d ./secrets /\nretrieved the file: buckets.go and wrote to: ./secrets/buckets.go\nretrieved the file: cmd.go and wrote to: ./secrets/cmd.go\nretrieved the file: doc.go and wrote to: ./secrets/doc.go\nretrieved the file: files.go and wrote to: ./secrets/files.go\nretrieved the file: formater.go and wrote to: ./secrets/formater.go\nretrieved the file: keys.go and wrote to: ./secrets/keys.go\nretrieved the file: main.go and wrote to: ./secrets/main.go\n```\n","travis":false,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change.\n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a\n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment\n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you\n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and\nwelcoming community, we pledge to respect all people who contribute through reporting issues,\nposting feature requests, updating documentation, submitting pull requests or patches, and other\nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone,\nregardless of level of experience, gender, gender identity and expression, sexual orientation,\ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits,\ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By\nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently\napplying these principles to every aspect of managing this project. Project maintainers who do not\nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is\nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an\nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org),\nversion 1.2.0, available at\n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)","masterBranchProtection":false},{"name":"UKHomeOffice/docker-fedora-baseservices","private":false,"url":"https://github.com/UKHomeOffice/docker-fedora-baseservices","license":null,"readme":"# docker-fedora-baseservices\nDocker base services fedora image\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/check_byod","private":false,"url":"https://github.com/UKHomeOffice/check_byod","license":null,"readme":"# check_byod\nScript to check OS is compliant with CESG guidelines\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/aws_usersync","private":false,"url":"https://github.com/UKHomeOffice/aws_usersync","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# aws_usersync\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/aws_usersync.svg?branch=master)](https://travis-ci.org/UKHomeOffice/aws_usersync)\n\nThis is used for syncing users from AWS to the local machine as well as their user key. It runs as a daemon and polls with whatever interval you define. By default it is set to run only once and exit, but this can be overriden.\n\nThe default group people are added to is sudo, but this can be overriden to add users to an alternative group.\n\nThis was written primarily to only work with AWS and also CoreOS. The user keys are really for AWS CodeCommit service, however, as they are\nassociated with the IAM account, they become accessible through IAM. It isn't particularly obvious that you need to place your key there but this is where it needs to go. \n\n### AWS IAM\n\nIf a user logs in to AWS Console and goes to AWS IAM Identity Access Management and then their own user, there is the codecommit section at the bottom. Users can paste in their public key in there, or multiple and make them active. This tool will only sync active keys, if you make a key inactive, then it will replace the keys on the box with only the active ones. \n\n#### IAM POLICY\n\nBelow is the policy that needs to be associated with the instances you are provisioning. Once you have created this, you can assign this to instances to give the relevant access to the instance to get the keys / users / groups.\n\n```\n{\n   \"Version\": \"2012-10-17\",\n   \"Statement\": [\n       {\n           \"Sid\": \"Stmt1442396947000\",\n           \"Effect\": \"Allow\",\n           \"Action\": [\n               \"iam:GetGroup\",\n               \"iam:GetSSHPublicKey\",\n               \"iam:GetUser\",\n               \"iam:ListSSHPublicKeys\"\n           ],\n           \"Resource\": [\n               \"arn:aws:iam::*\"\n           ]\n       }\n   ]\n}\n```\n\n\n### How to use this\n\nYou can build the go application by running:\n```\ngit clone git@github.com:UKHomeOffice/aws_usersync.git\ncd aws_usersync\ndocker run --rm -it -v \"$PWD\":/go -w /go quay.io/ukhomeofficedigital/go-gb:1.0.0 gb build all\n```\n\nThis will build the application in the current directory creating a bin/aws_usersync binary\n\nTo run the application you need to set environment variables or have relevant access to IAM:\n\n```\nexport AWS_ACCESS_KEY_ID=12345678893\nexport AWS_SECRET_ACCESS_KEY=30302499439434\n./bin/aws_usersync -g=\"group1,group2,group3\"\n```\n\nThis will grab all the users within that group and add them locally with relevant keys as a one time run, to run this at an interval of 5 minutes\n\n```\nexport AWS_ACCESS_KEY_ID=12345678893\nexport AWS_SECRET_ACCESS_KEY=30302499439434\n./bin/aws_usersync -o=false -i=5 -g=\"group1,group2,group3\"\n```\n\nFor debugging issues you can run it in debug mode\n```\n./bin/aws_usersync -o=false -i=5 -g=\"group1,group2,group3\" -L=debug\n```\n\n##### Notes\nThis is new and needs some cleanup on the code really and improving as it's a bit jumbled together in areas, but there are retrospective\nissues raised for things, to clean things up. \n\n\n","travis":true,"contributing":"# Contributing\n\nFeel free to submit pull requests and issues. If it's a particularly large PR, you may wish to\ndiscuss it in an issue first.\n\nPlease note that this project is released with a [Contributor Code of Conduct](code_of_conduct.md).\nBy participating in this project you agree to abide by its terms.\n","masterBranchProtection":false},{"name":"UKHomeOffice/brp-maintenance","private":false,"url":"https://github.com/UKHomeOffice/brp-maintenance","license":null,"readme":"# brp-maintenance\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-centos-base","private":false,"url":"https://github.com/UKHomeOffice/docker-centos-base","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Docker Base Image for the Home Office\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-centos-base.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-centos-base)\n\nThis is a base image to ensure that all home office containers are starting from a known state. This allows us to \nmonitor for security problems in only one operating system, rather than 5 or 6. It also gives us a place to insert \nfixes.\n\n## Getting Started\n\nThese instructions will cover usage information and for the docker container \n\n### Prerequisities\n\n\nIn order to run this container you'll need docker installed.\n\n* [Windows](https://docs.docker.com/windows/started)\n* [OS X](https://docs.docker.com/mac/started/)\n* [Linux](https://docs.docker.com/linux/started/)\n\n### Usage\n\n#### Container Parameters\n\nThis container has no entrypoint.\n\nThis will run bash (or anything else if you replace bash).\n\n```shell\ndocker run -it quay.io/ukhomeofficedigital/centos-base bash\n```\n\n## Built With\n\n* CentOS 7\n\n## Find Us\n\n* [GitHub](https://github.com/UKHomeOffice/docker-centos-base)\n* [Quay.io](https://quay.io/repository/ukhomeofficedigital/centos-base)\n\n## Contributing\n\nPlease read [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct, and the process for submitting\npull requests to us.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the \n[tags on this repository](https://github.com/UKHomeOffice/docker-centos-base/tags). \n\n## Authors\n\n* **Billie Thompson** - *Initial work* - [PurpleBooth](https://github.com/PurpleBooth)\n\nSee also the list of [contributors](https://github.com/UKHomeOffice/docker-centos-base/contributors) who \nparticipated in this project.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/docker-dropwizard","private":false,"url":"https://github.com/UKHomeOffice/docker-dropwizard","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Docker Dropwizard\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-dropwizard.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-dropwizard)\n\nThis is an onbuild container for Dropwizard.\n\n## Assumptions\n\n* You are using Maven 3 to build\n\n### Getting started\n\nCreate a Dockerfile in your project and extend this one with the additional ports you app expose. \nAlso specify the command to run the server including the jar file.\n\n```docker\nFROM ukhomeofficedigital:dropwizard\n\nCMD [\"target/my-java-app.jar\", \"server\", \"maybe-a-config.yml\"]\n\nEXPOSE 8080\nEXPOSE 8081\n```\n\nThen build!\n\nYou can change the CMD if you want to pass more than `server configuration.yml` to the jar.\n\n\n## Contributing\n\nFeel free to submit pull requests and issues. If it's a particularly large PR, you may wish to \ndiscuss it in an issue first.\n\nPlease note that this project is released with a [Contributor Code of Conduct](https://github.com/UKHomeOffice/docker-dropwizard/blob/master/code_of_conduct.md).\n By participating in this project you agree to abide by its terms.\n\n## Versioning\n\nWe use [Semantic Versioning](http://semver.org/) for the version tags available See the tags on this repository. \n\n## Authors\n\n* **Billie Thompson** - *Initial work* - [PurpleBooth](https://github.com/PurpleBooth)\n\nSee also the list of [contributors](https://github.com/UKHomeOffice/docker-dropwizard/graphs/contributors) who participated in this project.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](https://github.com/UKHomeOffice/docker-dropwizard/blob/master/LICENSE.md) file for details\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/ff","private":false,"url":"https://github.com/UKHomeOffice/ff","license":null,"readme":"# dsp-frontend-boilerplate\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-redis","private":false,"url":"https://github.com/UKHomeOffice/docker-redis","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# docker-redis\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-redis.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-redis)\n\nDocker image for redis. This image is designed to be used with kubernetes, it\nmay work outside kubernetes as well.\n\nIt is highly recommended to read through [redis sentinel\ndocumentation](http://redis.io/topics/sentinel).\n\n## Launching it in kubernetes\n\nFirst of all create a single replica pod of redis and redis-sentinel. Both\ncontainers will notice that `${REDIS_SENTINEL_SERVICE_HOST}` and\n`${REDIS_SENTINEL_SERVICE_PORT}` are empty and assume that this is an initial\nbootstrap of redis. Redis sentinel will connect to the master at `$(hostname\n-i)` and start monitoring it.\n\n```\nkubectl create -f kube/redis-controller.yaml\n```\n\nThen you need to create redis sentinel service, which will become your redis\nsentinel endpoint for the following redis pods.\n\n```\nkubectl create -f kube/redis-sentinel-service.yaml\n```\n\nOnce the service is up and running, you can check whether it is working\nproperly. Run the following command in some temporary container.\n\n```\nredis-cli -h ${REDIS_SENTINEL_SERVICE_HOST} -p 26379 INFO\n```\n\nNext, we can start scaling our redis out. It is recommended to add redis and\nredis-sentinel replicas one by one.\n\n```\nkubectl scale rc redis --replicas=2\n```\n\nWait a minute and check on the sentinel service `redis-cli -h\n${REDIS_SENTINEL_SERVICE_HOST} -p 26379 INFO`, then scale to `--replicas=3`.\n\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/docker-mysql","private":false,"url":"https://github.com/UKHomeOffice/docker-mysql","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Docker MySQL Container\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-mysql.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-mysql)\n\nDocker MySQL Container that extends the official home office docker base image.\n\n## Getting Started\n\nThese instructions will cover usage information and for the docker container \n\n### Prerequisities\n\n\nIn order to run this container you'll need docker installed.\n\n* [Windows](https://docs.docker.com/windows/started)\n* [OS X](https://docs.docker.com/mac/started/)\n* [Linux](https://docs.docker.com/linux/started/)\n\n### Usage\n\n#### Container Parameters\n\nParameters passed to the container will be passed onto `mysqld`\n\n```shell\ndocker run \\\n       -e 'MYSQL_ROOT_PASSWORD=my-password' \\\n       quay.io/ukhomeofficedigital/mysql:v0.5.0 \\\n       -yr --param=eters\n```\n\nPassing MySQLd  will start MySQLd without any parameters.  \n\n```shell\ndocker run \\\n    -e 'MYSQL_ROOT_PASSWORD=my-password' \\\n    quay.io/ukhomeofficedigital/mysql:v0.5.0 \\\n    mysqld\n```\n\nStarting MySQLd without any parameters is also the default behaviour.\n\n```shell\ndocker run \\\n    -e 'MYSQL_ROOT_PASSWORD=my-password' \\\n    quay.io/ukhomeofficedigital/mysql:v0.5.0 \\\n```\n\nYou can also run arbitrary stuff\n\n```shell\ndocker run quay.io/ukhomeofficedigital/mysql:v0.5.0 bash\n```\n\n#### Environment Variables\n\n* `MYSQL_ROOT_PASSWORD` - The password you want to set as the root password\n* `MYSQL_ROOT_PASSWORD_PATH` - Alternatively, you can put the password at a path and read it from \n  there\n* `MYSQL_ALLOW_EMPTY_PASSWORD` - Set this to true if you want to be able to set a blank password\n\n#### Volumes\n\n* `/var/lib/mysql` - MySQL Data Files\n\n#### Useful File Locations\n\n* `/docker-entrypoint-initdb.d/*.sql` - Any SQL file in that location will be loaded into the \n  database on container init \n  \n* `/healthcheck.sh` - You can execute this file to check the health of the mysql installation. It \n  does `SELECT 1+1` on the database.\n\n## Contributing\n\nFeel free to submit pull requests and issues. If it's a particualy large PR, you may wish to discuss\nit in an issue first.\n\nPlease note that this project is released with a [Contributor Code of Conduct](code_of_conduct.md). \nBy participating in this project you agree to abide by its terms.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the \n[tags on this repository](https://github.com/UKHomeOffice/docker-mysql/tags). \n\n## Authors\n\n* **Billie Thompson** - *Initial work* - [PurpleBooth](https://github.com/PurpleBooth)\n\nSee also the list of [contributors](https://github.com/UKHomeOffice/docker-mysql/contributors) who \nparticipated in this project.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.\n\n## Acknowledgments\n\n* Large portions of this container are taken from the \n  [official mysql docker container](https://hub.docker.com/_/mysql/).\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/docker-mysql/branches/master/protection","requiredStatusChecks":{"url":"https://api.github.com/repos/UKHomeOffice/docker-mysql/branches/master/protection/required_status_checks","strict":true,"includeAdmins":true,"contextsUrl":"https://api.github.com/repos/UKHomeOffice/docker-mysql/branches/master/protection/required_status_checks/contexts"}}},{"name":"UKHomeOffice/docker-openjdk8-gradle","private":false,"url":"https://github.com/UKHomeOffice/docker-openjdk8-gradle","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"#docker-openjdk8-gradle\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-openjdk8-gradle.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-openjdk8-gradle)\n\nBuilds upon ukhomeofficedigital/centos-base by adding openjdk8 and running gradlew.\n\n##Assumptions\n\n* you use the installApp plugin to generate your Build\n\n##Usage\n\nBase your application on this image like so:\n\n###Dockerfile\n```\nFROM quay.io/ukhomeofficedigital/openjdk8-gradle:v0.1.0\n\nCMD [\"build/install/myapp/bin/myapp\", \"server\", \"src/main/resources/myconfiguration.yaml\"]\n\nEXPOSE 8080\nEXPOSE 8081\n```\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/docker-nodejs","private":false,"url":"https://github.com/UKHomeOffice/docker-nodejs","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# Node.JS On Build Container\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-nodejs.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-nodejs)\n\nThis is an onbuild container for Node.JS Projects. \n\n## Usage  \n\nThis docker container is an `ONBUILD`. Simply extend the Dockerfile in your application with this Dockerfile and your \nproject will be copied into the `/app` directory and have `npm install` run on it.  You must ensure that your \ndownstream images sets USER nodejs and additionally in rare cases any required permission beyond read.\n\nPlease note, storing state on this container is not recommended, and logs should be written to stdout, thus adding further \npermissions isn't something we'd normally envision.\n\n### Container Parameters\n\n* `start`, `test` or `run` will run `npm COMMAND`\n\nThe following command will run `npm start` on the code within the container\n\nSo if your Dockerfile looks like this\n```shell\nFROM quay.io/ukhomeofficedigital/nodejs:v3.0.0\n\nUSER nodejs\nCMD [\"start\"]\n```\n\nThe following will run `npm start`:\n\n```shell\ndocker run your-docker-container:latest\n```\n\nYou can also run arbitrary commands such as:\n\n```shell\ndocker run your-docker-container:latest /opt/nodejs/bin/npm run \n```\n\nHowever, we'd prefered there was a standard way to start your app and thus,\nhave settled on `npm start` being the canonical way to run your app.\n\n\n### Useful Directories\n\n* `/app` - Where you app will be copied to on build\n\n## Contributing\n\nFeel free to submit pull requests and issues. If it's a particularly large PR, you may wish to \ndiscuss it in an issue first.\n\nPlease note that this project is released with a \n[Contributor Code of Conduct](https://github.com/UKHomeOffice/docker-nodejs/blob/master/CODE_OF_CONDUCT.md). \nBy participating in this project you agree to abide by its terms.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for the version tags available See the tags on this repository. \n\n## Build With\n\n* Node v4.4.2\n\n## Authors\n\n* **Billie Thompson** - *Initial work* - [PurpleBooth](https://github.com/PurpleBooth)\n\nSee also the list of \n[contributors](https://github.com/UKHomeOffice/docker-nodejs/graphs/contributors) who participated \nin this project.\n\n## License\n\nThis project is licensed under the GPL v2 License - see the \n[LICENSE.md](https://github.com/UKHomeOffice/docker-nodejs/blob/master/LICENSE.md) file for details\n\n## Acknowledgments\n\n* [NodeJS](https://nodejs.org/)\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/docker-nginx-proxy","private":false,"url":"https://github.com/UKHomeOffice/docker-nginx-proxy","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# OpenResty Docker Container\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-nginx-proxy.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-nginx-proxy)\n\nThis container aims to be a generic proxy layer for your web services. It includes OpenResty with \nLua and NAXSI filtering compiled in.\n\n## Getting Started\n\nIn this section I'll show you some examples of how you might run this container with docker.\n\n### Prerequisites\n\nIn order to run this container you'll need docker installed.\n\n* [Windows](https://docs.docker.com/windows/started)\n* [OS X](https://docs.docker.com/mac/started/)\n* [Linux](https://docs.docker.com/linux/started/)\n\n## Usage\n\n### Environment Variables\n\n#### Multi-location Variables\n\nVariables to control how to configure the proxy (can be set per location, see \n[Using Multiple Locations](#using-multiple-locations)).\n\n* `PROXY_SERVICE_HOST` - The upstream host you want this service to proxy.\n* `PROXY_SERVICE_PORT` - The port of the upstream host you want this service to proxy.\n* `NAXSI_RULES_URL_CSV` - A CSV of [Naxsi](https://github.com/nbs-system/naxsi) URL's of files to download and use. \n(Files must end in .rules to be loaded)\n* `NAXSI_RULES_MD5_CSV` - A CSV of md5 hashes for the files specified above\n* `EXTRA_NAXSI_RULES` - Allows NAXSI rules to be specified as an environment variable. This allows one or two extra  \nrules to be specified without downloading or mounting in a rule file.\n* `NAXSI_USE_DEFAULT_RULES` - If set to \"FALSE\" will delete the default rules file.\n* `ENABLE_UUID_PARAM` - If set to \"FALSE\", will NOT add a UUID url parameter to all requests. The Default will add this\n for easy tracking in down stream logs e.g. `nginxId=50c91049-667f-4286-c2f0-86b04b27d3f0`.\n If set to `HEADER` it will add `nginxId` to the headers, not append to the get params.\n* `CLIENT_CERT_REQUIRED` - if set to `TRUE`, will deny access at this location, see [Client Certs](#client-certs).\n* `ERROR_REDIRECT_CODES` - Can override when Nginx will redirect requests to its own error page. Defaults to\n\"`500 501 502 503 504`\". To support a new code, say `505`, an error page must be provided at\n`/usr/local/openresty/nginx/html/505.shtml`, see [Useful File Locations](#useful-file-locations).\n* `ADD_NGINX_LOCATION_CFG` - Arbitrary extra NGINX configuration to be added to the location context, see \n[Arbitrary Config](#arbitrary-config).\n* `PORT_IN_HOST_HEADER` - If FALSE will remove the port from the http `Host` header.\n* `BASIC_AUTH` - Define a path for username and password file (in `username:password` format), this will turn the file into a .htpasswd file.\n* `REQS_PER_MIN_PER_IP` - Will limit requests based on IP e.g. set to 60 to allow one request per second.\n* `CONCURRENT_CONNS_PER_IP` - Will limit concurrent connections based on IP e.g. set to 10 to allow max of 10 connections per browser or proxy!\n* `REQS_PER_PAGE` - Will limit requests to 'bursts' of x requests at a time before terminating (will default to 20)\n* `DENY_COUNTRY_ON` - Set to `TRUE` to deny access to countries not listed in ALLOW_COUNTRY_CSV with 403 status for a location (set location for 403 with ADD_NGINX_LOCATION_CFG).\n\n#### Single set Variables\n\nNote the following variables can only be set once:\n\n* `ADD_NGINX_SERVER_CFG` - Arbitrary extra NGINX configuration to be added to the server context, see \n[Arbitrary Config](#arbitrary-config)\n* `ADD_NGINX_HTTP_CFG` - Arbitrary extra NGINX configuration to be added to the http context, see\n[Arbitrary Config](#arbitrary-config)\n* `LOCATIONS_CSV` - Set to a list of locations that are to be independently proxied, see the example \n[Using Multiple Locations](#using-multiple-locations). Note, if this isn't set, `/` will be used as the default \nlocation.\n* `LOAD_BALANCER_CIDR` - Set to preserve client IP addresses. *Important*, to enable, see \n[Preserve Client IP](#preserve-client-ip).\n* `NAME_RESOLVER` - Can override the *default* DNS server used to re-resolve the backend proxy (based on TTL). \nThe *Default DNS Server* is the first entry in the resolve.conf file in the container and is normally correct and \nmanaged by Docker or Kubernetes.  \n* `CLIENT_MAX_BODY_SIZE` - Can set a larger upload than Nginx defaults in MB.\n* `HTTPS_REDIRECT_PORT` - Only required for http to https redirect and only when a non-standard https port is in use. \nThis is useful when testing or for development instances or when a load-balancer mandates a non-standard port.\n* `LOG_FORMAT_NAME` - Can be set to `text` or `json` (default).\n* `NO_LOGGING_URL_PARAMS` - Can be set to `TRUE` if you don't want to log url params. Default is empty which means URL params are logged\n* `NO_LOGGING_BODY` - Defaults to true `TRUE`.  Set otherwise and nginx should log the request_body.\n* `NO_LOGGING_RESPONSE` - Defaults to true `TRUE`.  Set otherwise and nginx should log the response_body\n* `SERVER_CERT` - Can override where to find the server's SSL cert.\n* `SERVER_KEY` - Can override where to find the server's SSL key.\n* `SSL_CIPHERS` - Change the SSL ciphers support default only AES256+EECDH:AES256+EDH:!aNULL\n* `SSL_PROTOCOLS` - Change the SSL protocols supported default only TLSv1.2\n* `HTTP_LISTEN_PORT` - Change the default inside the container from 80.\n* `HTTPS_LISTEN_PORT` - Change the default inside the container from 443. \n* `HTTPS_REDIRECT` - Toggle whether or not we force redirects to HTTPS.  Defaults to true.\n* `ALLOW_COUNTRY_CSV` - List of [country codes](http://dev.maxmind.com/geoip/legacy/codes/iso3166/) to allow.\n* `STATSD_METRICS_ENABLED` - Toggle if metrics are logged to statsd (defaults to true)\n* `STATSD_SERVER` - Server to send statsd metrics to, defaults to 127.0.0.1\n\n### Ports\n\nThis container exposes\n\n* `80` - HTTP\n* `443` - HTTPS\n\nN.B. see HTTP(S)_LISTEN_PORT above\n\n### Useful File Locations\n\n* `nginx.conf` is stored at `/usr/local/openresty/nginx/conf/nginx.conf`\n* `/etc/keys/crt` & `/etc/keys/key` - A certificate can be mounted here to make OpenResty use it. However a self \n  signed one is provided if they have not been mounted.\n* `/etc/keys/client-ca` If a client CA is mounted here, it will be loaded and configured. \nSee `CLIENT_CERT_REQUIRED` above in [Environment Variables](#environment-variables).\n* `/usr/local/openresty/naxsi/*.conf` - [Naxsi](https://github.com/nbs-system/naxsi) rules location in default \nnginx.conf.\n* `/usr/local/openresty/nginx/html/$CODE.shtml` - HTML (with SSI support) displayed when a the status code $CODE\nis encountered upstream and the proxy is configured to intercept. See ERROR_REDIRECT_CODES to change this.\n* `/usr/local/openresty/nginx/html/418-request-denied.shtml` - HTML (with SSI support) displayed when NAXSI\nblocks a request.\n\n### Examples\n\n#### Self signed SSL Certificate\n\n```shell\ndocker run -e 'PROXY_SERVICE_HOST=http://stackexchange.com' \\\n           -e 'PROXY_SERVICE_PORT=80' \\\n           -p 8443:443 \\\n           quay.io/ukhomeofficedigital/nginx-proxy:v1.0.0\n```\n\n#### Custom SSL Certificate\n\n```shell\ndocker run -e 'PROXY_SERVICE_HOST=http://stackexchange.com' \\\n           -e 'PROXY_SERVICE_PORT=80' \\\n           -p 8443:443 \\\n           -v /path/to/key:/etc/keys/key:ro \\\n           -v /path/to/crt:/etc/keys/crt:ro \\\n           quay.io/ukhomeofficedigital/nginx-proxy:v1.0.0\n```\n\n#### Preserve Client IP\n\nThis proxy supports [Proxy Protocol](http://www.haproxy.org/download/1.5/doc/proxy-protocol.txt).\n\nTo use this feature you will need:\n\n* To enable [proxy protocol](http://www.haproxy.org/download/1.5/doc/proxy-protocol.txt) on your load balancer.  \n  For AWS, see [Enabling Proxy Protocol for AWS](http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/enable-proxy-protocol.html).\n* Find the private address range of your load balancer.  \n  For AWS, this could be any address in the destination network. E.g.\n  if you have three compute subnets defined as 10.50.0.0/24, 10.50.1.0/24 and 10.50.2.0/24,\n  then a suitable range would be 10.50.0.0/22 see [CIDR Calculator](http://www.subnet-calculator.com/cidr.php).\n  \n```shell\ndocker run -e 'PROXY_SERVICE_HOST=http://stackexchange.com' \\\n           -e 'PROXY_SERVICE_PORT=80' \\\n           -e 'LOAD_BALANCER_CIDR=10.50.0.0/22' \\\n           -p 8443:443 \\\n           quay.io/ukhomeofficedigital/nginx-proxy:v1.0.0\n```\n\n#### Extra NAXSI Rules from Environment\n\nThe example below allows large documents to be POSTED to the /documents/uploads and /documents/other_uploads locations.\nSee [Whitelist NAXSI rules](https://github.com/nbs-system/naxsi/wiki/whitelists) for more examples.\n\n```shell\ndocker run -e 'PROXY_SERVICE_HOST=http://myapp.svc.cluster.local' \\\n           -e 'PROXY_SERVICE_PORT=8080' \\\n           -e 'EXTRA_NAXSI_RULES=BasicRule wl:2 \"mz:$URL:/documents/uploads|BODY\";\n               BasicRule wl:2 \"mz:$URL:/documents/other_uploads|BODY\";' \\\n           -p 8443:443 \\\n           quay.io/ukhomeofficedigital/nginx-proxy:v1.0.0\n```\n\n#### Using Multiple Locations\n\nWhen the LOCATIONS_CSV option is set, multiple locations can be proxied. The settings for each proxy location can be \ncontrolled with the use of any [Multi-location Variables](#multi-location-variables) by suffixing the variable name with\n both a number, and the '_' character, as listed in the LOCATIONS_CSV variable. \n \n##### Two servers \n\nThe example below configures a simple proxy with two locations '/' (location 1) and '/api' (location 2):\n\n```shell\ndocker run -e 'PROXY_SERVICE_HOST_1=http://stackexchange.com' \\\n           -e 'PROXY_SERVICE_PORT_1=80' \\\n           -e 'PROXY_SERVICE_HOST_2=https://api.svc.cluster.local' \\\n           -e 'PROXY_SERVICE_PORT_2=8888' \\\n           -e 'LOCATIONS_CSV=/,/api' \\\n           -p 8443:443 \\\n           quay.io/ukhomeofficedigital/nginx-proxy:v1.0.0\n```           \n\nFor more detail, see the [generated config](./docs/GeneratedConfigs.md#two-separate-proxied-servers).\n\n##### One Server, Multiple locations\n\nThe example below will proxy the same address for two locations but will disable the UUID (nginxId) parameter for the\n/about location only.\n\nSee the [generated config](./docs/GeneratedConfigs.md#same-server-proxied) for below:\n\n```shell\ndocker run -e 'PROXY_SERVICE_HOST=http://stackexchange.com' \\\n           -e 'PROXY_SERVICE_PORT=80' \\\n           -e 'LOCATIONS_CSV=/,/about' \\\n           -e 'ENABLE_UUID_PARAM_2=FALSE' \\\n           -p 8443:443 \\\n           quay.io/ukhomeofficedigital/nginx-proxy:v1.0.0\n```\n\n#### Client Certs\n\nIf a client CA certificate is mounted, the proxy will be configured to load it. If a client has the cert, the client CN\nwill be set in the X-Username header and logged.\n```shell\ndocker run -e 'PROXY_SERVICE_HOST=http://stackexchange.com' \\\n           -e 'PROXY_SERVICE_PORT=80' \\\n           -v \"${PWD}/client_certs/ca.crt:/etc/keys/client-ca\" \\\n           -p 8443:443 \\\n           quay.io/ukhomeofficedigital/nginx-proxy:v1.0.0\n```\n\nThe following example will specifically deny access to clients without a cert:\n\n```shell\ndocker run -e 'PROXY_SERVICE_HOST=http://serverfault.com' \\\n           -e 'PROXY_SERVICE_PORT=80' \\\n           -e 'LOCATIONS_CSV=/,/about' \\\n           -e 'CLIENT_CERT_REQUIRED_2=TRUE' \\\n           -v \"${PWD}/client_certs/ca.crt:/etc/keys/client-ca\" \\\n           -p 8443:443 \\\n           quay.io/ukhomeofficedigital/nginx-proxy:v1.0.0\n```\nSee [./client_certs](./client_certs) for scripts that can be used to generate a CA and client certs.  \n\n#### Arbitrary Config\n\nThe example below will return \"ping ok\" for the URL /ping.\n```shell\ndocker run -e 'PROXY_SERVICE_HOST=http://stackexchange.com' \\\n           -e 'PROXY_SERVICE_PORT=80' \\\n           -e 'ADD_NGINX_LOCATION_CFG=if ($uri = /proxy-ping) return 200 \"ping ok\";' \\\n           -p 8443:443 \\\n           quay.io/ukhomeofficedigital/nginx-proxy:v1.0.0\n```\n\nThe example below will return \"404\" for the URL /notfound.\n```shell\ndocker run -e 'PROXY_SERVICE_HOST=http://stackexchange.com' \\\n           -e 'PROXY_SERVICE_PORT=80' \\\n           -e 'ADD_NGINX_SERVER_CFG=location /notfound { return 404; };' \\\n           -p 8443:443 \\\n           quay.io/ukhomeofficedigital/nginx-proxy:v1.0.0\n```\n\nThe example below enables proxy_cache_path directive.  Allows you to define where cached files are stored.\n```shell\ndocker run -e 'PROXY_SERVICE_HOST=http://stackexchange.com' \\\n           -e 'PROXY_SERVICE_PORT=80' \\\n           -e 'ADD_NGINX_HTTP_CFG=proxy_cache_path /data/nginx/cache levels=1:2 keys_zone=static:10m;' \\\n           -p 8443:443 \\\n           quay.io/ukhomeofficedigital/nginx-proxy:v1.0.0\n```\n\n#### Basic Auth\n\nTo add basic auth to your server you need to define the username and password by mounting a file and defining that file in the `BASIC_AUTH` variable, then add the location config to you config.\n\n```shell\ndocker run -e 'PROXY_SERVICE_HOST=http://stackexchange.com' \\\n           -e 'PROXY_SERVICE_PORT=80' \\\n           -e 'ADD_NGINX_LOCATION_CFG='auth_basic \"Restricted\"; auth_basic_user_file /etc/secrets/.htpasswd;' \\\n           -e BASIC_AUTH='/etc/secrets/basic-auth'\n           -p 8443:443 \\\n           -v ~/Documents:/etc/secrets/\n           quay.io/ukhomeofficedigital/nginx-proxy:v1.0.0\n```\n\nThe basic auth file will look like this.\n```shell\nadmin:testing\nusername:password\n```\n##### Basic Auth on mutliple Locations\n\nIf you're using multiple locations then we need to define the location that basic_auth will be set in relation to the `LOCATIONS_CSV`\n\n```shell\ndocker run -e 'PROXY_SERVICE_HOST=http://serverfault.com' \\\n           -e 'PROXY_SERVICE_PORT=80' \\\n           -e 'LOCATIONS_CSV=/,/about' \\\n           -e 'CLIENT_CERT_REQUIRED_2=TRUE' \\\n           -e BASIC_AUTH_2=/etc/secrets/basic-auth \\\n           -v \"${PWD}/client_certs/ca.crt:/etc/keys/client-ca\" \\\n           -p 8443:443 \\\n           quay.io/ukhomeofficedigital/nginx-proxy:v1.0.0\n```\n\nthis will setup basic-auth for the the `/about` location or simply swap the 2 for a 1 to setup basic auth for the root location. \n\n\n\n## Built With\n\n* [OpenResty](https://openresty.org/) - OpenResty (aka. ngx_openresty) is a full-fledged web\n  application server by bundling the standard Nginx core, lots of 3rd-party Nginx modules, as well \n  as most of their external dependencies.\n* [Nginx](https://www.nginx.com/resources/wiki/) - The proxy server core software.\n* [ngx_lua](http://wiki.nginx.org/HttpLuaModule) - Embed the power of Lua into Nginx\n* [Naxsi](https://github.com/nbs-system/naxsi) - NAXSI is an open-source, high performance, low \n  rules maintenance WAF for NGINX \n* [GeoLite data](http://www.maxmind.com\">http://www.maxmind.com) This product includes GeoLite data created by MaxMind.\n\n## Find Us\n\n* [GitHub](https://github.com/UKHomeOffice/docker-nginx-proxy)\n* [Quay.io](https://quay.io/repository/ukhomeofficedigital/nginx-proxy)\n\n## Contributing\n\nFeel free to submit pull requests and issues. If it's a particularly large PR, you may wish to \ndiscuss it in an issue first.\n\nPlease note that this project is released with a [Contributor Code of Conduct](code_of_conduct.md). \nBy participating in this project you agree to abide by its terms.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for the version tags available See the tags on this repository. \n\n## Authors\n\n* **Lewis Marshal** - *Initial work* - [lewismarshall](https://github.com/lewismarshall)\n\nSee also the list of \n[contributors](https://github.com/UKHomeOffice/docker-nginx-proxy/graphs/contributors) who \nparticipated in this project.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/dropwizard-sample-gradle","private":false,"url":"https://github.com/UKHomeOffice/dropwizard-sample-gradle","license":null,"readme":"#Dropwizard Sample Application with Gradle\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/dropwizard-sample-gradle.svg?branch=master)](https://travis-ci.org/UKHomeOffice/dropwizard-sample-gradle)\n\nThis is a sample application using Gradle for the build and package\n\n##Building\n\n```\n./gradlew installApp\n```\n\n##Running\n\n```\nbuild/install/dropwizard-gradle-sample/bin/dropwizard-gradle-sample server\n```\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/jenkins-docker-aws","private":false,"url":"https://github.com/UKHomeOffice/jenkins-docker-aws","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# DOCKER JENKINS\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/jenkins-docker-aws.svg?branch=master)](https://travis-ci.org/UKHomeOffice/jenkins-docker-aws)\n\nThis folder contains the build for a docker image of jenkins with given plugins. Features include:\n- Backing up and restoring of config from Amazon S3\n- Includes docker, git, awscli\n- Includes kubectl and restoration of corresponding config from encrypted file in Amazon S3\n- Includes restoration of encrypted config for docker logins from encrypted file in Amazon S3\n\nTo automatically build and push a new version to your chosen docker repository from this folder run:\n```bash\n$ ./build_and_push.sh <repositoryname>/<username>/<reponame>:<tag>\n```\ne.g.\n```bash\n./build_and_push.sh quay.io/timgent/aws-jenkins:v0.5\n```\n\n# Syncing config from S3 bucket\nJenkins docker image. Jenkins configuration can be synced from AWS S3 bucket at\nstartup.\n\nBy default there is only one-way configuration sync, but you can set up a jenkins\njob which syncs `${JENKINS_HOME}` to the same S3 bucket, so next time you start\nthis container you will have all your config loaded at startup time.\n\nIf `JENKINS_HOME_S3_BUCKET_NAME` is set, bucket config will be written out to\n`/etc/jenkins-bucket-config`, which is used by\n`/srv/jenkins/jenkins_backup.sh`. So you can just simply create a jenkins job\nwhich runs the backup script.\n\nConfiguration is done using environment variables.\n\nAuthentication to S3 bucket can be passed in via `AWS_SECRET_ACCESS_KEY` and\n`AWS_ACCESS_KEY_ID` or EC2 instance IAM role.\n\n- `JENKINS_HOME` Default: `/var/lib/jenkins`. If you decide to change this,\n  make sure you run docker container with `-v <new_jenkins_home>` set\n- `JENKINS_HOME_S3_BUCKET_NAME` Default: unset. If unset, config sync will not run\n- `JAVA_OPTS` Default: unset.\n- `JENKINS_OPTS` Default: unset. Any valid jenkins parameter is supported\n\n# Secrets for kubeconfig and dockercfg\n## Option 1 - getting secrets from S3\nkubeconfig and docker login config syncing to S3 bucket are supported. You will need to encrypt and upload dockercfg and kubeconfig files to your chosen S3 buckets to enable this. For example to encrypt:\n\n`aws kms encrypt --key-id xxxxxxx --plaintext \"$(cat dockercfg)\" --query CiphertextBlob --output text | base64 -d > dockercfg.encrypted`\n\nThen upload to s3. The bucket name will need to be set as an environment variable SECRETS_BUCKET when the container is run.\n## Option 2 - map secrets in using volumes\nUsing plain docker you can map secrets in with the -v command when running this container.\n- Kube config needs to be mapped in to /root/.kube/config\n- Docker config needs to be mapped in to /root/.docker/config.json\nIf you are running this container using kubernetes then kubernetes secrets can be used to map these in as volumes as usual. Documentation is available [here](https://github.com/kubernetes/kubernetes/tree/master/docs/user-guide/secrets)\n\n# Enabling docker in docker\nThis container containers docker which enables it to execute docker commands using the host machines docker daemon. To enable this the docker socket will need to be mapped in as a volume to the container like:\n-v /var/run/docker.sock:/var/run/docker.sock\n\n# Running\n\n```bash\ndocker run \\\n  -e AWS_SECRET_ACCESS_KEY=xxx \\\n  -e AWS_ACCESS_KEY_ID=xxx \\\n  -e JENKINS_HOME_S3_BUCKET_NAME=example-jenkinsconfig-us-east-1 \\\n  -e SECRETS_BUCKET=my_secrets_bucket \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  -p 8080:8080 state/jenkins\n```\n\n# Useful Paths\n\nYou may choose to mount your Amazon secrets in a file that looks like this at\n`/root/.aws/credentials`\n\n```\n[default]\naws_access_key_id = xxx\naws_secret_access_key = xxx\n```\n\nRather than via your environment variables.\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/docker-mongonodejava8","private":false,"url":"https://github.com/UKHomeOffice/docker-mongonodejava8","license":null,"readme":"# docker-mongonodejava8\nImage that has Sun Java 8, mongodb and node installed.\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/registered-traveller-devops","private":false,"url":"https://github.com/UKHomeOffice/registered-traveller-devops","license":null,"readme":false,"travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-logstash-s3","private":false,"url":"https://github.com/UKHomeOffice/docker-logstash-s3","license":null,"readme":"# docker-logstash-s3\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-logstash-s3.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-logstash-s3)\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-s3-backup","private":false,"url":"https://github.com/UKHomeOffice/docker-s3-backup","license":null,"readme":"# docker-archive\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-archive.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-archive)\n\nSo this is how we do backups.\n\nIt looks at the share dir for a configureable named file; \"*.tar.gz\" by default.\nGPG the file\nUploads to s3.\n\nRuns in a cruddy while loop.\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-go-gb","private":false,"url":"https://github.com/UKHomeOffice/docker-go-gb","license":null,"readme":"# docker-go-gb\nFor using gb build and fetch for go applications\n\n# Build the image\ndocker build -t <user>/<repo>:<version> .\n\n# Example use case if the image is built and pushed into a repo\ncd \"$GO_REPO\"\ndocker run --rm -it -v \"$PWD\":/go -w /go quay.io/ukhomeofficedigital/go-gb:1.0.0 gb build all\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/vaultconf","private":false,"url":"https://github.com/UKHomeOffice/vaultconf","license":{"key":"apache-2.0","name":"Apache License 2.0","spdxId":"Apache-2.0","url":"https://api.github.com/licenses/apache-2.0","featured":true},"readme":"[![Build Status](https://travis-ci.org/UKHomeOffice/vaultconf.svg)](https://travis-ci.org/UKHomeOffice/vaultconf)\n\n# Vaultconf\nA command line tool to allow mass configuration updates in vault with support included for kubernetes. Functions include:\n- update of policies in vault\n- update of users in Vault\n \nFor more context please see this [blog post](http://timturnstechie.blogspot.co.uk/2015/10/vaultconf-managing-vault-logins-for.html).\n\n## Installation\nThis tool has not yet been setup as a Ruby gem, though it would be easy to do so. Instead we recommend running using docker to ensure no dependency issues:\n\ne.g. docker run --net=host -v policies:/policies -ti quay.io/ukhomeofficedigital/vaultconf policies -c /policies -u user -p password -a http://localhost:8200 --nokube\nNB: In this example --net=host is needed as we are accessing a local vault server. This is not required for accessing remote vault servers.\n\n## Usage\nRun with option --help to show command line help.\n\nExample usage is included in vaultconf.feature.\nExample policies directory structure is provided in test/resources/policies.\nExample users yaml structure is provided in test/resources/users/users/yaml\n\nIn order to not need to define password in the command line vaultconf can read login details from a file called \"login\" in the .vaultconf directory in your home directory. The format for this file is as follows:\n``` yaml\n---\nusername: myusername\npassword: mypassword\n```\n\n## Development\n\nAfter checking out the repo, run `bin/setup` to install dependencies. Then, run `bin/console` for an interactive prompt that will allow you to experiment.\n\nTo install this gem onto your local machine, run `bundle exec rake install`. To release a new version, update the version number in `version.rb`, and then run `bundle exec rake release` to create a git tag for the version, push git commits and tags, and push the `.gem` file to [rubygems.org](https://rubygems.org).\n\n## Contributing\n\n1. Fork it ( https://github.com/UKHomeOffice/vaultconf/fork )\n2. Create your feature branch (`git checkout -b my-new-feature`)\n3. Commit your changes (`git commit -am 'Add some feature'`)\n4. Push to the branch (`git push origin my-new-feature`)\n5. Create a new Pull Request\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-confluence","private":false,"url":"https://github.com/UKHomeOffice/docker-confluence","license":null,"readme":"# docker-confluence\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-confluence.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-confluence)\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-mysql-sonarqube","private":false,"url":"https://github.com/UKHomeOffice/docker-mysql-sonarqube","license":null,"readme":"# docker-mysql-sonarqube\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-mysql-sonarqube.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-mysql-sonarqube)\n\nThe docker MySQL container plus a single SQL file that creates a sonar db. For use with the sonarqube docker container\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-sonarqube","private":false,"url":"https://github.com/UKHomeOffice/docker-sonarqube","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Docker Sonar Qube\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-sonarqube.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-sonarqube)\n\nThis is a [Sonar Qube](http://www.sonarqube.org/) Docker container.\n\n## Getting Started\n\nThese instructions will get the container running.\n\nThere is a H2 Database included in Sonar Qube, which you may choose to use, however it is not \nsuitable for production\n\n### Prerequisities\n\nIn order to run this container you'll need docker installed.\n\n* [Windows](https://docs.docker.com/windows/started)\n* [OS X](https://docs.docker.com/mac/started/)\n* [Linux](https://docs.docker.com/linux/started/)\n\nYou'll also need a database you can connect to.\n\n### Usage\n\n#### Container params\n\nIf the arguments passed to the container begin with `-` for example `-something` All those arguments\nwill be passed to Sonar Qube.\n\n```bash\ndocker run quay.io/ukhomeofficedigital/sonarqube:v0.2.0 -something\n```\n\nLikewise, no arguments will also start Sonar Qube.\n\n```bash\ndocker run quay.io/ukhomeofficedigital/sonarqube:v0.2.0\n```\n\nOtherwise it'll run what you passed in. So for example `bash` would run bash\n\n```bash\ndocker run quay.io/ukhomeofficedigital/sonarqube:v0.2.0 bash\n```\n\n#### Backups\n\nThis container will attempt to backup and restore itself on start and stop. You can also trigger the process manually by running\n\n* `/opt/sonarqube/backup.sh`\n* `/opt/sonarqube/restore.sh`\n\n#### Environment Variables\n\n* `SONARQUBE_JDBC_USERNAME` Database username for Sonar Qube. Defaults to `sonar`\n* `SONARQUBE_JDBC_PASSWORD` Database password for Sonar Qube. Defaults to `sonar`\n* `$SONARQUBE_JDBC_PASSWORD_PATH` Path to file with database password for Sonar Qube. Overwrites \n  `SONARQUBE_JDBC_PASSWORD` if present.\n* `SONARQUBE_JDBC_URL` The JDBC url to the database for Sonar Qube. Defaults to \n  `jdbc:h2:tcp://localhost:9092/sonar`\n\nIf you want to back things up, then you'll need to set these too.\n\n* `AWS_ACCESS_KEY_ID` AWS Access Key to use for backups\n* `AWS_SECRET_ACCESS_KEY` AWS Secret Key to use for backups\n* `SONAR_QUBE_BACKUP_S3_BUCKET_NAME` Bucket to backup to\n\n#### Exposed Ports\n\n* `9000` Web Interface\n* `9092` H2 if you choose to use that database\n\n#### Volumes\n\n* `/opt/sonarqube/extensions` - Installed Extensions\n\n## Built With\n\n* Sonar Qube 5.1.2\n\n## Contributing\n\nFeel free to submit pull requests and issues. If it's a particualy large PR, you may wish to discuss\nit in an issue first.\n\nPlease note that this project is released with a [Contributor Code of Conduct](code_of_conduct.md). \nBy participating in this project you agree to abide by its terms.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the \n[tags on this repository](https://github.com/UKHomeOffice/docker-sonarqube/tags). \n\n## Authors\n\n* **Billie Thompson** - *Initial work* - [PurpleBooth](https://github.com/PurpleBooth)\n\nSee also the list of [contributors](https://github.com/UKHomeOffice/docker-sonarqube/contributors) \nwho participated in this project.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.\n\n## Acknowledgments\n\n* Lots of this code comes from the official \n  [Sonar Qube Docker image](https://github.com/SonarSource/docker-sonarqube).\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/docker-mysql-java","private":false,"url":"https://github.com/UKHomeOffice/docker-mysql-java","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Docker MySQL Java Container\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-mysql-java.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-mysql-java)\n\nDocker MySQL Container that also includes Open Java 8 *JRE* install.\n\n## Getting Started\n\nThese instructions will cover usage information and for the docker container \n\n### Prerequisities\n\nIn order to run this container you'll need docker installed.\n\n* [Windows](https://docs.docker.com/windows/started)\n* [OS X](https://docs.docker.com/mac/started/)\n* [Linux](https://docs.docker.com/linux/started/)\n\n### Usage\n\nThis is intended as a base image that would extended mysql so Java code maybe run along with mysql tools installed e.g.\n\n\n```\nFROM quay.io/ukhomeofficedigital/mysql-java:v0.1.2\n\n# Customisations to allow for schema updates using liquidbase Java file\n# =====================================================================\n\nENV TERM dumb\n\nCOPY docker-entrypoint.sh /\n\nENTRYPOINT [\"/docker-entrypoint.sh\"]\n```\n\nIt was created to run a simple bash mysql users script and then run a Java \n[Liquidbase](http://www.liquibase.org/) schema install.\n\nIt extends the mysql only repository and as such, most of the documentation is available here:\n[Docker MySQL](https://github.com/UKHomeOffice/docker-mysql/blob/v0.5.1/README.md)\n\n \n\n## Contributing\n\nFeel free to submit pull requests and issues. If it's a particualy large PR, you may wish to discuss\nit in an issue first.\n\nPlease note that this project is released with a [Contributor Code of Conduct](code_of_conduct.md). \nBy participating in this project you agree to abide by its terms.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the \n[tags on this repository](https://github.com/UKHomeOffice/docker-mysql-java/tags). \n\n## Authors\n\n* **Lewis Marshall** - *Initial work* - [Lewis Marshall](https://github.com/LewisMarshall)\n\nSee also the list of [contributors](https://github.com/UKHomeOffice/docker-mysql-java/contributors) who \nparticipated in this project.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.\n\n## Acknowledgments\n\n* This container is taken from the \n  [UKHomeOffice mysql docker container](https://quay.io/repository/ukhomeofficedigital/mysql).\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-crond","private":false,"url":"https://github.com/UKHomeOffice/docker-crond","license":null,"readme":"# docker-cron\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-crond.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-crond)\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-selenium-standalone-server","private":false,"url":"https://github.com/UKHomeOffice/docker-selenium-standalone-server","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Docker: Selenium Server with Firefox and Google Chrome\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-selenium-standalone-server.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-selenium-standalone-server)\n\nDocker container containing Selenium Server\n\n> Selenium automates browsers. That's it! What you do with that power is entirely up to you. \n> Primarily, it is for automating web applications for testing purposes, but is certainly not \n> limited to just that. Boring web-based administration tasks can (and should!) also be automated as\n> well.\n\n## Getting Started\n\nThese instructions will cover usage information and for the docker container \n\n### Prerequisities\n\n\nIn order to run this container you'll need docker installed.\n\n* [Windows](https://docs.docker.com/windows/started)\n* [OS X](https://docs.docker.com/mac/started/)\n* [Linux](https://docs.docker.com/linux/started/)\n\n### Usage\n\n#### Container Parameters\n\nParameters passed to the container will be passed onto Selenium Server.\n\n```shell\ndocker run \\\n       quay.io/ukhomeofficedigital/selenium-standalone-server:v0.1.2 \\\n       -your --param=eters\n```\n\nPassing no parameters will start Selenium Server\n\n```shell\ndocker run \\\n       quay.io/ukhomeofficedigital/selenium-standalone-server:v0.1.2\n```\n\nYou can also run arbitrary stuff\n\n```shell\ndocker run \\\n       quay.io/ukhomeofficedigital/selenium-standalone-server:v0.1.2 \\\n       bash\n```\n\n### Exposes\n\n* `4444` Selenium Server \n\n## Kubernetes\n\nFor example Kubernetes files see [/kb8](/kb8)\n\n## Built With\n\n* Chrome Stable\n* Firefox\n* Selenium Chrome Driver 2.18\n* Selenium Server Standalone 2.47.1\n\n## Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md)\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the \n[tags on this repository][tags]. \n\n[tags]: https://github.com/UKHomeOffice/docker-selenium-standalone-server/tags\n\n## Authors\n\n* **Billie Thompson** - *Initial work* - [PurpleBooth](https://github.com/PurpleBooth)\n\nSee also the list of [contributors][contrib] who participated in this project.\n\n[contrib]: https://github.com/UKHomeOffice/docker-selenium-standalone-server/contributors\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details\n\n## Acknowledgments\n\n* Lots of this code was stolen from the \n  [official Selenium container](https://github.com/SeleniumHQ/docker-selenium).\n","travis":true,"contributing":"# Contributing\n\nFeel free to submit pull requests and issues. If it's a particularly large PR, you may wish to \ndiscuss it in an issue first.\n\nPlease note that this project is released with a [Contributor Code of Conduct](code_of_conduct.md). \nBy participating in this project you agree to abide by its terms.\n","masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/docker-selenium-standalone-server/branches/master/protection"}},{"name":"UKHomeOffice/docker-mediawiki","private":false,"url":"https://github.com/UKHomeOffice/docker-mediawiki","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# docker-mediawiki\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-mediawiki.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-mediawiki)\n\nFor this to work, PHP will be running in another container separate to mediawiki\nThis will be handled currently as a sidekick container in a pod for Kubernetes, but also could be\njust a bound container also.\n\nFor additional extensions, modify the extensions.txt with the git hash. These can be found at https://extdist.wmflabs.org/dist/extensions/ .\nThe contents of the file will look like\n\n```\nTwoFactorAuthentication:3e8f4ce\n```\n### Prerequisities\n\n\nIn order to run this container you'll need docker installed.\n\n* [Windows](https://docs.docker.com/windows/started)\n* [OS X](https://docs.docker.com/mac/started/)\n* [Linux](https://docs.docker.com/linux/started/)\n\n### Usage\n\n#### Container Parameters\n\nParameters passed to the container will be passed onto Selenium Server.\n\n```shell\ndocker run -e MEDIAWIKI_VERSION=<version> \\\n       quay.io/ukhomeofficedigital/mediawiki:v0.5.1 \\\n       \n```\n\nPassing no parameters will start mediawiki \n\n```shell\ndocker run \\\n       quay.io/ukhomeofficedigital/mediawiki:v0.5.1\n```\n\nYou can also run arbitrary stuff\n\n```shell\ndocker run \\\n       quay.io/ukhomeofficedigital/mediawiki:v0.5.1 \\\n       bash\n```\n\n## Kubernetes\n\nFor example Kubernetes files see [/kb8](/kb8)\n\n## Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md)\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the\n[tags on this repository][tags].\n\n[tags]: https://github.com/UKHomeOffice/docker-mediawiki/tags\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details\n","travis":true,"contributing":"# Contributing\n\nFeel free to submit pull requests and issues. If it's a particularly large PR, you may wish to\ndiscuss it in an issue first.\n\nPlease note that this project is released with a [Contributor Code of Conduct](code_of_conduct.md).\nBy participating in this project you agree to abide by its terms.\n","masterBranchProtection":false},{"name":"UKHomeOffice/docker-php-fpm","private":false,"url":"https://github.com/UKHomeOffice/docker-php-fpm","license":null,"readme":"# docker-php-fpm\n\nThis container is for running PHP apps in kubernetes.  It doesn't contain composer as that's only required at the build step which this isn't intended to offer.\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-php-fpm.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-php-fpm)\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-s3registry","private":false,"url":"https://github.com/UKHomeOffice/docker-s3registry","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Docker Trusted Private Registry Container\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-s3registry.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-s3registry)\n\nDocker Trusted Private Registry Container. Requires fully trusted certs \n\n## Getting Started\n\nThese instructions will cover usage information and for the docker container \n\n### Prerequisites\n\nIn order to run this container you'll need docker installed.\n\n* [Windows](https://docs.docker.com/windows/started)\n* [OS X](https://docs.docker.com/mac/started/)\n* [Linux](https://docs.docker.com/linux/started/)\n\n### Usage\n\n#### Container Parameters\n\nStarting the registry without any parameters is also the default behaviour.\n\n```shell\ndocker run \\\n    -v ${PWD}/secrets:/etc/secrets \\\n    -p 5000:5000\n    quay.io/ukhomeofficedigital/s3registry:v2.0.0 \\\n```\n\n#### Required secrets files\n\nThe yaml file below represents the secret files required to run the registry.\n\nAll the files are required to be present and mounted at /etc/secrets \n\n```yaml\n---\nkind: \"Secret\"\napiVersion: \"v1\"\nmetadata:\n  name: \"registry-secrets\"\ntype: \"Opaque\"\ndata:\n  s3-accesskey: bG9vayBpbiBhd3MgZm9yIGNyZWRzCg==\n  s3-secretkey: bG9vayBpbiBhd3MgZm9yIGNyZWRzCg==\n  s3-region: bG9vayBpbiBhd3MgZm9yIGNyZWRzCg==\n  s3-bucket: bG9vayBpbiBhd3MgZm9yIGNyZWRzCg==\n  key: dXNlIGEgcmVhbCBrZXkK\n  crt: dXNlIGEgcmVhbCBjZXJ0Cg==\n  docker_user: bXJkb2NrZXJ1c2VyCg==\n  docker_pass: YmFkcGFzcwo=\n\n```\n\n## Contributing\n\nFeel free to submit pull requests and issues. If it's a particualy large PR, you may wish to discuss\nit in an issue first.\n\nPlease note that this project is released with a [Contributor Code of Conduct](code_of_conduct.md). \nBy participating in this project you agree to abide by its terms.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the \n[tags on this repository](https://github.com/UKHomeOffice/docker-s3registry/tags). \n\n## Authors\n\n* **Lewis Marshall** - *Initial work* - [lewismarshall](https://github.com/lewismarshall)\n\nSee also the list of [contributors](https://github.com/UKHomeOffice/docker-s3registry/contributors) who \nparticipated in this project.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.\n\n## Acknowledgments\n\n* Large portions of this container are taken from the \n  [official registry docker container](https://hub.docker.com/_/registry/).\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-openjdk8","private":false,"url":"https://github.com/UKHomeOffice/docker-openjdk8","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Docker Java JDK Container\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-openjdk8.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-openjdk8)\n\nDocker container that also includes Open Java 8 *JDK* install for running containerized builds.\n\n## Getting Started\n\nThese instructions will cover usage information and for the docker container \n\n### Prerequisites\n\nIn order to run this container you'll need docker installed.\n\n* [Windows](https://docs.docker.com/windows/started)\n* [OS X](https://docs.docker.com/mac/started/)\n* [Linux](https://docs.docker.com/linux/started/)\n\n### Usage\n\nThe example below, runs a Java (gradle) build:\n\n```\ndocker run -i --rm=true \\\n        -v ${BUILD_HOME_DIR}:/code \\\n        -e BUILD_NUMBER=${BUILD_NUMBER} \\\n        -v ${GRADLE_CACHE}:/root/.gradle/caches \\\n        quay.io/ukhomeofficedigital/openjdk8:v0.1.2 \\\n        ./gradlew \"$@\"\n```\n\n## Contributing\n\nFeel free to submit pull requests and issues. If it's a particularly large PR, you may wish to discuss\nit in an issue first.\n\nPlease note that this project is released with a [Contributor Code of Conduct](code_of_conduct.md). \nBy participating in this project you agree to abide by its terms.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the \n[tags on this repository](https://github.com/UKHomeOffice/docker-openjdk8/tags). \n\n## Authors\n\n* **Lewis Marshall** - *Initial work* - [Lewis Marshall](https://github.com/LewisMarshall)\n\nSee also the list of [contributors](https://github.com/UKHomeOffice/docker-openjdk8/contributors) who \nparticipated in this project.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.\n\n## Acknowledgments\n\n* [OpenJDK8](http://openjdk.java.net/projects/jdk8/)\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-gitlab-tools","private":false,"url":"https://github.com/UKHomeOffice/docker-gitlab-tools","license":{"key":"apache-2.0","name":"Apache License 2.0","spdxId":"Apache-2.0","url":"https://api.github.com/licenses/apache-2.0","featured":true},"readme":false,"travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/dsp-frontend-boilerplate","private":false,"url":"https://github.com/UKHomeOffice/dsp-frontend-boilerplate","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# Digital Services Application scaffold\n\nThis respository should be used as a template for Node.js applications to be deployed on the Digital Services Platform (DSP).\n\n*(This project assumes the user has Node.js installed on their system. For full instructions on how to install, go to the [Node.js downloads page](https://nodejs.org/download/).)*\n\n- [Quick start](./documentation/QUICK_START.md)\n- [Environment variables](./documentation/ENVIRONMENT_VARIABLES.md)\n- [NPM Scripts](./documentation/NPM_SCRIPTS.md)\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-openjdk8-jre","private":false,"url":"https://github.com/UKHomeOffice/docker-openjdk8-jre","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Docker Java JRE Container\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-openjdk8-jre.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-openjdk8-jre)\n\nDocker container that also includes Open Java 8 *JRE* install for running production applications.\n\n## Getting Started\n\nThese instructions will cover usage information and for the docker container \n\n### Prerequisites\n\nIn order to run this container you'll need docker installed.\n\n* [Windows](https://docs.docker.com/windows/started)\n* [OS X](https://docs.docker.com/mac/started/)\n* [Linux](https://docs.docker.com/linux/started/)\n\n### Usage\n\nNormally, this would be used as a base image for a Java application.\nThe example Dockerfile below will add custom artefacts and an entrypoint to run them.\nThere is an onbuild trigger which will calls the downstream (child) docker images to upgrade the java-openjdk on each iteration\n\n```\n# Use this repo\nFROM quay.io/ukhomeofficedigital/openjdk8-jre:v0.2.0\n\n# Add application artefacts\nENV app_deploy_path=/var/lib/myapp\nCOPY my_jars/* ${app_deploy_path}/\nENTRYPOINT [\"java -jar ${app_deploy_path}/myapp.jar\"]\n\n```\n\n## Contributing\n\nFeel free to submit pull requests and issues. If it's a particularly large PR, you may wish to discuss\nit in an issue first.\n\nPlease note that this project is released with a [Contributor Code of Conduct](code_of_conduct.md). \nBy participating in this project you agree to abide by its terms.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the \n[tags on this repository](https://github.com/UKHomeOffice/docker-openjdk8-jre/tags). \n\n## Authors\n\n* **Lewis Marshall** - *Initial work* - [Lewis Marshall](https://github.com/LewisMarshall)\n\nSee also the list of [contributors](https://github.com/UKHomeOffice/docker-openjdk8-jre/contributors) who \nparticipated in this project.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.\n\n## Acknowledgments\n\n* [OpenJDK8](http://openjdk.java.net/projects/jdk8/)\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/rotm","private":false,"url":"https://github.com/UKHomeOffice/rotm","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# ROTM Application project for nodejs\n\n[![Docker Repository on Quay.io](https://quay.io/repository/ukhomeofficedigital/rotm-app/status \"Docker Repository on Quay.io\")](https://quay.io/repository/ukhomeofficedigital/rotm-app)\n[![Build Status](https://drone.digital.homeoffice.gov.uk/api/badges/UKHomeOffice/rotm/status.svg)](https://drone.digital.homeoffice.gov.uk/UKHomeOffice/rotm)\n\n\n## Quick start\n\nInstall the dependencies and build the project resources\n```bash\n$ npm install\n```\n\nInitiate the server in development mode (Express is used to serve the static resources in development).\n```bash\n$ npm run dev\n```\n\nThe app runs on the path /report-terrorism\n\nThen select one of the following journeys to see the application in action\n\n## NPM scripts\n\nStart the application in default mode (production).\nWe use Nginx to serve our static resources in production and ci.\n```bash\n$ npm start\n```\n\nStart the application with [Nodemon](https://www.npmjs.com/package/nodemon) in development mode.\nDebug is switched on and the server restarts when the JS or Sass are recompiled.\n```bash\n$ npm run dev\n```\n\nRun the unit tests\n```bash\n$ npm run test\n```\n\nRun the EcmaScript (ES) linter.  Rules are defined in [.eslintrc](./.eslintrc)\n```bash\n$ npm run lint\n```\n\nRun the jscs style checker. Rules are defined in [.jscsrc](./.jscsrc)\n```bash\n$ npm run style\n```\n\nAnalyse the quality of the codebase (for results - open [./reports/plato/index.html](./reports/plato/index.html))\n```bash\n$ npm run quality\n```\n\nCompile the Sass to CSS\n```bash\n$ npm run sass\n```\n\n_____________________________________________________________\n\n- For details on [Acceptance tests](https://github.com/UKHomeOffice/RTM/tree/master/acceptance_tests)\n\n- See the [package.json](./package.json) for a full list of scripts.\n\n- Full list of [environment variables](./documentation/ENVIRONMENT_VARIABLES.md)\n\ntouched\n","travis":false,"contributing":"# Contribution guidelines\n\nWe welcome patches!\n\n## Commit hygiene\n\nWe like to follow the recommendations set out in the GDS [git style guide][gitstyle]\nwhich describes how we prefer git history and commit messages to read.\n\n[gitstyle]: https://github.com/alphagov/styleguides/blob/master/git.md\n\n## JavaScript\n\nWe have a JavaScript style checker `npm run style`\n\nAll our styles are defined in our [JavaScript style config][jsstyle]\n\nWe follow the [Google JavaScript style guide](https://google.github.io/styleguide/javascriptguide.xml)\n\nWe also lint our code `npm run lint`.\n\n[jsstyle]: https://github.com/UKHomeOffice/brp_app/blob/master/.jscsrc.json\n\nA pre commit hook is run as part of the project which runs the above checks and our tests (`npm run test`).\n\n## Visual changes\n\nFor visual changes, it can be helpful to provide images in your pull-request\nshowing before and after to highlight the differences.","masterBranchProtection":false},{"name":"UKHomeOffice/scala-futures-demo","private":false,"url":"https://github.com/UKHomeOffice/scala-futures-demo","license":{"key":"other","name":"Other","spdxId":null,"url":null,"featured":false},"readme":"Scala Futures Demo\n==================\nDemo of Scala Futures at a high level - Get the basics of using Futures correctly.\n\nApplication built with the following (main) technologies:\n\n- Scala\n\n- SBT\n\n- Specs\n\nIntroduction\n------------\nTODO\n\nBuild\n-----\nThe project is built with SBT. On a Mac (sorry everyone else) do:\n> brew install sbt\n\nIt is also a good idea to install Typesafe Activator (which sits on top of SBT) for when you need to create new projects - it also has some SBT extras, so running an application with Activator instead of SBT can be useful. On Mac do:\n> brew install typesafe-activator\n\nTo compile:\n> sbt compile\n\nor\n> activator compile\n\nTo run the specs:\n> sbt test\n\nHow Not to use Futures\n----------------------\nThe original Registered Traveller Customer application is a prime example of how not to use Scala Futures.\nAt the time of writing, there are some issues in the Registered Traveller Caseworker application, and we shall highlight some examples here that have been fixed.\n\nIn \"corecaseworker\" WICrossCheckDownloadServiceSpec, there was the following code:\n\n```scala\nwiCrossCheckDownloadService.generateDownload(\"tester@tester.com\")\nthere was one(crossCheckService).setCheckToInProgress(casesReadyForTravelHistory)\n\n```\n\nWhere generateDownload results in a Future[ProcessingStatus]\n\nThis was subsequently changed to:\n\n```scala\nwiCrossCheckDownloadService.generateDownload(\"tester@tester.com\") must beLike[ProcessingStatus] {\n  case ProcessingStatus(ProcessingStatus.SUCCESS, 5, 3, Nil) =>\n    there was one(crossCheckService).setCheckToInProgress(casesReadyForTravelHistory)\n}.awaitFor(10 seconds)\n```","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/ReportTerroristMaterialPrototype","private":false,"url":"https://github.com/UKHomeOffice/ReportTerroristMaterialPrototype","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# ReportTerroristMaterialPrototype\nReport Terrorist Material UX Prototype\n","travis":false,"contributing":"# Contribution guidelines\n\nWe really like contributions and bug reports, in fact the project wouldn't have got to this stage without them. \nWe do have a few guidelines to bear in mind.\n\n## GOV.UK Elements\n\nThe project contains code taken from the [GOV.UK Elements](https://github.com/alphagov/govuk_elements/) project.\nPlease check that any issues related to that code are raised with that project, not this one.\n\n## Raising bugs\n\nWhen raising bugs please explain the issue in good detail and provide a guide to how to replicate it. \nWhen describing the bug it's useful to follow the format:\n\n- what you did\n- what you expected to happen\n- what happened\n\n## Suggesting features\n\nPlease raise feature requests as issues before contributing any code.\nThis is just to ensure they are discussed properly before any time is spent on them.\n\n## Contributing code\n\n### Indentation and whitespace\n\n2-space, soft-tabs only please. No trailing whitespace.\n\n### Versioning\n\nWe use [semantic versioning](http://semver.org/), and bump the version\non master only. Please don't submit your own proposed version numbers.\n\n### Commit hygiene\n\nPlease see our [git style guide](https://github.com/alphagov/styleguides/blob/master/git.md)\nwhich describes how we prefer git history and commit messages to read.\n","masterBranchProtection":false},{"name":"UKHomeOffice/docker-selenium-local-server","private":false,"url":"https://github.com/UKHomeOffice/docker-selenium-local-server","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Docker Selenium Server in the Background\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-selenium-local-server.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-selenium-local-server)\n\nThis docker container extends selenium server and allows you to run \nprocesses which require it locally. This is useful for tests that require \nfile uploads, which can only be done locally from the selenium server.\n\n## Getting Started\n\nThese instructions will cover usage information and for the docker container \n\n### Prerequisities\n\n\nIn order to run this container you'll need docker installed.\n\n* [Windows](https://docs.docker.com/windows/started)\n* [OS X](https://docs.docker.com/mac/started/)\n* [Linux](https://docs.docker.com/linux/started/)\n\n### Usage\n\n#### Container Parameters\n\nThis will run anything you pass after the container. The example below will run a java application mounted from the \ncurrent directory:\n\n```shell\ndocker run -v ${PWD}:/code quay.io/ukhomeofficedigital/selenium-local-server:v0.1.2 java -jar /code/myjar.jar\n```\n\n#### Environment Variables\n\n* `LOCAL_HOSTS_ENTRY` - An entry point to a hosts file (Supports browser endpoint testing without complex whitelisting \nrules).  \n  Example: LOCAL_HOSTS_ENTRY='127.0.0.1 mywebsite.prod.gov.uk'\n\n#### Volumes\n\n* `/code` - Mount any dependencies you want to send as files to Selenium as a volume.\n* `/root/.gradle/caches` - Speeds up gradle builds when this data is mounted. \n\n## Built With\n\n* [quay.io/ukhomeofficedigital/selenium-standalone-server:v0.1.2](https://github.com/UKHomeOffice/docker-selenium-standalone-server)\n\n## Find Us\n\n* [GitHub](https://github.com/UKHomeOffice/docker-selenium-local-server)\n* [Quay.io](https://quay.io/ukhomeofficedigital/selenium-local-server)\n\n## Contributing\n\nPlease read [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct, and the process for submitting pull requests to us.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the \n[tags on this repository](https://github.com/UKHomeOffice/docker-selenium-local-server/tags). \n\n## Authors\n\n* **Lewis Marshall** - *Initial work* - [Lewis Marshall](https://github.com/lewismarshall)\n\nSee also the list of [contributors](https://github.com/UKHomeOffice/docker-selenium-local-server/contributors) who \nparticipated in this project.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/UKHomeOffice.github.io","private":false,"url":"https://github.com/UKHomeOffice/UKHomeOffice.github.io","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# UKHomeOffice.github.io\n\nGitHub pages site for the Home Office Digital team summarising what has been open sourced.\n\nIt uses [Jekyll](https://jekyllrb.com/), see there for more usage documentation\n\n## Getting Started\n\nThese instructions will get you a copy of the project up and running on your local machine for development and testing purposes. See deployment for notes on how to deploy the project on a live system.\n\n### Prerequisities\n\nYou'll need ruby, and bundler.\n\nDownload ruby through however you prefer for you system. Bundler can be installed by gem.\n\n```\ngem install bundler\n```\n\n### Installing\n\nSimply install the dependencies\n\n```\nbundle install\n```\n\nAnd run the server\n\n```\nbundle exec jekyll serve\n```\n\nEnd with an example of getting some data out of the system or using it for a little demo\n\n## Deployment\n\nThis is deployed using [Github Pages](https://help.github.com/articles/using-jekyll-with-pages/)\n\n## Built With\n\n* jekyll\n* Github Pages\n\n## Contributing\n\nPlease read [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct, and the process for submitting pull requests to us.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the [tags on this repository](https://github.com/UKHomeOffice/UKHomeOffice.github.io/tags). \n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details\n","travis":false,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\nYou may merge the Pull Request in once you have the sign-off of two other developers, or if you \ndo not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/UKHomeOffice.github.io/branches/master/protection","requiredStatusChecks":{"url":"https://api.github.com/repos/UKHomeOffice/UKHomeOffice.github.io/branches/master/protection/required_status_checks","strict":true,"includeAdmins":true,"contextsUrl":"https://api.github.com/repos/UKHomeOffice/UKHomeOffice.github.io/branches/master/protection/required_status_checks/contexts"}}},{"name":"UKHomeOffice/docker-mysql-java-jdk","private":false,"url":"https://github.com/UKHomeOffice/docker-mysql-java-jdk","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Docker MySQL Java JDK Container\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-mysql-java-jdk.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-mysql-java-jdk)\n\nDocker MySQL Container that also includes Open Java 8 *JDK* install.\nIt will start mysql in the background then run any parameters provided. \n\n## Getting Started\n\nThese instructions will cover usage information and for the docker container \n\n### Prerequisities\n\nIn order to run this container you'll need docker installed.\n\n* [Windows](https://docs.docker.com/windows/started)\n* [OS X](https://docs.docker.com/mac/started/)\n* [Linux](https://docs.docker.com/linux/started/)\n\n### Usage\n\nThe example below, starts the mysql instance then runs a Java (gradle) build:\n\n```\ndocker run -i --rm=true \\\n        -v ${BUILD_HOME_DIR}:/code \\\n        -e BUILD_NUMBER=${BUILD_NUMBER} \\\n        -e MYSQL_ROOT_PASSWORD=password \\\n        -v ${GRADLE_CACHE}:/root/.gradle/caches \\\n        quay.io/ukhomeofficedigital/mysql-java-jdk:v0.1.1 \\\n        ./gradlew -Dspring.datasource.username=root \\\n            -Dspring.datasource.password=${MYSQL_ROOT_PASSWORD} \\\n            -Dspring.datasource.url=jdbc:mysql://127.0.0.1/mydb \\\n            -Dliquibase.url=jdbc:mysql://127.0.0.1/mydb \\\n            -Dliquibase.user=root \\\n            -Dliquibase.password=${MYSQL_ROOT_PASSWORD} \\\n            \"$@\"\n    exit 0\nfi\n```\n\nIt extends the mysql only repository and as such, additional relevant documentation is available here:\n[Docker MySQL](https://github.com/UKHomeOffice/docker-mysql/blob/v0.5.1/README.md)\n \n\n## Contributing\n\nFeel free to submit pull requests and issues. If it's a particualy large PR, you may wish to discuss\nit in an issue first.\n\nPlease note that this project is released with a [Contributor Code of Conduct](code_of_conduct.md). \nBy participating in this project you agree to abide by its terms.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the \n[tags on this repository](https://github.com/UKHomeOffice/docker-mysql-java/tags). \n\n## Authors\n\n* **Lewis Marshall** - *Initial work* - [Lewis Marshall](https://github.com/LewisMarshall)\n\nSee also the list of [contributors](https://github.com/UKHomeOffice/docker-mysql-java/contributors) who \nparticipated in this project.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.\n\n## Acknowledgments\n\n* This container is taken from the \n  [UKHomeOffice mysql docker container](https://quay.io/repository/ukhomeofficedigital/mysql).\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-mysql-maintenance","private":false,"url":"https://github.com/UKHomeOffice/docker-mysql-maintenance","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Docker MySQL Maintenance Container\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-mysql-maintenance.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-mysql-maintenance)\n\nThis is a one shot docker container that change your MySQL root password from the default. Optionally it can also run \nscripts and SQL after it has done this to do basic DB initialisation.\n\n## Getting Started\n\nThese instructions will cover usage information and for the docker container \n\n### Prerequisities\n\n\nIn order to run this container you'll need docker installed.\n\n* [Windows](https://docs.docker.com/windows/started)\n* [OS X](https://docs.docker.com/mac/started/)\n* [Linux](https://docs.docker.com/linux/started/)\n\n### Usage\n\n#### Container Parameters\n\nProvide no parameters and the container will ensure the root password is set correctly and run any SQL or shell scripts \nin the directory and exit\n\n```shell\ndocker run quay.io/ukhomeofficedigital/mysql-maintenance:v0.1.0\n```\n\nProvide any other parameter and it'll execute it\n\n```shell\ndocker run quay.io/ukhomeofficedigital/mysql-maintenance:v0.1.0 echo hello\n```\n\nwill echo `hello`\n\n#### Environment Variables\n\n* `MYSQL_HOST` - Host of MySQL server\n* `MYSQL_PORT` - MySQL Port (defaults to `3306`)\n* `DEFAULT_PW` - Default password your MySQL server is started up with (defaults to `changeme`)\n* `MYSQL_PASSWORD_PATH` - Path to file with new password in\n\n#### Useful File Locations\n\n* `/docker-entrypoint-initdb.d/*.sh` - Will be executed. MySQL password and user root is already set.\n* `/docker-entrypoint-initdb.d/*.sql` - Will be ran as root mysql user\n\n#### Kubernetes Example\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    db: mysql\n    type: oneshot\n    maintenance: true\n  name: mysql-maintenance\nspec:\n  containers:\n  - image: quay.io/ukhomeofficedigital/mysql-maintenance:v0.1.0\n    name: mysql-maintenance\n    env:\n    - name: MYSQL_HOST\n      value: mymysqlserver\n    - name: MYSQL_PASSWORD_PATH\n      value: /secrets/password.txt\n    volumeMounts:\n    - mountPath: /secrets\n      name: mysql-password\n  imagePullPolicy: Always\n  restartPolicy: Never\n  volumes:\n    -\n      name: mysql-password\n      secret:\n        secretName: \"mysql-password\"\n```\n\n\n## Built With\n\n* [ukhomeofficedigital/mysql v0.5.0](https://github.com/UKHomeOffice/docker-mysql/releases/tag/v0.5.0)\n\n## Find Us\n\n* [GitHub](https://github.com/UKHomeOffice/docker-mysql-maintenance)\n* [Quay.io](https://quay.io/repository/ukhomeofficedigital/mysql-maintenance)\n\n## Contributing\n\nPlease read [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct, and the process for submitting pull requests to us.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the \n[tags on this repository](https://github.com/UKHomeOffice/docker-mysql-maintenance/tags). \n\n## Authors\n\nSee the list of [contributors](https://github.com/UKHomeOffice/docker-mysql-maintenance/contributors) who participated in this project.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/vault-sidekick","private":false,"url":"https://github.com/UKHomeOffice/vault-sidekick","license":{"key":"apache-2.0","name":"Apache License 2.0","spdxId":"Apache-2.0","url":"https://api.github.com/licenses/apache-2.0","featured":true},"readme":"[![Build Status](https://travis-ci.org/UKHomeOffice/vault-sidekick.svg?branch=master)](https://travis-ci.org/UKHomeOffice/vault-sidekick)\n[![GoDoc](http://godoc.org/github.com/UKHomeOffice/vault-sidekick?status.png)](http://godoc.org/github.com/UKHomeOffice/vault-sidekick)\n[![Docker Repository on Quay](https://quay.io/repository/ukhomeofficedigital/vault-sidekick/status \"Docker Repository on Quay\")](https://quay.io/repository/ukhomeofficedigital/vault-sidekick)\n[![GitHub version](https://badge.fury.io/gh/UKHomeOffice%2Fvault-sidekick.svg)](https://badge.fury.io/gh/UKHomeOffice%2Fvault-sidekick)\n\n### **Vault Side Kick**\n\n**Summary:**\nVault Sidekick is a add-on container which can be used as a generic entry-point for interacting with Hashicorp [Vault](https://vaultproject.io) service, retrieving secrets\n(both static and dynamic) and PKI certs. The sidekick will take care of renewal's and extension of leases for you and renew the credentials in the specified format for you.\n\n**Usage:**\n\n```shell\n[jest@starfury vault-sidekick]$ bin/vault-sidekick --help\nUsage of bin/vault-sidekick:\n  -alsologtostderr=false: log to standard error as well as files\n  -auth=\"\": a configuration file in a json or yaml containing authentication arguments\n  -cn=: a resource to retrieve and monitor from vault (e.g. pki:name:cert.name, secret:db_password, aws:s3_backup)\n  -ca-cert=\"\": a CA certificate to use in order to validate the vault service certificate\n  -delete-token=false: once the we have connected to vault, delete the token file from disk\n  -dryrun=false: perform a dry run, printing the content to screen\n  -log_backtrace_at=:0: when logging hits line file:N, emit a stack trace\n  -log_dir=\"\": If non-empty, write log files in this directory\n  -logtostderr=false: log to standard error instead of files\n  -output=\"/etc/secrets\": the full path to write the protected resources (VAULT_OUTPUT if available)\n  -stats=5m0s: the interval to produce statistics on the accessed resources\n  -stderrthreshold=0: logs at or above this threshold go to stderr\n  -tls-skip-verify=false: skip verifying the vault certificate\n  -token=\"\": the token used to authenticate to teh vault service (VAULT_TOKEN if available)\n  -v=0: log level for V logs\n  -vault=\"https://127.0.0.1:8200\": the url the vault service is running behind (VAULT_ADDR if available)\n  -vmodule=: comma-separated list of pattern=N settings for file-filtered logging\n```\n\n**Building**\n\nThere is a Makefile in the base repository, so assuming you have make and go: # make\n\n**Example Usage**\n\nThe below is taken from a [Kubernetes](https://github.com/kubernetes/kubernetes) pod specification;\n\n```YAML\nspec:\n      containers:\n      - name: vault-side-kick\n        image: gambol99/vault-sidekick:latest\n        args:\n          - -output=/etc/secrets\n          - -cn=pki:project1/certs/example.com:common_name=commons.example.com,revoke=true,update=2h\n          - -cn=secret:secret/db/prod/username:file=.credentials\n          - -cn=secret:secret/db/prod/password\n          - -cn=aws:aws/creds/s3_backup_policy:file=.s3_creds\n        volumeMounts:\n          - name: secrets\n            mountPath: /etc/secrets\n```\n\nThe above say's\n\n - Write all the secrets to the /etc/secrets directory\n - Retrieve a dynamic certificate pair for me, with the common name: 'commons.example.com' and renew the cert when it expires automatically\n - Retrieve the two static secrets /db/prod/{username,password} and write them to .credentials and password.secret respectively\n - Apply the IAM policy, renew the policy when required and file the API tokens to .s3_creds in the /etc/secrets directory\n - Read the template at /etc/templates/db.tmpl, produce the content from Vault and write to /etc/credentials file\n\n**Authentication**\n\nA authentication file can be specified in either yaml of json format which contains a method field, indicating one of the authentication\nmethods provided by vault i.e. userpass, token, github etc and then followed by the required arguments for that plugin.\n\nIf the required arguments for that plugin are not contained in the authentication file, fallbacks from environment variables are used.\nEnvironment variables are prefixed with `VAULT_SIDEKICK`, i.e. `VAULT_SIDEKICK_USERNAME`, `VAULT_SIDEKICK_PASSWORD`.\n\n**Secret Renewals**\n\nThe default behaviour of vault-sidekick is **not** to renew a lease, but to retrieve a new secret and allow the previous to\nexpire, in order ensure the rotation of secrets. If you don't want this behaviour on a resource you can override using resource options. For exmaple,\nyour using the mysql dynamic secrets, you want to renew the secret not replace it\n\n```shell\n[jest@starfury vault-sidekick]$ build/vault-sidekick -cn=mysql:mysql/creds/my_database:fmt=yaml,renew=true\nor an iam policy renewed every hour\n[jest@starfury vault-sidekick]$ build/vault-sidekick -cn=aws:aws/creds/policy:fmt=yaml,renew=true,update=1h\n\n```\n\nOr you want to rotate the secret every **1h** and **revoke** the previous one\n\n```shell\n[jest@starfury vault-sidekick]$ build/vault-sidekick -cn=aws:project/creds/my_s3_bucket:fmt=yaml,update=1h,revoke=true\n\nThe format is;\n\n-cn=RESOURCE_TYPE:PATH:OPTIONS\n```\n\nThe sidekick supports the following resource types: mysql, postgres, pki, aws, secret, cubbyhole, raw, cassandra and transit\n\n**Environment Variable Expansion**\n\nThe resource paths can contain environment variables which the sidekick will resolve beforehand. A use case being, using a environment\nor domain within the resource e.g -cn=secret:secrets/myservice/${ENV}/config:fmt=yaml\n\n**Output Formatting**\n\nThe following output formats are supported: json, yaml, ini, txt, cert, csv, bundle, env\n\nUsing the following at the demo secrets\n\n```shell\n[jest@starfury vault-sidekick]$ vault write secret/password this=is demo=value nothing=more\nSuccess! Data written to: secret/password\n[jest@starfury vault-sidekick]$ vault read secret/password\nKey            \tValue\nlease_id       \tsecret/password/7908eceb-9bde-e7de-23da-96131505214a\nlease_duration \t2592000\nlease_renewable\tfalse\ndemo           \tvalue\nnothing        \tmore\nthis           \tis\n```\n\nIn order to change the output format:\n\n```shell\n[jest@starfury vault-sidekick]$ build/vault-sidekick -cn=secret:secret/password:fmt=ini -logtostderr=true -dry-run\n[jest@starfury vault-sidekick]$ build/vault-sidekick -cn=secret:secret/password:fmt=json -logtostderr=true -dry-run\n[jest@starfury vault-sidekick]$ build/vault-sidekick -cn=secret:secret/password:fmt=yaml -logtostderr=true -dry-run\n```\n\nFormat: 'cert' is less of a format of more file scheme i.e. is just extracts the 'certificate', 'issuing_ca' and 'private_key' and creates the three files FILE.{ca,key,crt}. The\nbundle format is very similar in the sense it similar takes the private key and certificate and places into a single file.\n\n**Resource Options**\n\n- **file**: (filaname) by default all file are relative to the output directory specified and will have the name NAME.RESOURCE; the fn options allows you to switch names and paths to write the files\n- **create**: (create) create the resource\n- **update**: (update) override the lease time of this resource and get/renew a secret on the specified duration e.g 1m, 2d, 5m10s\n- **renew**: (renewal) override the default behavour on this resource, renew the resource when coming close to expiration e.g true, TRUE\n- **delay**: (renewal-delay) delay the revoking the lease of a resource for x period once time e.g 1m, 1h20s\n- **revoke**: (revoke) revoke the old lease when you get retrieve a old one e.g. true, TRUE (default to allow the lease to expire and naturally revoke)\n- **fmt**: (format) allows you to specify the output format of the resource / secret, e.g json, yaml, ini, txt\n- **exec** (execute) execute's a command when resource is updated or changed\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change.\n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a\n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment\n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you\n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and\nwelcoming community, we pledge to respect all people who contribute through reporting issues,\nposting feature requests, updating documentation, submitting pull requests or patches, and other\nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone,\nregardless of level of experience, gender, gender identity and expression, sexual orientation,\ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits,\ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By\nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently\napplying these principles to every aspect of managing this project. Project maintainers who do not\nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is\nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an\nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org),\nversion 1.2.0, available at\n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)","masterBranchProtection":false},{"name":"UKHomeOffice/docker-vault-sidekick","private":false,"url":"https://github.com/UKHomeOffice/docker-vault-sidekick","license":{"key":"apache-2.0","name":"Apache License 2.0","spdxId":"Apache-2.0","url":"https://api.github.com/licenses/apache-2.0","featured":true},"readme":false,"travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-nginx-tls","private":false,"url":"https://github.com/UKHomeOffice/docker-nginx-tls","license":{"key":"apache-2.0","name":"Apache License 2.0","spdxId":"Apache-2.0","url":"https://api.github.com/licenses/apache-2.0","featured":true},"readme":"#### **Nginx TLS Sidekick**\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-nginx-tls.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-nginx-tls)\n\nA small utility container which is responsible to rotating the certificates on a nginx proxy.\n\n```shell\nUsage: run.sh\n  -c|--confd DIRECTORY      : the path of the nginx conf.d directory (default /etc/nginx/conf.d)\n  -d|--dir DIRECTORY        : the directory which contains the certificates (default /etc/secrets)\n  -p|--proxy SPEC           : the specification for a proxy\n  -h|--help                 : display this usage menu\n```\n\n##### **Usage**\n\n```shell\n[jest@starfury docker-nginx-tls]$ make demo\nsudo docker run -ti  --name nginx-tls --rm -v /home/jest/scm/github/UKHomeOffice/docker-nginx-tls/tests:/etc/secrets gambol99/nginx-tls /run.sh -p 443:127.0.0.1:80:demo.example.com\n[v] proxy spec: '443:127.0.0.1:80:demo.example.com' is valid\n[v] reconfiguring the nginx service\n[v] configuring the nginx proxy: 443:127.0.0.1:80:demo.example.com\n[v] starting the nginx service\n[v] watching the directory: /etc/secrets for changes\n[v] /etc/secrets/ CLOSE_WRITE,CLOSE demo.example.com.crt has changed, reconfiguring the service now\n[v] reconfiguring the nginx service\n[v] configuring the nginx proxy: 443:127.0.0.1:80:demo.example.com\n[v] nginx config passed validation, reloading service\n```\n\nA proxy specification takes the form for: LISTENING_PORT:PROXY_IPADDRESS:PROXY_PORT:CERTIFICATE. Multiple endpoints can be defined by repeating the -p|--proxy command line option.\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/AlfrescoAuditAnalysis","private":false,"url":"https://github.com/UKHomeOffice/AlfrescoAuditAnalysis","license":null,"readme":"# AlfrescoAuditAnalysis\nAlfresco Audit Analysis\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/OSX-Provisioning","private":false,"url":"https://github.com/UKHomeOffice/OSX-Provisioning","license":null,"readme":"# OSX-Provisioning\n\n**Admin-setup.sh**\n\nThis script is designed to be run on a mac that is brand new, or had been rebuilt from a usb image. The script assumes the inital stages of first boot have been completed and that you have created a local admin account, are logged on and know the password for that. There should be no other accounts present, so runt his prior to creating any user accounts.\n\nThis will apply a number of security hardening settings, including applying full disk encryption wiht file vault. PLEASE make sure you make a note of the key that is shown on screen during this script running.\n\n**byod-check.sh**\n\nThis script, must be run as admin, and will check to see if a device has the required security applied. It does not change settings, only reports on them.\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-sonar-mysql-maintenance","private":false,"url":"https://github.com/UKHomeOffice/docker-sonar-mysql-maintenance","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Docker Sonar Maintenance Container\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-sonar-mysql-maintenance.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-sonar-mysql-maintenance)\n\nThis is a one shot container that will create the missing Sonar DB in your database, and also ensure the password is up \nto date (and not the default one).\n\nIf you are looking for a container that has a MySQL server running within it, that has the sonar database, see \n[UKHomeOffice/docker-mysql-sonarqube](https://github.com/UKHomeOffice/docker-mysql-sonarqube).\n\n## Getting Started\n\nThese instructions will cover usage information and for the docker container \n\n### Prerequisities\n\n\nIn order to run this container you'll need docker installed.\n\n* [Windows](https://docs.docker.com/windows/started)\n* [OS X](https://docs.docker.com/mac/started/)\n* [Linux](https://docs.docker.com/linux/started/)\n\n### Usage\n\n#### Container Parameters\n\nProvide no parameters and the container will ensure the root password is set correctly and create the Sonar database.\nin the directory and exit\n\n```shell\ndocker run quay.io/ukhomeofficedigital/sonar-mysql-maintenance:v0.1.0\n```\n\nProvide any other parameter and it'll execute it\n\n```shell\ndocker run quay.io/ukhomeofficedigital/sonar-mysql-maintenance:v0.1.0 echo hello\n```\n\nwill echo `hello`\n\n#### Environment Variables\n\n* `MYSQL_HOST` - Host of MySQL server\n* `MYSQL_PORT` - MySQL Port (defaults to `3306`)\n* `DEFAULT_PW` - Default password your MySQL server is started up with (defaults to `changeme`)\n* `MYSQL_PASSWORD_PATH` - Path to file with new password in\n\n#### Kubernetes Example\n\nSee the [kb8 directory](kb8)\n\n## Built With\n\n* [UKHomeOffice/docker-mysql-maintenance v0.1.0](https://github.com/UKHomeOffice/docker-sonar-mysql-maintenance/releases/tag/v0.1.0)\n\n## Find Us\n\n* [GitHub](https://github.com/UKHomeOffice/docker-sonar-mysql-maintenance)\n* [Quay.io](https://quay.io/ukhomeofficedigital/sonar-mysql-maintenance/docker-repository)\n\n## Contributing\n\nPlease read [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct, and the process for submitting pull requests to us.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the \n[tags on this repository](https://github.com/UKHomeOffice/docker-sonar-mysql-maintenance/tags). \n\n## Authors\n\nSee also the list of [contributors](https://github.com/UKHomeOffice/docker-sonar-mysql-maintenance/contributors) who \nparticipated in this project.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.\n\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/docker-logstash-kubernetes","private":false,"url":"https://github.com/UKHomeOffice/docker-logstash-kubernetes","license":null,"readme":"# docker-logstash-kubernetes\n\nLogstash container for pulling docker logs with kubernetes metadata support.\nAdditionally logs are pulled from systemd journal too. Events can be pushed to\nCloudwatch Logs and or ElasticSearch.\n\nLogstash tails docker logs and extracts `pod`, `container_name`, `namespace`,\netc. The way this works is very simple. Logstash looks at an event field which\ncontains full path to kubelet created symlinks to docker container logs, and\nextracts useful information from a symlink name. No access to Kubernetes API\nis required.\n\nEvents can then pushed to Cloudwatch logs (disabled by default). An example\nevent in Cloudwatch Logs looks like below:\n\n```json\n{\n    \"log\": \"10.10.112.0 - - [02/Oct/2015:15:20:38 +0000] \\\"GET /dataset HTTP/1.1\\\" 200 2 \\\"-\\\" \\\"axios/0.5.4\\\" 6\\n\",\n    \"stream\": \"stdout\",\n    \"time\": \"2015-10-02T15:20:38.706043658Z\",\n    \"replication_controller\": \"data-example-api\",\n    \"pod\": \"data-example-api-p82sy\",\n    \"namespace\": \"hoapi-catalogue\",\n    \"container_name\": \"data-example-api\",\n    \"container_id\": \"df1874255f0c85d18747b5edfc8dc372dbebf725b9ccbfb37549f5f81bba8326\"\n}\n```\n\nOther outputs can be added in the future.\n\n## Requirements\n\nYou need to have kubelet process running on the host. Normally kubelet creates\nsymlinks to container logs from `/var/log/containers/` to\n`/var/lib/docker/containers/`. So for that you need to make sure that logstash\nhas access to both directories.\n\nFor logstash to be able to pull logs from journal, you need to make sure that\nlogstash can read `/var/log/journal`.\n\nAlso, logstash writes `sincedb` file to its home directory, which by default is\n`/var/lib/logstash`. If you don't want logstash to start reading docker or\njournal logs from the beginning after a restart, make sure you mount\n`/var/lib/logstash` somewhere on the host.\n\nIf you want to push events to Cloudwatch Logs, then you will have to set AWS\naccess keys via environment variables.\n\n\n## Configuration\n\nAs usual, configuration is passed through environment variables.\n\n- `LS_HEAP_SIZE` - logstash JVM heap size. Defaults to `500m`.\n- `OUTPUT_CLOUDWATCH` - whether to enable this output. Defaults to `false`.\n- `AWS_REGION` - defaults to `eu-west-1`.\n- `AWS_ACCESS_KEY_ID` - must be set.\n- `AWS_SECRET_ACCESS_KEY` - must be set.\n- `LOG_GROUP_NAME` - Cloudwatch logs group name. Defaults to `logstash`.\n- `LOG_STREAM_NAME` - Cloudwatch logs stream name. Defaults to `hostname()`.\n- `INPUT_JOURNALD` - Enable logs ingestion from journald. Default: `true`.\n- `OUTPUT_ELASTICSEARCH` - Enable logs output to ElasticSearch. Default `true`.\n- `ELASTICSEARCH_HOST` - ElasticSearch host, can be comma separated. Default: `127.0.0.1:9200`.\n- `ELASTICSEARCH_INDEX_SUFFIX` - ElasticSearch index suffix. Default: `\"\"`.\n- `LOGSTASH_ARGS` - Sets additional logstash command line arguments.\n\n\n## Running\n\n```\n$ docker run -ti --rm \\\n    -v /var/lib/logstash-kubernetes:/var/lib/logstash:z \\\n    -v /var/log/journal:/var/log/journal:ro \\\n    -v /var/lib/docker/containers:/var/lib/docker/containers:ro \\\n    -v /var/log/containers:/var/log/containers:ro \\\n    -e ELASTICSEARCH_HOST=my-est-host.local:9200 \\\n    quay.io/ukhomeofficedigital/logstash-kubernetes:v0.4.0\n```\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-landscaper-server","private":false,"url":"https://github.com/UKHomeOffice/docker-landscaper-server","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Ubuntu LandScape Docker Container\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-landscape-server.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-landscape-server)\n\nThis container runs the Ubuntu landscape server components\n\n#Requirements\n\n- Landscape requires a postgres 9.3/9.4 server with plpython and the debversion modules installed\n- A rabbitmq server is also required as the message bus between the various components\n\n#TLS\n\nThere is a placeholer certificate in the files/certs directory which gets added to the container and used by apache for the SSL endpoint.\n\nThis has a common name of 'landscape-server'.\nThis should be replaced with a valid certificate and key\n\n#Running locally\n\nThere is a docker compose file which will bring up a landscape server,\nthis will bring up the landscape server on port 80/443 on your docker host\n```\ndocker-compose build\ndocker-compose up\n```\n\nIt does the following:\n## Postgres database server\nCreate a postgres container based off of the official 9.4 version with plpython and debversion installed\n\n```\ndocker build -t postgres .\ndocker run -d --name postgres -e POSTGRES_PASSWORD=password postgres\n```\n\n## Rabbitmq server\nCreate a rabbitmq container that will be linked in, which has the management module enables so you can \naccess it via a web console\n\n```\ndocker run -d --name rabbitmq -p 15672:15672 rabbitmq:3-management\n```\n\n## Landscape container creation\nThen it build the landscape container, this container is based on ubuntu:14.04, this will link the postgres container into the landscape container and use that, if you have an external postgres instance you would just set the variables that are required\n\n```\ndocker build -t landscape-server\ndocker run -d --link postgres:postgres --link rabbitmq:rabbitmq -e INITIALIZE_SCHEMA=yes -e DB_USER=postgres -e DB_PASS=password -e DB_LANDSCAPE_PASS=password -p 80:80 -p 443:443 landscape-server\n```\n\n### Valid commands for the landscape container\n- app:schema - This will create the landscape user and schema but not start the application\n- app:start - This starts the application, this is also the default action\n\n#Variables that can be set\n\n| Variable             | Default   | Usage  |\n| -------------------- | --------- | ------ |\n| STARTUP_WAIT_TIME    | empty     | Wait number of seconds before starting process, useful for waiting for other services to come up |\n| INITIALIZE_SCHEMA    | empty     | If set this will create the database schema or confirm it is valid |\n| DB_HOST              | empty     | The postgres server hostname |\n| DB_PORT              | 5432      | The postgres server port |\n| DB_LANDSCAPE_PASS    | password  | The landscape user password |\n| DB_USER              | landscape | The postgres super user, this user is used for schema creation|\n| DB_PASS              | landscape | The postgres super user password |\n| DB_NAME              | postgres  | The default database name for testing connectivity |\n| RMQ_HOST             | empty     | The rabbitmq server hostname |\n| RMQ_PORT             | 5672      | The rabbitmq server amqp port |\n| RMQ_USER             | guest     | The rabbitmq user |\n| RMQ_PASS             | guest     | The rabbitmq password |\n| RMQ_VHOST            | default   | The vhost to be used by the message broker |\n","travis":true,"contributing":"# Contributing\n\nFeel free to submit pull requests and issues. If it's a particularly large PR, you may wish to\ndiscuss it in an issue first.\n\nPlease note that this project is released with a [Contributor Code of Conduct](code_of_conduct.md).\nBy participating in this project you agree to abide by its terms.\n","masterBranchProtection":false},{"name":"UKHomeOffice/docker-elasticsearch","private":false,"url":"https://github.com/UKHomeOffice/docker-elasticsearch","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# ElasticSearch on Kubernetes\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-elasticsearch.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-elasticsearch)\n[![Docker Repository on Quay](https://quay.io/repository/ukhomeofficedigital/elasticsearch/status \"Docker Repository on Quay\")](https://quay.io/repository/ukhomeofficedigital/elasticsearch)\n\nElasticSearch 2.3.x with kubernetes discovery plugin for simple deployment and\ndiscovery.\n\n### Configuration\nConfiguration is done via environment variables.\n\nThe following configuration defaults may not necessarily be set to the same\nvalues in [kube/](kube/) example files.\n\n* `CLUSTER_NAME`: ElasticSearch cluster name. Default: `elasticsearch`.\n* `NODE_NAME`: Node name. Default: `${HOSTNAME}` (kubernetes assigned pod name by default).\n* `PATH_DATA`: Path where ES stores its data. Default: `/data`.\n* `ES_HEAP_SIZE`: JVM heap size. Default: `450m`. If you adjust this parameter,\n  make sure to increase container limits as well.\n* `INDEX_AUTO_EXPAND_REPLICAS`: Whether to automatically expand index replicas\n  across data nodes. Default: `false`.\n* `INDEX_NUMBER_OF_SHARDS`: The default number of primary shards for each index. Default: `5`.\n* `INDEX_NUMBER_OF_REPLICAS`: The number of replicas per shard that an index should create. Default `1`.\n* `INDEX_REFRESH_INTERVAL`: How often to refresh indexes. Default: `1s`.\n* `NODE_MASTER`: Whether this node can be a master node. Default: `true`.\n* `NODE_DATA`: Whether this node can be a data node. Default: `true`.\n* `HTTP_ENABLE`: Whether this node can be a client (HTTP) node. Default: `true`.\n* `HTTP_BIND_HOST`: http bind address.. Default: `0.0.0.0`.\n* `KUBERNETES_SERVICE`: kubernetes service name for master nodes. Default `elasticsearch-master`.\n* `ENABLE_TRANSPORT_SSL`: whether to enable search-guard transport SSL. Default: `false`.\n* `DISCOVERY_ZEN_FD_PING_INTERVAL` - see https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery-zen.html#fault-detection\n* `DISCOVERY_ZEN_FD_PING_TIMEOUT` - see https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery-zen.html#fault-detection\n* `DISCOVERY_ZEN_FD_PING_RETRIES` - see https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery-zen.html#fault-detection\n* `DISCOVERY_ZEN_PUBLISH_TIMEOUT` - see https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery-zen.html#_cluster_state_updates\n\n\n### Plugins\n#### Kubernetes Discovery\nFor more kubernetes discovery plugin related options, see\nhttps://github.com/fabric8io/kubernetes-client. Our examples use just a\nstandard kubernetes auth token to authenticate against the kubernetes API for\ndiscovery.\n\n#### Search Guard SSL\nIf you want to use transport TLS, please take a look at their documentation\nhttps://github.com/floragunncom/search-guard-ssl.\n\nElasticSearch expects `truststore.jks` and `keystore.jks` files to be placed in\n`/elasticsearch/config/certs`. Keystore cert/key alias must be `cert` and\ntruststore alias - `ca`. Bare in mind that certs need to be signed by the same\nCA. If you use vault, then take a look at\nhttps://github.com/UKHomeOffice/vaultjks, which could help you to get your\ncerts from vault and create keystore files.\n\n\n### Deployment\nBy default if you start the docker container, ElasticSearch will start in\nstandalone mode.\n\nDeploying onto a Kubernetes cluster is fairly easy. There are example\nkubernetes controller and service files in [kube/](kube/) directory.\n\n\n#### Deploy Master Node\nFirst of all we need to deploy master service for ES master nodes to find each\nother and other communications between nodes. Then we can create the master\nreplication controller.\n\n```bash\n$ kubectl create -f kube/es-master-svc.yaml\n$ kubectl create -f kube/es-master-rc.yaml\n```\n\nWait a few seconds and verify whether it is up and running. You can also scale\nthe master nodes to 3.\n\n```bash\n$ kubectl logs -f es-master-fdfw -c elasticsearch\n$ kubectl scale --replicas=3 rc/es-master\n```\n\n#### Deploy Client and Data Nodes\nOnce the master node is up and running, you can start deploying the rest of the cluster.\n\n```bash\n$ kubectl create -f kube/es-svc.yaml\n$ kubectl create -f kube/es-client-rc.yaml\n$ kubectl create -f kube/es-data-rc.yaml\n```\n\n","travis":true,"contributing":false,"masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/docker-elasticsearch/branches/master/protection"}},{"name":"UKHomeOffice/rtp-proxy-lib","private":false,"url":"https://github.com/UKHomeOffice/rtp-proxy-lib","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"RTP Proxy Library\n=================\n\nScala Spray library to proxy request/response between client and server\n\nApplication built with the following (main) technologies:\n\n- Scala\n\n- SBT\n\n- Akka\n\n- Spray\n\nIntroduction\n------------\nTODO\n\nApplication\n-----------\nThe application is configured as per any Akka application, where the default configuration file is \"application.conf\".\nThis default file can be overridden with other \"conf\" files and then given to the application upon boot with the following example Java option:\n```bash\n-Dconfig.file=test-classes/application.test.conf\n```\n\nIndividual configuration properties can be overridden again by Java options e.g. to override which Mongodb to connect (if Mongo required configuring):\n```bash\n-Dmongo.db=some-other-mongo\n```\n\nwhere this overrides the default in application.conf.\n\nBooting the application (uk.gov.homeoffice.rtp.proxy.Boot) exposes a RESTful API to act as a proxy to the real API e.g. the following URL could be given in a browser, a browser's REST client plugin or curl:\n```bash\nhttp://localhost:9300/blah\n```\n\nthis would get back some appropriate response for some existing API.\n\nBuild and Deploy\n----------------\nThe project is built with SBT. On a Mac (sorry everyone else) do:\n```bash\nbrew install sbt\n```\n\nIt is also a good idea to install Typesafe Activator (which sits on top of SBT) for when you need to create new projects - it also has some SBT extras, so running an application with Activator instead of SBT can be useful. On Mac do:\n```bash\nbrew install typesafe-activator\n```\n\nTo compile:\n```bash\nsbt compile\n```\n\nor\n```bash\nactivator compile\n```\n\nTo run the specs:\n```bash\nsbt test\n```\n\nNote: Do not turn off the CONSOLE logging in test/resources/logback.xml as there are Specs that rely on this\n\nTo actually run the application, first \"assemble\" it:\n```bash\nsbt assembly\n```\n\nThis packages up an executable JAR - Note that \"assembly\" will first compile and test.\n\nThen just run as any executable JAR, with any extra Java options for overriding configurations.\n\nFor example, to use a config file (other than the default application.conf) which is located on the file system (in this case in the boot directory)\n```bash\njava -Dconfig.file=test-classes/my-application.conf -jar <jar name>.jar\n```\n\nNote that the log configuration file could also be included e.g.\n```bash\n-Dlogback.configurationFile=path/to/my-logback.xml\n```\n\nSo a more indepth startup with sbt itself could be:\n```bash\nsbt run -Dconfig.file=target/scala-2.11/test-classes/application.test.conf -Dlogback.configurationFile=target/scala-2.11/test-classes/logback.test.xml\n```\n\nAnd other examples:\n\nbooting from project root:\n```bash\njava -Dspray.can.server.port=8080 -jar target/scala-2.11/<jar name>.jar\n```\n\nand running from directory of the executable JAR using a config that is within said JAR:\n```bash\njava -Dconfig.resource=application.uat.conf -jar <jar name>.jar\n```\n\nFinally you can perform a quick test of the application by calling one of the monitor API e.g. making a cURL call to the application:\n```bash\ncurl http://localhost:9300/proxy-server \n```\n\nExample Usage\n-------------\nProxying can be just a dumb proxy or it can use certificates to create a SSL connection.\nThere are examples in the code e.g. regarding SSL the application configuration would be similar to:\n```scala\nspray {\n  can {\n    server {\n      sslEncryption = true\n      ssl-tracing = on\n    }\n\n    client {\n      sslEncryption = true\n    }\n  }\n}\n\nproxied.server {\n  host = \"localhost\"\n  port = 8443\n}\n\nssl {\n  keystore {\n    type = \"jks\"\n    path = \"classpath:test.keystore\"\n    password = \"password\"\n  }\n\n  truststore {\n    type = \"jks\"\n    path = \"classpath:test.keystore\"\n    password = \"password\"\n  }\n}\n```\nAnd a \"boot\" object would be required for your proxy such as:\n```scala\nobject ExampleBootSSL extends App with HasConfig {\n  val proxiedServer = ProxiedServer(config.getString(\"proxied.server.host\"),\n                                    config.getInt(\"proxied.server.port\"))\n\n  val server = Server(config.getString(\"spray.can.server.host\"),\n                      config.getInt(\"spray.can.server.port\"))\n\n  implicit val system = ActorSystem(config.getString(\"spray.can.server.name\"))\n\n  sys.addShutdownHook {\n    system.shutdown()\n  }\n\n  SSLProxying(sslContext(config)).proxy(proxiedServer, server)\n}\n```\n\nWe can cURL the application - Note that this is related to the SSL section below e.g.\n```bash\ncurl -ki https://localhost:9300\n```\nwhere -k command line argument turns off SSL certificate verification.\n\n```bash\ncurl -i --cacert src/main/resources/test-certificate.crt https://localhost:9300\n```\nwhere the certificate is passed along with the cURL command so a complete SSL certificate verification takes place.\n\nNOTE about timeouts.\nTimeout of requests defaults to 30 seconds. To override this in an application.conf, declare something like:  \nproxied.request-timeout = 1 minute\n\nwhere you can use the likes of second, seconds, minute, minutes, hour etc.\n\nSBT - Revolver\n--------------\nsbt-revolver is a plugin for SBT enabling a super-fast development turnaround for your Scala applications:\n\nSee https://github.com/spray/sbt-revolver\n\nFor development, you can use ~re-start to go into \"triggered restart\" mode.\nYour application starts up and SBT watches for changes in your source (or resource) files.\nIf a change is detected SBT recompiles the required classes and sbt-revolver automatically restarts your application. \nWhen you press &lt;ENTER&gt; SBT leaves \"triggered restart\" and returns to the normal prompt keeping your application running.\n\nSSL\n---\nGenerate x509 certificate and private key:\n```bash\nopenssl req \n        -x509 \n        -sha256 \n        -newkey rsa:2048 \n        -keyout test-certificate.key \n        -out test-certificate.crt \n        -days 100000 \n        -nodes\n```\n\nOn JVM platform the goal is to have a Java keystore (JKS), a repository of security certificates.\nTo import our newly generated certificate into JKS, we have to export it in PKCS12 format and then create keystore out of it:\n```bash\nopenssl pkcs12 \n        -export \n        -in test-certificate.crt \n        -inkey test-certificate.key \n        -out test-keystore.p12 \n        -name test-keystore \n        -password pass:password\n\nkeytool -importkeystore \n        -srcstorepass password \n        -destkeystore test.keystore \n        -deststorepass password \n        -srckeystore test-keystore.p12 \n        -srcstoretype PKCS12 \n        -alias test-keystore\n```","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/removals_wallboard","private":false,"url":"https://github.com/UKHomeOffice/removals_wallboard","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Removals Wallboard\n\n[![Build](https://travis-ci.org/UKHomeOffice/removals_wallboard.png)](https://travis-ci.org/UKHomeOffice/removals_wallboard)\n\n## Quickstart:\n\n Get [NodeJS](https://nodejs.org) via [nvm](https://github.com/creationix/nvm)\n```sh\n$ curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.31.0/install.sh | bash\n```\n\n#### Install NodeJS 4 LTS\n```sh\n$ nvm install 4\n$ nvm use 4\n```\n### Build:\n```sh\n$ npm install\n```\n### Test:\n```sh\n$ npm test\n```\n### CI Test:\n```sh\n$ npm test\n```\n### Start development service using localhost keycloak and localhost backend\n```sh\n$ npm start\n```\n### Build service to localhost\n```sh\n$ npm run build\n```\n## Environment variables\n\n| VAR | OPTION | RESULT |\n| --- | ------ | ------ |\n| BACKEND | [string] | backend to use |\n| KEYCLOAKURL | [string] | keycloak login url |\n| CLIENTID | [string] | keycloak client id |\n| KEYCLOAKACCOUNTSERVICE | [string] | url to use for managing the user's keycloak account |\n| PORT | [integer] | port to run nginx server on |\n\n## Docker\nCan be built and run in the same way with docker for example:\n```sh\n$ docker build -t ibm-frontend .\n$ docker run -i -e \"BACKEND=localhost:8000\" ibm-frontend\n```\n","travis":true,"contributing":false,"masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/removals_wallboard/branches/master/protection","requiredStatusChecks":{"url":"https://api.github.com/repos/UKHomeOffice/removals_wallboard/branches/master/protection/required_status_checks","strict":true,"includeAdmins":true,"contextsUrl":"https://api.github.com/repos/UKHomeOffice/removals_wallboard/branches/master/protection/required_status_checks/contexts"}}},{"name":"UKHomeOffice/removals_schema","private":false,"url":"https://github.com/UKHomeOffice/removals_schema","license":null,"readme":"# Bed Space Management Interface Control Document and schema\n\n[![Build](https://travis-ci.org/UKHomeOffice/removals_schema.png)](https://travis-ci.org/UKHomeOffice/removals_schema)\n\n## Purpose and Scope\nThis document describes the interface between IRC Bed Management and its data providers\nThe purpose of the document is to detail the interactions available between each IRC platform and the Home Office dashboard for Bed Allocation by DEPMU and describes the metadata and security arrangements for the data.\n\n## OWNERSHIP AND CONTROL\n\n### ICD Ownership\nThis ICD is currently owned by Home Office Digital on behalf of the IDP.\n\n### ICD Maintenance Policy\nProposed changes to this ICD and schema will be managed via [Github pull requests](https://help.github.com/articles/using-pull-requests/)\nAny material change to this ICD will need to be approved by the HO change control process.\nNon-material changes such as spelling mistakes of clarifications of existing capabilities do not require the HO change control process.\n\n\n## Interface Context\n\n### Business Context\nThe aim of this interface is to support the processing of updates of bed occupancy and events logged in the IRCs that DEPMU operate.\nThe business require a technology that will aggregate, store and display data in a secure manner that is highly resilient and available.\n\n### Conceptual Architecture Diagram\n\nProgramming interactions between IRCs and the DEPMU Bed Management Dashboard will be through a common API. \n\n[diagram]\n![Conceptual Architecture Diagram](./assets/architecture_diagram.png)\n\nThe API presents the following HTTP endpoints:\n- `/irc_entry/event`\n- `/irc_entry/heartbeat`\n\n## Event API\nInvoked on the following events by the IRC:\n\n1. When a detainee checked in IRC.\n1. When a detainee checked out IRC.\n1. When a bed becomes out of operation.\n1. When a bed returns into operation.\n1. When a detainee is moved between moved between two sites by the IRC.\n1. When a detainee is reinstated.\n1. When a detainee cid/gender/nationality is updated.\n\n##### Process flow:\n- Capture the data required as described in the schema\n- Validate data with the [schema](./event.json)\n- Submit to the correct endpoint (as provided to the provider) over HTTPS/TLS\n- Should an error occur submitting, queue the event, and retry the queue at `1 minute` intervals raising exceptions to the relevant support party so that it can be addressed and monitored\n  - timeout should be set to 5 seconds\n  - `3xx` redirects should be followed\n  - should a `4xx` or `5xx` error occur, \n  - consider ultimately anything (after any redirects) that result in a non `2xx` status code to be an error\n\n## Heartbeat API\nThe purpose of this is to provide always up to date bed occupation and out of commission information.\n\nInvoked at `1 minute` intervals.\n##### Process flow:\n- Capture the data required as described in the schema\n- Validate data with the [schema](./heartbeat.json)\n- Submit to the correct endpoint (as provided to the provider) over HTTPS/TLS\n- Should an error occur submitting *do not queue* and raise the exception to the relevant support party so that it can be addressed and monitored.\n  - Timeout should be set to 5 seconds\n  - `3xx` redirects should be followed\n  - Consider ultimately anything (after any redirects) that result in a non `2xx` status code to be an error\n\n# Utilities\nIn this repository you will also find a tool that can be used to generate fake data which can be useful for testing and exploring the schema.\n### To output 10 events to stdout\n```shell\nnode generate.js event.json 10\n```\n### To output 10 heartbeats to stdout\n```shell\nnode generate.js heartbeat.json 10\n```\nYou can also include tagged releases of the repository in your application.\n","travis":true,"contributing":false,"masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/removals_schema/branches/master/protection","requiredStatusChecks":{"url":"https://api.github.com/repos/UKHomeOffice/removals_schema/branches/master/protection/required_status_checks","strict":true,"includeAdmins":true,"contextsUrl":"https://api.github.com/repos/UKHomeOffice/removals_schema/branches/master/protection/required_status_checks/contexts"}}},{"name":"UKHomeOffice/ges-proxy-service","private":false,"url":"https://github.com/UKHomeOffice/ges-proxy-service","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"GES Proxy Service\n=================\n\nScala Spray service to proxy request/response between client and server\n\nApplication built with the following (main) technologies:\n\n- Scala\n\n- SBT\n\n- Akka\n\n- Spray\n\nIntroduction\n------------\nTODO\n\nApplication\n-----------\nThe application is configured as per any Akka application, where the default configuration file is \"application.conf\".\nThis default file can be overridden with other \"conf\" files and then given to the application upon boot with the following example Java option:\n```bash\n-Dconfig.file=test-classes/application.test.conf\n```\n\nIndividual configuration properties can be overridden again by Java options e.g. to override which Mongodb to connect (if Mongo required configuring):\n```bash\n-Dmongo.db=some-other-mongo\n```\n\nwhere this overrides the default in application.conf.\n\nBooting the application (uk.gov.homeoffice.rtp.proxy.Boot) exposes a RESTful API to act as a proxy to the real API e.g. the following URL could be given in a browser, a browser's REST client plugin or curl:\n```bash\nhttp://localhost:9300/blah\n```\n\nthis would get back some appropriate response for some existing API.\n\nBuild and Deploy\n----------------\nThe project is built with SBT. On a Mac (sorry everyone else) do:\n```bash\nbrew install sbt\n```\n\nIt is also a good idea to install Typesafe Activator (which sits on top of SBT) for when you need to create new projects - it also has some SBT extras, so running an application with Activator instead of SBT can be useful. On Mac do:\n```bash\nbrew install typesafe-activator\n```\n\nTo compile:\n```bash\nsbt compile\n```\n\nor\n```bash\nactivator compile\n```\n\nTo run the specs:\n```bash\nsbt test\n```\n\nNote: Do not turn off the CONSOLE logging in test/resources/logback.xml as there are Specs that rely on this\n\nTo actually run the application, first \"assemble\" it:\n```bash\nsbt assembly\n```\n\nThis packages up an executable JAR - Note that \"assembly\" will first compile and test.\n\nThen just run as any executable JAR, with any extra Java options for overriding configurations.\n\nFor example, to use a config file (other than the default application.conf) which is located on the file system (in this case in the boot directory)\n```bash\njava -Dconfig.file=test-classes/my-application.conf -jar <jar name>.jar\n```\n\nNote that the log configuration file could also be included e.g.\n```bash\n-Dlogback.configurationFile=path/to/my-logback.xml\n```\n\nSo a more indepth startup with sbt itself could be:\n```bash\nsbt run -Dconfig.file=target/scala-2.11/test-classes/application.test.conf -Dlogback.configurationFile=target/scala-2.11/test-classes/logback.test.xml\n```\n\nAnd other examples:\n\nbooting from project root:\n```bash\njava -Dspray.can.server.port=8080 -jar target/scala-2.11/<jar name>.jar\n```\n\nand running from directory of the executable JAR using a config that is within said JAR:\n```bash\njava -Dconfig.resource=application.uat.conf -jar <jar name>.jar\n```\n\nFinally you can perform a quick test of the application by calling one of the monitor API e.g. making a cURL call to the application:\n```bash\ncurl http://localhost:9300/proxy-server \n```\n\nand to check the connection between the proxy and SOAP service:\n```bash\ncurl -X GET localhost:9300/soapservice/GesService?wsdl\n```\n\nSBT - Revolver\n--------------\nsbt-revolver is a plugin for SBT enabling a super-fast development turnaround for your Scala applications:\n\nSee https://github.com/spray/sbt-revolver\n\nFor development, you can use ~re-start to go into \"triggered restart\" mode.\nYour application starts up and SBT watches for changes in your source (or resource) files.\nIf a change is detected SBT recompiles the required classes and sbt-revolver automatically restarts your application. \nWhen you press &lt;ENTER&gt; SBT leaves \"triggered restart\" and returns to the normal prompt keeping your application running.\n\nGatling - Performance (Integration) Testing\n-------------------------------------------\nPerformance tests are under src/it, and test reports are written to the \"target\" directory.\n\nTo execute Gatling performance integration tests from withing SBT:\n```bash\ngatling-it:test\n```\n\nNote that as Gatling tests are integration tests, then a ges-proxy-service must be running.\nWhen running the proxy locally, the global-entry-stub should be started, where both applications run in either SSL or non-SSL mode.","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-clamav","private":false,"url":"https://github.com/UKHomeOffice/docker-clamav","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Docker ClamAV\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-clamav.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-clamav)\n\nDocker container for starting a [ClamAV](http://www.clamav.net/) daemon.\n\n## Getting Started\n\nThese instructions will cover how to start a container both in Docker and within a [Kubernetes](http://kubernetes.io/) cluster.\n\n### Prerequisites\n\nIn order to run this container you'll need docker installed.\n\n* [Windows](https://docs.docker.com/windows/started)\n* [OS X](https://docs.docker.com/mac/started/)\n* [Linux](https://docs.docker.com/linux/started/)\n\nOptionally:\n\n* A [Kubernetes](http://kubernetes.io/) cluster to enable Kubernetes api discovery of other nodes.\n\n### Usage\n\nThe example below will start a single ClamAV instance.\n\n```\ndocker run --name clamav -d -p 3310:3310 quay.io/ukhomeofficedigital/clamav:v0.1.0\n```\n\nTo use with [Kubernetes](http://kubernetes.io/) see the [kubernetes examples](examples/kubernetes.md).\n\n\n#### Environment Variables\n\nThe variables and the defaults are shown below.\nBy default, the container does not depend on [Kubernetes](http://kubernetes.io/). \n\n* `CLAMD_SETTINGS_CSV=\"LogVerbose yes,VirusEvent /custom_alert.sh\"` See [clamd.conf](http://linux.die.net/man/5/clamd.conf) for more details  \n  and see [./clamd.conf](./clamd.conf) for the default settings.  \n  To use specify a CSV of settings as they would apear in the config file e.g. `\"CLAMD_SETTINGS_CSV=Setting value\"`\n  Note, clamd has already been configured appropriately for a container but some useful settings include:    \n  * `VirusEvent /path/to/alert_script.sh` If mounted in the container, will provide a custom alert facility\n  * `LogClean yes` Will log every scan performed\n* `FRESHCLAM_SETTINGS_CSV=\"LogVerbose yes\"` See [freshclam.conf](http://linux.die.net/man/5/freshclam.conf) for more details  \n  and see [./freshclam.conf](freshclam.conf) for the default settings. See above for how this works.  \n* `UPDATE=true` (default) will start freshclam daemon in background to watch for update antivirus definitions  \n  `UPDATE=false` will watch for first successful update from separate sidecar container before starting\n* `UPDATE_ONLY=true` configure as a sidecar container and run the update process in the foreground  \n  `UPDATE_ONLY=false` (default) will run clamd and freshclam as normal.  \n  \n#### Ports\n\nThis container exposes:\n\n* `3310` - Access the [Clam AV API](http://linux.die.net/man/8/clamd).\n\n## Contributing\n\nFeel free to submit pull requests and issues. If it's a particularly large PR, you may wish to discuss\nit in an issue first.\n\nPlease note that this project is released with a [Contributor Code of Conduct](code_of_conduct.md). \nBy participating in this project you agree to abide by its terms.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the \n[tags on this repository](https://github.com/UKHomeOffice/docker-clamav/tags). \n\n## Authors\n\n* **Lewis Marshall** - *Initial work* - [Lewis Marshall](https://github.com/LewisMarshall)\n\nSee also the list of [contributors](https://github.com/UKHomeOffice/docker-clamav/contributors) who \nparticipated in this project.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.\n\n## Acknowledgments\n\n* http://www.clamav.net/\n\n## TODO:\n\n* Ensure the DB access doesn't need to be for user 999 (so the volume can be mounted)...\n* Long startup time, see point above.\n* Add testing for Travis","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-static-haproxy","private":false,"url":"https://github.com/UKHomeOffice/docker-static-haproxy","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Static HAProxy Docker Container\n\n[![Docker Repository on Quay](https://quay.io/repository/ukhomeofficedigital/static-haproxy/status \"Docker Repository on Quay\")](https://quay.io/repository/ukhomeofficedigital/static-haproxy)\n\nThis container aims to be a generic and very basic tcp proxy service with static backends, i.e. not fancy service discovery here :-). You can specify\nvia the command line multiple proxies\n\n## Getting Started\n\nIn this section I'll show you some examples of how you might run this container with docker.\n\n### Prerequisities\n\nIn order to run this container you'll need docker installed.\n\n* [Windows](https://docs.docker.com/windows/started)\n* [OS X](https://docs.docker.com/mac/started/)\n* [Linux](https://docs.docker.com/linux/started/)\n\n## Usage\n\n```shell\nUsage: haconfig [options]\n    -p, --proxy SPEC                 a proxy specification for the haproxy\n    -d, --dryrun                     perform dryrun, i.e. just show the resulting configuration\n    -t, --template TEMPLATE          the path to the haproxy template erb\n    -h, --help                       display this usage menu\n```\n\nSo to create a load balancer on 127.0.0.1:8080 going to endpoints 10.50.10.100:3499,10.50.10.101:3499\n\n```shell\n[jest@starfury docker-static-haproxy]$ \tdocker run -ti --rm --net=host ukhomeofficedigital/static-haproxy -p 127.0.0.1:6443,10.50.10.100:3499,10.50.10.101:3499\n```\n\nNote: you can specify multiple proxies by repeating the -p switch.\n\n### Useful File Locations\n\n* `haproxy.conf.erb` is stored at `/etc/haproxy/haproxy.conf.erb`\n\n### Examples\n\n## Find Us\n\n* [GitHub](https://github.com/UKHomeOffice/docker-static-haproxy)\n* [Quay.io](https://quay.io/repository/ukhomeofficedigital/docker-static-haproxy)\n\n## Contributing\n\nFeel free to submit pull requests and issues. If it's a particularly large PR, you may wish to\ndiscuss it in an issue first.\n\nPlease note that this project is released with a [Contributor Code of Conduct](code_of_conduct.md).\nBy participating in this project you agree to abide by its terms.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for the version tags available See the tags on this repository.\n\n## Authors\n\n* **Rohith Jayawardene** - *Initial work* - [gambol99](https://github.com/gambol99)\n\nSee also the list of\n[contributors](https://github.com/UKHomeOffice/docker-static-haproxy/graphs/contributors) who\nparticipated in this project.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details\n","travis":false,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change.\n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a\n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment\n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you\n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and\nwelcoming community, we pledge to respect all people who contribute through reporting issues,\nposting feature requests, updating documentation, submitting pull requests or patches, and other\nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone,\nregardless of level of experience, gender, gender identity and expression, sexual orientation,\ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits,\ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By\nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently\napplying these principles to every aspect of managing this project. Project maintainers who do not\nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is\nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an\nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org),\nversion 1.2.0, available at\n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/hof","private":false,"url":"https://github.com/UKHomeOffice/hof","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# HOF [![npm version](https://badge.fury.io/js/hof.svg)](https://badge.fury.io/js/hof)\n\nHome Office Forms (HOF) is a single package that bundles up a collection of modules used to create forms at the Home Office in node.js.\n\n[*Read the support documentation*](./documentation/index.md) for more details or see use the simple instructions below to get started, or [*start a discussion on Slack*](https://ukgovernmentdigital.slack.com/messages/hof/)\n\n[The example app](https://github.com/UKHomeOffice/hof-example-form) is also a good place to start. We recommend cloning the repository, cleaning the commit history, and replacing the example form in there with one of your own. The example shows examples for most of the common ways you might want to use the libraries.\n\n## What is it?\n\nHOF provides the following which can be accessed through its properties.\n\n * [hmpo-form-wizard](https://github.com/UKHomeOffice/passports-form-wizard)\n * [hmpo-frontend-toolkit](https://github.com/UKHomeOffice/passports-frontend-toolkit)\n * [hmpo-govuk-template](https://github.com/UKHomeOffice/govuk-template-compiler)\n * [hmpo-model](https://github.com/UKHomeOffice/passports-model)\n * [hmpo-template-mixins](https://github.com/UKHomeOffice/passports-template-mixins)\n * [hof-controllers](https://github.com/UKHomeOffice/hof-controllers)\n * [i18n-future](https://github.com/lennym/i18n-future)\n * [hof-middleware](https://github.com/UKHomeOffice/hof-middleware)\n\n## Who's using HOF\n\n * [Contact UK Trade & Investment (UK Trade & Investment)](https://github.com/UKTradeInvestment/contact-ukti)\n * [Biometric Residence Permit (Home Office)](https://github.com/UKHomeOffice/brp_app)\n * [Report terrorist material (Home Office)](https://github.com/UKHomeOffice/RTM)\n * [HOF Example Form (Home Office)](https://github.com/UKHomeOffice/hof-example-form)\n * [UKVI Complaints (Home Office)](https://github.com/UKHomeOffice/Complaints)\n\n## Installation\n```bash\n$ npm install --save hof\n```\n\n## Usage\n```js\nvar hof = require('hof');\n\nvar wizard = hof.wizard;\nvar toolkit = hof.toolkit;\nvar template = hof.template;\nvar Model = hof.Model;\nvar mixins = hof.mixins;\nvar controllers = hof.controllers;\nvar i18n = hof.i18n;\nvar middleware = hof.middleware;\n```\n","travis":false,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change.\n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a\n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment\n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you\n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and\nwelcoming community, we pledge to respect all people who contribute through reporting issues,\nposting feature requests, updating documentation, submitting pull requests or patches, and other\nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone,\nregardless of level of experience, gender, gender identity and expression, sexual orientation,\ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits,\ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By\nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently\napplying these principles to every aspect of managing this project. Project maintainers who do not\nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is\nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an\nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org),\nversion 1.2.0, available at\n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)","masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/hof/branches/master/protection"}},{"name":"UKHomeOffice/hof-transpiler","private":false,"url":"https://github.com/UKHomeOffice/hof-transpiler","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# HOF Transpiler\n\nHome office forms transpiler is a tiny tool that can be used as part of a build or manually to convert multipart locales files into one default.json. This is used in our stack for translations of form applications.\n\n## Installation\n\n\n```npm install --save-dev hof-transpiler```\n\n## Usage\n\n```\nhof-transpiler [source dir|glob] {OPTIONS}\n\n       --shared, -s  A path or glob to a directory of shared translations\n\n  --writeShared, -w  Generate a built JSON file of the the shared\n                     translations. Default setting is false.\n\n```\n\n## Example\n\nLets say you have a directory such as: ```translations/src/en```\n\nWhich contains:\n```\nbuttons.json\nemails.json\nerrors.json\nvalidation.json\n```\n\nIf you run hof-transpiler against the directory ```hof-transpiler ./translations/src```\n\nIt will iterate through src and for each directory it will create a new directory at the root level with a built default.json file ```translations/en/default.json```\n\nWhich will look something like\n\n```\n{\n  \"buttons\": {\n    json blob from buttons.json\n  },\n  \"emails\": {\n    json blob from emails.json\n  },\n  \"errors\": {\n    json blob from errors.json\n  },\n  \"validation\": {\n    json blob from validation.json\n  }\n}\n```\n\nThis is used further down the hof stack for application translations.\n\n## Advanced example - duplicate keys between source folder and shared folder\n\nLets say you have a directory such as: ```translations/src/en```\n\nWhich contains:\nbuttons.json containing:\n```json\n{\n  \"unusual-button\": \"Moo\"\n}\n```\nemails.json containing:\n```json\n{\n  \"customer-email\": \"Hi how are you?\"\n}\n```\n\nAnd you also have a directory of shared translations such as: ```shared-translations/src/en```\n\nWhich contains:\nbuttons.json containing:\n```json\n{\n  \"common-button\": \"Click me\"\n}\n```\n\nIf you then run:\n```bash\nhof-transpiler translations/src -w --shared shared-translations/src\n```\n\nThen transpiled translations should appear in translations/en/default.json as follows:\n```json\n{\n  \"buttons\": {\n    \"unusual-button\": \"Moo\",\n    \"common-button\": \"Click me\"\n  },\n  \"emails\": {\n    \"customer-email\": \"Hi how are you?\"\n  }\n}\n```\n\nNote how a deep merge is performed between the json, with key value pairs from \"buttons\" being included from both files.\n\n## Multiple shared sources\n\nhof-transpiler supports multiple shared sources, extending them from right to left. This is useful if you have translations shared between applications, and additional shared translations between routes within an application.\n\nIf you have the following sources:\n\nnode_modules/hof-template-partials/translations/src/en/buttons.json\n```json\n{\n  \"continue\": \"Continue\",\n  \"skip\": \"Skip\",\n  \"submit\": \"Submit\",\n  \"abort\": \"Abort\"\n}\n```\n\ncommon/translations/src/en/buttons.json\n```json\n{\n  \"skip\": \"Skip this step\",\n  \"cancel\": \"Cancel\"\n}\n```\n\nmy-application/translations/src/en/buttons.json\n```json\n{\n  \"continue\": \"Go Forth!\"\n}\n```\n\nIf you then run:\n```bash\nhof-transpiler my-application/translations/src -w --shared common/translations/src --shared node_modules/hof-template-partials/translations/src\n```\n\nYou will end up with the following compiled files:\n\nnode_modules/hof-template-partials/translations/en/default.json\n```json\n{\n  \"buttons\": {\n    \"continue\": \"Continue\",\n    \"skip\": \"Skip\",\n    \"submit\": \"Submit\",\n    \"abort\": \"Abort\"\n  }\n}\n```\n\ncommon/translations/en/default.json\n```json\n{\n  \"buttons\": {\n    \"continue\": \"Continue\",\n    \"skip\": \"Skip this step\",\n    \"submit\": \"Submit\",\n    \"abort\": \"Abort\",\n    \"cancel\": \"Cancel\"\n  }\n}\n```\n\nmy-application/translations/en/default.json\n```json\n{\n  \"buttons\": {\n    \"continue\": \"Go Forth!\",\n    \"skip\": \"Skip this step\",\n    \"submit\": \"Submit\",\n    \"abort\": \"Abort\",\n    \"cancel\": \"Cancel\"\n  }\n}\n```\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/myproject","private":false,"url":"https://github.com/UKHomeOffice/myproject","license":null,"readme":false,"travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/email-api","private":false,"url":"https://github.com/UKHomeOffice/email-api","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# Email API\n\n[![GitHub version](https://badge.fury.io/gh/ukhomeoffice%2Femail-api.svg)](https://badge.fury.io/gh/ukhomeoffice%2Femail-api) [![Build Status](https://travis-ci.org/UKHomeOffice/email-api.svg?branch=master)](https://travis-ci.org/UKHomeOffice/email-api) [![Docker Repository on Quay.io](https://quay.io/repository/ukhomeofficedigital/email-api/status \"Docker Repository on Quay.io\")](https://quay.io/repository/ukhomeofficedigital/email-api) [![Codacy Badge](https://api.codacy.com/project/badge/grade/8fad759d912b4a5793dfd101e71861f8)](https://www.codacy.com/app/purplebooth/email-api)\n\nThis is an service that will allow you to send templated emails via a RESTful API. \n\n## Getting Started\n\nThese instructions will cover usage information for developing stand alone, and running the docker container.\n\n### Clients\n\n#### Java Email Api Client\n\nClient Generated from the swagger file from this API.\n\nIncludes MVN and Gradle imports, for easy inclusion\n\n[[github](https://github.com/UKHomeOffice/email-api-client-java)] [[jitpack](https://jitpack.io/#UKHomeOffice/email-api-client-java)]\n\n#### JavaScript swagger-client (Swagger JS library)\n\nThis is the official Swagger javascript client for use with swagger enabled APIs (such as this one). Simply provide is the swagger.json ('yourhost:8080/swagger.json' on this project), to have a working client.\n\n[[npm](https://www.npmjs.com/package/swagger-client)]\n\n### Usage\n\nThe first step to using this API is to create some templates for it to use. To do this we use \n[freemarker](http://freemarker.org/). An example of this is below.\n\n```freemarker\nHello ${user},\n\nYou have received a test email.\n\nFrom\nThe Email API.\n```\n\nThe location that this application looks for templates is set in the `TEMPLATE_PATH` environment variable. \n\nThe template is then referred to by the filename when we try to load it. If we were to put it as \"test-text\" in the \ndirectory referred to by that environment variable, we could use it like below.\n\nIt's worth mentioning that this email service will send an MIME email with both text and html sections. The Html \ntemplates work in the exact same way, and you could even use the same template for both if you really wanted to. Below \nis an example of that.\n\n\n\nTo send the email, send a http `POST` request to the email service `http://localhost:8080/outbound` (assuming you're \nrunning the service at localhost on the default port).\n\n```json\n{\n  \"sender\": \"example@example.org\",\n  \"subject\": \"Subject of the email\",\n  \"htmlTemplate\": \"test-html\",\n  \"textTemplate\": \"test-text\",\n  \"variables\": {\"user\":\"user\"},\n  \"recipients\": [\n    \"test@example.com\"\n  ]\n}\n```\n\nThis will send an email.\n\nMost of these are self explanatory, however I just want to mention that the \"variables\" parameter can contain any JSON,\ndata, including objects, and arrays (on top of normal things like Numbers and Strings).\n\nIf you had made your email template the same as the one below, you should get an email which looks like the one below.\n\n```\nto: test@example.com\nfrom: example@example.org\nSubject: Subject of the email\n\nHello ${user},\n\nYou have received a test email.\n\nFrom\nThe Email API.\n```\n\nFor further documentation and a test client see the swagger documentation at `http://localhost:8080/swagger` \n\n### Running Stand Alone\n\nYou can run this application as a stand alone Java application\n\n#### Building\n\nThe tests will be automatically ran.\n\n```shell\n./gradlew install\n```\n\n#### Running\n\nWe configure the application through environment variables. See below.\n\n```shell\nSMTP_REQUIRE_TSL=false \\\nSMTP_START_TSL_ENABLED=false \\\nSMTP_ON_SSL_CONNECT=false \\\nSMTP_PASSWORD=\"\" SMTP_USERNAME=\"\" \\\nSMTP_PORT=1025 \\\nSMTP_HOSTNAME=localhost \\\nTEMPLATE_PATH=/tmp \\\n./build/install/email-api/bin/email-api server src/main/resources/configuration.yaml \n```\n\nMore details on these environment variables can be found in the docker section.\n\n#### Tests\n\n```shell\n./gradlew test\n```\n\n### Docker\n\n#### Prerequisites\n\nIn order to run this container you'll need docker installed.\n\n* [Windows](https://docs.docker.com/windows/started)\n* [OS X](https://docs.docker.com/mac/started/)\n* [Linux](https://docs.docker.com/linux/started/)\n\n#### Usage\n\n##### Kubernetes Examples\n\nYou can find Kubernetes examples in the [k8s directory](k8s).\n\n##### Container Parameters\n\nIf you run the application without parameters it'll start the application.\n\n```shell\ndocker run quay.io/ukhomeofficedigital/email-api:v2.0.0\n```\n\nOtherwise it'll run the command you provide. For example the command below will run bash.\n\n```shell\ndocker run quay.io/ukhomeofficedigital/email-api:v2.0.0 bash\n```\n\n##### Environment Variables\n\n* `SMTP_HOSTNAME` The hostname of the SMTP server to use.\n* `SMTP_PORT` Server port (Default: 25)\n* `SMTP_REQUIRE_TSL` Require TSL (Default: false)\n* `SMTP_START_TSL_ENABLED` Start TSL Enabled (Default: false)\n* `SMTP_ON_SSL_CONNECT` SSL On Connect (Default: false)\n* `SMTP_USERNAME` If this is populated we will attempt to authenticate with the SMTP server (Default: \"\")\n* `SMTP_PASSWORD` Used if SMTP_USERNAME is set (Default: \"\")\n* `SMTP_PASSWORD_PATH` If used this will overwrite SMTP_PASSWORD with the contents of this file.\n* `TEMPLATE_PATH` Where to look for templates to use (Default: \"/templates\")\n\n##### Useful File Locations\n\n* `/templates` - Where to put your Freemarker templates\n\n## Built With\n\n* Dropwizard 0.8.2\n* Freemarker 2.3.23\n\n## Find Us\n\n* [GitHub](https://github.com/UKHomeOffice/email-api)\n* [Quay.io](https://quay.io/repository/ukhomeofficedigital/email-api)\n\n## Contributing\n\nPlease read [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct, and the process for submitting pull requests to us.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the \n[tags on this repository](https://github.com/UKHomeOffice/email-api/tags). \n\n## Authors\n\nSee the list of [contributors](https://github.com/UKHomeOffice/email-api/contributors) who \nparticipated in this project.\n\n## License\n\nThis project is licensed under the GPL v2 License - see the [LICENSE.md](LICENSE.md) file for details.\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure you have discussed any large changes in an issue first, and reference that issue in the PR.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of one other developer, or if you \n   do not have permission to do that, you may request the reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)","masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/email-api/branches/master/protection","requiredStatusChecks":{"url":"https://api.github.com/repos/UKHomeOffice/email-api/branches/master/protection/required_status_checks","strict":true,"includeAdmins":true,"contextsUrl":"https://api.github.com/repos/UKHomeOffice/email-api/branches/master/protection/required_status_checks/contexts"}}},{"name":"UKHomeOffice/email-api-client-java","private":false,"url":"https://github.com/UKHomeOffice/email-api-client-java","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# Email API Client\n\n[![GitHub version](https://badge.fury.io/gh/ukhomeoffice%2Femail-api-client-java.svg)](https://badge.fury.io/gh/ukhomeoffice%2Femail-api-client-java) [![Build Status](https://travis-ci.org/UKHomeOffice/email-api-client-java.svg?branch=master)](https://travis-ci.org/UKHomeOffice/email-api-client-java)\n\nThis is a client for the [Email API](https://github.com/UKHomeOffice/email-api)\n\n## Getting Started\n\nThis documents how to get started using Maven or Gradle.\n\nThis repository is generated using [swagger-codegen](https://github.com/swagger-api/swagger-codegen). The command used is as follows:\n\n```shell\njava -jar modules/swagger-codegen-cli/target/swagger-codegen-cli.jar generate   \\\n    -i http://localhost:8080/swagger.json \\\n    -l java \\\n    --library jersey2 \\\n    --group-id uk.gov.homeoffice.emailapi \\\n    --artifact-id email-api-client \\\n    --api-package uk.gov.homeoffice.emailapi.client \\\n    --artifact-version v2.0.0  \\\n    -o ../email-api-client/ \n```\n\n### Adding to your project\n\n#### Gradle\n\nAdd JetPack as a repository\n\n```gradle\n repositories {\n        // ...\n        maven { url \"https://jitpack.io\" }\n    }\n```\n\n\n\n```gradle\n    dependencies {\n            compile 'com.github.UKHomeOffice:email-api-client:v2.0.0'\n    }\n```\n\n#### Maven\n\n```xml\n    <repository>\n        <id>jitpack.io</id>\n        <url>https://jitpack.io</url>\n    </repository>\n```\n\n```xml\n    <dependency>\n        <groupId>com.github.UKHomeOffice</groupId>\n        <artifactId>email-api-client</artifactId>\n        <version>v2.0.0</version>\n    </dependency>\n```\n\n### Using it\n\n```java\nimport io.swagger.client.ApiClient;\nimport io.swagger.client.model.TemplatedEmail;\nimport uk.gov.homeoffice.emailapi.client;\n```\n\n```java\nApiClient client = new ApiClient(\"localhost\");\nOutboundApi outboundEmailApi = new OutboundApi(client);\n\nTemplatedEmail email = TemplatedEmail();\n\n// Set some parameters on the email\n// email.setSender(\"annie@example.com\");\n// etc.\n\noutboundEmailApi.sendEmail(email);\n```\n\n## Built With\n\n* swagger-codegen\n\n## Find Us\n\n* [GitHub](https://github.com/UKHomeOffice/email-api-client-java)\n\n## Contributing\n\nPlease read [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct, and the process for submitting pull requests to us.\n\n## Versioning\n\nThe version of this repository tracks the [Email API](https://github.com/UKHomeOffice/email-api). For the versions available, see the \n[tags on this repository](https://github.com/UKHomeOffice/email-api-client-java/tags). \n\n## Authors\n\nSee the list of [contributors](https://github.com/UKHomeOffice/email-api-client-java/contributors) who \nparticipated in this project.\n\n## License\n\nThis project is licensed under the GPL v2 License - see the [LICENSE.md](LICENSE.md) file for details.\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure you have discussed any large changes in an issue first, and reference that issue in the PR.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of one other developer, or if you \n   do not have permission to do that, you may request the reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)","masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/email-api-client-java/branches/master/protection","requiredStatusChecks":{"url":"https://api.github.com/repos/UKHomeOffice/email-api-client-java/branches/master/protection/required_status_checks","strict":true,"includeAdmins":true,"contextsUrl":"https://api.github.com/repos/UKHomeOffice/email-api-client-java/branches/master/protection/required_status_checks/contexts"}}},{"name":"UKHomeOffice/docker-stacks","private":false,"url":"https://github.com/UKHomeOffice/docker-stacks","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Docker Stacks\n\n[Stacks](https://github.com/State/stacks) it's an Aws CloudFormation stacks management tool.\nIt can generate templates, list, create, delete and update stacks.\n\nTo use the docker image\n\n        -> % docker run -it --rm -v $(HOME)/.aws:/root/.aws:ro \\\n            quay.io/ukhomeofficedigital/stacks stacks --profile default --region eu-west-1 list\n\n            ukhomeofficedigital-guestbook-elb        CREATE_COMPLETE\n            ukhomeofficedigital-kubernetes-elb       CREATE_COMPLETE\n            ukhomeofficedigital-coreos-compute       UPDATE_COMPLETE\n            ukhomeofficedigital-coreos-etcd          UPDATE_COMPLETE\n            ukhomeofficedigital-coreos-etcd-volumes  UPDATE_COMPLETE\n            ukhomeofficedigital-infra                CREATE_COMPLETE\n\n\nThere are a few details you have to provide. AWS Credentials, profile and default region.\nThe name of your stack (called ENV) and the location of the templates folder.\n\n        -> % docker run -it --rm\n                -e AWS_PROFILE=HomeOfficeProfile \\\n                -e AWS_REGION=eu-west-1 \\\n                -e ENV=MyNewStack \\\n                -v $(HOME)/.aws:/root/.aws:ro  \\\n                -v $(pwd)/../examples/templates:/templates\n            quay.io/ukhomeofficedigital/stacks \\\n                stacks -p $AWS_PROFILE -r $AWS_REGION create -e ${ENV} -t /templates/infra.yaml ${ENV}-infra\n\n## Contributing\n\nFeel free to submit pull requests and issues. If it's a particularly large PR, you may wish to\ndiscuss it in an issue first.\n\nPlease note that this project is released with a\n[Contributor Code of Conduct](https://github.com/UKHomeOffice/docker-stacks/blob/master/CODE_OF_CONDUCT.md).\nBy participating in this project you agree to abide by its terms.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for the version tags available See the tags on this repository.\n\n\n## Authors\n\n* **Ivan Pedrazas** - *Initial work* - [ipedrazas](https://github.com/ipedrazas)\n\nSee also the list of\n[contributors](https://github.com/UKHomeOffice/docker-stacks/graphs/contributors) who participated\nin this project.\n\n## License\n\nThis project is licensed under the MIT License - see the\n[LICENSE.md](https://github.com/UKHomeOffice/docker-stacks/blob/master/LICENSE.md) file for details\n","travis":false,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change.\n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a\n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment\n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you\n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and\nwelcoming community, we pledge to respect all people who contribute through reporting issues,\nposting feature requests, updating documentation, submitting pull requests or patches, and other\nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone,\nregardless of level of experience, gender, gender identity and expression, sexual orientation,\ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits,\ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By\nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently\napplying these principles to every aspect of managing this project. Project maintainers who do not\nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is\nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an\nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org),\nversion 1.2.0, available at\n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/hubot-merge-spam","private":false,"url":"https://github.com/UKHomeOffice/hubot-merge-spam","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# Hubot Merge Spam\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/hubot-merge-spam.svg?branch=master)](https://travis-ci.org/UKHomeOffice/hubot-merge-spam) [![npm version](https://badge.fury.io/js/hubot-merge-spam.svg)](https://badge.fury.io/js/hubot-merge-spam)\n\nPeriodically announce to the channel what merge requests are available. Also print them on demand. Supports both GitLab's Merge Requests and GitHubs Pull Requests.\n\n## Usage\n\nThis is a plugin to Hubot\n\n```\n5:34:08 PM <•purplebooth> dec4rd: list mr\n5:34:09 PM <•dec4rd> @purplebooth: Listing Merge Requests\n5:34:09 PM <•dec4rd>  \n5:34:09 PM <•dec4rd> ⭐ API-Factory / data-assurance-dataimport#3 Added standard format\n5:34:09 PM <•dec4rd> 🔗 https://gitlab.digital.homeoffice.gov.uk/API-Factory/data-assurance-dataimport/merge_requests/3 \n5:34:09 PM <•dec4rd> 👤 purplebooth\n5:34:09 PM <•dec4rd>  \n5:34:09 PM <•dec4rd> ⭐ API-Factory / data-assurance-api#9 This should cause a test to fail\n5:34:09 PM <•dec4rd> 🔗 https://gitlab.digital.homeoffice.gov.uk/API-Factory/data-assurance-api/merge_requests/9 \n5:34:09 PM <•dec4rd> 👤 mikeyhu\n5:34:09 PM <•dec4rd>  \n5:34:09 PM <•dec4rd> ⭐ API-Factory / data-assurance-api#7 Standardise on coding style\n5:34:09 PM <•dec4rd> 🔗 https://gitlab.digital.homeoffice.gov.uk/API-Factory/data-assurance-api/merge_requests/7 \n5:34:09 PM <•dec4rd> 👤 purplebooth\n5:34:09 PM <•dec4rd>  \n```\n\n```\n9:23:33 AM <•purplebooth> dec4rd: list pr\n9:23:35 AM <•dec4rd> @purplebooth: Listing Pull Requests\n9:23:35 AM <•dec4rd>  \n9:23:35 AM <•dec4rd> ⭐ UKHomeOffice/passports-form-wizard#31 Support for multiple translators\n9:23:35 AM <•dec4rd> 🔗 https://github.com/UKHomeOffice/passports-form-wizard/pull/31 \n9:23:35 AM <•dec4rd> 👤 easternbloc 🔍 gavboulton\n9:23:35 AM <•dec4rd>  \n9:23:35 AM <•dec4rd> ⭐ UKHomeOffice/vaultconf#13 Added support for configuring secrets in vault\n9:23:35 AM <•dec4rd> 🔗 https://github.com/UKHomeOffice/vaultconf/pull/13 \n9:23:35 AM <•dec4rd> 👤 timgent\n9:23:35 AM <•dec4rd>  \n9:23:35 AM <•dec4rd> ⭐ UKHomeOffice/RTM#4 Add a local dev environment based on docker-compose\n9:23:35 AM <•dec4rd> 🔗 https://github.com/UKHomeOffice/RTM/pull/4 \n9:23:35 AM <•dec4rd> 👤 daniel-ac-martin\n9:23:35 AM <•dec4rd>  \n9:23:35 AM <•dec4rd> ⭐ UKHomeOffice/removals_dashboard#11 BM-264 unit tests\n9:23:35 AM <•dec4rd> 🔗 https://github.com/UKHomeOffice/removals_dashboard/pull/11 \n9:23:35 AM <•dec4rd> 👤 fulljames 🔍 chrisns\n9:23:35 AM <•dec4rd>  \n```\n\n## Installing\n\nTo add this plugin to hubot run \n\n```\nnpm i --save hubot-merge-spam\n```\n\nAnd add `hubot-merge-spam` to `external-scripts.json` in your hubot\n\n## Environment Variables\n\n* `HUBOT_MERGE_SPAM_ANNOUNCE_ROOMS` Rooms to periodically announce the state of the PRs and MRs into. Make this empty to not announce\n* `HUBOT_MERGE_SPAM_CRON` [Standard CRON](http://linuxconfig.org/linux-cron-guide) for when it should announce. Defaults to every 3 hours.\n* `HUBOT_MERGE_SPAM_GITHUB_ORGANISATION` GitHub Organisation to get the Pull Requests from. If this is blank it'll disable the GitHub functionality.\n* `HUBOT_MERGE_SPAM_GITHUB_AUTH_USERNAME` GitHub Username. If this or the auth token are missing it'll try to do the requests without authentication, but it'll probably hit rate limiting.\n* `HUBOT_MERGE_SPAM_GITHUB_AUTH_PASSWORD` GitHub password (generate one). \n* `HUBOT_MERGE_SPAM_GITLAB_HOST` GitLab URL. If token or this are missing it'll disable the GitLab aspects. \n* `HUBOT_MERGE_SPAM_GITLAB_API_TOKEN` GitLab API Token\n\n## Contributing\n\nPlease read [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct, and the process for submitting pull requests to us.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the [tags on this repository](https://github.com/UKHomeOffice/hubot-merge-spam/tags). \n\n## Authors\n\nSee the list of [contributors](https://github.com/UKHomeOffice/hubot-merge-spam/contributors) who participated in this project.\n\n## License\n\nThis project is licensed under the GPL v2 License - see the [LICENSE.md](LICENSE.md) file for details\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/hubot-merge-spam/branches/master/protection","requiredStatusChecks":{"url":"https://api.github.com/repos/UKHomeOffice/hubot-merge-spam/branches/master/protection/required_status_checks","strict":true,"includeAdmins":true,"contextsUrl":"https://api.github.com/repos/UKHomeOffice/hubot-merge-spam/branches/master/protection/required_status_checks/contexts"}}},{"name":"UKHomeOffice/hubot-decard","private":false,"url":"https://github.com/UKHomeOffice/hubot-decard","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# Decard\n\n[![GitHub version](https://badge.fury.io/gh/ukhomeoffice%2Fhubot-decard.svg)](https://badge.fury.io/gh/ukhomeoffice%2Fhubot-decard) [![Build Status](https://travis-ci.org/UKHomeOffice/hubot-decard.svg?branch=master)](https://travis-ci.org/UKHomeOffice/hubot-decard) [![Docker Repository on Quay.io](https://quay.io/repository/ukhomeofficedigital/hubot-decard/status \"Docker Repository on Quay.io\")](https://quay.io/repository/ukhomeofficedigital/hubot-decard)\n\nDecard is a chat bot built on the [Hubot][hubot] framework. It was\ninitially generated by [generator-hubot][generator-hubot], and configured to be\ndeployed on [Heroku][heroku] to get you up and running as quick as possible.\n\nThis particular Hubot comes with the default scripts, and the [hubot-merge-spam](https://github.com/UKHomeOffice/hubot-merge-spam) script. This periodically announce to the channel what merge requests are available. It also prints them on demand.\n\n[heroku]: http://www.heroku.com\n[hubot]: http://hubot.github.com\n[generator-hubot]: https://github.com/github/generator-hubot\n\n### Running decard Locally\n\nYou can test your hubot by running the following, however some plugins will not\nbehave as expected unless the [environment variables](#configuration) they rely\nupon have been set.\n\nYou can start decard locally by running:\n\n    % bin/hubot\n\nYou'll see some start up output and a prompt:\n\n    [Sat Feb 28 2015 12:38:27 GMT+0000 (GMT)] INFO Using default redis on localhost:6379\n    decard>\n\nThen you can interact with decard by typing `decard help`.\n\n    decard> decard help\n    decard animate me <query> - The same thing as `image me`, except adds [snip]\n    decard help - Displays all of the help commands that decard knows about.\n    ...\n\n### Configuration\n\nA few scripts (including some installed by default) require environment\nvariables to be set as a simple form of configuration.\n\nThe default scripts that come with this bot are\n\n```json\n[\n  \"hubot-diagnostics\",\n  \"hubot-help\",\n  \"hubot-heroku-keepalive\",\n  \"hubot-google-images\",\n  \"hubot-google-translate\",\n  \"hubot-pugme\",\n  \"hubot-maps\",\n  \"hubot-redis-brain\",\n  \"hubot-rules\",\n  \"hubot-shipit\",\n  \"hubot-merge-spam\"\n]\n```\n\nAnd the `slack` adapter.\n\nThese are the environment variables for this bot\n\n* `REDISTOGO_URL` or `REDISCLOUD_URL` or `BOXEN_REDIS_URL` or `REDIS_URL` URL format: redis://<host>:<port>[/<brain_prefix>]\n* `HUBOT_SLACK_TOKEN` Your slack token\n* `HUBOT_MERGE_SPAM_ANNOUNCE_ROOMS` Rooms to periodically announce the state of the PRs and MRs into. Make this empty to not announce\n* `HUBOT_MERGE_SPAM_CRON` [Standard CRON](http://linuxconfig.org/linux-cron-guide) for when it should announce. Defaults to every 3 hours.\n* `HUBOT_MERGE_SPAM_GITHUB_ORGANISATION` GitHub Organisation to get the Pull Requests from. If this is blank it'll disable the GitHub functionality.\n* `HUBOT_MERGE_SPAM_GITHUB_AUTH_USERNAME` GitHub Username. If this or the auth token are missing it'll try to do the requests without authentication, but it'll probably hit rate limiting.\n* `HUBOT_MERGE_SPAM_GITHUB_AUTH_PASSWORD` GitHub password (generate one). \n* `HUBOT_MERGE_SPAM_GITLAB_HOST` GitLab URL. If token or this are missing it'll disable the GitLab aspects. \n* `HUBOT_MERGE_SPAM_GITLAB_API_TOKEN` GitLab API Token\n\n## Adapters\n\nAdapters are the interface to the service you want your hubot to run on, such\nas Campfire or IRC. There are a number of third party adapters that the\ncommunity have contributed. Check [Hubot Adapters][hubot-adapters] for the\navailable ones.\n\nIf you would like to run a non-Campfire or shell adapter you will need to add\nthe adapter package as a dependency to the `package.json` file in the\n`dependencies` section.\n\nOnce you've added the dependency with `npm install --save` to install it you\ncan then run hubot with the adapter.\n\n    % bin/hubot -a <adapter>\n\nWhere `<adapter>` is the name of your adapter without the `hubot-` prefix.\n\n[hubot-adapters]: https://github.com/github/hubot/blob/master/docs/adapters.md\n\n## Deploying To Heroku\n\n    % heroku create\n    % git push heroku master\n\nIf your Heroku account has been verified you can run the following to enable\nand add the Redis to Go addon to your app.\n\n    % heroku addons:add redistogo:nano\n\nIf you run into any problems, checkout Heroku's [docs][heroku-node-docs].\n\nYou'll need to edit the `Procfile` to set the name of your hubot.\n\nMore detailed documentation can be found on the [deploying hubot onto\nHeroku][deploy-heroku] wiki page.\n\n## Deploying To Docker & Kubernetes\n\nYou can use the docker container [quay.io/ukhomeofficedigital/hubot-decard](https://quay.io/repository/ukhomeofficedigital/hubot-decard), there are example k8s files in `/k8s`\n\n### Deploying to UNIX or Windows\n\nIf you would like to deploy to either a UNIX operating system or Windows.\nPlease check out the [deploying hubot onto UNIX][deploy-unix] and [deploying\nhubot onto Windows][deploy-windows] wiki pages.\n\n[heroku-node-docs]: http://devcenter.heroku.com/articles/node-js\n[deploy-heroku]: https://github.com/github/hubot/blob/master/docs/deploying/heroku.md\n[deploy-unix]: https://github.com/github/hubot/blob/master/docs/deploying/unix.md\n[deploy-windows]: https://github.com/github/hubot/blob/master/docs/deploying/unix.md\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/hubot-decard/branches/master/protection","requiredStatusChecks":{"url":"https://api.github.com/repos/UKHomeOffice/hubot-decard/branches/master/protection/required_status_checks","strict":true,"includeAdmins":true,"contextsUrl":"https://api.github.com/repos/UKHomeOffice/hubot-decard/branches/master/protection/required_status_checks/contexts"}}},{"name":"UKHomeOffice/hof-example-form","private":false,"url":"https://github.com/UKHomeOffice/hof-example-form","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"[![Build Status](https://travis-ci.org/UKHomeOffice/hof-example-form.svg?branch=master)](https://travis-ci.org/UKHomeOffice/hof-example-form)[![Dependencies](https://david-dm.org/UKHomeOffice/hof-example-form.svg)](https://david-dm.org/UKHomeOffice/hof-example-form)\n\n# Home Office Forms Example Form\n\nThis is an example of a service built with [Home Office Forms](https://github.com/UKHomeOffice/hof), A.K.A HOF. It intends to highlight many of the features available from HOF, but is not exhaustive.\n\n## Items of Note\n\nThis is not the only way to configure your HOF service. This service uses a typical Node.JS, Express architecture, with an entry point named `app.js`, which is where the majority of the set up occurs.\n\nThe specifics of a form are configured in `apps/`, this is where views, controllers, translations and the steps and fields are defined for each form journey (spoiler: there is only one at the moment).\n\nFor more info see the [HOF documentation](https://github.com/UKHomeOffice/hof/blob/master/documentation/index.md) or [join the discussion](https://ukgovernmentdigital.slack.com/messages/hof/)\n\n## Getting Started\n\nThese instructions will get you a copy of the project up and running on your local machine for development and testing purposes.\n\n### Prerequisities\n\n- [NodeJS](https://nodejs.org/en/) - version 4 and up.\n- npm version 3 (bundled with node 5 and up)\n- [Redis server](http://redis.io/topics/quickstart) running on the default port\n- A basic understanding of Node.JS\n\n### Installing\n\nClone this repository: `git clone git@github.com:UKHomeOffice/hof-example-form`\n\nInstall the dependencies required to run the service and start the server in 'development' mode:\n  ```\n  $ npm install\n  $ npm run dev\n  ```\n\nVisit: [http://localhost:8080/my-awesome-form](http://localhost:8080/my-awesome-form)\n\n__If you are going to use this example form as a starting point for your own service, we encourage you to follow the next fews steps:__\n\n1. Delete the commit history: `rm -rf .git`\n\n2. Reconstruct the Git repo with only the current content:\n\n  ```\n  git init\n  git add .\n  git commit -m \"Initial commit\"\n  ```\n\n4. Set the remote origin:\n\n  ```\n  git remote add origin <github-uri>\n  git push -u --force origin master\n  ```\n\n## Running the tests\n\n### Unit tests\n```bash\n$ npm run test\n```\n\n### Functional tests\n\n```bash\n$ npm run test:acceptance\n```\n\nIt's worth glancing at the `scripts` in `package.json` to see what's happening\n\n## Contributing\n\nWe welcome contributions, especially if you have a new \"app\" to add to `apps/`, but we must insist you first [read the our contribution docs](CONTRIBUTING.md) for details on our code of conduct, and the process for submitting pull requests to us.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the [tags on this repository](https://github.com/your/project/tags).\n\n## License\n\nThis project is licensed under the GPLv2 License - see the [LICENSE.md](LICENSE.md) file for details\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/hof-controllers","private":false,"url":"https://github.com/UKHomeOffice/hof-controllers","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# hof-controllers [![npm version](https://badge.fury.io/js/hof-controllers.svg)](https://badge.fury.io/js/hof-controllers) [![Build Status](https://travis-ci.org/UKHomeOffice/hof-controllers.svg)](https://travis-ci.org/UKHomeOffice/hof-controllers)\n\nA collection of controllers extended from [passports-form-wizard](https://github.com/UKHomeOffice/passports-form-wizard) Wizard, Form Controller:\n```js\nrequire('hmpo-form-wizard').Controller\n```\n\n## Usage\n\n```js\nvar controllers = require('hof-controllers');\n```\n\n### Base Controller\n\nAccessed as `base` from `hof-controllers`\n\n```js\nvar baseController = require('hof-controllers').base;\n```\n\nExtends from [passports-form-wizard](https://github.com/UKHomeOffice/passports-form-wizard) Wizard, Form Controller.\n\n#### Added functionality for clearing sessions\n\n```js\n{\n  clearSession: true,\n  /* step options */\n}\n```\n#### Handles edit actions.\n\nIn the wizard options\n\n```js\n  hofWizard(steps, fields, {\n    /* wizard options */\n    params: '/:action?'\n  });\n```\n\nIn the view template\n\n```js\na href='page_name/edit'\n```\n\nOr override in step options\n\n```js\n{\n  continueOnEdit: true\n  /* step options */\n}\n```\n\n#### Locals for pluralisation\n\nAdds `single` or `multiple` to the locals to describe the number of errors for pluralisation of error messages.\n\n#### Exposes meta to templates\n\nAdd a locals object to step config to expose configurable key/value pairs in the template. Useful for generating template partials programmatically. These will override any locals provided further up the tree.\n\nSteps config\n```js\n'/step-name': {\n  locals: {\n    pageTitle: 'Page Title'\n    foo: 'bar'\n  }\n}\n```\n\nTemplate\n```html\n<h1>{{pageTitle}}</h1>\n<div class=\"{{foo}}\"></div>\n```\n\n#### Exposes fields to templates\n\nFields given in step config will be exposed to the template along with a mixin if defined in field config. This can be used with the [renderField](#renderField) mixin to programmatically generate templates.\n\nsteps.js\n```js\nsteps: {\n  'step-1': {\n    fields: [\n      'field-1',\n      'field-2'\n    ]\n  }\n}\n```\n\nfields.js\n```js\nfields: {\n  'field-1': {\n    mixin: 'input-text',\n    ...\n  },\n  'field-2': {\n    mixin: 'radio-group',\n    ...\n  }\n}\n```\n\nexposed to templates in format:\n```js\nfields: [{\n  key: 'field-1',\n  mixin: 'input-text'\n}, {\n  key: 'field-2',\n  mixin: 'radio-group'\n}]\n```\n\n#### Handles journey forking\n\nEach step definition accepts a `next` property, the value of which is the next route in the journey. By default, when the form is successfully submitted, the next steps will load. However, there are times when it is necessary to fork from the current journey based on a users response to certain questions in a form. For such circumstances there exists the `forks` property.\n\nIn this example, when the submits the form, if the field called 'example-radio' has the value 'superman', the page at '/fork-page' will load, otherwise '/next-page' will be loaded.\n\n```js\n\n'/my-page': {\n  next: '/next-page',\n  forks: [{\n    target: '/fork-page',\n    condition: {\n      field: 'example-radio',\n      value: 'superman'\n    }\n  }]\n}\n```\n\nThe condition property can also take a function. In the following example, if the field called 'name' is more than 30 characters in length, the page at '/fork-page' will be loaded.\n\n```js\n\n'/my-page': {\n  next: '/next-page',\n  forks: [{\n    target: '/fork-page',\n    condition: function (req, res) {\n      return req.form.values['name'].length > 30;\n    }\n  }]\n}\n```\n\nForks is an array and therefore each fork is interrogated in order from top to bottom. The last fork whose condition is met will assign its target to the next page variable.\n\nIn this example, if the last condition resolves to true - even if the others also resolve to true - then the page at '/fork-page-three' will be loaded. The last condition to be met is always the fork used to determine the next step.\n\n```js\n\n'/my-page': {\n  next: '/next-page',\n  forks: [{\n    target: '/fork-page-one',\n    condition: function (req, res) {\n      return req.form.values['name'].length > 30;\n    }\n  }, {\n    target: '/fork-page-two',\n    condition: {\n      field: 'example-radio',\n      value: 'superman'\n    }\n  }, {\n    target: '/fork-page-three',\n    condition: function (req, res) {\n      return typeof req.form.values['email'] === 'undefined';\n    }\n  }]\n}\n```\n\n--------------------------------\n\n### Date Controller\n\nAccessed as `\n` from `hof-controllers`\n\n```js\nvar dateController = require('hof-controllers').date;\n```\n\nExtends from `require('hof-controllers').base;`\n\n#### Date validation\n\n- Validates the dates as a single item.\n\n- Date validators default to: `required`, `numeric`, `format` (`DD-MM-YYYY`), and `future`.\n\n- What the validators the date validates against can be overridden with the `validate` property on the date key field.\n\nIn this example, the `'my-date'` fields will only validate if they contain non-numeric characters.\n\n```js\n{\n  'my-date': {\n    validate: ['numeric']\n  }\n}\n```\n\nNote: In the preceding example the field is not required and will not error on empty values.\n\n\n#### Extend and override `validateField`\n\nIf you want a shared date field to be required, but on a particular page wish it to be optional, `validateField` will accept a third parameter called `isRequired`.\nThis will allow the date field to be optional unless the user enters a value, in which case an appropriate message will be shown.\n\n```js\nMyController.prototype.validateField = function validateField(keyToValidate, req) {\n  return DateController.prototype.validateField.call(this, keyToValidate, req, false);\n};\n```\n\n#### Formats date\n\n- Adds a 'pretty' formatted (`D MMMM YYYY`) date to the form values.\n\n------------------------------\n\n### Error Controller\n\nA simple wrapper around `require('hmpo-form-wizard').Error;` to make it easier to extend and customise error behaviour on error.\n\n### Extending\n\nTo extend the functionality of a controller call the parent constructor and use node `util` to inherit the prototype;\n\n`this.dateKey` is the value of the date field that the controller will process. The value of the `this.dateKey` must match the name of the date field.\n[Read more about date fields](https://github.com/UKHomeOffice/hof/blob/master/documentation/fields.md#date-fields)\n\n```js\nvar DateController = function DateController() {\n  this.dateKey = 'my-date';\n  Controller.apply(this, arguments);\n};\n\nutil.inherits(DateController, Controller);\n```\n------------------------------\n\n### Confirm Controller\n\nExtends the base controller's locals method to provide data in a format suitable for generating a summary table.\n\nAccessed as `confirm` from `hof-controllers`.\n\n```js\nvar confirmController = require('hof-controllers').confirm;\n```\n\nExtends from `require('hof-controllers').base`\n\n#### Usage\n\nIn step options\n\n```js\n'/confirm': {\n  controller: require('hof-controllers').confirm,\n  config: {\n    tableSections: [{\n      name: 'section-one',\n      fields: [\n        'field-one',\n        'field-two',\n        'field-three'\n      ]\n    }],\n    modifiers: { // transform {{value}}, values hash provided\n      'field-two': function(values) {\n        return values['field-two'].toUpperCase();\n      }\n    }\n  }\n}\n```\n\nIn config page template\n\n```html\n{{#tableSections}}\n  {{> partials-summary-table}} <!-- {{name}}, {{value}} and {{step}} are available in this scope -->\n{{/tableSections}}\n```\n\n------------------------------\n\n------------------------------\n\n## Mixins\n\n### renderField\n\nThe renderField mixin can be called in your template with the field to render as the scope. This will lookup the field.mixin in res.locals and call it passing the field key.\n\n```html\n{{#fields}}\n  {{#renderField}}{{/renderField}}\n{{/fields}}\n```\n\n#### conditionally rendering fields\n\n`renderField` supports conditionally omitting fields if `useWhen` is passed in field config.  `useWhen` accepts another field key `String` and checks the value is `true`, or an `Object` with the keys `field` and `value`.  The field to check cannot appear on the same step - consider using the `toggle` property to show/hide a field on the same step.\n\n```js\n'field-1': {\n  useWhen: 'field-2'\n}\n```\n`field-1` will only be included if `field-2` value is `true`\n\n```js\n'field-3': {\n  useWhen: {\n    field: 'field-4',\n    value: 'a-value'\n  }\n}\n```\n`field-3` will only be included if `field-4` value is `a-value`\n\n##### Use case\n\nWhen a field on a multiple-step form is only to be included depending on the outcome of a previous answer. In the below example `dependant-field` is only included on step-2 if `dependent-radio` on step-1 is `'yes'`;\n\nsteps.js\n```js\n{\n  '/step-1': {\n    fields: [\n      'dependent-radio'\n    ]\n  },\n  '/step-2': {\n    fields: [\n      'dependant-field',\n      'regular-field'\n    ]\n  }\n}\n```\n\nfields.js\n```js\n{\n  'dependent-radio': {\n    options: ['yes', 'no']\n  },\n  'dependant-field': {\n    useWhen: {\n      field: 'dependant-field',\n      value: 'yes'\n    }\n  },\n  'regular-field': {}\n}\n```\n\n## Test\n\n```bash\n$ npm test\n```\n","travis":true,"contributing":false,"masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/hof-controllers/branches/master/protection"}},{"name":"UKHomeOffice/rtp-mongo-lib","private":false,"url":"https://github.com/UKHomeOffice/rtp-mongo-lib","license":null,"readme":"RTP Mongo Library - Scala library to work with Mongodb drivers\n==============================================================\n\nApplication built with the following (main) technologies:\n\n- Scala\n\n- SBT\n\n- Casbah\n\n- Salat\n\nIntroduction\n------------\nA library to easily \"configure\" your application to interact with Mongodb, currently via the Casbah driver.\n\nConfiguration, as well as using the standard reference/application.conf, is done via mixins to your application and test code.\n\nTo interact with Mongodb, choose to either utilise a Casbah or Salat Repository.\n\nA Casbah Repository represents a Mongodb collection to save and get back JSON.\n\nA Salat Repository represents a Mongodb collection to save a \"domain\" object (a case class) and get back said object.\n\nBuild and Deploy\n----------------\nThe project is built with SBT. On a Mac (sorry everyone else) do:\n```bash\nbrew install sbt\n```\n\nIt is also a good idea to install Typesafe Activator (which sits on top of SBT) for when you need to create new projects - it also has some SBT extras, so running an application with Activator instead of SBT can be useful. On Mac do:\n```bash\nbrew install typesafe-activator\n```\n\nTo compile:\n```bash\nsbt compile\n```\n\nor\n```bash\nactivator compile\n```\n\nTo run the specs:\n```bash\nsbt test\n```\n\nThe following packages up this library - Note that \"assembly\" will first compile and test:\n```bash\nsbt assembly\n```\n\nCasbah Repository Example\n-------------------------\n```scala\nimport uk.gov.homeoffice.mongo.casbah.Repository\n\ntrait ThingsRepository extends Repository {\n  val collectionName = \"things\"\n}\n\nval thingsRepository = new ThingsRepository with MyMongo\nthingsRepository.collection.save(<my JSON>)\n\n// OR if you \"apply\" the instance of the repository being created (a la JavaScript), then you don't need to call \"collection\" before calling an API method such as \"save\", \"find\" etc.\n\nval thingsRepository = (new ThingsRepository with MyMongo)()\nthingsRepository.save(<my JSON>)\n```\n\nOf course, where did that \"MyMongo\" come from? Each repository, whether Casbah or Salat, needs a \"Mongo\" mixed in, where the Mongo trait wraps the actual connection to Mongodb and so needs to be configured with the Mongodb details e.g. host, port, credentials.\n\nMyMongo could be coded as:\n```scala\nimport com.typesafe.config.ConfigFactory\nimport com.mongodb.casbah.MongoClientURI\n\ntrait MyMongo extends Mongo {\n  lazy val db = MyMongo.mydb\n}\n\nobject MyMongo {\n  lazy val mydb = Mongo db MongoClientURI(ConfigFactory.load getString \"mydb\")\n}\n```\n\nHey! That seems like a lot of extra set up code?\n\nWell, the trait (MyMongo) is a must, as we need this to mixin to all your repositories for a particular Mongodb.\n\nThen the object reads the actual configuration - but why here, why not in the trait? For example, why not just do the following?\n```scala\ntrait MyMongo extends Mongo {\n  lazy val db = Mongo db MongoClientURI(ConfigFactory.load getString \"mydb\")\n}\n```\n\nBig mistake! Everytime the trait is now mixed in, not only is a new Mongo connection created, an actual Mongo pool of connections are created - you'll soon have many connection pools and your application will quickly slow down.\n\nSalat Repository Example\n------------------------\n```scala\nimport uk.gov.homeoffice.mongo.salat.Repository\n\ntrait ThingsRepository extends Repository[Thing] {\n  val collectionName = \"things\"\n}\n\nval thingsRepository = new ThingsRepository with MyMongo\nthingsRepository save Thing()\n```\n\nwhere Thing would be one of your case classes.\n\nTesting\n-------\nThere are two available specifications for tests that interact with Mongo.\nMongoSpecification, which requires Mongo to be running locally, and EmbeddedMongoSpecification which has an embedded Mongo per specification.\n\nVia EmbeddedMongoSpecification, each example, within a specification, is run sequentially, as a test database is created and dropped.\n\nAnd via MongoSpecification, a unique test database is generated per example of a specification, allowing each to run (by default) in parallel.\n\nEmbeddedMongoSpecification Example\n----------------------------------\nThis trait must be mixed into a Specs2 specification and will give you a TestMongo to mix into your repository.\n```scala\nclass RepositoryEmbeddedMongoSpec extends Specification with EmbeddedMongoSpecification {\n  trait Context extends Scope {\n    val repository = new Repository[Thing] with TestMongo {\n      val collectionName = \"tests\"\n    }\n  }\n\n  \"Repository\" should {\n    \"find nothing\" in new Context {\n      repository.findAll().toList must beEmpty\n    }\n  }\n}\n```\n\nExample App\n-----------\nTo run ExampleApp:\n```bash\nsbt test:run\n```","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/aws-dsp-toolset","private":false,"url":"https://github.com/UKHomeOffice/aws-dsp-toolset","license":null,"readme":"[![Docker Repository on Quay](https://quay.io/repository/ukhomeofficedigital/aws-dsp-toolset/status \"Docker Repository on Quay\")](https://quay.io/repository/ukhomeofficedigital/aws-dsp-toolset)\n\n# AWS Digital Services Platform Toolset Container\n\n### Overview\nThis container is responsible for holding the necessary tools for working with AWS to build infrastructure:\n* STACKS\n* AWS CLI\n* CFSSL\n* COREOS CLOUDINIT\n* KB8OR\n* VAULTCTL\n* DOCKER\n* S3SECRETS\n* KUBECTL\n* FLEETCTL\n\nThis is so we have versioned tools that we can test and validate against CI.\n\n### Additions\n\nAlong side the core tools are additional scripts that enable functionality in a central place.\n\n* peer_vpc\n* encrypt_secrets\n* decrypt_secrets\n* instances-list\n\n#### Peer VPC\n\nThis is used to peer VPC's together, (VPC Peering)\n\n#### Encrypt Secrets\n\nThis is used to encrypt secrets in a specific path and based on environment. If there are any files:\n```\nstacks/config.d/secrets_${stacks_env}.yaml\n```\n\nIt will use the kms key to encrypt those files leaving them as base64 encoded files e.g.\n\n```\nstacks/config.d/secrets_dev.yaml.enc\n```\n\n#### Decrypt Secrets\n\nThis is used to decrypt secrets based on the above leaving the yaml data as native data to be used by stacks\nallowing you to use potentially more sensitive information inside your templates without compromising the security\n\n```\ncat stacks/config.d/secrets_dev.yaml\ndev:\n  some_secret: 'some_data'\n\n{{some_secret}} now becomes a variable inside your templates for the development environment\n```\nThis is done when run.sh is initiated, decrypt_secrets will be executed before it runs stacks\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/typeahead-aria","private":false,"url":"https://github.com/UKHomeOffice/typeahead-aria","license":null,"readme":"[![build status](https://secure.travis-ci.org/twitter/typeahead.js.svg?branch=master)](http://travis-ci.org/twitter/typeahead.js)\n[![Built with Grunt](https://cdn.gruntjs.com/builtwith.png)](http://gruntjs.com/)\n\n\n[typeahead.js][gh-page]\n=======================\n\nInspired by [twitter.com]'s autocomplete search functionality, typeahead.js is \na flexible JavaScript library that provides a strong foundation for building \nrobust typeaheads.\n\nThe typeahead.js library consists of 2 components: the suggestion engine, \n[Bloodhound], and the UI view, [Typeahead]. \nThe suggestion engine is responsible for computing suggestions for a given \nquery. The UI view is responsible for rendering suggestions and handling DOM \ninteractions. Both components can be used separately, but when used together, \nthey can provide a rich typeahead experience.\n\n<!-- section links -->\n\n[gh-page]: http://twitter.github.io/typeahead.js/\n[twitter.com]: https://twitter.com\n[Bloodhound]: https://github.com/twitter/typeahead.js/blob/master/doc/bloodhound.md\n[Typeahead]: https://github.com/twitter/typeahead.js/blob/master/doc/jquery_typeahead.md\n\nGetting Started\n---------------\n\nHow you acquire typeahead.js is up to you.\n\nPreferred method:\n* Install with [Bower]: `$ bower install typeahead.js`\n\nOther methods:\n* [Download zipball of latest release][zipball].\n* Download the latest dist files individually:\n  * *[bloodhound.js]* (standalone suggestion engine)\n  * *[typeahead.jquery.js]* (standalone UI view)\n  * *[typeahead.bundle.js]* (*bloodhound.js* + *typeahead.jquery.js*)\n  * *[typeahead.bundle.min.js]*\n\n**Note:** both *bloodhound.js* and *typeahead.jquery.js* have a dependency on \n[jQuery] 1.9+.\n\n<!-- section links -->\n\n[Bower]: http://bower.io/\n[zipball]: http://twitter.github.com/typeahead.js/releases/latest/typeahead.js.zip\n[bloodhound.js]: http://twitter.github.com/typeahead.js/releases/latest/bloodhound.js\n[typeahead.jquery.js]: http://twitter.github.com/typeahead.js/releases/latest/typeahead.jquery.js\n[typeahead.bundle.js]: http://twitter.github.com/typeahead.js/releases/latest/typeahead.bundle.js\n[typeahead.bundle.min.js]: http://twitter.github.com/typeahead.js/releases/latest/typeahead.bundle.min.js\n[jQuery]: http://jquery.com/\n\nDocumentation \n-------------\n\n* [Typeahead Docs]\n* [Bloodhound Docs]\n\n[Typeahead Docs]: https://github.com/twitter/typeahead.js/blob/master/doc/jquery_typeahead.md\n[Bloodhound Docs]: https://github.com/twitter/typeahead.js/blob/master/doc/bloodhound.md\n\nExamples\n--------\n\nFor some working examples of typeahead.js, visit the [examples page].\n\n<!-- section links -->\n\n[examples page]: http://twitter.github.io/typeahead.js/examples\n\nBrowser Support\n---------------\n\n* Chrome\n* Firefox 3.5+\n* Safari 4+\n* Internet Explorer 8+\n* Opera 11+\n\n**NOTE:** typeahead.js is not tested on mobile browsers.\n\nCustomer Support\n----------------\n\nFor general questions about typeahead.js, tweet at [@typeahead].\n\nFor technical questions, you should post a question on [Stack Overflow] and tag \nit with [typeahead.js][so tag].\n\n<!-- section links -->\n\n[Stack Overflow]: http://stackoverflow.com/\n[@typeahead]: https://twitter.com/typeahead\n[so tag]: http://stackoverflow.com/questions/tagged/typeahead.js\n\nIssues\n------\n\nDiscovered a bug? Please create an issue here on GitHub!\n\nhttps://github.com/twitter/typeahead.js/issues\n\nVersioning\n----------\n\nFor transparency and insight into our release cycle, releases will be numbered \nwith the following format:\n\n`<major>.<minor>.<patch>`\n\nAnd constructed with the following guidelines:\n\n* Breaking backwards compatibility bumps the major\n* New additions without breaking backwards compatibility bumps the minor\n* Bug fixes and misc changes bump the patch\n\nFor more information on semantic versioning, please visit http://semver.org/.\n\nTesting\n-------\n\nTests are written using [Jasmine] and ran with [Karma]. To run\nthe test suite with PhantomJS, run `$ npm test`.\n\n<!-- section links -->\n\n[Jasmine]: http://jasmine.github.io/\n[Karma]: http://karma-runner.github.io/\n\nDevelopers\n----------\n\nIf you plan on contributing to typeahead.js, be sure to read the \n[contributing guidelines]. A good starting place for new contributors are issues\nlabeled with [entry-level]. Entry-level issues tend to require minor changes \nand provide developers a chance to get more familiar with typeahead.js before\ntaking on more challenging work.\n\nIn order to build and test typeahead.js, you'll need to install its dev \ndependencies (`$ npm install`) and have [grunt-cli] \ninstalled (`$ npm install -g grunt-cli`). Below is an overview of the available \nGrunt tasks that'll be useful in development.\n\n* `grunt build` – Builds *typeahead.js* from source.\n* `grunt lint` – Runs source and test files through JSHint.\n* `grunt watch` – Rebuilds *typeahead.js* whenever a source file is modified.\n* `grunt server` – Serves files from the root of typeahead.js on localhost:8888. \n  Useful for using *test/playground.html* for debugging/testing.\n* `grunt dev` – Runs `grunt watch` and `grunt server` in parallel.\n\n<!-- section links -->\n\n[contributing guidelines]: https://github.com/twitter/typeahead.js/blob/master/CONTRIBUTING.md\n[entry-level]: https://github.com/twitter/typeahead.js/issues?&labels=entry-level&state=open\n[grunt-cli]: https://github.com/gruntjs/grunt-cli\n\nMaintainers\n-----------\n\n* **Jake Harding** \n  * [@JakeHarding](https://twitter.com/JakeHarding) \n  * [GitHub](https://github.com/jharding)\n\n* **You?**\n\nAuthors\n-------\n\n* **Jake Harding** \n  * [@JakeHarding](https://twitter.com/JakeHarding) \n  * [GitHub](https://github.com/jharding)\n\n* **Veljko Skarich**\n  * [@vskarich](https://twitter.com/vskarich) \n  * [GitHub](https://github.com/vskarich)\n\n* **Tim Trueman**\n  * [@timtrueman](https://twitter.com/timtrueman) \n  * [GitHub](https://github.com/timtrueman)\n\nLicense\n-------\n\nCopyright 2013 Twitter, Inc.\n\nLicensed under the MIT License\n","travis":true,"contributing":"Contributing to typeahead.js\n============================\n\n*These contributing guidelines were proudly stolen from the \n[Flight](https://github.com/flightjs/flight) project*\n\nLooking to contribute something to typeahead.js? Here's how you can help.\n\nBugs Reports\n------------\n\nA bug is a _demonstrable problem_ that is caused by the code in the\nrepository. Good bug reports are extremely helpful – thank you!\n\nGuidelines for bug reports:\n\n1. **Use the GitHub issue search** &mdash; check if the issue has already been\n   reported.\n\n2. **Check if the issue has been fixed** &mdash; try to reproduce it using the\n   latest `master` or integration branch in the repository.\n\n3. **Isolate the problem** &mdash; ideally create a reduced test\n   case and a live example.\n\n4. Please try to be as detailed as possible in your report. Include specific\n   information about the environment – operating system and version, browser\n   and version, version of typeahead.js – and steps required to reproduce the \n  issue.\n\nFeature Requests & Contribution Enquiries\n-----------------------------------------\n\nFeature requests are welcome. But take a moment to find out whether your idea\nfits with the scope and aims of the project. It's up to *you* to make a strong\ncase for the inclusion of your feature. Please provide as much detail and\ncontext as possible.\n\nContribution enquiries should take place before any significant pull request,\notherwise you risk spending a lot of time working on something that we might\nhave good reasons for rejecting.\n\nPull Requests\n-------------\n\nGood pull requests – patches, improvements, new features – are a fantastic\nhelp. They should remain focused in scope and avoid containing unrelated\ncommits.\n\nMake sure to adhere to the coding conventions used throughout the codebase\n(indentation, accurate comments, etc.) and any other requirements (such as test\ncoverage).\n\nPlease follow this process; it's the best way to get your work included in the\nproject:\n\n1. [Fork](http://help.github.com/fork-a-repo/) the project, clone your fork,\n   and configure the remotes:\n\n   ```bash\n   # Clone your fork of the repo into the current directory\n   git clone https://github.com/<your-username>/typeahead.js\n   # Navigate to the newly cloned directory\n   cd <repo-name>\n   # Assign the original repo to a remote called \"upstream\"\n   git remote add upstream git://github.com/twitter/typeahead.js\n   ```\n\n2. If you cloned a while ago, get the latest changes from upstream:\n\n   ```bash\n   git checkout master\n   git pull upstream master\n   ```\n\n3. Install the dependencies (you must have Node.js and [Bower](http://bower.io)\n   installed), and create a new topic branch (off the main project development\n   branch) to contain your feature, change, or fix:\n\n   ```bash\n   npm install\n   bower install\n   git checkout -b <topic-branch-name>\n   ```\n\n4. Make sure to update, or add to the tests when appropriate. Patches and\n   features will not be accepted without tests. Run `npm test` to check that\n   all tests pass after you've made changes.\n\n5. Commit your changes in logical chunks. Provide clear and explanatory commit\n   messages. Use Git's [interactive rebase](https://help.github.com/articles/interactive-rebase) feature to tidy up\n   your commits before making them public.\n\n6. Locally merge (or rebase) the upstream development branch into your topic branch:\n\n   ```bash\n   git pull [--rebase] upstream master\n   ```\n\n7. Push your topic branch up to your fork:\n\n   ```bash\n   git push origin <topic-branch-name>\n   ```\n\n8. [Open a Pull Request](https://help.github.com/articles/using-pull-requests/)\n    with a clear title and description.\n\n9. If you are asked to amend your changes before they can be merged in, please\n   use `git commit --amend` (or rebasing for multi-commit Pull Requests) and\n   force push to your remote feature branch. You may also be asked to squash\n   commits.\n\nLicense\n-------\n\nBy contributing your code,\n\nYou agree to license your contribution under the terms of the MIT License\nhttps://github.com/twitter/typeahead.js/blob/master/LICENSE\n","masterBranchProtection":false},{"name":"UKHomeOffice/docker-ckan","private":false,"url":"https://github.com/UKHomeOffice/docker-ckan","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# CKAN Docker Container\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-ckan.svg)](https://travis-ci.org/UKHomeOffice/docker-ckan) [![GitHub version](https://badge.fury.io/gh/ukhomeoffice%2Fdocker-ckan.svg)](https://badge.fury.io/gh/ukhomeoffice%2Fdocker-ckan) [![Docker Repository on Quay.io](https://quay.io/repository/ukhomeofficedigital/ckan/status \"Docker Repository on Quay.io\")](https://quay.io/repository/ukhomeofficedigital/ckan)\n\nThis is the home office packaging of [CKAN](http://ckan.org/)\n\n## Getting Started\n\nThese instructions will cover usage information and for the docker container\n\n### Prerequisites\n\n\nIn order to run this container you'll need docker installed.\n\n* [Windows](https://docs.docker.com/windows/started)\n* [OS X](https://docs.docker.com/mac/started/)\n* [Linux](https://docs.docker.com/linux/started/)\n\n### Usage\n\n#### Get started quick\n\nThis will get CKAN running\n\n```\ndocker run -d --privileged=true --name solr milafrerichs/ckan_solr\ndocker run -d --privileged=true --name db ckan/postgresql\ndocker run -p 5000:5000 \\\n           --link db:db \\\n           --link solr:solr \\\n           quay.io/ukhomeofficedigital/ckan:$CONTAINER_VERSION\n```\n\nThen Point your browser at `https://<your-docker-host>:5000` and you'll see ckan.\n\n#### TLS Parameters\n\nTLS is enabled by default in this container, and we dynamically create a self signed certificate if no certificate is created.\nIf you'd like to implement your own certs then simply mount then into `/etc/httpd/ssl`\n\n```\ndocker run -p 5000:5000 \\\n           --link db:db \\\n           --link solr:solr \\\n           -v /path/to/certs:/etc/httpd/ssl\n           quay.io/ukhomeofficedigital/ckan:$CONTAINER_VERSION\n```\n\nWe also allow you to define the domain for your self-signed tls certs, just use the `DOMAIN` env variable.\n\n#### Container Parameters\n\nIf you run the container without parameters, just run it\n\n```shell\ndocker run quay.io/ukhomeofficedigital/ckan:$CONTAINER_VERSION\n```\n\nIf you pass a parameter to the container we'll try to run it, so\n\n```shell\ndocker run quay.io/ukhomeofficedigital/ckan:$CONTAINER_VERSION bash\n```\n\n#### Environment Variables\n\n* `DATABASE_URL` - URL for the primary database, in the format expected by sqlalchemy (required\n                   unless linked to a container called 'db')\n* `SOLR_URL` - URL for solr (required unless linked to a container called 'solr')\n\n* `DOMAIN` - Domain for ckan to run under, defaults to `localhost`\n\n* `DB_CREDS` - Path to file where username and password are stored, this will in turn populate `DATABASE_USER` and `DATABASE_PASSWORD` (useful for vault_sidekick)\n\n* `DATABASE_USER` - String containing the username for DB\n\n* `DATABASE_PASSWORD` - String containing password for DB\n\n#### Volumes\n\n* `/var/lib/ckan` - CKAN Data Directory\n\n#### Useful File Locations\n\n* `/userscripts` - All executable files in this directory will be executed before starting ckan\n* `/app/ckan/plugins` - All plugins placed in here will be added to ckan by running `python setup.py develop` on them\n\n## Built With\n\n* CKAN 2.4.1\n\n## Find Us\n\n* [GitHub](https://github.com/UKHomeOffice/docker-ckan)\n* [Quay.io](https://quay.io/repository/ukhomeofficedigital/ckan)\n\n## Contributing\n\nPlease read [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct, and the process for submitting pull requests to us.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the\n[tags on this repository](https://github.com/UKHomeOffice/docker-ckan/tags).\n\n## Authors\n\nSee the list of [contributors](https://github.com/UKHomeOffice/docker-ckan/contributors) who\nparticipated in this project.\n\n## License\n\nThis project is licensed under the GPLv2 License - see the [LICENSE.md](LICENSE.md) file for details.\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and welcoming community, we pledge to respect all people who contribute through reporting issues, posting feature requests, updating documentation, submitting pull requests or patches, and other activities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, regardless of level of experience, gender, gender identity and expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit permission\n* Other unethical or unprofessional conduct\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By adopting this Code of Conduct, project maintainers commit themselves to fairly and consistently applying these principles to every aspect of managing this project. Project maintainers who do not follow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is representing the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an issue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), version 1.2.0, available at [http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/Feedback","private":false,"url":"https://github.com/UKHomeOffice/Feedback","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# BRP Application project for nodejs\n\n[![Docker Repository on Quay.io](https://quay.io/repository/ukhomeofficedigital/brpapp/status \"Docker Repository on Quay.io\")](https://quay.io/repository/ukhomeofficedigital/brpapp)\n\n## Quick start\n\nInstall the dependencies and build the project resources\n```bash\n$ npm install\n```\n\nInitiate the server in development mode (Express is used to serve the static resources in development).\n```bash\n$ npm run dev\n```\n\nThen select one of the following journeys to see the applcation in action\n\n- [Collection](http://localhost:8080/collection)\n- [Someone else](http://localhost:8080/someone-else)\n- [Not arrived](http://localhost:8080/not-arrived)\n- [Correct mistakes](http://localhost:8080/correct-mistakes)\n- [Lost, damaged or stolen](http://localhost:8080/lost-damaged-stolen)\n\nSee the [development documentation](./documentation/DEVELOPMENT.MD) for a complete description of the application and how to maintain and support BRP.\n\n\n## NPM scripts\n\nStart the application in default mode (production).\nWe use Nginx to serve our static resources in production and ci.\n```bash\n$ npm start\n```\n\nStart the application with [Nodemon](https://www.npmjs.com/package/nodemon) in development mode.\nDebug is switched on and the server restarts when the JS or Sass are recompiled.\n```bash\n$ npm run dev\n```\n\nRun the unit tests\n```bash\n$ npm run test\n```\n\nRun the EcmaScript (ES) linter.  Rules are defined in [.eslintrc](./.eslintrc)\n```bash\n$ npm run lint\n```\n\nRun the jscs style checker. Rules are defined in [.jscsrc.json](./.jscsrc.json)\n```bash\n$ npm run style\n```\n\nAnalyse the quality of the codebase (for results - open [./reports/plato/index.html](./reports/plato/index.html))\n```bash\n$ npm run quality\n```\n\nCompile the Sass to CSS\n```bash\n$ npm run sass\n```\n\n_____________________________________________________________\n\n- For details on [Acceptance tests](https://github.com/UKHomeOffice/brp_app/tree/master/acceptance_tests)\n\n- See the [package.json](./package.json) for a full list of scripts.\n\n- Full list of [environment variables](./documentation/ENVIRONMENT_VARIABLES.md)\n\n","travis":false,"contributing":"# Contribution guidelines\n\nWe welcome patches!\n\n## Commit hygiene\n\nWe like to follow the recommendations set out in the GDS [git style guide][gitstyle]\nwhich describes how we prefer git history and commit messages to read.\n\n[gitstyle]: https://github.com/alphagov/styleguides/blob/master/git.md\n\n## JavaScript\n\nWe have a JavaScript style checker `npm run style`\n\nAll our styles are defined in our [JavaScript style config][jsstyle]\n\nWe follow the [Google JavaScript style guide](https://google.github.io/styleguide/javascriptguide.xml)\n\nWe also lint our code `npm run lint`.\n\n[jsstyle]: https://github.com/UKHomeOffice/brp_app/blob/master/.jscsrc.json\n\nA pre commit hook is run as part of the project which runs the above checks and our tests (`npm run test`).\n\n## Visual changes\n\nFor visual changes, it can be helpful to provide images in your pull-request\nshowing before and after to highlight the differences.","masterBranchProtection":false},{"name":"UKHomeOffice/passport-enquiries-form","private":false,"url":"https://github.com/UKHomeOffice/passport-enquiries-form","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# Passport Enquiries Form project for nodejs\n\n\n## Quick start\n\nInstall the dependencies and build the project resources\n```bash\n$ npm install\n```\n\nInitiate the server in development mode (Express is used to serve the static resources in development).\n```bash\n$ npm run dev\n```\n\n\n## NPM scripts\n\nStart the application in default mode (production).\nWe use Nginx to serve our static resources in production and ci.\n```bash\n$ npm start\n```\n\nStart the application with [Nodemon](https://www.npmjs.com/package/nodemon) in development mode.\nDebug is switched on and the server restarts when the JS or Sass are recompiled.\n```bash\n$ npm run dev\n```\n\nRun the unit tests\n```bash\n$ npm run test\n```\n\nRun the EcmaScript (ES) linter.  Rules are defined in [.eslintrc](./.eslintrc)\n```bash\n$ npm run lint\n```\n\nRun the jscs style checker. Rules are defined in [.jscsrc.json](./.jscsrc.json)\n```bash\n$ npm run style\n```\n\nAnalyse the quality of the codebase (for results - open [./reports/plato/index.html](./reports/plato/index.html))\n```bash\n$ npm run quality\n```\n\nCompile the Sass to CSS\n```bash\n$ npm run sass\n```\n\n_____________________________________________________________\n\n- For details on [Acceptance tests](https://github.com/UKHomeOffice/passport-enquiries-form/tree/master/acceptance_tests)\n\n- See the [package.json](./package.json) for a full list of scripts.\n\n- Full list of [environment variables](./documentation/ENVIRONMENT_VARIABLES.md)\n\n","travis":false,"contributing":"# Contribution guidelines\n\nWe welcome patches!\n\n## Commit hygiene\n\nWe like to follow the recommendations set out in the GDS [git style guide][gitstyle]\nwhich describes how we prefer git history and commit messages to read.\n\n[gitstyle]: https://github.com/alphagov/styleguides/blob/master/git.md\n\n## JavaScript\n\nWe have a JavaScript style checker `npm run style`\n\nAll our styles are defined in our [JavaScript style config][jsstyle]\n\nWe follow the [Google JavaScript style guide](https://google.github.io/styleguide/javascriptguide.xml)\n\nWe also lint our code `npm run lint`.\n\n[jsstyle]: https://github.com/UKHomeOffice/brp_app/blob/master/.jscsrc.json\n\nA pre commit hook is run as part of the project which runs the above checks and our tests (`npm run test`).\n\n## Visual changes\n\nFor visual changes, it can be helpful to provide images in your pull-request\nshowing before and after to highlight the differences.","masterBranchProtection":false},{"name":"UKHomeOffice/mockingjay-server","private":false,"url":"https://github.com/UKHomeOffice/mockingjay-server","license":null,"readme":"# mockingjay server\n\n[![Build Status](https://travis-ci.org/quii/mockingjay-server.svg?branch=master)](https://travis-ci.org/quii/mockingjay-server)[![Coverage Status](https://coveralls.io/repos/quii/mockingjay-server/badge.svg?branch=master)](https://coveralls.io/r/quii/mockingjay-server?branch=master)[![GoDoc](https://godoc.org/github.com/quii/mockingjay-server?status.svg)](https://godoc.org/github.com/quii/mockingjay-server)\n\nMockingjay lets you define the contract between a consumer and producer and with just a configuration file you get:\n\n- A fast to launch fake server for your integration tests\n - Configurable to simulate the eratic nature of calling other services\n- [Consumer driven contracts (CDCs)](http://martinfowler.com/articles/consumerDrivenContracts.html) to run against your real downstream services.\n\n**Mockingjay makes it really easy to check your integration points**. It's fast, requires no coding and is better than other solutions because it will ensure your mock servers and real integration points are consistent\n\n- [Installation](https://github.com/quii/mockingjay-server/wiki/Installing) (I promise it's really easy)\n- [Rationale](https://github.com/quii/mockingjay-server/wiki/Rationale)\n- [See how mockingjay can easily fit into your workflow to make integration testing really easy and robust](https://github.com/quii/mockingjay-server/wiki/Suggested-workflow)\n\n\n## Running a fake server\n\n````yaml\n---\n - name: My very important integration point\n   request:\n     uri: /hello\n     method: POST\n     body: \"Chris\" # * matches any body\n   response:\n     code: 200\n     body: '{\"message\": \"hello, Chris\"}'   # * matches any body\n     headers:\n       content-type: application/json\n\n# define as many as you need...\n````\n\n````bash\n$ mockingjay-server -config=example.yaml -port=1234 &\n2015/04/13 14:27:54 Serving 3 endpoints defined from example.yaml on port 1234\n$ curl http://localhost:1234/hello\n{\"message\": \"hello, world\"}\n````\n\n## Check configuration is compatible with a real server\n\n````bash\n$ mockingjay-server -config=example.yaml -realURL=http://some-real-api.com\n2015/04/13 21:06:06 Test endpoint (GET /hello) is incompatible with http://some-real-api - Couldn't reach real server\n2015/04/13 21:06:06 Test endpoint 2 (DELETE /world) is incompatible with http://some-real-api - Couldn't reach real server\n2015/04/13 21:06:06 Failing endpoint (POST /card) is incompatible with http://some-real-api - Couldn't reach real server\n2015/04/13 21:06:06 At least one endpoint was incompatible with the real URL supplied\n````\n\n### Inspect what requests mockingjay has received\n\n     http://{mockingjayhost}:{port}/requests\n\nCalling this will return you a JSON list of requests\n\n## Make your fake server flaky\n\nMockingjay has an annoying friend, a monkey. Given a monkey configuration you can make your fake service misbehave. This can be useful for performance tests where you want to simulate a more realistic scenario (i.e all integration points are painful).\n\n````yaml\n---\n# Writes a different body 50% of the time\n- body: \"This is wrong :( \"\n  frequency: 0.5\n\n# Delays initial writing of response by a second 20% of the time\n- delay: 1000\n  frequency: 0.2\n\n# Returns a 404 30% of the time\n- status: 404\n  frequency: 0.3\n\n# Write 10,000,000 garbage bytes 9% of the time\n- garbage: 10000000\n  frequency: 0.09\n````\n\n````bash\n$ mockingjay-server -config=examples/example.yaml -monkeyConfig=examples/monkey-business.yaml\n2015/04/17 14:19:53 Serving 3 endpoints defined from examples/example.yaml on port 9090\n2015/04/17 14:19:53 Monkey config loaded\n2015/04/17 14:19:53 50% of the time | Body: This is wrong :(\n2015/04/17 14:19:53 20% of the time | Delay: 1s\n2015/04/17 14:19:53 30% of the time | Status: 404\n2015/04/17 14:19:53  9% of the time | Garbage bytes: 10000000\n````\n\n## Building\n\n### Requirements\n\n- Go 1.3+ installed ($GOPATH set, et al)\n- godep https://github.com/tools/godep\n- golint https://github.com/golang/lint\n\n````bash\n$ go get github.com/quii/mockingjay-server\n$ cd $GOPATH/src/github.com/quii/mockingjay-server\n$ ./build.sh\n````\n\nMIT license\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-solr","private":false,"url":"https://github.com/UKHomeOffice/docker-solr","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# Solr Docker Container\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-solr.svg)](https://travis-ci.org/UKHomeOffice/docker-solr) [![GitHub version](https://badge.fury.io/gh/ukhomeoffice%2Fdocker-solr.svg)](https://badge.fury.io/gh/ukhomeoffice%2Fdocker-solr) [![Docker Repository on Quay.io](https://quay.io/repository/ukhomeofficedigital/solr/status \"Docker Repository on Quay.io\")](https://quay.io/repository/ukhomeofficedigital/solr)\n\nThis is a docker container for [Solr](http://lucene.apache.org/solr/).\n\n## Getting Started\n\nThese instructions will cover usage information and for the docker container \n\n### Prerequisites\n\n\nIn order to run this container you'll need docker installed.\n\n* [Windows](https://docs.docker.com/windows/started)\n* [OS X](https://docs.docker.com/mac/started/)\n* [Linux](https://docs.docker.com/linux/started/)\n\n### Usage\n\n#### Container Parameters\n\nTo run a single Solr server:\n\n```shell\ndocker run --name my_solr -d -p 8983:8983 -t quay.io/ukhomeofficedigital/solr:$CONTAINER_VERSION\n```\n\nThen with a web browser go to `http://localhost:8983/` to see the Admin Console (adjust the hostname for your docker host).\n\nTo use Solr, you need to create a \"core\", an index for your data. For example:\n\n```shell\ndocker exec -it --user=solr my_solr bin/solr create_core -c gettingstarted\n```\n\nIn the web UI if you click on \"Core Admin\" you should now see the \"gettingstarted\" core.\n\nIf you want to load some example data:\n\n```shell\ndocker exec -it --user=solr my_solr bin/post -c gettingstarted example/exampledocs/manufacturers.xml\n```\n\nIn the UI, find the \"Core selector\" popup menu and select the \"gettingstarted\" core, then select the \"Query\" menu item. This gives you a default search for \":\" which returns all docs. Hit the \"Execute Query\" button, and you should see a few docs with data. Congratulations!\n\nTo learn more about Solr, see the [Apache Solr Reference Guide](https://cwiki.apache.org/confluence/display/solr/Apache+Solr+Reference+Guide).\n\nDistributed Solr\nYou can also run a distributed Solr configuration, with Solr nodes in separate containers, sharing a single ZooKeeper server:\n\nRun ZooKeeper, and define a name so we can link to it:\n\n```shell\ndocker run --name zookeeper -d -p 2181:2181 -p 2888:2888 -p 3888:3888 jplock/zookeeper\n```\n\nRun two Solr nodes, linked to the zookeeper container:\n\n```shell\ndocker run --name solr1 --link zookeeper:ZK -d -p 8983:8983 \\\n      quay.io/ukhomeofficedigital/solr:$CONTAINER_VERSION \\\n      bash -c '/opt/solr/bin/solr start -f -z $ZK_PORT_2181_TCP_ADDR:$ZK_PORT_2181_TCP_PORT'\ndocker run --name solr2 --link zookeeper:ZK -d -p 8984:8983 \\\n      quay.io/ukhomeofficedigital/solr:$CONTAINER_VERSION \\\n      bash -c '/opt/solr/bin/solr start -f -z $ZK_PORT_2181_TCP_ADDR:$ZK_PORT_2181_TCP_PORT'\n```\n\nCreate a collection:\n\n```shell\ndocker exec -i -t solr1 /opt/solr/bin/solr create_collection \\\n        -c collection1 -shards 2 -p 8983\n```\nThen go to `http://localhost:8983/solr/#/~cloud` (adjust the hostname for your docker host) to see the two shards and Solr nodes.\n\n## Environment Variables\n\n* `ZK_HOST` (Optional) The ZooKeeper connection string your current SolrCloud nodes use to connect \n  to ZooKeeper; this value will be the same for all nodes in the cluster.\n* `SOLR_HOST` (Optional) The hostname each Solr node used to register with ZooKeeper when joining \n  the SolrCloud cluster; this value will be used to set the host Java system property when starting \n  the new Solr 5 process.\n* `SOLR_PORT` (Optional) The port each Solr node is listening on, such as 8983.\n* `OVERRIDE_SOLR_PORT` (Optional) Sets `SOLR_PORT` on runtime.\n* `SOLR_HOME` (Optional) The absolute path to the Solr home directory for each Solr node; this\n  directory must contain a solr.xml file\n\n## Built With\n\n* Solr 5.3.1\n\n## Find Us\n\n* [GitHub](https://github.com/UKHomeOffice/docker-solr)\n* [Quay.io](https://quay.io/repository/ukhomeofficedigital/solr)\n\n## Contributing\n\nPlease read [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct, and the process for submitting pull requests to us.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the \n[tags on this repository](https://github.com/UKHomeOffice/docker-solr/tags). \n\n## License\n\nThis is based off the official Solr container, and we have included much of the text and code they \nprovide.\n\nThe primary changes made to this repository is to allow us to base this image of our parent image, \nrather than one provided.\n\nWe have sublicensed this variant under the GPLv2 License - see the [LICENSE.md](LICENSE.md) file for\n details. You can find the Apache v2.0 license they distribute that code with at \n[ORIGINAL-LICENSE.md](ORIGINAL-LICENSE.md).\n\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and welcoming community, we pledge to respect all people who contribute through reporting issues, posting feature requests, updating documentation, submitting pull requests or patches, and other activities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, regardless of level of experience, gender, gender identity and expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit permission\n* Other unethical or unprofessional conduct\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By adopting this Code of Conduct, project maintainers commit themselves to fairly and consistently applying these principles to every aspect of managing this project. Project maintainers who do not follow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is representing the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an issue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), version 1.2.0, available at [http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/drone-test-build","private":false,"url":"https://github.com/UKHomeOffice/drone-test-build","license":null,"readme":"# drone-test-build\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/drone-kubernetes","private":false,"url":"https://github.com/UKHomeOffice/drone-kubernetes","license":{"key":"apache-2.0","name":"Apache License 2.0","spdxId":"Apache-2.0","url":"https://api.github.com/licenses/apache-2.0","featured":true},"readme":"# drone-kubernetes\nKubernetes plugin for publishing kubernetes artifacts from [drone](https://drone.io/)\n\n## Overview\n\nThis plugin is responsible for publishing artifacts to a kubernetes cluster:\n\n```\nsh ./drone-kubernetes <<EOF\n{\n    \"vargs\": {\n        \"replicationcontrollers\": [ \"example/nginx.json\" ],\n        \"services\": [],\n        \"secrets\": [\"examples/secrets.yaml\"]\n        \"apiserver\": \"https://127.0.0.1\",\n        \"namespace\": \"default\",\n        \"token\": \"eyJhbGciOiJSUz...\",\n        \"webhook\": \"https://webhook-gateway.test/drone-deploys\n        \"webhook_token\": \"12345abcdf\"\n\n    }\n}\nEOF\n```\n\n\n## Docker\n\nBuild the Docker container. Note that we need to use the `-netgo` tag so that\nthe binary is built without a CGO dependency:\n\n```sh\nCGO_ENABLED=0 go build -a -tags netgo\ndocker build --rm=true -t plugins/drone-kubernetes .\n```\n\nDeploy to kubernetes:\n\n```\ndocker run -i -v $(pwd):/drone/src quay.io/ukhomeofficedigital/drone-kubernetes <<EOF\n{\n    \"vargs\": {\n        \"replicationcontrollers\": [ \"example/nginx.json\" ],\n        \"services\": [],\n        \"apiserver\": \"https://127.0.0.1\",\n        \"namespace\": \"default\",\n        \"token\": \"eyJhbGciOiJSUz...\"\n        \"webhook\": \"https://webhook-gateway.test/drone-deploys\n        \"webhook_token\": \"12345abcdf\"\n    }\n}\nEOF\n```\n\nIn your `.drone.yml` you will need to add the following\n\n```\ndeploy:\n  kubernetes:\n    image: quay.io/ukhomeofficedigital/drone-kubernetes\n    replicationcontrollers: [\"kubernetes/deep-api-rc.json\", \"kubernetes/deep-web-rc.json\"]\n    services: []\n    token: $$TOKEN\n    apiserver: $$APISERVER\n    namespace: default\n    webhook: $$WEBHOOK_URL\n    webhook_token: $$WEBHOOK_TOKEN\n```\n\nThe webhook will post a json with the following structure:\n\n```\n{\n    \"Timestamp\": 1447753701,\n    \"Images\": [\n        \"kubernetes/rc.json\"\n    ],\n    \"Namespace\": \"default\",\n    \"Source\": \"DRONE\",\n    \"Target\": \"API_SERVER\",\n    \"Url\": \"WEBOHOOK\",\n    \"Token\": \"TOKEN\"\n}\n```\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/openvpn-authd","private":false,"url":"https://github.com/UKHomeOffice/openvpn-authd","license":{"key":"apache-2.0","name":"Apache License 2.0","spdxId":"Apache-2.0","url":"https://api.github.com/licenses/apache-2.0","featured":true},"readme":false,"travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/kube-cover","private":false,"url":"https://github.com/UKHomeOffice/kube-cover","license":{"key":"apache-2.0","name":"Apache License 2.0","spdxId":"Apache-2.0","url":"https://api.github.com/licenses/apache-2.0","featured":true},"readme":"\n### **Kube Cover**\n---\n\n**Kube Cover** is a short-term hack to enable security policies via the Kubernetes API. Presently, items such as privileged, host network, host, pid/ipc, host port range and docker capabilities are difficult or in some cases impossible to enforce a security policy. Kube Cover provide's a stepping stone into using  those policies while we wait for the kubernetes project to resolve and release them. Note, the actually policies are based on a PR released into Openshift Origin\n\n\n##### **Usage**\n----\n```shell\nUsage of bin/kube-cover:\n  -alsologtostderr          log to standard error as well as files\n  -bind string              the interface and port for the service to listen on (default \":6444\")\n  -log_backtrace_at value   when logging hits line file:N, emit a stack trace (default :0)\n  -log_dir string           If non-empty, write log files in this directory\n  -logtostderr              log to standard error instead of files\n  -policy-file string       the path to the policy file container authorization security policies\n  -stderrthreshold value    logs at or above this threshold go to stderr\n  -tls-cert string          the path to the tls cerfiicate for the service to use\n  -tls-key string           the path to the tls private key for the service\n  -url string               the url for the kubernetes upstream api service, must be https (default \"https://127.0.0.1:6443\")\n  -v value                  log level for V logs\n  -vmodule value            comma-separated list of pattern=N settings for file-filtered logging\n```\n\n##### **Example Usage**\n----\n```shell\n[jest@starfury kube-cover]$ bin/kube-cover \\\n    -logtostderr=true -v=10 \\\n    -tls-cert=tests/kubeapi.pem \\\n    -tls-key=tests/kubeapi-key.pem \\\n    -policy-file=tests/policies.json \\\n    -url=https://the_url_for_the_k8s_api_must_be_https\n\n[jest@starfury openvpn]$ kubectl get pods\nNAME            READY     STATUS                                         RESTARTS   AGE\nservice-u6ea0   0/1       Image: nginx is ready, container is creating   0          2h\nweb-7jthn       1/1       Running                                        0          1d\n\nI1116 16:34:49.748882   30023 server.go:32] create a new kube cover service\nI1116 16:34:49.749001   30023 controller.go:41] loading the policies file: tests/policies.json\nI1116 16:34:49.749355   30023 controller.go:46] found 1 polices in the file\n[GIN] 2015/11/16 - 16:35:13 | 200 |  130.948277ms | 127.0.0.1 |   GET     /api\n[GIN] 2015/11/16 - 16:35:13 | 200 |   28.218429ms | 127.0.0.1 |   GET     /api/v1/namespaces/default/pods\n\n# attempt to create a pod with a hostpath mapped into /etc\n[jest@starfury kube-cover]$ kubectl create -f tests/services/service-hostpaths.yml \nError from server: error when creating \"tests/services/service-hostpaths.yml\": security policy violation, reason: host path /run/vault\n\n# logging from the kube-cover proxy filter\n\n[GIN] 2015/11/16 - 16:38:13 | 200 |   55.299491ms | 127.0.0.1 |   GET     /api\nI1116 16:38:13.587799   30023 handlers.go:48] authorizating replication controller, namespace: default, name: service\nI1116 16:38:13.587823   30023 controller.go:56] validating the pod spec, namespace: default\nE1116 16:38:13.587832   30023 handlers.go:86] unauthorized request from: (127.0.0.1:44040), failure: host path /run/vault violation\nE1116 16:38:13.587836   30023 handlers.go:87] failing specification: \n\n.. -> plus a insert of pod json which violated the policy\n\n```\n\n##### **Security Policies**\n\nThe security policy file is a single json file containing an array of PodSecurityPolicy types (which you can find in\npolicy/acl/types.go)\n\nAt the moment the filter / matching for security policies is applied at a *namespace* level (since that's what were using use to segregate projects  - we then use a [auth-policy](https://github.com/kubernetes/kubernetes/blob/release-1.1/docs/admin/authorization.md) to enforce which namespaces a user has permissions to access. You could technically grab the user / group from a JWT or tokenfile, **BUT**, depends on how long it takes for k8s to merge the security policy proposal.\n\n```JSON\n{\n  \"kind\": \"PodSecurityPolicyList\",\n  \"apiVersion\": \"v1\",\n  \"items\": [\n    {\n      \"kind\": \"PodSecurityPolicy\",\n      \"version\": \"v1\",\n      \"namespaces\": [\n        \"*\"\n      ],\n      \"spec\": {\n        \"privileged\" : false,\n        \"hostNetwork\" : false,\n        \"hostPID\": false,\n        \"hostIPC\": false,\n        \"volumes\": {\n          \"hostPath\": true,\n          \"hostPathAllowed\": [\n            \"/var/data\"\n          ],\n          \"emptyDir\": true,\n          \"gitRepo\": true,\n          \"secret\": true,\n          \"rbd\": true,\n          \"downwardAPI\": true\n        }\n      }\n    }\n  ]\n}\n```\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/deep-ui","private":false,"url":"https://github.com/UKHomeOffice/deep-ui","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# deep-ui\nWeb interface for CI/CD private and public dashboards\n\n","travis":false,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change.\n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a\n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment\n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you\n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and\nwelcoming community, we pledge to respect all people who contribute through reporting issues,\nposting feature requests, updating documentation, submitting pull requests or patches, and other\nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone,\nregardless of level of experience, gender, gender identity and expression, sexual orientation,\ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits,\ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By\nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently\napplying these principles to every aspect of managing this project. Project maintainers who do not\nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is\nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an\nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org),\nversion 1.2.0, available at\n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/docker-ckan-solr","private":false,"url":"https://github.com/UKHomeOffice/docker-ckan-solr","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# Docker Container with Ckan Configuration of Solr\n\n[![Docker Repository on Quay](https://quay.io/repository/ukhomeofficedigital/ckan-solr/status \"Docker Repository on Quay\")](https://quay.io/repository/ukhomeofficedigital/ckan-solr) [![Build Status](https://travis-ci.org/UKHomeOffice/docker-ckan-solr.svg)](https://travis-ci.org/UKHomeOffice/docker-ckan-solr) [![GitHub version](https://badge.fury.io/gh/UKHomeOffice%2Fdocker-ckan-solr.svg)](https://badge.fury.io/gh/UKHomeOffice%2Fdocker-ckan-solr) \n\nThis docker container CKAN configuration of Solr.\n\n## Running\n\nSee the [docker-solr](https://github.com/UKHomeOffice/docker-solr) repo for full details.\n\nTo run a single Solr server:\n\n```bash\ndocker run --name ckan-solr -d -p 8983:8983 -t quay.io/ukhomeofficedigital/ckan-solr:$CONTAINER_VERSION\n```\n\n## Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for details\n\n## License\n\nThis repository is licensed under the GPL v2 License. See [LICENSE.md](LICENSE.md) for full details.\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and welcoming community, we pledge to respect all people who contribute through reporting issues, posting feature requests, updating documentation, submitting pull requests or patches, and other activities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, regardless of level of experience, gender, gender identity and expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit permission\n* Other unethical or unprofessional conduct\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By adopting this Code of Conduct, project maintainers commit themselves to fairly and consistently applying these principles to every aspect of managing this project. Project maintainers who do not follow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is representing the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an issue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), version 1.2.0, available at [http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/deep-api","private":false,"url":"https://github.com/UKHomeOffice/deep-api","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# deep-api\nRest API  for deep\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/data-catalogue","private":false,"url":"https://github.com/UKHomeOffice/data-catalogue","license":{"key":"other","name":"Other","spdxId":null,"url":null,"featured":false},"readme":"# Data Catalogue\n\n[![Codacy Badge](https://api.codacy.com/project/badge/grade/617b2a093c8246179ca234fcd7b765fd)](https://www.codacy.com/app/purplebooth/data-catalogue) [![Build Status](https://travis-ci.org/UKHomeOffice/data-catalogue.svg)](https://travis-ci.org/UKHomeOffice/data-catalogue) [![Docker Repository on Quay](https://quay.io/repository/ukhomeofficedigital/data-catalogue/status \"Docker Repository on Quay\")](https://quay.io/repository/ukhomeofficedigital/data-catalogue) [![GitHub version](https://badge.fury.io/gh/UKHomeOffice%2Fdata-catalogue.svg)](https://badge.fury.io/gh/UKHomeOffice%2Fdata-catalogue)\n\nA quick spike to get CKAN running in docker with our own config\n\n## Starting\n```\ndocker-compose up db solr\ndocker-compose up ckan\n```\n\n## Deploying\n\nKubernetes files can be found at [k8s/](k8s/)\n\n## Loading data\n\nRequires *Python* and *pip*\n\n```\ncd loader\npip install -r requirements.txt\npython baseloader.py http://your-docker-instance your-api-key\n```\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/docker-scala-play","private":false,"url":"https://github.com/UKHomeOffice/docker-scala-play","license":{"key":"lgpl-2.1","name":"GNU Lesser General Public License v2.1","spdxId":"LGPL-2.1","url":"https://api.github.com/licenses/lgpl-2.1","featured":false},"readme":"# Deprecated in favour of [this image](https://github.com/UKHomeOffice/docker-scala-sbt)\n\n# docker-scala-play\nEnables build of Scala apps using the play framework\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/lev-web","private":false,"url":"https://github.com/UKHomeOffice/lev-web","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# LEV Front End\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/lev-web.svg?branch=master)](https://travis-ci.org/UKHomeOffice/lev-web)\n\n## Getting Started\n\nThese instructions will get you a copy of the project up and running on your local machine for development and testing purposes. See deployment for notes on how to deploy the project on a live system.\n\n### Prerequisities\n\nWhat things you need to install the software and how to install them\n- NodeJS\n\n### Installing\n\n`npm install`\n\n## Running the tests\n\n### Locally\n```bash\nnpm test\n```\n\n### Acceptance tests against a server\n```bash\nENV=dev TEST_URL=http://lev-web-dev.dsp.notprod.homeoffice.gov.uk USERNAME=xxxx PASSWORD=xxxx npm run chimp\n```\nOR\n```\ndocker build -f ./E2E_test_Dockerfile -t lev-web-e2e-tests .\ndocker run --rm -e ENV=dev -e TEST_URL=http://lev-web-dev.dsp.notprod.homeoffice.gov.uk -e USERNAME=xxxx -e PASSWORD=xxxx lev-web-e2e-tests\n```\n\n## Contributing\n\nPlease read [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct, and the process for submitting pull requests to us.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the [tags on this repository](https://github.com/your/project/tags).\n\n## License\n\nThis project is licensed under the GPLv2 License - see the [LICENSE.md](LICENSE.md) file for details\n\n\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n\n","masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/lev-web/branches/master/protection","requiredStatusChecks":{"url":"https://api.github.com/repos/UKHomeOffice/lev-web/branches/master/protection/required_status_checks","strict":true,"includeAdmins":true,"contextsUrl":"https://api.github.com/repos/UKHomeOffice/lev-web/branches/master/protection/required_status_checks/contexts"}}},{"name":"UKHomeOffice/docker-mysql-client","private":false,"url":"https://github.com/UKHomeOffice/docker-mysql-client","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Docker Mysql client\n\nDocker container for provisioning mysql databases.\n\n## Getting Started\n\nThese instructions will cover how to start a container both in Docker and within a [Kubernetes](http://kubernetes.io/) cluster.\n\n### Prerequisites\n\nIn order to run this container you'll need docker installed.\n\n* [Windows](https://docs.docker.com/windows/started)\n* [OS X](https://docs.docker.com/mac/started/)\n* [Linux](https://docs.docker.com/linux/started/)\n\nOptionally:\n\n* A [Kubernetes](http://kubernetes.io/) cluster to enable Kubernetes api discovery of other nodes.\n\n### Usage\n\nThe example below will run a mysql client container and create the database test with the user test_user:\n\n```\ndocker run -i --rm=true \\\n       -e MYSQL_HOST=localhost \\\n       -e APP_DB_NAME=mydb \\\n       -e ROOT_PASS=secretpass \\\n       -e APP_DB_USER=myapp_user \\\n       -e APP_DB_PASS=myapppass \\\n       quay.io/ukhomeofficedigital/mysql-client:v0.1.2\n```\n\nTo use with [Kubernetes](http://kubernetes.io/) see the [kubernetes examples](examples/kubernetes.md).\n\n\n#### Environment Variables\n\nThe variables and the defaults are shown below.\nBy default, the container does not depend on [Kubernetes](http://kubernetes.io/). \n\n* `MYSQL_HOST=hostname` The host to connect to.\n* `MYSQL_PORT=3306` The port to connect to.\n* `ENABLE_SSL=FALSE` When set to TRUE, will ensure all users must connect using SSL using the Amazon RDS CA.\n* `DEFAULT_PW=changeme` Supports changing a database provisioned root password from this value.\n* `ROOT_PASS=`\n\n\n## Contributing\n\nFeel free to submit pull requests and issues. If it's a particularly large PR, you may wish to discuss\nit in an issue first.\n\nPlease note that this project is released with a [Contributor Code of Conduct](code_of_conduct.md). \nBy participating in this project you agree to abide by its terms.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the \n[tags on this repository](https://github.com/UKHomeOffice/docker-mysql-client/tags).\n\n## Authors\n\n* **Lewis Marshall** - *Initial work* - [Lewis Marshall](https://github.com/LewisMarshall)\n\nSee also the list of [contributors](https://github.com/UKHomeOffice/docker-mysql-client/contributors) who\nparticipated in this project.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/chimp","private":false,"url":"https://github.com/UKHomeOffice/chimp","license":null,"readme":"[![Chimp by Xolv.io](./header.png?raw=true)](http://chimpjs.com)\n\n[![Circle CI](https://circleci.com/gh/xolvio/chimp.svg?style=svg)](https://circleci.com/gh/xolvio/chimp) [![Gitter](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/xolvio/chimp?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n\n This package allows you to easily write the automating code in BDD using Cucumber.js or Mocha (Jasmine soon). \n\nYou can use chimp with any technology stack since it allows your to write your automation layer in JavaScript ( the language of the web.)\n\n[Click here to see a demo](http://chimpjs.com).\n\n\n## Installation\n```sh\nnpm install chimp\n```\n\n## Documentation\nYou can read [read the full documentation here](http://chimp.readme.io/docs).\n\n## Prerequisites\nYou need to be sure you have the following installed:\n\n* Node & NPM\n* Java 1.8+\n* Google Chrome (or you can set the `--browser` flag and use any other browser)\n\nChimp will do the rest.\n\n# Using Meteor?\n\n## Installation\n\nOur [xolvio:cucumber package](https://atmospherejs.com/xolvio/cucumber) wraps Chimp and gives you an \neven smoother development experience.\n\n```sh\nmeteor add xolvio:cucumber\n```\n\n## Get the Book\nTo learn more about testing with Meteor, consider purchasing our book [The Meteor Testing Manual](http://www.meteortesting.com/?utm_source=Cucumber&utm_medium=banner&utm_campaign=Cucumber).\n\n[![](http://www.meteortesting.com/img/tmtm.gif)](http://www.meteortesting.com/?utm_source=GitHubChimp&utm_medium=banner&utm_campaign=Chimp)\n\nYour support helps us continue our work on Chimp, Meteor Cucumber and Velocity.\n","travis":false,"contributing":"# Contributing\n\n## Reporting a bug?\n\nThank you for taking the time to come here and report a bug! In order to get you the best help and\nso that you get a quick response, please consider this checklist for reporting a bug:\n\n* [ ] Provide an explanation of what you're expecting and what is actually happening\n* [ ] Attach the code that is causing the issue \n* [ ] Attach console outputs\n* [ ] Run chimp with the `--debug` flag (Not applicable to Meteor, see below)\n\nPlease be sure to include any logs inside a fenced code block \n[like this](https://help.github.com/articles/github-flavored-markdown/#fenced-code-blocks). This \nmakes it easier to read.\n\n#### Using Meteor?\n* [ ] Run Meteor with `VELOCITY_DEBUG=1 meteor`\n* [ ] Attach content of `.meteor/local/log/cucumber.log`\n* [ ] Attach content of `.meteor/versions` \n* [ ] Attach content of `.meteor/packages`\n","masterBranchProtection":false},{"name":"UKHomeOffice/Employers-Checking-Service-Form","private":false,"url":"https://github.com/UKHomeOffice/Employers-Checking-Service-Form","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# Employers-Checking-Service-Form\nEmployers-Checking-Service-Form\n","travis":false,"contributing":"# Contribution guidelines\n\nWe welcome patches!\n\n## Commit hygiene\n\nWe like to follow the recommendations set out in the GDS [git style guide][gitstyle]\nwhich describes how we prefer git history and commit messages to read.\n\n[gitstyle]: https://github.com/alphagov/styleguides/blob/master/git.md\n\n## JavaScript\n\nWe have a JavaScript style checker `npm run style`\n\nAll our styles are defined in our [JavaScript style config][jsstyle]\n\nWe follow the [Google JavaScript style guide](https://google.github.io/styleguide/javascriptguide.xml)\n\nWe also lint our code `npm run lint`.\n\n[jsstyle]: https://github.com/UKHomeOffice/brp_app/blob/master/.jscsrc.json\n\nA pre commit hook is run as part of the project which runs the above checks and our tests (`npm run test`).\n\n## Visual changes\n\nFor visual changes, it can be helpful to provide images in your pull-request\nshowing before and after to highlight the differences.","masterBranchProtection":false},{"name":"UKHomeOffice/gro","private":false,"url":"https://github.com/UKHomeOffice/gro","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# GRO (General Registrars Office) [![Build Status](https://drone.digital.homeoffice.gov.uk/api/badges/UKHomeOffice/gro/status.svg)](https://drone.digital.homeoffice.gov.uk/UKHomeOffice/gro)\n\n## Getting Started\n\n### Prerequisities\n\n- [Node.js](https://nodejs.org/en/) - Tested against LTS\n- NPM (installed with Node.js) - Works with versions 2 and 3.\n- [Redis server](http://redis.io/download) running on the default port\n\n### Up & Running\n\n```bash\n$ cd gro\n$ npm install\n$ npm run dev\n```\n\nThen visit: [http://localhost:8080/](http://localhost:8080/)\n\n## Testing\n\n### Acceptance Tests\nWith the server running in development mode (`npm run dev`), start the acceptance tests:\n\n```bash\n$ npm run test:acceptance\n```\nPhantomjs is required to run the acceptance tests (`npm install phantomjs`), or alternatively, export `IN_BROWSER=true` to run the tests in Firefox.\n\n### Unit Tests\n```bash\n$ npm t\n```\n\n## Contributing\n\nPlease read [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct, and the process for submitting pull requests to us.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the [tags on this repository](https://github.com/your/project/tags).\n\n## License\n\nThis project is licensed under the GPLv2 License - see the [LICENSE.md](LICENSE.md) file for details\n","travis":false,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/docker-artifactory","private":false,"url":"https://github.com/UKHomeOffice/docker-artifactory","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# Docker Artifactory Container\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-artifactory.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-artifactory)\n\nDocker container that runs artifactory and supports both PRO and Community edition building.\n\n## Getting Started\n\nThese instructions will cover usage information and for the docker container \n\n### Prerequisites\n\nIn order to run this container you'll need docker installed.\n\n* [Windows](https://docs.docker.com/windows/started)\n* [OS X](https://docs.docker.com/mac/started/)\n* [Linux](https://docs.docker.com/linux/started/)\n\n### BUILD ARG Variables\n\n* `ARTIFACTORY_VERSION` - The version of artifactory you want to pull down the RPM, this defaults to artifactory-pro-rpms as oppose artifactory-rpms\n\n### Environment Variables\n\n* `ARTIFACTORY_HOME` - The artifactory home path\n* `TOMCAT_HOME` - The tomcat home path\n* `ARTIFACTORY_INIT` - The artifactory shell script\n* `ARTIFACTORY_USER` - The artifactory user\n* `ARTIFACTORY_VERSION` - The artifactory version, defaults to the build arg\n* `MAVEN_MYSQL` - The maven MYSQL path for the JDBC driver\n* `DEBUG` - This will set the startup script to bash debug mode when you run it to troubleshoot issues\n* `PROXY` - Whether you intend to have a Proxy infront of the service or not, defaults to false\n* `STORAGE_PROPERTIES` - Path to the storage properties file\n* `LICENSE` - The license string for the PRO version to pass in as text\n* `MYSQL` - Whether you are using MYSQL or not defaults to false\n* `MYSQL_CONNECTOR_VERSION` - The MYSQL connector version for the JDBC version defaults to 5.1.37\n* `MYSQL_CONNECTOR_MD5SUM` - The MYSQL connector MD5SUM to validate the right thing is pulled down\n* `MYSQL_OUTPUT_FILE` - The output file location of where to place the JDBC driver connector\n* `MYSQL_USER` - The MYSQL Username\n* `MYSQL_DB` - The MYSQL Database name\n* `MYSQL_PASS` - The MYSQL Password\n* `MYSQL_HOST` - The MYSQL HOSTNAME\n* `MYSQL_PORT` - The MYSQL Port\n* `S3` - Whether you are using S3 to store binaries instead of the filesystem, defaults to false\n* `S3_AWS_ACCESS_KEY` - The S3 Access Key\n* `S3_AWS_SECRET_ACCESS_KEY` - The S3 Secret\n* `S3_AWS_ENDPOINT` - The S3 Endpoint, defaults to eu-west-1\n\n\n### Ports\n\n* `8081`- This container exposes port 8081\n\n\n## Volumes\n* `${ARTIFACTORY-HOME}/logs` - The logs should be going to stdout / stderr but is a volume\n* `${ARTIFACTORY_HOME/data` - The data directory for where the data lives, this is for the filesystem binaries but negated if using s3\n* `${ARTIFACTORY_HOME/backup` - Used for backups, we can then sync up these to S3 as a scheduled job\n\n### Usage\n\nTo do a standard build for the pro version\n```docker build -t artifactory:latest .```\n\nTo do a standard build but for the basic version\n```docker build --build-arg ARTIFACTORY_VERSION=artifactory-rpms -t artifactory:latest .```\n\nTo run artifactory with support for varying requirements, specify them as runtime environment variables\n```docker run -e MYSQL=true -e MYSQL_DB=artifactory -e MYSQL_USER=artifactory -e MYSQL_PASS=artifactory -e MYSQL_HOST=1.2.3.4```\n\n# Use this repo\nFROM quay.io/ukhomeofficedigital/artifactory:v0.4.0\n\n## Contributing\n\nFeel free to submit pull requests and issues. If it's a particularly large PR, you may wish to discuss\nit in an issue first.\n\nPlease note that this project is released with a [Contributor Code of Conduct](code_of_conduct.md). \nBy participating in this project you agree to abide by its terms.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the \n[tags on this repository](https://github.com/UKHomeOffice/docker-artifactory/tags). \n\n## Authors\n\n* **Jon Shanks** - *Initial work* - [Jon Shanks](https://github.com/jon-shanks)\n\nSee also the list of [contributors](https://github.com/UKHomeOffice/docker-artifactory/contributors) who \nparticipated in this project.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.\n\n## Acknowledgments\n\n* [JFrog Artifactory](https://www.jfrog.com/artifactory/)\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/blueprint","private":false,"url":"https://github.com/UKHomeOffice/blueprint","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# blueprint\nBlueprinting system for DSP\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-mailcatcher","private":false,"url":"https://github.com/UKHomeOffice/docker-mailcatcher","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Docker Mail Catcher\n\nDocker container for [Mail Catcher](http://mailcatcher.me/)\n\n## Getting Started\n\nThese instructions will cover how to start a container both in Docker and within a [Kubernetes](http://kubernetes.io/) cluster.\n\n### Prerequisites\n\nIn order to run this container you'll need docker installed.\n\n* [Windows](https://docs.docker.com/windows/started)\n* [OS X](https://docs.docker.com/mac/started/)\n* [Linux](https://docs.docker.com/linux/started/)\n\nOptionally:\n\n* A [Kubernetes](http://kubernetes.io/) cluster to enable Kubernetes api discovery of other nodes.\n\n### Usage\n\nThe example below will run a mailcatcher container listening on port 1025 (SMTP) and 1080 (API and UI):\n\n```\ndocker run -i --rm=true \\\n       -p 1025:1025 \\\n       -p 1080:1080 \\\n       quay.io/ukhomeofficedigital/mailcatcher:v0.1.0\n```\n\n## Contributing\n\nFeel free to submit pull requests and issues. If it's a particularly large PR, you may wish to discuss\nit in an issue first.\n\nPlease note that this project is released with a [Contributor Code of Conduct](code_of_conduct.md). \nBy participating in this project you agree to abide by its terms.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the \n[tags on this repository](https://github.com/UKHomeOffice/docker-mailcatcher/tags).\n\n## Authors\n\n* **Lewis Marshall** - *Initial work* - [Lewis Marshall](https://github.com/LewisMarshall)\n\nSee also the list of [contributors](https://github.com/UKHomeOffice/docker-mailcatcher/contributors) who\nparticipated in this project.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.\n\n## Acknowledgments\n\n[Mail Catcher](http://mailcatcher.me/)","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-java7-mvn","private":false,"url":"https://github.com/UKHomeOffice/docker-java7-mvn","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# docker-java7-mvn\nbase docker image with java7 and maven\n\n## Usage\n\nThis docker container is intended for use in Java projects.\n\n\n## Contributing\n\nFeel free to submit pull requests and issues. If it's a particularly large PR, you may wish to\ndiscuss it in an issue first.\n\nPlease note that this project is released with a\n[Contributor Code of Conduct](https://github.com/UKHomeOffice/docker-java7-mvn/blob/master/CODE_OF_CONDUCT.md).\nBy participating in this project you agree to abide by its terms.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for the version tags available See the tags on this repository.\n\n## Build With\n\n* java-1.7.0-openjdk-devel\n\nSee also the list of\n[contributors](https://github.com/UKHomeOffice/java-1.7.0-openjdk-deve/graphs/contributors) who participated\nin this project.\n\n## License\n\nThis project is licensed under the GPL v2 License - see the\n[LICENSE.md](https://github.com/UKHomeOffice/java-1.7.0-openjdk-deve/blob/master/LICENSE.md) file for details\n","travis":false,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change.\n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a\n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment\n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you\n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and\nwelcoming community, we pledge to respect all people who contribute through reporting issues,\nposting feature requests, updating documentation, submitting pull requests or patches, and other\nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone,\nregardless of level of experience, gender, gender identity and expression, sexual orientation,\ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits,\ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By\nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently\napplying these principles to every aspect of managing this project. Project maintainers who do not\nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is\nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an\nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org),\nversion 1.2.0, available at\n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/dspctl","private":false,"url":"https://github.com/UKHomeOffice/dspctl","license":null,"readme":false,"travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/dronescheduler","private":false,"url":"https://github.com/UKHomeOffice/dronescheduler","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Drone scheduler\n\n[![Build Status](https://drone.notprod.homeoffice.gov.uk/api/badges/UKHomeOffice/dronescheduler/status.svg)](https://drone.notprod.homeoffice.gov.uk/UKHomeOffice/dronescheduler) [![Docker Repository on Quay](https://quay.io/repository/ukhomeofficedigital/dronescheduler/status \"Docker Repository on Quay\")](https://quay.io/repository/ukhomeofficedigital/dronescheduler)\n\nCurrently drone doesn't support scheduled builds. Since we need to build some projects on a regular base, we have created a small container that will run a cron job and will trigger drone builds.\n\n","travis":false,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n\n","masterBranchProtection":false},{"name":"UKHomeOffice/pingdom_tools","private":false,"url":"https://github.com/UKHomeOffice/pingdom_tools","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# pingdom_tools\nA place to put a Pingdom management tool\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/AppealRightsExhausted","private":false,"url":"https://github.com/UKHomeOffice/AppealRightsExhausted","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# AppealRightsExhausted\nA calculator to determine Appeal Rights Exhausted\n","travis":false,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/dockerfile-validator","private":false,"url":"https://github.com/UKHomeOffice/dockerfile-validator","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# dockerfile-validator\nLittle util to check if your Dockerfile is valid according to your defined rules\n\nIt works by defining your rules in a file, `rules.yaml` for example, and running the tool against the `Dockerfile` you want to test. This tool is useful\nas a previous step to do your `docker build` to guarantee that you only build docker images that match your rules.\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/HttpsClient","private":false,"url":"https://github.com/UKHomeOffice/HttpsClient","license":null,"readme":"# HttpsClient\n\nThis repository contains software to test client certificates against a web server with a configured certificate authority.\nThe assumption is that you have created an RSA private key (client.key) file and you have had a certificate signing request signed by a certificate authority making an x509 certificate (client.crt) file.\n\n## Build\n\nThis program can be built using the makefile provided.  There are commands for building OSX, Linux and Windows versions of the software.  Binaries are generated in the bin directory.  This software is built with Go 1.5.  \nAlternatively you can download the binaries you need from the bin directory.\n\n    // OSX\n    make osx\n    \n    // Linux\n    make linux\n    \n    // Windows 32 bit\n    make win32\n    \n    // Windows 64 bit\n    make win64\n\n## Usage\n\nThe httpsClient program requires three arguments:\n\n    - key  The key file created by the client.\n    - cert The certificate generated by the certificate authority.\n    - url  The url of the web server to test the client certificate against. \n \n## Example\n\n    ./httpsClient_linux -key client.key -cert client.crt -url https://www.someserver.com\n    \n    // Sample output\n    httpsClient v1.0 - UK Home Office\n    \n    STATUS\n    HTTP/1.1 200 OK\n    \n    HEADERS\n    Server: nginx\n    Date: Wed, 13 Jan 2016 10:02:52 GMT\n    Content-Type: text/plain;charset=ISO-8859-1\n    Content-Length: 7\n    Connection: keep-alive\n    X-Application-Context: application\n    \n    BODY\n    SUCCESS\n\n    \n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/keycloakjs-redirect","private":false,"url":"https://github.com/UKHomeOffice/keycloakjs-redirect","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# keycloakjs-redirect\n\n[![Build](https://travis-ci.org/UKHomeOffice/keycloakjs-redirect.png)](https://travis-ci.org/UKHomeOffice/keycloakjs-redirect)\n\n## Use case\n\nA Frontend Javascript service that integrates with the [Keycloak authentication service](http://keycloak.jboss.org/), guiding users to a login portal when a 401 Unauthorised response is received from an API.\n\n## Install\n\n```bash\n$ npm i keycloak-redirect\n```\n\n## Configuration\n\nImport the package, then use the object exposed to return the function `authenticate`, passing in all mandatory arguments: a config object, a XMLHttpRequest object, and window.\n\n```js\n    \n   import keycloakRedirect from 'keycloak-redirect';\n   \n   var config = {\n       backend: \"http://yourBackendUrl.com\",\n       clientId: \"yourClientId\",\n       keycloakUrl: \"http://yourKeycloakUrl.com\"\n   };\n   \n   keycloakRedirect.authenticate(config, new XMLHttpRequest(), $window);\n```\n\n## Run Tests\n\n```bash\n$ npm test\n```\n\n## Compile the code with babel\n```bash\n$ npm run compile\n```","travis":true,"contributing":false,"masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/keycloakjs-redirect/branches/master/protection","requiredStatusChecks":{"url":"https://api.github.com/repos/UKHomeOffice/keycloakjs-redirect/branches/master/protection/required_status_checks","strict":true,"includeAdmins":true,"contextsUrl":"https://api.github.com/repos/UKHomeOffice/keycloakjs-redirect/branches/master/protection/required_status_checks/contexts"}}},{"name":"UKHomeOffice/vitess","private":false,"url":"https://github.com/UKHomeOffice/vitess","license":null,"readme":"# vitess","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-nginx-sticky","private":false,"url":"https://github.com/UKHomeOffice/docker-nginx-sticky","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# Nginx-sticky\n \nHack for nginx sticky sessions used for the removals project.  This is hopefully a temp thing until kubernetes supports sticky sessions based on something that isn't ClientIp\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/gds-payments","private":false,"url":"https://github.com/UKHomeOffice/gds-payments","license":{"key":"other","name":"Other","spdxId":null,"url":null,"featured":false},"readme":"This is your new Play application\n=================================\n\nThis file will be packaged with your application, when using `activator dist`.\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/drone-docker","private":false,"url":"https://github.com/UKHomeOffice/drone-docker","license":null,"readme":"# drone-docker\n\n[![Build Status](http://beta.drone.io/api/badges/drone-plugins/drone-docker/status.svg)](http://beta.drone.io/drone-plugins/drone-docker)\n[![Coverage Status](https://aircover.co/badges/drone-plugins/drone-docker/coverage.svg)](https://aircover.co/drone-plugins/drone-docker)\n[![](https://badge.imagelayers.io/plugins/drone-docker:latest.svg)](https://imagelayers.io/?images=plugins/drone-docker:latest 'Get your own badge on imagelayers.io')\n\nDrone plugin to build and publish images to a Docker registry\n\n## Docker\n\nBuild the container using `make`:\n\n```\nmake deps docker\n```\n\n### Example\n\n```sh\ndocker run -i --privileged -v $(pwd):/drone/src plugins/drone-docker <<EOF\n{\n    \"repo\": {\n        \"clone_url\": \"git://github.com/drone/drone\",\n        \"owner\": \"drone\",\n        \"name\": \"drone\",\n        \"full_name\": \"drone/drone\"\n    },\n    \"system\": {\n        \"link_url\": \"https://beta.drone.io\"\n    },\n    \"build\": {\n        \"number\": 22,\n        \"status\": \"success\",\n        \"started_at\": 1421029603,\n        \"finished_at\": 1421029813,\n        \"message\": \"Update the Readme\",\n        \"author\": \"johnsmith\",\n        \"author_email\": \"john.smith@gmail.com\"\n        \"event\": \"push\",\n        \"branch\": \"master\",\n        \"commit\": \"436b7a6e2abaddfd35740527353e78a227ddcb2c\",\n        \"ref\": \"refs/heads/master\"\n    },\n    \"workspace\": {\n        \"root\": \"/drone/src\",\n        \"path\": \"/drone/src/github.com/drone/drone\"\n    },\n    \"vargs\": {\n        \"username\": \"kevinbacon\",\n        \"password\": \"pa$$word\",\n        \"email\": \"foo@bar.com\",\n        \"repo\": \"foo/bar\",\n        \"storage_driver\": \"aufs\"\n    }\n}\nEOF\n```\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/custom-fields-middleware","private":false,"url":"https://github.com/UKHomeOffice/custom-fields-middleware","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Custom Fields Middleware [![Build Status](https://travis-ci.org/UKHomeOffice/custom-fields-middleware.svg?branch=master)](https://travis-ci.org/UKHomeOffice/custom-fields-middleware)\n\nAdds and transforms custom fields on the response\n\n## Usage\n\nIn Express, pass the middleware to `app.use` before the router\n```js\napp.use(require('custom-fields-middleware'));\n```\n\nAssign a model to `customfields` from anywhere in your app\n```js\n\nres.customfields = {\n  id: 'foo',\n  value: 'bar'\n};\n```\n\nAssign a collection\n```js\nres.customfields = [{id: 'foo', value: 'bar'}, {id: 'bar', value: 'bar'}];\n```\n\nRead the value(s)\n```js\nres.customfields.foo // 'bar'\nres.customfields.bar // 'baz'\n```\n\n\n### Params\n\n- `id`: {String} required. The name of the value.\n- `value`: {*} required. The value to be assigned to the id.\n- `transforms`: {Array|String|Function} options. A function or list of functions to transforms the value.\n\n\n### Transforms\n\nA transform is a function that takes two arguments, the value and the request object.\n\n```js\n\nvar square (value, req) => value * value;\n\nres.customfields = {\n  id: 'foo',\n  value: 'bar',\n  transforms: [square]\n};\n```\n\nBuilt-in transforms include:\n\n- `baseurl`: prepends the value with `req.baseUrl`\n\nUse a built-in transform by passing the name to the `transforms` field.\n```js\nres.customfields = {\n  id: 'foo',\n  value: 'bar',\n  transforms: ['baseurl']\n};\n```\n\n### Install\n\n```bash\n$ npm install custom-fields-middleware --save\n```\n\n### Scripts\n```bash\n$ npm test\n```\n\n```bash\n$ npm lint\n```\n","travis":true,"contributing":false,"masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/custom-fields-middleware/branches/master/protection","requiredStatusChecks":{"url":"https://api.github.com/repos/UKHomeOffice/custom-fields-middleware/branches/master/protection/required_status_checks","strict":true,"includeAdmins":true,"contextsUrl":"https://api.github.com/repos/UKHomeOffice/custom-fields-middleware/branches/master/protection/required_status_checks/contexts"}}},{"name":"UKHomeOffice/docker-rtp-testing","private":false,"url":"https://github.com/UKHomeOffice/docker-rtp-testing","license":null,"readme":false,"travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/scala-presentation","private":false,"url":"https://github.com/UKHomeOffice/scala-presentation","license":{"key":"other","name":"Other","spdxId":null,"url":null,"featured":false},"readme":"Scala Presentation\n==================\nApplication built with the following (main) technologies:\n\n- Scala\n\n- SBT\n\n- Specs2\n\nIntroduction\n------------\nExamples of using Scala as a high level introduction, but also some funky stuff as well.\n\nBuild and Deploy\n----------------\nThe project is built with SBT. On a Mac (sorry everyone else) do:\n> brew install sbt\n\nIt is also a good idea to install Typesafe Activator (which sits on top of SBT) for when you need to create new projects - it also has some SBT extras, so running an application with Activator instead of SBT can be useful. On Mac do:\n> brew install typesafe-activator\n\nTo compile:\n> sbt compile\n\nor\n> activator compile\n\nTo run the specs:\n> sbt test\n\nAmmonite-REPL in SBT\n--------------------\n> sbt test:console","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/rtp-caseworker-mongo-lib","private":false,"url":"https://github.com/UKHomeOffice/rtp-caseworker-mongo-lib","license":{"key":"other","name":"Other","spdxId":null,"url":null,"featured":false},"readme":"RTP Caseworker Mongo Library\n============================\nApplication built with the following (main) technologies:\n\n- Scala\n\n- SBT\n\n- Specs2\n\n- Casbah/Salat\n\nIntroduction\n------------\nTODO\n\nBuild and Deploy\n----------------\nThe project is built with SBT. On a Mac (sorry everyone else) do:\n> brew install sbt\n\nIt is also a good idea to install Typesafe Activator (which sits on top of SBT) for when you need to create new projects - it also has some SBT extras, so running an application with Activator instead of SBT can be useful. On Mac do:\n> brew install typesafe-activator\n\nTo compile:\n> sbt compile\n\nor\n> activator compile\n\nTo run the specs:\n> sbt test\n\nAmmonite-REPL in SBT\n--------------------\n> sbt test:console","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/kube-cfn-signal","private":false,"url":"https://github.com/UKHomeOffice/kube-cfn-signal","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Kubernetes CloudFormation Signal\n\nThis little utility can health check kubernetes endpoints until they become\nready and send a signal to CloudFormation API.\n\nCloudFormation allows you to set\n[CreationPolicy](http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-creationpolicy.html)\nand\n[UpdatePolicy](http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-updatepolicy.html)\nattributes on stack resources, the one we're interested in is the Autoscaling group\nresource which looks after the Kubernetes nodes.\n\nThe most useful place to use this is when you're doing AutoScaling group\nrolling updates.\n\n### Requirements\n#### IAM Instance Policy\nNormally you would want to run `kube-cfn-signal` from within an instance which\nis being created/updated. So to make things simpler, it is advisable to allow\nyour kubernetes nodes to query tags and send a signal to CloudFormation API.\n\n```json\n{\n    \"Statement\": [\n        {\n            \"Resource\": \"arn:aws:ec2:*:*:instance/*\",\n            \"Action\": [\n                \"ec2:DescribeTags\",\n            ],\n            \"Effect\": \"Allow\"\n        },\n        {\n            \"Resource\": \"arn:aws:cloudformation:*:*:stack/*/*\",\n            \"Action\": [\n                \"cloudformation:SignalResource\"\n            ],\n            \"Effect\": \"Allow\"\n        }\n    ]\n}\n```\n\n### Running\n#### Systemd Unit\n```\n[Unit]\nDescription=Kubernetes cfn signal\nDocumentation=https://github.com/UKHomeOffice/kube-cfn-signal\n\n[Service]\nType=oneshot\nPrivateTmp=true\nProtectSystem=full\nRemainAfterExit=yes\nTimeoutStartSec=10m\nExecStart=/opt/bin/kube-cfn-signal --insecure-skip-tls-verify\n```\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-mysql-galera","private":false,"url":"https://github.com/UKHomeOffice/docker-mysql-galera","license":null,"readme":false,"travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/fileproducer_kafka","private":false,"url":"https://github.com/UKHomeOffice/fileproducer_kafka","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# File Producer for Kafka\n\nThis tool is a Kafka producer to be used as a side-ckick container to push files into Kafka.\n\nAfter building the tool, you can run it using the following command:\n\n        FILE=\"file_to_be_sent\" TOPIC=\"TOPIC_USED\" PARTITION=0 BROKERS=\"localhost:9092\" CLIENT_NAME=\"mygotest\" ./file_producer\n\n\nIf you want to use the container, the command is:\n\n        docker run -e FILE=\"myfile.zip\" -e TOPIC=\"TEST_GO\" \\\n            -e PARTITION=0 -e BROKERS=\"localhost:9092\"  \\\n            -e CLIENT_NAME=\"ivantest2\" \\\n            -v $(pwd)/myfile.zip:/myfile.zip \\\n            quay.io/ukhomeofficedigital/docker-file-producer\n\n","travis":false,"contributing":"# How to contribute\n\nThis document outlines some of the conventions on commit message formatting,\ncontact points for developers and other resources to make getting your\ncontribution into DSP easier.\n\n## Contribution flow\n\nThis is a rough outline of what a contributor's workflow looks like:\n\n- Create a topic branch from where you want to base your work. This is usually master.\n- Make commits of logical units.\n- Make sure your commit messages are in the proper format (see below).\n- Push your changes to a topic branch.\n- Submit a pull request to UKHomeOffice/dsp.\n- Your PR must receive a LGTM from two people.\n\nIf unsure about your change, submit an issue to start a discussion.\n\nThanks for your contributions!\n\n### Format of the Commit Message\n\nWe follow a rough convention for commit messages that is designed to answer two\nquestions: what changed and why. The subject line should feature the what and\nthe body of the commit should describe the why.\n\n```\nscripts: add the test-cluster command\n\nthis uses tmux to setup a test cluster that you can easily kill and\nstart for debugging.\n\nFixes #38\n```\n\nThe format can be described more formally as follows:\n\n```\n<subsystem>: <what changed>\n<BLANK LINE>\n<why this change was made>\n<BLANK LINE>\n<footer>\n```\n\nThe first line is the subject and should be no longer than 70 characters, the\nsecond line is always blank, and other lines should be wrapped at 80 characters.\nThis allows the message to be easier to read on GitHub as well as in various\ngit tools.\n","masterBranchProtection":false},{"name":"UKHomeOffice/vaultctl","private":false,"url":"https://github.com/UKHomeOffice/vaultctl","license":{"key":"apache-2.0","name":"Apache License 2.0","spdxId":"Apache-2.0","url":"https://api.github.com/licenses/apache-2.0","featured":true},"readme":"### **Vaultctl**\n\n---\nVaultctl is a command line utilty for provisioning a Hashicorp's [Vault](https://www.vaultproject.io) from configuration files. Essentially it was written so we could source control our users, policies, backends and secrets, synchronize the vault against them and rebuild on-demand if required.\n \n##### **Build**\n---\n \n There is a Makefile in the root directory, so a simply ***make*** will build the project. Alternatively you can run the build inside a docker via ***make docker-build***\n \n##### **Usage**\n---\n \n```shell\n[jest@starfury vaultctl]$ bin/vaultctl --help\nNAME:\n   vaultctl - is a utility for provisioning a hashicorp's vault service\n\nUSAGE:\n   vaultctl [global options] command [command options] [arguments...]\n   \nVERSION:\n   v0.0.1\n   \nAUTHOR(S):\n   Rohith <gambol99@gmail.com> \n   \nCOMMANDS:\n   synchronize, sync\tsynchonrize the users, policies, secrets and backends\n   transit, tr, trans\tEncrypts / decrypts files using the Vault transit backend\n   help, h\t\tShows a list of commands or help for one command\n   \nGLOBAL OPTIONS:\n   -A, --vault-addr \"http://127.0.0.1:8200\"\tthe url address of the vault service [$VAULT_ADDR]\n   -u, --vault-username \t\t\tthe vault username to use to authenticate to vault service [$VAULT_USERNAME]\n   -p, --vault-password \t\t\tthe vault password to use to authenticate to vault service [$VAULT_PASSWORD]\n   -c, --credentials \t\t\t\tthe path to a file (json|yaml) containing the username and password for userpass authenticaion [$VAULT_CRENDENTIALS]\n   --verbose\t\t\t\t\tswitch on verbose logging for debug purposed\n   --kube-populate\t\t\t\twhether or not to populate the vault crendentials into the namespaces\n   --help, -h\t\t\t\t\tshow help\n   --version, -v\t\t\t\tprint the version\n``` \n\n##### **Configuration**\n\nThe configuration files for vaultctl can be written in json or yml format *(note, it check the file extension to determine the format)*. You can specify multiple configuration files and or multiple directories containing config files. \n\n###### - **Authentication**\n\nAuthentication backends can be created using the following\n\n```YAML\nauths:\n- path: userpass\n  type: userpass\n- path: some/path/users\n  type: userpass\n- path: github\n  type: github\n  attributes:\n  - uri: config\n    organization: SomeOrganization\n```\n\n###### - **Users**\n\nUsers are place in a users: [] collection, the vault authentication type *(at present only userpass is supported, though it would be trivial to add more)* followed by the policies associated to the user\n\n```YAML\nusers:\n- userpass:\n    username: rohithj\n    password: password1\n  policies:\n    - common\n    - platform_tls\n```\n\n###### - **Backends**\n\nThe backends are defined under the 'backends[]' collection, each backend must have a path *(i.e. a mount point)*, a type which is the Vault backend type, a description *(which is enforced)* and an optional collection of config items. Keeping it simple the config[] is essentially a series of PUT requests. You can grab the configuration options and the uri from the Vault documentation. Note. an extra option *'oneshot'* been added, it simply means the config option will ONLY is run the first time the backend is created, which is useful for some backends like PKI, transit etc.\n\n```YAML\nbackends:\n- type: transit\n  path: platform/encode\n  description: A transit backend used to encrypt configuration files\n  attributes:\n  - uri: keys/default\n    oneshot: true\n- type: generic\n  path: platform/secrets\n  description: platform secrets\n- path: platform/platform_tls\n  description: platform tls\n  type: generic\n- path: platform/pki\n  type: pki\n  description: Platform PKI backend\n  attributes:\n  - uri: root/generate/internal\n    common_name: example.com\n    ttl: 3h\n    oneshot: true\n  - uri: roles/example-dot-com\n    allowed_domains: example.com\n    allow_subdomains: true\n    max_ttl: 1h \n# one of the annoying things about the mysql backend is it attempts to connect to the db when\n# adding the config/connection config??\n- path: platform/db\n  type: mysql\n  description: Platform Database\n  attributes:\n  - uri: config/connection\n    value: root:root@tcp(127.0.0.1:3306)/\n    oneshot: true\n  - uri: roles/readonly\n    sql: CREATE USER '{{name}}'@'%' IDENTIFIED BY '{{password}}';GRANT SELECT ON *.* TO '{{name}}'@'%'\n```    \n\n###### - **Secrets**\n\n```YAML\nsecrets:\n  - path: platform/secrets/platform_tls\n    values:\n      hello: world\n      rohith: yes\n  - path: platform/secrets/se1\n    values:\n      hello: world\n      rohith: yes\n```      \n\n###### - **Example Output**\n\n```shell\n[jest@starfury vaultctl]$ bin/vaultctl -u admin -p password  sync -p tests/policies -c platform.yml\nINFO[0000] -> synchronizing the vault policies, 3 files \nINFO[0001] [policy: common.hcl] successfully applied the policy, filename: tests/policies/common.hcl \nINFO[0001] [policy: platform.hcl] successfully applied the policy, filename: tests/policies/platform.hcl \nINFO[0001] [policy: platform_tls.hcl] successfully applied the policy, filename: tests/policies/platform_tls.hcl \nINFO[0001] -> synchronizing the vault users, users: 1 \nINFO[0001] [user: rohithj] ensuring user, policies: root \nINFO[0001] -> synchronizing the backends, backend: 2 \nINFO[0001] [backend: platform/encode]: already exist, moving to configuration \nINFO[0001] [backend:platform/encode/keys/default] skipping the config, as it's a oneshot setting \nINFO[0001] [backend: platform/secrets]: already exist, moving to configuration \nINFO[0001] -> synchronizing the secrets with vault, secrets: 0 \nINFO[0001] synchronization complete, time took: 1.733908869s \n```\n\n#### **Transit Encryption**\n---\nThe sub-command 'transit' permits you to encrypt and decrypt the file contents using a [Vault transit](https://www.vaultproject.io/docs/secrets/transit/index.html) backend. The current use case being we hand off management to others to manage their our namespaces, secret, backends etc and behold a generic endpoint for encryption. \n\n##### **TODO**\n---\n\n- Need to finish off the Kubernetes intregetion to place the vault credentials in k8s secrets.\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/vault-web-client","private":false,"url":"https://github.com/UKHomeOffice/vault-web-client","license":{"key":"apache-2.0","name":"Apache License 2.0","spdxId":"Apache-2.0","url":"https://api.github.com/licenses/apache-2.0","featured":true},"readme":"# Vault webclient\n\n\nThis client is a lightweight web interface to interact with Vault.\n\n\nTo install it you have to run the usual javascript suspects:\n\n```\nnpm install\nbrower install bootstrap\n\n```\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-zookeeper","private":false,"url":"https://github.com/UKHomeOffice/docker-zookeeper","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Zookeeper on Kubernetes\n[![Docker Repository on Quay](https://quay.io/repository/ukhomeofficedigital/zookeeper/status \"Docker Repository on Quay\")](https://quay.io/repository/ukhomeofficedigital/zookeeper)\n\nBits you need to run Zookeeper cluster on Kubernetes. It is based on Zookeeper\nversion 3.5.x which is currently in alpha, but it's been pretty stable.\n\n\n### Deployment\nBy default, if you don't specify any parameters, zookeeper will start in\nstandalone mode.\n\nDeploying onto a Kubernetes cluster is fairly easy. There are example\nkubernetes controller and service files in [kube/](kube/) directory.\n\nIn the service yaml files, you will notice that we asked for static\n`ClusterIP`, in this example case, we're using `10.200.0.0/16` service IP\nrange. It is very likely that your estate is configured to use different\nservice IP range, so be sure you set the right IPs.\n\nZookeeper itself relies on the following DNS names for find its peers:\n- `zookeeper-1`\n- `zookeeper-2`\n- `zookeeper-3`\n\n\n#### Deploy Services\nThere is no strict ordering how you deploy the resources, let's start with\nservices first:\n\n```bash\n$ kubectl create -f kube/zookeeper-service.yaml\n$ kubectl create -f kube/zookeeper-1-service.yaml\n$ kubectl create -f kube/zookeeper-2-service.yaml\n$ kubectl create -f kube/zookeeper-3-service.yaml\n```\n\nLet's list the services. There are four services, `zookeeper` service is\npointing to all zookeeper instances - for clients to use. The rest are pointing\nto each relevant zookeeper pod.\n\n```bash\n$ kubectl get services\nNAME          CLUSTER_IP       EXTERNAL_IP   PORT(S)                      SELECTOR                          AGE\nzookeeper     10.200.143.219   <none>        2181/TCP                     service=zookeeper                 4h\nzookeeper-1   10.200.10.31     <none>        2181/TCP,2888/TCP,3888/TCP   name=zookeeper-1,zookeeper_id=1   23h\nzookeeper-2   10.200.10.32     <none>        2181/TCP,2888/TCP,3888/TCP   name=zookeeper-2,zookeeper_id=2   23h\nzookeeper-3   10.200.10.33     <none>        2181/TCP,2888/TCP,3888/TCP   name=zookeeper-3,zookeeper_id=3   23h\n```\n\n\n#### Deploy Replication Controllers\n\n```\n$ kubectl create -f kube/zookeeper-1-controller.yaml\n$ kubectl create -f kube/zookeeper-2-controller.yaml\n$ kubectl create -f kube/zookeeper-3-controller.yaml\n```\n\nGet the pods:\n```\n$ kubectl get pods\nNAME                READY     STATUS    RESTARTS   AGE\nzookeeper-1-w3u4g   1/1       Running   0          9m\nzookeeper-2-kpwaj   1/1       Running   0          9m\nzookeeper-3-vcl94   1/1       Running   0          9m\n```\n\n#### Test the Cluster\n\nNow, let's see if our zookeeper cluster is healthy. First, we will set `/foo`\nkey to `bar`, then kill the Pod and try to get `/foo` from another zookeeper\ninstance:\n\n```bash\n$ kubectl exec -ti zookeeper-1-w3u4g bash\n\n[root@zookeeper-1-w3u4g zookeeper]# bin/zkCli.sh\n[zk: localhost:2181(CONNECTED) 1] create /foo bar\nCreated /foo\n[zk: localhost:2181(CONNECTED) 2] get /foo\nbar\n```\n\nDelete the pod we just used to set the `/foo` value:\n```\n$ kubectl delete zookeeper-1-w3u4g\n$ kubectl exec -ti zookeeper-3-vcl94 bash\n\n[root@zookeeper-3-vcl94 zookeeper]# bin/zkCli.sh\n[zk: localhost:2181(CONNECTED) 0] get /foo\nbar\n```\n\nThis just shows that if one node dies, the cluster is still functioning and the\ndeleted pod will be re-created by the replication controller.\n\n### Known Caveats\n\nBy default there is no data persistence. So be aware that if you delete more\nthan one replication controller or more than one pod, you will lose the quorum.\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-mongo","private":false,"url":"https://github.com/UKHomeOffice/docker-mongo","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# docker-mongo\nDocker container for Mongo\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/rest-experian-qas-internet","private":false,"url":"https://github.com/UKHomeOffice/rest-experian-qas-internet","license":{"key":"gpl-3.0","name":"GNU General Public License v3.0","spdxId":"GPL-3.0","url":"https://api.github.com/licenses/gpl-3.0","featured":true},"readme":"\n# rest-experian-qas-internet\n\nAddress Lookup for the Passport Office Renewals application.\n\nThis project implements the address lookup service for the Passport Office Renewals application - using Java, the DropWizard framework, and Maven for building.\n\nThe Passport Office Renewals application allows people to renew their passports online.\n\nFor address lookup the service uses the QAS Experian 'On Demand' SOAP web service. The service provides a WSDL, and we use the Apache CXF framework to generate and provide Java wrapper classes for the functions exposed in the WSDL.\n\nThis address lookup service provides a RESTful abstraction over the SOAP web service, for use by the passport exemplar frontend application.\n\nYou will need valid credentials to use the web service. Credentials are configured in the service's 'configuration.yml' configuration file.\n\n## Prerequisites\n\n* Git\n* Oracle Oracle Java 8 JDK/OpenJDK 8\n* Maven (version 3.0 or above)\n* Credentials for using the QAS OnDemand web service\n\n## Build and Deploy\n\nUsing Maven:\n\n```\n$ mvn clean package\n```\n\n## Configuration\n\nBefore you can run the service you need to configure it.\n\nYou probably want to create your own configuration file that is a copy of `configuration.yml` and call it `configuration_development.yml`, and then edit that.\n\n## Running the service\n\nExecute the jar file, providing 'server' and the name of the configuration file as arguments.\n\nFrom the command line (example):\n\n```\n$ java -jar target/rest-experian-qas-internet-0.1.jar server configuration_development.yml\n```\n\n## Example responses\n\n### Swagger\n\nThe most fun way to see responses from the api is to visit `http://your-hostname:9190/swagger` in your browser and run \nsome commands through the swagger client.\n\nNote: To prevent csrf, you can only use swagger from the host that drop wizard thinks it's hosted at. This is probably\nthe hostname of your machine, rather than localhost.\n\n### Wget\n\nIf you prefer you can also use wget\n\n#### Search\n\n```\nwget -O- http://localhost:9190/addresses.json?postcode=N19%205BW\n```\n```\n[{\n    moniker: \"APR|xxxxxxxx-3f1d-4465-a03c-5f8c0ff41a04|xxxxxxxx.vkgAhGAIAAAAAAAAA..9kAAAAAP....8AAAAAAAAAAABOMTkgNUJXAA--\",\n    uprn: null,\n    lines: null,\n    town: null,\n    postcode: \"N19 5BW\",    \n    easting: null,\n    northing: null,\n    country: null,\n    dependentLocality: null,\n    dependentThroughfare: null,\n    administrativeArea: null,\n    localAuthorityUpdateDate: null,\n    royalMailUpdateDate: null,\n    partial: \"Larch Close, Islington, London N19 5BW\"\n}, {\n    moniker: \"APR|xxxxxxxx-3f1d-4465-a03c-5f8c0ff41a04|xxxxxxxx.yUgAhGAIAAAAAAAAA..9kAAAAAP....8AAAAAAAAAAABOMTkgNUJXAA--\",\n    uprn: null,\n    lines: null,\n    town: null,\n    postcode: \"N19 5BW\",\n    easting: null,\n    northing: null,\n    country: null,\n    dependentLocality: null,\n    dependentThroughfare: null,\n    administrativeArea: null,\n    localAuthorityUpdateDate: null,\n    royalMailUpdateDate: null,\n    partial: \"Marlborough Road, Islington, London N19 5BW\"\n}, {\n    moniker: \"APR|xxxxxxxx-3f1d-4465-a03c-5f8c0ff41a04|xxxxxxxx.1EgAhGAIAAAAAAAAA..9kAAAAAP....8AAAAAAAAAAABOMTkgNUJXAA--\",\n    uprn: null,\n    lines: null,\n    town: null,\n    postcode: \"N19 5BW\",\n    easting: null,\n    northing: null,\n    country: null,\n    dependentLocality: null,\n    dependentThroughfare: null,\n    administrativeArea: null,\n    localAuthorityUpdateDate: null,\n    royalMailUpdateDate: null,\n    partial: \"Rowan Walk, Islington, London N19 5BW\"\n}, {\n    moniker: \"APR|xxxxxxxx-3f1d-4465-a03c-5f8c0ff41a04|xxxxxxxx.sUgAhGAIAAAAAAAAA..9kAAAAAP....8AAAAAAAAAAABOMTkgNUJXAA--\",\n    uprn: null,\n    lines: null,\n    town: null,\n    postcode: \"N19 5BW\",\n    easting: null,\n    northing: null,\n    country: null,\n    dependentLocality: null,\n    dependentThroughfare: null,\n    administrativeArea: null,\n    localAuthorityUpdateDate: null,\n    royalMailUpdateDate: null,\n    partial: \"Alder Mews, Islington, London N19 5BW\"\n},\n... \n{\n    moniker: \"APR|xxxxxxxx-3f1d-4465-a03c-5f8c0ff41a04|0.xxxxxxxx..2QAAAAA.....wAAAAAAAAAAAE4xOSA1QlcA\",\n    uprn: null,\n    lines: null,\n    town: null,\n    postcode: \"N19 5BW\",\n    easting: null,\n    northing: null,\n    country: null,\n    dependentLocality: null,\n    dependentThroughfare: null,\n    administrativeArea: null,\n    localAuthorityUpdateDate: null,\n    royalMailUpdateDate: null,\n    partial: \"Flat C, 43 Bredgar Road, Islington, London N19 5BW\"\n}]\n```\n\n#### Get\n\n```\nwget -O- http://localhost:9190/addresses/APR%xxxxxxxx-3f1d-4465-a03c-5f8c0ff41a04%7C0KOAPRCwfeBwAAAAABAwEAAAAD0l.sUgAhGAIAAAAAAAAA..9kAAAAAP....8AAAAAAAAAAABOMTkgNUJXAA--.json\n```\n\n```\n{\n    moniker: \"APR|xxxxxxxx-3f1d-4465-a03c-5f8c0ff41a04|0KOAPRCwfeBwAAAAABAwEAAAAD0l.sUgAhGAIAAAAAAAAA..9kAAAAAP....8AAAAAAAAAAABOMTkgNUJXAA--\",\n    uprn: \"10008979790\",\n    lines: [\n        \"Alder Mews\"\n    ],\n    town: \"LONDON\",\n    postcode: \"N19 5BW\",\n    easting: \"529252.00\",\n    northing: \"186643.00\",\n    country: \"United Kingdom\",\n    dependentLocality: \"\",\n    dependentThroughfare: null,\n    administrativeArea: \"Islington\",\n    localAuthorityUpdateDate: \"2013-04-16\",\n    royalMailUpdateDate: \"\",\n    partial: null\n}\n```\n## Testing\n\n### Run Unit Tests\n\n```\nmvn clean install\n```\n\n### Run Integration Tests (and Unit Tests)\n\n**WARNING:  the integration tests make actual API calls to the service.**\n\nIntegration tests are not run by default. Enable them by setting th skipITests parameter to false\n\n```\nWCRS_ADDRESS_USER=usernameHere WCRS_ADDRESS_PASSWORD=passwordHere mvn clean install -DskipITests=false\n```\n\nThe environment variables (WCRS_ADDRESS_USER, and WCRS_ADDRESS_PASSWORD) need to be set to your password on QAS \nProOnDemand, and the ones in configuration will ibe ignored.\n\n## Vagrant\n\nThis project is setup with a vagrant file. The vagrant file has two boxes, `web` and `proxy`. These might be useful for \ndebugging problems you're having with the proxy.\n\nTo start them type:\n\n```\nvagrant up\n```\n\nTo connect to one of them, for example web:\n\n```\nvagrant ssh web\n```\n\nOnce connected, you'll find the directory that this README.md is located in mounted on `/vagrant`\n\n### Web\n\nWeb is the box that you'll want to do your building and running on.\n\nThe IP Address is: `192.xxx.xx.xx`\n\nYou cannot directly connect to the Experian API from this box, as on the live system, you must connect through the proxy box.\n\n### Proxy\n\nProxy just runs squid and you can talk to the Experian API through it.\n\nThe IP Address is: `192.xxxx.xxxx.xxx`\n\nSquid is running on port `xxxx` and accepts connections from `192.xxx.x.x/xx`\n \n## FAQ\n\n### Changing the port from the command line\n\nSet the config variables `dw.server.applicationConnectors[0].port` (for the frontend) and `dw.server.adminConnectors[0].port` for the admin panel to the ports you want them to run on\n\n```\njava -jar -Ddw.server.applicationConnectors[0].port=xxxx -Ddw.server.adminConnectors[0].port=xxxx target/rest-experian-qas-internet-0.1.jar server configuration_development.yml\n```\n \n### Proxy Support\n\nIf for example your proxy does not have a username and password, and is running at 192.168.91.10, on port 3128 you add \nthe following java parameters `-Dhttp.proxyHost=192.xx.xx.x -Dhttp.proxyPort=3128 -Dhttps.proxyHost=192.xx.xx.x -Dhttps.proxyPort=xx` see below for specific examples.\n\n#### Running maven with a proxy\n\n```\nmvn -Dhttp.proxyHost=192.xx.xx.xx -Dhttp.proxyPort=xx -Dhttps.proxyHost=192.xx.xx.xx -Dhttps.proxyPort=xx clean install\n```\n \n#### Running service with a proxy \n \n```\njava -Dhttp.proxyHost=192.xx.xx.xx -Dhttp.proxyPort=xx -Dhttps.proxyHost=192.xx.xx.xx -Dhttps.proxyPort=xx -jar target/rest-experian-qas-internet-0.1.jar server configuration_development.yml\n```\n\n## Common Errors \n\n### Incorrect Username and/or password\n\nIf you get the username or password wrong, you'll see a error similar to this in your stack trace.\n\n```\nERROR [2014-08-21 09:41:14,836] com.yammer.dropwizard.jersey.LoggingExceptionMapper: Error handling a request: xxx\n! javax.xml.ws.soap.SOAPFaultException: Authentication failure (User name: your_username_here). (xxxx-xxxx-xxxx-xxxx-xxxx)\n```\n \n## Related Resources\n\n* The passport office frontend application, which is implemented in Node.JS Express, is the client of the services exposed by this application. \n* DropWizard framework: http://dropwizard.codahale.com\n* Apache Maven: http://maven.apache.org\n\n\n## License\n\nGNU General Public License version 3 (GPL v3)\n\n## Support\n \nUk.support.qas@experian.com\n \nWebsite: http://support.qas.com\n\nTel: 020 7498 7788\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/rest-payments","private":false,"url":"https://github.com/UKHomeOffice/rest-payments","license":{"key":"gpl-3.0","name":"GNU General Public License v3.0","spdxId":"GPL-3.0","url":"https://api.github.com/licenses/gpl-3.0","featured":true},"readme":"# rest-payments\nJava Dropwizard REST API to interface with ATOS payments with duplicate payment protection\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/hodac-style-guide","private":false,"url":"https://github.com/UKHomeOffice/hodac-style-guide","license":null,"readme":false,"travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-kafka","private":false,"url":"https://github.com/UKHomeOffice/docker-kafka","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Kafka on Kubernetes\n[![Docker Repository on Quay](https://quay.io/repository/ukhomeofficedigital/kafka/status \"Docker Repository on Quay\")](https://quay.io/repository/ukhomeofficedigital/kafka)\n\nBits you need to run Kafka cluster on Kubernetes. It is based on Kafka\nversion 0.9.x.\n\nKafka requires access to a zookeeper cluster. We run zookeeper in Kubernetes\ntoo, take a look here: https://github.com/UKHomeOffice/docker-zookeeper.\n\n\n### Configuration\n* `ZOOKEEPER_CONNECT` - a comma separated list of zookeeper `node:port` pairs.\n  Default: `localhost:2181`.\n* `BROKER_ID` - Kafka broker.id. Default: `unset`. If unset, Kafka will get\n  zookeeper to allocate one.\n* `ADVERTISED_HOSTNAME` - what address to advertise to other brokers and\n  producers/consumers. Default: `unset`. If `unset`, Kafka uses the hostname.\n* `NUM_PARTITIONS` - Number of partitions by default. Default: `1`.\n* `DEFAULT_REPLICATION_FACTOR` - Default replication factor. Default: `unset`.\n\n\n### Deployment\nBy default, if you don't specify any parameters, kafka will start in\na single broker mode.\n\nDeploying onto a Kubernetes cluster is fairly easy. There are example\nkubernetes controller and service files in [kube/](kube/) directory.\n\n\n#### Deploy Services\nThere is no strict ordering how you deploy the resources, let's start with\nservices first:\n\n```bash\n$ kubectl create -f kube/kafka-service.yaml\n$ kubectl create -f kube/kafka-1-service.yaml\n$ kubectl create -f kube/kafka-2-service.yaml\n$ kubectl create -f kube/kafka-3-service.yaml\n```\n\n\n#### Deploy Replication Controllers\n\n```\n$ kubectl create -f kube/kafka-1-controller.yaml\n$ kubectl create -f kube/kafka-2-controller.yaml\n$ kubectl create -f kube/kafka-3-controller.yaml\n```\n\n\n### Known Caveats\n\nBy default there is no data persistence. So be aware that if you delete more\nthan one replication controller or more than one pod, you may end up losing\ndata.\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/rtp-logger","private":false,"url":"https://github.com/UKHomeOffice/rtp-logger","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# rtp-logger  [![Build Status](https://img.shields.io/travis/UKHomeOffice/rtp-logger.svg)](https://travis-ci.org/UKHomeOffice/rtp-logger)\n\nThin wrapper around [winston](https://www.npmjs.com/package/winston) for use in Registered Traveller Programme node.js applications.\n\n## Usage\n\nTo use the logger simply add **rtp-logger** to your dependencies in the `package.json` and then require it in your main javascript file.\n\nThe default are as follows: -\n- Console transport logging to stdout and stderr\n- Log level = debug\n- Include timestamps on log entries\n\n``` \n  logger.info('message');\n```\n\nTo log objects, simply pass an additional parameter to the logging function. This will be Stringified using the `util.inspect` module\n\n\n``` \n  logger.error('message', {'key': 'value});\n```\n\n### Configuration\n\nTo configure the logger further you can use the `setup()` function, passing an object. Below is an example of the options that can be used: -\n\n``` JavaScript\n{\n    loglevel: 'info',\n    appName: 'MY-APP', // will appear as [MY-APP] in log entries\n    transports: {\n        console: {\n            // any valid winston config options when creating a console transport\n            timestamp: false,\n            debugStdout: false\n        }\n    }\n}\n```\n\n## Run tests\n\nThe unit tests are written in mocha and can be run using npm. \n```\nnpm test\n```\n\nYou can also run the tests using grunt. Before running the unit tests it will perform a run jshint and jscs. From the project root, run the following: -\n\n```\ngrunt dev\n```\n\nIf you would like to watch all javascript files and automatically re-run jshint, jscs and mocha you can use the following: -\n\n```\ngrunt watch\n```\n\n## File transport\n\nFile logging is not currently a requirement as all logs file are created from stdout and stderr and will be for the foreseeable future. However, the code to handle configuration of a file transport was written and is available in the `file-transport` branch. Should this be required at a later date, it could be merged into the master branch and used.\n\nTo configure the logger with a file transport you can use the `setup()` function, passing an object. Below is an example of the options that can be used: -\n\n``` JavaScript\n{\n    logLocation: '/log/test.log'\n    transports: {\n        file: {\n            // any valid winston config options when creating a file transport\n            filename: 'some-log-file.log', // this would override logLocation\n            timestamp: false,\n            maxsize: 128,\n            maxFiles: 1\n        }\n    }\n}\n```\n\nThe existence of `logLocation` or `transports.file` in the config will trigger the addition of a file transport to the logger.\n\nIf only `logLocation` is present then the default config for a file transport will be used, this is as defined here.\n\n``` JavaScript\n{\n    filename: // logLocation or 'app.log'\n    timestamp: true,\n    maxsize: 10240,\n    maxFiles: 3\n}\n```\n\nThe Registered Traveller Programme uses BrowserStack for mobile and desktop testing https://www.browserstack.com/\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/eslint-config-homeoffice","private":false,"url":"https://github.com/UKHomeOffice/eslint-config-homeoffice","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# eslint-config-homeoffice [![Build Status](https://travis-ci.org/UKHomeOffice/eslint-config-homeoffice.svg?branch=master)](https://travis-ci.org/UKHomeOffice/eslint-config-homeoffice)\n\nThis is the `eslint` configuration used on a variety of UKHomeOffice projects, including:\n\n* [brp](https://github.com/UKHomeOffice/brp_app)\n* [hof example form](https://github.com/UKHomeOffice/hof-example-form)\n\nThe version of `eslint` currently supported is `0.23.0`.\n\n# Configurations\nTwo configurations are currently supported:\n\n* **default**\n\t- this is used for all frontend and node code\n* **testing**\n\t- this adds in a few globals required for testing with mocha, and disables a few of the rules to make the tests more readable\n\nThey can be used as following:\n\nDefault:\n\n```yml\nextends:\n- \"homeoffice/config/default\"\n```\n\nTesting:\n\n```yml\nextends:\n- '../.eslintrc'\n- 'homeoffice/config/testing'\n```\n> Note: To inherit from your project settings, you will need to inherit them first *then* override them using the testing configuration, due to the order of overrides\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change.\n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a\n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment\n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you\n   do not have permission to do that, you may request the second reviewer to merge it for you.\n","masterBranchProtection":false},{"name":"UKHomeOffice/rtp-hof-spike-form","private":false,"url":"https://github.com/UKHomeOffice/rtp-hof-spike-form","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"[![Build Status](https://travis-ci.org/UKHomeOffice/hof-example-form.svg?branch=master)](https://travis-ci.org/UKHomeOffice/hof-example-form)\n\n# Home Office Forms Example Form\n\nIn order to provide a starting point for people using the [home office forms toolkit](https://github.com/UKHomeOffice/hof) this app aims to give a simple example of how to use the module. We encourage users to clone this repository in order to provide a starting point for their own forms.\n\n## Getting Started\n\nThese instructions will get you a copy of the project up and running on your local machine for development and testing purposes. See deployment for notes on how to deploy the project on a live system.\n\n### Prerequisities\n\nWhat things you need to install the software and how to install them\n- NodeJS\n- npm (version 3 is not yet supported, please use version 2)\n- Redis server running on the default port\n\n### Installing\n\n```bash\n$ cd hof-example-form\n$ npm install\n$ npm run dev\n```\n\nGo to http://localhost:8080/my-awesome-form\n\n## Running the tests\nYou will need the server running to run the cucumber tests against.\n\n```bash\n$ cd acceptance_tests\n$ bundle install\n$ cucumber -r features\n```\n\nYou will need phantomjs installed to run tests. Alternatively you can export IN_BROWSER=true to run the tests in firefox.\n\n\n## Contributing\n\nPlease read [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct, and the process for submitting pull requests to us.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the [tags on this repository](https://github.com/your/project/tags). \n\n## License\n\nThis project is licensed under the GPLv2 License - see the [LICENSE.md](LICENSE.md) file for details\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/rtp-hof-spike-mongo","private":false,"url":"https://github.com/UKHomeOffice/rtp-hof-spike-mongo","license":null,"readme":false,"travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-kibana","private":false,"url":"https://github.com/UKHomeOffice/docker-kibana","license":null,"readme":false,"travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/activiti","private":false,"url":"https://github.com/UKHomeOffice/activiti","license":null,"readme":"# Table of Contents\n- [Introduction](#introduction)\n    - [Version](#version)\n    - [Changelog](Changelog.md)\n- [Installation](#installation)\n- [Quickstart](#quickstart)\n- [Configuration](#configuration)\n  - [Database](#database)\n  - [Available Configuration Parameters](#available-configuration-parameters)\n\n# Introduction\n\nDockerfile to build an [Activiti BPM](#http://www.activiti.org/) container image.\n\n## Version\n\nCurrent Version: 5.19.0\n\n# Installation\n\nPull the latest version of the image from the docker index. This is the recommended method of installation as it is easier to update image in the future. These builds are performed by the **Docker Trusted Build** service.\n\n```bash\ndocker pull eternnoir/activiti:latest\n```\n\nSince version `latest`, the image builds are being tagged. You can now pull a particular version of activiti by specifying the version number. For example,\n\n```bash\ndocker pull eternnoir/activiti:5.16.4\n```\n\nAlternately you can build the image yourself.\n\n```bash\ngit clone https://github.com/eternnoir/activiti.git\ncd activiti\ndocker build --tag=\"$USER/activiti\" .\n```\n\n# Quickstart\n\nRun the activiti image\n\n```bash\ndocker run --name='activiti' -it --rm \\\n-p 8080:8080 \\\n-v /var/run/docker.sock:/run/docker.sock \\\n-v $(which docker):/bin/docker \\\neternnoir/activiti:latest\n```\n\nPoint your browser to `http://localhost:8080` and login using the default username and password:\n\n* username: **kermit**\n* password: **kermit**\n\nYou should now have the Activiti application up and ready for testing. If you want to use this image in production the please read on.\n\n\n# Configuration\n\n## Database\n\nActiviti uses a database backend to store its data. You can configure this image to use MySQL.\n\n### MySQL\n\n#### External MySQL Server\n\nThe image can be configured to use an external MySQL database instead of starting a MySQL server internally. The database configuration should be specified using environment variables while starting the Activiti image.\n\nBefore you start the Activiti image create user and database for activiti.\n\n```sql\nCREATE USER 'activiti'@'%.%.%.%' IDENTIFIED BY 'password';\nCREATE DATABASE IF NOT EXISTS `activiti_production` DEFAULT CHARACTER SET `utf8` COLLATE `utf8_unicode_ci`;\nGRANT ALL PRIVILEGES ON `activiti_production`.* TO 'activiti'@'%.%.%.%';\n```\n\nWe are now ready to start the Activiti application.\n\n*Assuming that the mysql server host is 192.0.2.1*\n\n```bash\ndocker run --name=activiti -d \\\n  -e 'DB_HOST=192.0.2.1’ -e 'DB_NAME=activiti_production' -e 'DB_USER=activiti’ -e 'DB_PASS=password' \\\neternnoir/activiti:latest\n```\n\n#### Linking to MySQL Container\n\nYou can link this image with a mysql container for the database requirements. The alias of the mysql server container should be set to **mysql** while linking with the activiti image.\n\nIf a mysql container is linked, only the `DB_TYPE`, `DB_HOST` and `DB_PORT` settings are automatically retrieved using the linkage. You may still need to set other database connection parameters such as the `DB_NAME`, `DB_USER`, `DB_PASS` and so on.\n\nTo illustrate linking with a mysql container, we will use the [sameersbn/mysql](https://github.com/sameersbn/docker-mysql) image. When using docker-mysql in production you should mount a volume for the mysql data store. Please refer the [README](https://github.com/sameersbn/docker-mysql/blob/master/README.md) of docker-mysql for details.\n\nFirst, lets pull the mysql image from the docker index.\n\n```bash\ndocker pull sameersbn/mysql:latest\n```\n\nFor data persistence lets create a store for the mysql and start the container.\n\nSELinux users are also required to change the security context of the mount point so that it plays nicely with selinux.\n\n```bash\nmkdir -p /opt/mysql/data\nsudo chcon -Rt svirt_sandbox_file_t /opt/mysql/data\n```\n\nThe run command looks like this.\n\n```bash\ndocker run --name=mysql -d \\\n  -e 'DB_NAME=activiti_production' -e 'DB_USER=activiti' -e 'DB_PASS=password' \\\n\t-v /opt/mysql/data:/var/lib/mysql \\\n\tsameersbn/mysql:latest\n```\n\nThe above command will create a database named `activiti_production` and also create a user named `activiti` with the password `activiti` with full/remote access to the `activiti_production` database.\n\nWe are now ready to start the Activiti application.\n\n```bash\ndocker run --name=activiti -d --link mysql:mysql \\\n  eternnoir/activiti:latest\n```\n\nThe image will automatically fetch the `DB_NAME`, `DB_USER` and `DB_PASS` variables from the mysql container using the magic of docker links and works with the following images:\n - [sameersbn/mysql](https://registry.hub.docker.com/u/sameersbn/mysql/)\n\n### Available Configuration Parameters\n\n*Please refer the docker run command options for the `--env-file` flag where you can specify all required environment variables in a single file. This will save you from writing a potentially long docker run command.*\n\nBelow is the complete list of available options that can be used to customize your activiti installation.\n\n- **TOMCAT_ADMIN_USER**: Tomcat admin user name. Defaults to `admin`.\n- **TOMCAT_ADMIN_PASSWORD**: Tomcat admin user password. Defaults to `admin`.\n- **DB_HOST**: The database server hostname. Defaults to ``.\n- **DB_PORT**: The database server port. Defaults to `3306`.\n- **DB_NAME**: The database database name. Defaults to ``.\n- **DB_USER**: The database database user. Defaults to ``.\n- **DB_PASS**: The database database password. Defaults to ``.\n\n# Maintenance\n\n## Shell Access\n\nFor debugging and maintenance purposes you may want access the container shell. Since the container does not allow interactive login over the SSH protocol, you can use the [nsenter](http://man7.org/linux/man-pages/man1/nsenter.1.html) linux tool (part of the util-linux package) to access the container shell.\n\nSome linux distros (e.g. ubuntu) use older versions of the util-linux which do not include the `nsenter` tool. To get around this @jpetazzo has created a nice docker image that allows you to install the `nsenter` utility and a helper script named `docker-enter` on these distros.\n\nTo install the nsenter tool on your host execute the following command.\n\n```bash\ndocker run --rm -v /usr/local/bin:/target jpetazzo/nsenter\n```\n\nNow you can access the container shell using the command\n\n```bash\nsudo docker-enter activiti\n```\n\nFor more information refer https://github.com/jpetazzo/nsenter\n\nAnother tool named `nsinit` can also be used for the same purpose. Please refer https://jpetazzo.github.io/2014/03/23/lxc-attach-nsinit-nsenter-docker-0-9/ for more information.\n\n# Upgrading\n\nTODO\n\n# References\n\n* http://activiti.org/\n* http://github.com/Activiti/Activiti\n* http://tomcat.apache.org/\n* http://dev.mysql.com/downloads/connector/j/5.1.html\n* https://github.com/jpetazzo/nsenter\n* https://jpetazzo.github.io/2014/03/23/lxc-attach-nsinit-nsenter-docker-0-9/\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/dropwizard-smart-logging-bundle","private":false,"url":"https://github.com/UKHomeOffice/dropwizard-smart-logging-bundle","license":{"key":"gpl-3.0","name":"GNU General Public License v3.0","spdxId":"GPL-3.0","url":"https://api.github.com/licenses/gpl-3.0","featured":true},"readme":"# Dropwizard Smart Logging Bundle\n\n## Why\n\nAPIs are great. Microservices are great. But how do we keep track of a user who uses multiple APIs throughout a session? \nOne approach is to add an additional value to each request i.e. user_id or session_id. This forces every API call to have \nan additional id attached to it (if available) and somewhere in the code we need to assign this to a log message.\n\nWouldn't it be easier to let an API client send identifiable information to the host via a header?\n\nIt would also be nice to be able to configure some extra fields to appear in every log message.\n\n## How\n\nAdd the corresponding configuration to your config file (MyServiceConfiguration in this example) and implement interface\n\n```java\n\n    public class MyServiceConfiguration extends Configuration implements PrependLogConfiguration\n    \n    @JsonProperty\n    private SmartLogging smartLogging;\n```\n\nSpecifiy what header and any extra fields you want to log in your requests by adding this to your configuration:\n\n```YAML\nsmartLogging:\n  useHeader: X_UNIQUE_ID\n  extraFields: {\n    \"environment\": \"TEST\",\n    \"host\": \"localhost\",\n    \"applicationName\" : \"my-cool-service\"\n  }\n```\nAdd your new log format to your chosen appender\n\n```YAML\n    logFormat: \"%-6level [%d{HH:mm:ss.SSS}] [%t] %logger{5} - %X{environment} %X{host} %X{applicationName} %X{X_UNIQUE_ID} %msg %n\"\n```\n\nThis bundle can be added to a dropwizard app using:\n\n```java\n    @Override\n    public void initialize(Bootstrap<MyServiceConfiguration> bootstrap) {\n        bootstrap.addBundle(new PrependLogBundle());\n    }\n```\n\n\n## Security\n\nBe careful of what you log, make sure you validate headers to ensure your logs don't become a potential attack\nvector.\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/passports-logger","private":false,"url":"https://github.com/UKHomeOffice/passports-logger","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# hmpo-logger\nConsistent logging for hmpo apps\n\n## Usage\n\nTop level logging configuration:\n```javascript\nvar hmpoLogger = require('hmpo-logger');\nhmpoLogger.config();\n\nvar app = require('express')();\napp.use(hmpoLogger.middleware());\n```\n\nLogging messages:\n```javascript\nvar logger = require('hmpo-logger').get();\n\nlogger.log('error', 'This is an error');\nlogger.warn('This is a warning');\nlogger.warn('This is an %s warning', 'interpolated');\nlogger.info('This is just info with :meta', {meta: 'metavalue'});\nlogger.info(':method :url took :responseTime ms and was res[content-length] bytes', {req: req, res: res});\n\nlogger.log('info', 'response :responseText', { responseText: logger.trimHtml(htmlBody, 100)});\n```\n\n\n### `get(name)`\n\nGet a named winston logger. The name is prepended to the log entry messages.\n\n```javascript\nrequire('hmpo-logger').get(name);\n```\n\nIf name is ommited it is guessed from the nearest package.json file found in the calling package.\n```javascript\nrequire('hmpo-logger').get();\n```\n\nIf name begins with a colon it is appended to the guessed name.\n```javascript\nrequire('hmpo-logger').get(':subname');\n```\nReturns a `winston` logger.\n\n### `logger.trimHtml(text, maxLength)`\n\nTrim tags out of an HTML string to help with more concise HTML error response logging. Defaults to a `maxLength` of 400.\n\nReturns a string, or passes through `text` if not a string.\n\n```javascript\nrequire('hmpo-logger').get(name);\n```\n\n\n### `config(options)`\n\nInitialise the logger at the top level of the app, specifying the log locations and logging levels of three pre-defined transports: console, app, and error.\n\n```javascript\nvar hmpoLogger = require('hmpo-logger');\nhmpoLogger.config({ // defaults:\n    console: true,\n    connsoleJSON: false,\n    consoleLevel: 'debug',\n    consoleColor: true,\n    app: './app.log',\n    appJSON: true,\n    appLevel: 'info',\n    error: './error.log',\n    errorJSON: true,\n    errorLevel: 'exceptions',\n    meta: {\n        host: 'host',\n        pm: 'env.pm_id',\n        sessionID: 'sessionID',\n        method: 'method',\n        request: 'request'\n    },\n    requestMeta: {\n        clientip: 'clientip',\n        uniqueID: 'req.x-uniq-id',\n        remoteAddress: 'connection.remoteAddress',\n        hostname: 'hostname',\n        port: 'port',\n        response: 'statusCode',\n        responseTime: 'responseTime',\n        httpversion: 'version',\n        bytes: 'res.content-length'\n    },\n    logPublicRequests: false,\n    logHealthcheckRequests: false,\n    format: ':clientip :sessionID :method :request HTTP/:httpVersion :statusCode :res[content-length] - :responseTime ms'\n});\n```\n\nReturns `hmpoLogger`.\n\n\n### `middleware()`\n\nLog incomming requests from an `express` app.\n\n```javascript\nvar hmpoLogger = require('hmpo-logger');\n\nvar app = require('express')();\napp.use(hmpoLogger.middleware());\n```\n\nReturns express compatible middleware\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/rtp-email-lib","private":false,"url":"https://github.com/UKHomeOffice/rtp-email-lib","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"RTP Email Library - Scala library to work with Emails\n==============================================================\n\nApplication built with the following (main) technologies:\n\n- Scala\n\n- SBT\n\nBuild and Deploy\n----------------\nThe project is built with SBT. On a Mac (sorry everyone else) do:\n```bash\nbrew install sbt\n```\n\nIt is also a good idea to install Typesafe Activator (which sits on top of SBT) for when you need to create new projects - it also has some SBT extras, so running an application with Activator instead of SBT can be useful. On Mac do:\n```bash\nbrew install typesafe-activator\n```\n\nTo compile:\n```bash\nsbt compile\n```\n\nor\n```bash\nactivator compile\n```\n\nTo run the specs:\n```bash\nsbt test\n```\n\nThe following packages up this library - Note that \"assembly\" will first compile and test:\n```bash\nsbt assembly\n```","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/vault-sidekick-pkcs12","private":false,"url":"https://github.com/UKHomeOffice/vault-sidekick-pkcs12","license":{"key":"apache-2.0","name":"Apache License 2.0","spdxId":"Apache-2.0","url":"https://api.github.com/licenses/apache-2.0","featured":true},"readme":"# Vault sidekick pkcs12\n\nSidekick container to run it in Kubernetes as part of a `Pod`. It receives some parameters that will allow to connect to a Vault instance, pull a certificate,\nformat it as `pkcs12` and add it to a java keystore.\n\n\n## Parameters\n\n* VAULT_TOKEN = token the can be used to access vault\n* VAULT_HOST = the ELB / host of vault\n\n* SERVICE =  the name of the service so the cert will be for SERVICE.DOMAIN\n* DOMAIN = the subdomain this is to be under (if blank try and find it)\n\nto run it:\n\ndocker run -it  \\\n     -e VAULT_TOKEN=$VAULT_TOKEN \\\n     -e VAULT_HOST=$VAULT_HOST \\\n     -e SERVICE=$SERVICE \\\n     -e DOMAIN=$DOMAIN \\\n            quay.io/ukhomeofficedigital/vault-sidekick-pkcs\n\n\nKeystore location is located at `/etc/ssl/certs/java/cacerts`\n\n\n\ndocker run -it  \\\n     -e VAULT_TOKEN=$VAULT_TOKEN \\\n     -e VAULT_HOST=$VAULT_HOST \\\n     -e SERVICE=www \\\n            quay.io/ukhomeofficedigital/vault-sidekick-pkcs\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/vaultjks","private":false,"url":"https://github.com/UKHomeOffice/vaultjks","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Vault JKS\n[![Docker Repository on Quay](https://quay.io/repository/ukhomeofficedigital/vaultjks/status \"Docker Repository on Quay\")](https://quay.io/repository/ukhomeofficedigital/vaultjks)\n\nA simple script to fetch a CA and request certificates from vault and stick\nthem into JAVA keystore files.\n\n### Requirements\nA working vault server and PKI backend mounted with long enough TTLs.\n\n### Configuration\n- `VAULT_ADDR` - Vault address. Required.\n- `VAULT_AUTH_FILE` - If specified, this file will be sourced. This file can\n  contain VAULT_TOKEN or VAULT_USER and VAULT_PASSWORD.\n- `VAULT_TOKEN` - If specified, the token will be used for auth.\n- `VAULT_USER` - If `VAULT_TOKEN` is unset, then this needs to be set.\n- `VAULT_PASSWORD` - Required if `VAULT_TOKEN` is not being used.\n- `VAULT_PKI_PATH` - Vault pki backend mount path. Default: `shared/pki`.\n- `VAULT_ROLE_NAME` - Vault pki backend role for requesting a new cert. Default: `cert-request`.\n- `CERT_COMMON_NAME` - Certificate request CN. Default: `localhost`.\n- `IP_SAN` - IP address to add to ip_sans. Default: `$(hostname -i)`.\n- `ALT_NAMES` - Requested Subject Alternative Names, in a comma-delimited list.\n  These can be host names or email addresses; they will be parsed into their\n  respective fields.\n- `IMPORT_SYSTEM_TRUSTSTORE`: If `true`, import `/etc/pki/java/cacerts` into a `TRUSTSTORE_FILE`. Default: `true`.\n- `TRUSTSTORE_FILE` - Where to write truststore file. Default: `truststore.jks`.\n- `KEYSTORE_FILE` - Where to write keystore file. Default: `keystore.jks`.\n- `SLEEP_FOREVER` - If set to `true`, `run.sh` will sleep forever after it\n  successfully created keystores. This can be useful if vaultjks is run as part\n  of a kubernetes pod.\n\n\n### Running\n```bash\n$ docker run -ti \\\n  -e VAULT_ADDR=https://vault:8200 \\\n  -e VAULT_TOKEN=44eecf54-5b01-4bd5-a8c4-f4032b9e7e10 \\\n  -v /keystore:/data \\\n  quay.io/ukhomeofficedigital/vaultjks:v0.0.4\n```\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/rtp-amazon-sqs-lib","private":false,"url":"https://github.com/UKHomeOffice/rtp-amazon-sqs-lib","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"RTP Amazon SQS and ElasticMQ Library\n====================================\nScala library to interact with Amazon SQS and where ElasticMQ can be used for embedding testing of the SQS messaging system.\n\nApplication built with the following (main) technologies:\n\n- Scala\n\n- SBT\n\n- Akka\n\n- Amazon SQS / ElasticMQ\n\nApplication\n-----------\nThe application is configured as per a typical Scala application, where the default configuration file is \"application.conf\" (or reference.conf).\nThis default file can be overridden with other \"conf\" files and then given to the application upon boot with the following example Java option:\n```bash\n-Dconfig.file=test-classes/application.test.conf\n```\n\nIndividual configuration properties can be overridden again by Java options e.g. to override which Mongodb to connect:\n```bash\n-Dmongo.db=some-other-mongo\n```\n\nwhere this overrides the default in application.conf.\n\nBuild and Deploy\n----------------\nThe project is built with SBT. On a Mac (sorry everyone else) do:\n```bash\nbrew install sbt\n```\n\nIt is also a good idea to install Typesafe Activator (which sits on top of SBT) for when you need to create new projects - it also has some SBT extras, so running an application with Activator instead of SBT can be useful. On Mac do:\n```bash\nbrew install typesafe-activator\n```\n\nTo compile:\n```bash\nsbt compile\n```\n\nor\n```bash\nactivator compile\n```\n\nTo run the specs:\n```bash\nsbt test\n```\n\nTo actually run the application, you can simply:\n```bash\nsbt run\n```\n\nor first \"assemble\" it:\n```bash\nsbt assembly\n```\n\nThis packages up an executable JAR - Note that \"assembly\" will first compile and test.\n\nThen just run as any executable JAR, with any extra Java options for overriding configurations.\n\nFor example, to use a config file (other than the default application.conf) which is located on the file system (in this case in the boot directory)\n```bash\njava -Dconfig.file=test-classes/my-application.conf -jar <jar name>.jar\n```\n\nNote that the log configuration file could also be included e.g.\n```bash\n-Dlogback.configurationFile=path/to/my-logback.xml\n```\n\nSo a more indepth startup with sbt itself could be:\n```bash\nsbt test:run -Dconfig.file=target/scala-2.11/test-classes/application.test.conf -Dlogback.configurationFile=target/scala-2.11/test-classes/logback.test.xml\n```\n\nNote the use of test:run. Usually we would only use \"run\", but as this is a library, there is no default \"main\" class, but we do have an example test \"main\" class.\n\nAnd another example:\n\nrunning from directory of the executable JAR using a config that is within said JAR:\n```bash\njava -Dconfig.resource=application.uat.conf -jar <jar name>.jar\n```\n\nSBT - Revolver\n--------------\nsbt-revolver is a plugin for SBT enabling a super-fast development turnaround for your Scala applications:\n\nSee https://github.com/spray/sbt-revolver\n\nFor development, you can use ~re-start to go into \"triggered restart\" mode.\nYour application starts up and SBT watches for changes in your source (or resource) files.\nIf a change is detected SBT recompiles the required classes and sbt-revolver automatically restarts your application. \nWhen you press &lt;ENTER&gt; SBT leaves \"triggered restart\" and returns to the normal prompt keeping your application running.\n\nGatling - Performance (Integration) Testing\n-------------------------------------------\nPerformance tests are under src/it, and test reports are written to the \"target\" directory.\n\nTo execute Gatling performance integration tests from withing SBT:\n```bash\ngatling-it:test\n```\n\nExample Usage\n-------------\nExample of booting an application to publish/subscribe to an Amazon SQS instance.\n\n1) Start up an instance of ElasticMQ (to run an instance of Amazon SQS locally) - From the root of this project:\n```bash\njava -jar elasticmq-server-0.9.3.jar\n```\nwhich starts up a working server that binds to localhost:9324\n\nor with a custom configuration that could create queues:\n```bash\njava -Dconfig.file=src/test/resources/application.test.conf -jar elasticmq-server-0.9.3.jar\n```\n   \n2) Boot this application:\n```bash\nsbt test:run\n```\n   \nwhere the example application can be found under the \"test\" directory and is also show here:\n```scala\nobject ExampleBoot extends App {\n  val system = ActorSystem(\"amazon-sqs-actor-system\")\n\n  implicit val sqsClient = new SQSClient(new URL(\"http://localhost:9324\"), new BasicAWSCredentials(\"x\", \"x\"))\n\n  val queue = new Queue(\"test-queue\")\n\n  system actorOf Props {\n    new SubscriberActor(new Subscriber(queue)) with ExampleSubscription\n  }\n\n  new Publisher(queue) publish compact(render(\"input\" -> \"blah\"))\n}\n\ntrait ExampleSubscription extends JsonSubscription with Exit {\n  this: SubscriberActor =>\n\n  def receive: Receive = {\n    case m: Message => exitAfter {\n      val result = s\"Well Done! Processed given message $m\"\n      println(result)\n      result\n    }\n  }\n}\n```","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-java8-mvn","private":false,"url":"https://github.com/UKHomeOffice/docker-java8-mvn","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# docker-java7-mvn\nbase docker image with java7 and maven\n\n## Usage\n\nThis docker container is intended for use in Java projects.\n\n\n## Contributing\n\nFeel free to submit pull requests and issues. If it's a particularly large PR, you may wish to\ndiscuss it in an issue first.\n\nPlease note that this project is released with a\n[Contributor Code of Conduct](https://github.com/UKHomeOffice/docker-java7-mvn/blob/master/CODE_OF_CONDUCT.md).\nBy participating in this project you agree to abide by its terms.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for the version tags available See the tags on this repository.\n\n## Build With\n\n* java-1.7.0-openjdk-devel\n\nSee also the list of\n[contributors](https://github.com/UKHomeOffice/java-1.7.0-openjdk-deve/graphs/contributors) who participated\nin this project.\n\n## License\n\nThis project is licensed under the GPL v2 License - see the\n[LICENSE.md](https://github.com/UKHomeOffice/java-1.7.0-openjdk-deve/blob/master/LICENSE.md) file for details\n","travis":false,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change.\n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a\n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment\n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you\n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and\nwelcoming community, we pledge to respect all people who contribute through reporting issues,\nposting feature requests, updating documentation, submitting pull requests or patches, and other\nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone,\nregardless of level of experience, gender, gender identity and expression, sexual orientation,\ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits,\ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By\nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently\napplying these principles to every aspect of managing this project. Project maintainers who do not\nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is\nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an\nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org),\nversion 1.2.0, available at\n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/hof-middleware","private":false,"url":"https://github.com/UKHomeOffice/hof-middleware","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# hof-middleware\nA collection of commonly used HOF middleware, exports `cookies`, `notFound`, and `errors` on `middleware`\n\n## Arranging the middleware in your app\n\nCookies middleware should be placed before any other routes, this guarantees that any data gathered in the form will be saved to the session.\nThe Not Found middleware should be placed after all routes and before the Error handler middleware. This arrangement ensures that if an error is thrown it will be caught.\n\n## Cookies\n\n### Usage\n```js\napp.use(require('hof-middleware').cookies({\n  'cookie-name': 'my-application-cookie',\n  'param-name': 'my-query-param'\n}));\n```\n\nThis middleware must be declared before your other routes.\n\n### Options\nThe `cookie-name` can be the same as your session cookie. (The\nmiddleware will not overwrite it.) Defaults to `hof-cookie-check`.\n\nThe `param-name` should be chosen so that it does not clash with names\nyou are using elsewhere. In almost all cases the default value of\n`hof-cookie-check` will suffice.\n\nThe error raised when cookies are not supported by the client can then\nbe handled in you error handler by identifying it using its `code`\nproperty which will be set to `NO_COOKIES`.\n\n## Not found (404)\n\nExpects there to be a view called 404 in your configured `/views` directory\n\n### Usage\n```js\napp.use(require('hof-middleware').notFound({\n  logger: require('/logger'),\n  translate: require('hof').i18n({path: path_to_translations/__lng__/__ns__.json}).translate\n}));\n```\n\nThis middleware should be declared *after* your other routes but *before* your errorhandler.\n\n### Options\n`logger` can be any object with a warn method.\n\n`translate` can be the HOF i18n translate function\n\n## Errors\n\n### Usage\n```js\napp.use(require('hof-middleware').errors({\n  logger: require('/logger'),\n  translate: require('hof').i18n({path: path_to_translations/__lng__/__ns__.json}).translate,\n  debug: true\n}));\n```\n\nThis middleware must be declared *after* your other routes.\n\n### Options\n`logger` can be any object with an error method.\n\n`translate` can be the HOF i18n translate function\n\n`debug` set to true will present the stack trace in the form and return the err as the content of the template.\n\n__Note__ If `debug === true` translations will not be served, but the error handler default messages\n=======\n## Deep translate\n\ndeepTranslate middleware supports nested conditional translations in order to show different content in different scenarios. The middleware adds a `translate` function to `req` which is used in various points throughout the architecture.  This middleware must be applied before any other middleware which rely on the `req.translate` function. Also when initializing the form wizard, or template mixins, if a `translate` function is provided, this will be used rather than the deepTranslate middleware.\n\n### Usage\n\n```js\nconst i18nFuture = require('hof').i18n;\nconst i18n = i18nFuture({\n  path: path.resolve(__dirname, './path/to/translations')\n})\napp.use(require('hof-middleware').deepTranslate({\n  translate: i18n.translate.bind(i18n)\n}));\n```\n\nlocales\n```json\n\"fields\": {\n    \"field-name\": {\n        \"label\": {\n            \"dependent-field\": {\n                \"value-1\": {\n                    \"dependent-field-2\": {\n                        \"value-1\": \"Label 1\",\n                        \"value-2\": \"Label 2\"\n                    }\n                },\n                \"value-2\": \"Label 3\"\n            },\n            \"default\": \"Fallback label\"\n        }\n    }\n}\n```\n\nUsing the translation key `fields.field-name.label` will return different values in different situations depending on the values of named fields. In the above example the following are true:\n\n* If both `dependent-field` and `dependent-field-2` have the value `\"value-1\"`, the label returned will be `\"Label 1\"`.\n* If the value of `dependent-field` is `\"value-1\"` and the value of `dependent-field-2` is `\"value-2\"`, the label returned will be `\"Label 2\"`.\n* If the value of `dependent-field` is `\"value-2\"` the label returned will be `\"Label 3\"` regardless of the value of `dependent-field-2`\n* The default label `\"Fallback label\"` will be used if value of `dependent-field` is neither of the given options, or it is `undefined`. It will also be used if the value of `dependent-field` is `\"value-1\"` and the value of `dependent-field-2` is neither of the given options or it is undefined.\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-elasticsearch-curator","private":false,"url":"https://github.com/UKHomeOffice/docker-elasticsearch-curator","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# ElasticSearch Curator docker image\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-postgres","private":false,"url":"https://github.com/UKHomeOffice/docker-postgres","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# docker-postgres\nbase docker image with postgres\n\n## Usage\n\nThis docker container is intended to be built upon in projects requiring Postgres.\n\n### Configuration\nIn your Dockerfile you can overwrite the default configuration by copying a file to /conf/postgres.conf\n\nFor example:\nCOPY postgresql.conf /conf/postgresql.con\n\nThe entrypoint will automatically copy this to the postgres configuration directory after the db has been initialized\n\n### Useful File Locations\n\n* `/docker-entrypoint-initdb.d/*.sql[.gz]` - Any SQL file in that\n  location will be loaded into the database on container init.\n* `/healthcheck.sh` - You can execute this file to check the health of\n  the postgres installation. It performs `SELECT 1+1` on the database.\n\n## Contributing\n\nFeel free to submit pull requests and issues. If it's a particularly large PR, you may wish to\ndiscuss it in an issue first.\n\nPlease note that this project is released with a\n[Contributor Code of Conduct](CODE_OF_CONDUCT.md).\nBy participating in this project you agree to abide by its terms.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for the version tags available See the tags on this repository.\n\n## License\n\nThis project is licensed under the GPL v2 License - see the\n[LICENSE.md](LICENSE) file for details\n","travis":false,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change.\n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a\n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment\n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you\n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and\nwelcoming community, we pledge to respect all people who contribute through reporting issues,\nposting feature requests, updating documentation, submitting pull requests or patches, and other\nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone,\nregardless of level of experience, gender, gender identity and expression, sexual orientation,\ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits,\ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By\nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently\napplying these principles to every aspect of managing this project. Project maintainers who do not\nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is\nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an\nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org),\nversion 1.2.0, available at\n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/docker-nodejs-base","private":false,"url":"https://github.com/UKHomeOffice/docker-nodejs-base","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# nodejs-base\nBase image for nodejs.  This only takes care of installing the LTS version of node.  It's recommended you should instead build from the downstream nodejs image here:\n\nhttps://quay.io/repository/ukhomeofficedigital/nodejs\nhttps://github.com/UKHomeOffice/docker-nodejs \n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/git-workflow","private":false,"url":"https://github.com/UKHomeOffice/git-workflow","license":{"key":"gpl-3.0","name":"GNU General Public License v3.0","spdxId":"GPL-3.0","url":"https://api.github.com/licenses/gpl-3.0","featured":true},"readme":"# Git Workflow\n\nA set of guidelines and principles to help define your Git workflow\n\n\n## The quick example\n\n```\n$ git clone git@github.com:UKHomeOffice/<repo_name>.git\n\n$ cd <repo_name>\n\n$ git checkout -b <branch_type>/<branch_name> (E.g. feature/add-feature1 or feature/ABC-1)\n```\n\n#### ...Develop the feature/fix the bug...\n\nAdd your changes to be committed. The `-p` (`--patch`) gives you the opportunity to accept (`y`) or decline (`n`).\n```\n$ git add -p\n```\n\nCommit staged changes. The `-v` (`--verbose`) will open an editor showing an overview of your changes, so you can be super-descriptive when writing your [commit message](https://github.com/alphagov/styleguides/blob/master/git.md).\n```\n$ git commit -v\n```\n\nFetch and rebase against the remote master branch. `-p` (`--prune`) removes remote-tracking references that no longer exist on the remote.\n```\n$ git fetch -p\n\n$ git rebase origin/master\n```\n\nPush your committed changes to a remote branch\n```\n$ git push origin <branch_type>/<branch_name>\n```\n\n- Visit your Github repo and select \"New pull request\", selecting which two branches you intend to merge. This will usually be your feature branch and master. Master will be preselected as the branch to merge into.\n\n- [Follow these guidelines](https://github.com/alphagov/styleguides/blob/master/git.md) to help describe the nature of your pull request, particularly the use case and the objectives it attempts to achieve.\n\n- Assign the pull request to a *qualified* member of your development team for a technical review.\n\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/GRO-Extranet-prototype","private":false,"url":"https://github.com/UKHomeOffice/GRO-Extranet-prototype","license":null,"readme":"# GRO-Extranet-prototype\nA simple prototype for GRO-extranet's CMS.\n\n## Run prototype\n* You need node (atleast 0.12.2) installed on your machine\n* Mongodb installed\n* Run the command `npm install`\n* Then run the command `node keystone.js`\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/request-oauth2","private":false,"url":"https://github.com/UKHomeOffice/request-oauth2","license":null,"readme":false,"travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/removals_e2etests","private":false,"url":"https://github.com/UKHomeOffice/removals_e2etests","license":null,"readme":"# End to End Feature & Performance Tests\n\n[![Build](https://travis-ci.org/UKHomeOffice/removals_e2etests.png)](https://travis-ci.org/UKHomeOffice/removals_e2etests)\n\nThere are two ways to run the tests, if you want to just get started quickly then use docker, if you want to integrate this into your IDE for example you might prefer to run the code on your machine.\n\n## Running the code on your machine:\n```shell\n# Install nvm\ncurl -o- https://raw.githubusercontent.com/creationix/nvm/v0.31.0/install.sh | bash\nsource ~/.nvm/nvm.sh\n\n# Install & Use Node 4\nnvm install 4\nnvm use 4\ncd removals_e2etests/nightwatch\nnpm install\n```\n\n## Run tests against an environment\n```shell\n# Start the [FE Application] (https://github.com/UKHomeOffice/removals_wallboard)\ncd removals_wallboard\ngulp dev\n\n# Start the [API Application] (https://github.com/UKHomeOffice/removals_integration)\ncd removals_integration\nPORT=8080 npm start\n\n# Run the e2e tests locally\ncd removals_e2etests/nightwatch\n./test.sh\n\n# Setup the keycloak credentials file & Run the e2e tests against a remote environment\ncd removals_e2etests\necho \"KEYCLOAK_USER=myusername\nKEYCLOAK_PASS=mypassword\" > mycredentials\n\ncd removals_e2etests/nightwatch\n./test.sh [docker|dev|int|uat]\n```\n\n##Run e2e tests against a local environment with docker-compose\n```shell\n# Build the [API Application] (https://github.com/UKHomeOffice/removals_integration)\ncd removals_integration\ndocker build -t removals_integration .\n\n# Build the [FE Application] (https://github.com/UKHomeOffice/removals_wallboard)\ncd removals_wallboard\ndocker build -t removals_wallboard .\n\n# Run tests\n./runtests.sh --env docker\n```\n\n## Run e2e tests against a remote environment with docker-compose\n```shell\n# Setup the keycloak credentials file\ncd removals_e2etests\necho \"KEYCLOAK_USER=myusername\nKEYCLOAK_PASS=mypassword\" > mycredentials\n\n# Run the e2e tests\n./runtests.sh --env [dev|int|uat]\n```\n\n## Run e2e performance tests against a remote environment with docker-compose\n```shell\n# Setup the keycloak credentials file\ncd removals_e2etests\necho \"KEYCLOAK_USER=myusername\nKEYCLOAK_PASS=mypassword\" > mycredentials\n\n# Run performance tests\n./runtests.sh --env [docker|dev|int|uat] --tag performance\n```\n\n## Run e2e tests against an environment with IntelliJ\n### Add a new Node.js Configuration setting for e2e testing\n![Run e2e tests against an environment with IntelliJ](images/intellij_settings_to_run_e2etests.png)\n### Add a new Node.js Configuration setting for performance testing\n![Run e2e performance tests against an environment with IntelliJ](./images/intellij_settings_to_run_e2e_performance_tests.png)\n\n## IBM Environments\n| env | backend | frontend |\n| --- | ------- | -------- |\n| default | http://localhost:8080 | http://localhost:8000 |\n| docker | http://backend | http://frontend |\n| dev | https://api-ircbd-dev.notprod.homeoffice.gov.uk | https://wallboard-ircbd-dev.notprod.homeoffice.gov.uk |\n| int | https://api-ircbd-int.notprod.homeoffice.gov.uk | https://wallboard-ircbd-int.notprod.homeoffice.gov.uk |\n| uat | https://api-ircbd-uat.notprod.homeoffice.gov.uk | https://wallboard-ircbd-uat.notprod.homeoffice.gov.uk |\n\n# CI branch testing\nTravis will try and fetch an image matching the same branch name of the `removals_integration` and `removals_wallboard` and test against that\n\n# [Architecture](http://static.codingthearchitecture.com/c4.pdf)\n### System context diagram\n![](https://www.lucidchart.com/publicSegments/view/45d8442c-ddf5-4a3c-861c-75d533ce4062/image.png)\n### Container/Component diagram\n![](https://www.lucidchart.com/publicSegments/view/f2fc4afe-a8cd-4f7e-8408-e583f5d5a235/image.png)\n","travis":true,"contributing":false,"masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/removals_e2etests/branches/master/protection","requiredStatusChecks":{"url":"https://api.github.com/repos/UKHomeOffice/removals_e2etests/branches/master/protection/required_status_checks","strict":true,"includeAdmins":true,"contextsUrl":"https://api.github.com/repos/UKHomeOffice/removals_e2etests/branches/master/protection/required_status_checks/contexts"}}},{"name":"UKHomeOffice/lev-api-docs","private":false,"url":"https://github.com/UKHomeOffice/lev-api-docs","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"Life Event Verification (LEV) API Guide\n=======================================\n:toc:\n:numbered:\n\n== This is a work in progress!\nIn the meantime please refer to the original docs at https://github.com/UKHomeOffice/lev-api-docs/blob/master/README.md\n\n== An important note\nThe contents of the lev-api-docs repo is automatically generated so please don't make changes directly to this repo!\n\n== Mock API\nIt is possible to run a mock version of the API as follows:\n\n=== Running a mock API with docker\nThe easiest way to run the mock API is with Docker\n```\n./mock/run_mock_api_docker.sh\n```\n\n=== Running a mock API without docker\nIt is also possible to run it without docker if you have the wiremock jar file:\n```\ncd mock\njava -jar wiremock.jar --port=8080\n```\n\n== Authenticating yourself with the API\n\nTo use the API you will need to provide 2 forms of authentication:\n. A client certificate\n. An auth token, which must be obtained by hitting the /oauth/login endpoint\n\n*NB: The client certificate must be included in every request, but is NOT shown in this documentation.*\n\nThe following examples are provided to help troubleshoot any issues:\n\n=== Valid request with correct credentials\n*Example request with curl*\ninclude::snippets/auth/valid-auth/curl-request.adoc[]\n\n*Example response*\ninclude::snippets/auth/valid-auth/http-response.adoc[]\n\n\n","travis":false,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n\n","masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/lev-api-docs/branches/master/protection"}},{"name":"UKHomeOffice/smilodon","private":false,"url":"https://github.com/UKHomeOffice/smilodon","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"## smilodon\nSmilodon manages attachment of EBS and ENI pairs in AWS EC2 auto scaling groups.\n\nThink about zookeeper, etcd or similar datastores, where a data volume and IP\naddress have to always go together. Achieving that can be tricky, especially\nif you want to take advantage of EC2 auto scaling groups.\n\n\n### Getting Started\n* First you need to create a number of EBS and ENI resources and tag them with\n  `NodeID`. `NodeID` tag value can be anything as long as you have a matching\n  EBS and ENI pair with the same `NodeID` tag value.\n\n* Secondly, create an autoscaling group with a number of instances with\n  smilodon provisioned. You can have more instances in auto scaling group than\n  you have EBS+ENI pairs.\n\nWhen smilodon starts it will try to find a matching EBS+ENI pair and attach\nthem. EBS gets attached first and ENI second. You can tell smilodon to create a\nfile system and mount it for convenience.\n\nSmilodon does not know how to start a service, but that work is in progress\nright now.\n\nIf your distro uses systemd, then you can easily tell your service unit to\nwatch for when a specific mount point is ready and start the service unit.\n\n\n### Required AWS Permissions\nYou have two options here.\n- Create an IAM user and provide smilodon with AWS API credentials via\n  environment variables.\n\n- Define an IAM instance role and reference that in the LaunchConfiguration.\n\nI recommend the latter, but regardless which option you pick, you need to allow\nthe following IAM permissions (below could be a lot more granular and specific):\n\n```yaml\nResource: \"*\"\nAction:\n  - ec2:DescribeInstances\n  - ec2:DescribeTags\n  - ec2:DescribeNetworkInterfaces\n  - ec2:DescribeVolumes\n  - ec2:AttachVolume\n  - ec2:AttachNetworkInterface\n  - ec2:DetachNetworkInterface\n  - ec2:ModifyNetworkInterfaceAttribute\n```\n\n\n### Configuration\nConfiguration is done using command line flags - `smilodon --help`.\n\n\n### Filtering AWS Resources\nIt is very likely that you have many EBS volumes and ENI devices in your AWS\naccount.\n\nWhen you create your EBS+ENI resources, it makes sense to tag them with a\nservice name or something sensible, so that smilodon attaches correct resources.\n\nOnly `NodeID` tag is required and the rest can be arbitrary. For example, you\ncould tag your resources with the following tags:\n\n```\nNodeID=[0-5]\nEnv=development\nService=etcd\nProject=<any value>\n```\n\nTo tell smilodon to only look for resources with the above tags, do this:\n```\nsmilodon --filters='tag:Env=development,tag:Service=etcd,tag-key=Project'\n```\n\nAs you can see above, last filter matches on any value of tag `Project`. You\ncan also filter on a bunch of other AWS specific filters.\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/rtp-formatted-id","private":false,"url":"https://github.com/UKHomeOffice/rtp-formatted-id","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# RTP formatted ID\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/rtp-formatted-id.svg?branch=master)](https://travis-ci.org/UKHomeOffice/rtp-formatted-id)\n[![npm version](https://badge.fury.io/js/rtp-formatted-id.svg)](https://www.npmjs.com/package/rtp-formatted-id)\n\nThis module creates non-sequential ids to use in your applications. The aim is to avoid duplicates: the longest the id\nyou creates, the most unlikely the creation of duplicates is.\n\n## Usage\n\nTo use straight off with the default format, you can simply do.\n\n``` JavaScript\nvar FormattedId = require('rtp-formatted-id');\nvar formattedId = new FormattedId();\nformattedId.generate();  // outputs something like EF-435670-LU\n```\n\n##### Advanced\n\nIf you set the format to something that uses the `mapYear` and / or `mapProduct` initialisers (Y or P respectively) then\nyou must supply the options to the `generate` function. An example is below: -\n \n``` javascript\nvar FormattedId = require('rtp-formatted-id');\nvar formattedId = new FormattedId({\n  format: 'Y-P-NN-LL',\n  products: {\n      productName: {\n          applicationTypeName: 'A',\n          otherApplicationTypeName: 'B'\n      },\n      otherProductName: {\n          applicationTypeName: 'C'\n      }\n  }\n});\nformattedId.generate({\n    // pass 2016 as argument to the method identified by the letter Y, in this case mapYear\n    Y : 2016,\n    // pass object as argument to the method identified by the letter P, in this case mapProduct \n    P : {\n        product: 'productName', // matches a product set in the FormattedId config \n        applicationType: 'applicationTypeName' // matches an applicationType set in the FormattedId config\n    }\n});  // outputs something like A-A-72-DH \n```\n\nNote, config can be passed to the constructor on initialisation or you can call the `setConfig` method.\n\nSome more examples of possible formats are as follows: -\n\n```\nformat: 'LLLNNNLLL  // outputs something like PLW682LMV\n```\n\nThis will create an id composed by 3 letters, 3 numbers, 3 letters.\nYou can use separators in the format, that will be conserved.\n\n```\nformat: 'LLL-NNN-LLL  // outputs something like PLW-682-LMV\n```\n\n## How it works\n\nIn the folder `initialisers` you'll find pre-made modules that can be added to your config. Each module needs to exports\ntwo things: `method` and `identifier`.\n\n``` javascript\nmodule.exports = {\n    method: mapYear,\n    identifier: 'Y'\n};\n```\n\nThe method is what outputs your result; the identifier is the letter that gets used in the config to identify strings made\nout of that component. So, in the example above, `mapYear` maps the years to alphabet letters, and therefore adding Y's to\nthe config will create sequences of the mapped letter. For example: -\n\n```\nformat: 'LLLNNNLLL-Y  // outputs something like PLW682LMV-A\n```\n\nConversely, you can pass arguments indexed by letters to the `generate` method -- they will be distributed to the correct\ncomponent.\n\n``` javascript\nvar FormattedId = require('rtp-formatted-id');\nvar formattedId = new FormattedId();\n//  pass 2016 as argument to the method identified by the letter Y, in this case mapYear\nformattedId.generate({\n   Y : 2016\n});\n```\n\nAll the components in the `initialisers` folder are loaded automatically. You can add your own as long as they have the\nsame interface and map to a letter unambiguosly.\n\n \n## Using the demo\n\nTo provide you with a quick evaluation tool, you can use the script `demo.js`. Run it as a bash script after doing a \n`chmod +x` to make it executable, or do `npm install -g` and run `demo` in your terminal.\n\nYou must specify how many codes you want to generate and the format to use. For example: -\n\n```\n./demo.js 100 LL-NNN-YY  // 100 codes in format letter-letter-number-number-number-mapYear-mapYear\n```\n    \nYou can also use the options -a (pass a json string as arguments to `generate`, see above) and -o (show the output).\n\n```\n./demo.js 100 LL-NNN-YY -a '{ \"Y\": 2016 }' -o true   // pass 2016 to mapYear, show the codes\n```\n\nPlease note that the generation may take a long time if you specify a very high number of codes, especially with `-o true` enabled.\n\n## Caveats\n \nThis software doesn't guarantee the ids will be unique. A short config like `LL-NN` is likely to generate conflicts after \na few hundred runs. Conversely, a longer config like `LLLLL-NNNNN` is unlikely to have one conflict after one million runs. \nYou can use the various initialisers to protect yourself even further, by adding deterministic parts to the generated id, \nuntil you reach a degree of risk that is either negligible or acceptable.\n\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change.\n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a\n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment\n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you\n   do not have permission to do that, you may request the second reviewer to merge it for you.\n","masterBranchProtection":false},{"name":"UKHomeOffice/hof-logger","private":false,"url":"https://github.com/UKHomeOffice/hof-logger","license":{"key":"gpl-3.0","name":"GNU General Public License v3.0","spdxId":"GPL-3.0","url":"https://api.github.com/licenses/gpl-3.0","featured":true},"readme":"# hof-logger\nCommon logger pattern\n\n## Installation\n\n```bash\n$ npm install hof-logger --save\n```\n\n## Usage\nhof-logger exports a function which you can call to access a winston logger instance.\n\n```js\nvar logger = require('hof-logger')();\n\nlogger.info('A message');\n```\n\n## Options\nOptions can be passed to override defaults:\n\n```js\nvar createLogger = require('hof-logger');\nvar logger = createLogger({\n  levels: {\n    info: 0,\n    email: 1,\n    warn: 2,\n    error: 3\n  },\n  colours: {\n    info: 'green',\n    email: 'magenta',\n    warn: 'yellow',\n    error: 'red'\n  },\n  transportOptions: {\n    json: true,\n    timestamp: true,\n    colorize: true,\n    stringify: JSON.stringify\n  }\n});\n```\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/hof-dotfiles","private":false,"url":"https://github.com/UKHomeOffice/hof-dotfiles","license":{"key":"gpl-3.0","name":"GNU General Public License v3.0","spdxId":"GPL-3.0","url":"https://api.github.com/licenses/gpl-3.0","featured":true},"readme":"# HOF Dotfiles [![npm version](https://badge.fury.io/js/hof-dotfiles.svg)](https://badge.fury.io/js/hof) [![Build Status](https://travis-ci.org/UKHomeOffice/hof-dotfiles.svg?branch=master)](https://travis-ci.org/UKHomeOffice/hof-dotfiles)\n## Common dotfiles used by HOF in a typical build\n\nAdds the following preconfigured dotfiles to the root of your project on `postinstall`.\n\n- `.dockerignore`\n- `.eslintignore`\n- `.editorconfig`\n- `.eslintrc`\n- `.gitignore`\n- `.jscsrc`\n- `.travis.yml`\n\nIt won't overwrite any current dotfiles of the same name so you can safely install without destroying your own config.\n\nIf you want to contribute, please follow [the guidelines](./contributing.md)\n","travis":true,"contributing":"# Contribution guidelines\n\nWe welcome patches!\n\n## Commit hygiene\n\nWe like to follow the recommendations set out in the GDS [git style guide][gitstyle]\nwhich describes how we prefer git history and commit messages to read.\n\n[gitstyle]: https://github.com/alphagov/styleguides/blob/master/git.md\n\n## JavaScript\n\nWe have a JavaScript style checker `npm run style`\n\nAll our styles are defined in our [JavaScript style config][jsstyle]\n\nWe follow the [Google JavaScript style guide](https://google.github.io/styleguide/javascriptguide.xml)\n\nWe also lint our code `npm run lint`.\n\n[jsstyle]: https://github.com/UKHomeOffice/brp_app/blob/master/.jscsrc.json\n\nA pre commit hook is run as part of the project which runs the above checks and our tests (`npm run test`).\n\n## Visual changes\n\nFor visual changes, it can be helpful to provide images in your pull-request\nshowing before and after to highlight the differences.\n","masterBranchProtection":false},{"name":"UKHomeOffice/passports-date-controller","private":false,"url":"https://github.com/UKHomeOffice/passports-date-controller","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"hmpo-date-controller\n====================\n\n[![npm version](https://badge.fury.io/js/hmpo-date-controller.svg)](https://badge.fury.io/js/hmpo-date-controller)\n[![Build Status](https://travis-ci.org/UKHomeOffice/passports-date-controller.svg)](https://travis-ci.org/UKHomeOffice/passports-date-controller)\n\nA controller for the [hmpo-form-wizard] that provides out-of-the-box\nsupport for [hmpo-template-mixins]' 'input-date' mixin. It is a drop-in\nreplacement for the standard controller and, if need be, can be\ninherited from in your custom controllers.\n\nThe functionality in this module could, at some point, be merged into\n[hmpo-form-controller] as that already has knowledge of the date\ncomponent fields provided by input-date.\n\nMain Benefits\n-------------\n\n* No more silly custom controllers just so that date fields can be\n  handled.\n* The date validators from [hmpo-form-controller] can finally be\n  leaveraged, giving us easy validation on date fields. (e.g. Date must\n  not be in the future, person must be over 18 etc.)\n* No more date components in the steps definition. (Surely a source of\n  confusion for new developers?)\n* The date components are also validated individually allowing a missing\n  month, let's say, to be highlighted directly. The validators are\n  automatically applied and come from [hmpo-form-controller]. i.e.\n  'date-year', 'date-month' and 'date-day'. This gives the developer a\n  lot of date validation for free helping to avoid bugs in their forms.\n\nQuality Assurance\n-----------------\n\nThe controller's functionality is fully documented in the unit test.\n\nWhilst this is the first version of this module the code coverage is\n100% as measured by [Istanbul]. This is tested for in CI to ensure new\nchanges do not introduce untested code.\n\nLinting is also checked in CI using the `.eslintrc` from\n[hmpo-form-controller].\n\nMigrating from HOF's date-controller\n------------------------------------\n\nIf you were using HOF's date-controller then you would have had a custom\ncontroller which declared a single field as being the only date field.\nYou will also have added the date components to your steps definition.\nNone of this is required in hmpo-date-controller so your migration is\nmore about deleting this redundant code.\n\ne.g. Consider the following steps definition:\n\n```js\n[...]\n'/step-one': {\n  controller: require('dob-controller'),\n  fields: [\n    'fullname',\n    'date-of-birth',\n    'date-of-birth-day',\n    'date-of-birth-month',\n    'date-of-birth-year',\n    'nationality'\n  ],\n  next:\n  '/step-two'\n},\n[...]\n```\n\nThis can now become simply:\n\n```js\n[...]\n'/step-one': {\n  fields: [\n    'fullname',\n    'date-of-birth',\n    'nationality'\n  ],\n  next:\n  '/step-two'\n},\n[...]\n```\n\nThis of course means that you are now free to have more than one date\nfield per step.\n\nIf you were doing any validation on the date you might need to add it to\nthe definition for the field.\n\nThe only thing left to do is to ensure the default controller is, or\ninherits from, hmpo-date-controller.\n\n[hmpo-form-controller]: https://github.com/UKHomeOffice/passports-form-controller\n[hmpo-form-wizard]: https://github.com/UKHomeOffice/passports-form-wizard\n[hmpo-template-mixins]: https://github.com/UKHomeOffice/passports-template-mixins\n","travis":true,"contributing":false,"masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/passports-date-controller/branches/master/protection","requiredStatusChecks":{"url":"https://api.github.com/repos/UKHomeOffice/passports-date-controller/branches/master/protection/required_status_checks","strict":true,"includeAdmins":true,"contextsUrl":"https://api.github.com/repos/UKHomeOffice/passports-date-controller/branches/master/protection/required_status_checks/contexts"}}},{"name":"UKHomeOffice/hod-portfolio","private":false,"url":"https://github.com/UKHomeOffice/hod-portfolio","license":null,"readme":"# DWP Digital Service Portfolio\n\n[Take a look](http://dwp-digital-services.herokuapp.com/)\n","travis":false,"contributing":"# Contribution guidelines\n\nWe really like contributions and bug reports, in fact the project wouldn't have got to this stage without them. \nWe do have a few guidelines to bear in mind.\n\n## GOV.UK Elements\n\nThe project contains code taken from the [GOV.UK Elements](https://github.com/alphagov/govuk_elements/) project.\nPlease check that any issues related to that code are raised with that project, not this one.\n\n## Raising bugs\n\nWhen raising bugs please explain the issue in good detail and provide a guide to how to replicate it. \nWhen describing the bug it's useful to follow the format:\n\n- what you did\n- what you expected to happen\n- what happened\n\n## Suggesting features\n\nPlease raise feature requests as issues before contributing any code.\nThis is just to ensure they are discussed properly before any time is spent on them.\n\n## Contributing code\n\n### Indentation and whitespace\n\n2-space, soft-tabs only please. No trailing whitespace.\n\n### Versioning\n\nWe use [semantic versioning](http://semver.org/), and bump the version\non master only. Please don't submit your own proposed version numbers.\n\n### Commit hygiene\n\nPlease see our [git style guide](https://github.com/alphagov/styleguides/blob/master/git.md)\nwhich describes how we prefer git history and commit messages to read.\n","masterBranchProtection":false},{"name":"UKHomeOffice/hof-bootstrap","private":false,"url":"https://github.com/UKHomeOffice/hof-bootstrap","license":{"key":"gpl-3.0","name":"GNU General Public License v3.0","spdxId":"GPL-3.0","url":"https://api.github.com/licenses/gpl-3.0","featured":true},"readme":"# Home Office Forms Bootstrap [![Build Status](https://travis-ci.org/UKHomeOffice/hof-bootstrap.svg?branch=master)](https://travis-ci.org/UKHomeOffice/hof-bootstrap) [![npm version](https://badge.fury.io/js/hof-bootstrap.svg)](https://badge.fury.io/js/hof-bootstrap)\n\nHome Office Forms (HOF) Bootstrap is a highly configurable mechanism for creating and optionally, launching your service.\n\n## Bootstrap is a function\n\nYou can call the `bootstrap` function with a list of [routes](#routes) and your [custom settings](#options) to invoke your personally configured service.\n\n```\nconst bootstrap = require('hof-bootstrap');\n\nbootstrap({\n  views: 'optional_path_to_your_views',\n  ...,\n  routes: [{ ... }, { ... }]\n});\n```\n\n\n## Interface\n`bootstrap` returns the bootstrap interface object, which includes `start`, `use`, `stop`, and `server`.\n\n### `start` Function(options)\n\n * Creates and starts the server listening for connections.\n * `@param {Object}` options\n * `@return {Object} bootstrap` interface object.\n\nConvenient if starting was deferred during the initial invocation of `hof-bootstrap` with the option and value `start: false` or the server has been stopped. Returns the `bootstrap` interface object.\n\nUses the following settings;\n\n  - `port`: 8080 or `NODE_ENV.port`\n  - `host`: '0.0.0.0' or `NODE_ENV.host`\n  - `protocol`: 'http' or `NODE_ENV.protocol`\n\n\n### `stop` Function(callback)\n\n * Closes the server, stops listening for connections\n * `@param {Function}` callback. Useful for testing\n * `@return {Object} bootstrap` interface object.\n\n### `use` Function(middleware)\n\n * Alias for Express's `app.use`.`\n * `@param {Function}` middleware.\n * `@return {Object} bootstrap` interface object.\n\nThe use function can only be used if bootstrap is called with `{ start: false }` passed in config, `bootstrap.start()` will need to be called afterwards to start the app. This is due to the significance of the order in which middleware are applied. Alternatively an array of middleware functions can be passed in config.\n\n### `server`\n\n * Instance of an `http`/`https` server bound to the `app`\n * `@type {Object}\n\n## Structure\n`bootstrap` does not dictate how to structure your service, however, it does provide a number of default settings so you don't need to pass in anything other than a `route` and `steps`.\n\nWhen the service consists of a single form journey\n```\n<service_name>\n  |__ views/\n  |__ fields/\n  |__ translations/\n  |__ public/\n```\n\nIf the service consists of multiple form journeys\n```\n<service_name>\n  |__ views/\n  |__ fields/\n  |__ translations/\n  |__ public/\n  |__ apps/\n       |__ <name>\n       |    |__ views/\n       |    |__ fields/\n       |    |__ translations/\n       |__ <name>\n            |__ views/\n            |__ fields/\n            |__ translations/\n```\n\n## Options\n\n- `views`: Location of the base views relative to the root of your project. Defaults to 'views'.\n- `middleware`: An optional array of middleware functions to add to the application middleware pipeline.\n- `fields`: Location of the common fields relative to the root of your project. Defaults to 'fields'.\n- `translations`: Location of the common translations relative to the root of your project. Defaults to 'translations'.\n- `viewEngine`: Name of the express viewEngine. Defaults to 'html'.\n- `start`: Start the server listening when the bootstrap function is called. Defaults to `true`.\n- `getCookies`: Load 'cookies' view at `GET /cookies`.\n- `getTerms`: Load 'terms' view at `GET /terms-and-conditions`.\n- `sessionStore`: Provide a sessionStore to be used in place of redis. Suggest using [express-session.MemoryStore](https://github.com/expressjs/session/blob/master/session/memory.js) for development and acceptance testing.\n\n\n## Routes\n\nThe most important element of your service are the routes. These are what you will use to define the path your user will take when completing your forms.\n\n### Settings\nNot all route settings are mandatory, you can create and launch a service with just a set of steps.\n\n#### Required\n- `steps`: An object that defines the url, fields and optionally more for each form within your service.\n\nFor example, the following step will validate two fields. When submitted, if both fields are successfully validated, the next step to be loaded will be '/two'.\n```\nsteps: {\n  '/one': {\n    fields: [\n      'name_of_field_one',\n      'name_of_field_two'\n    ],\n    next: '/two',\n    forks: [{\n      target: '/three',\n      field: 'option1',\n      value: 'yes'\n    }]\n  }\n}\n```\n[Read more about steps and fields](https://github.com/UKHomeOffice/hof/blob/master/documentation/index.md)\n\n#### Options\n- `name`: If provided, is used to locate views, fields and translations for a form journey.\n- `baseUrl`: Base url from which all steps are relative. Defaults to `/`. If provided will be used to locate views, fields and translations for a form journey.\n- `fields`: Location of the routes' fields, relative to the root of your project. Defaults `fields`.\n- `views`: Location of the routes' views relative to the root of your project. Defaults `views`.\n\n**NOTE**: `fields` defined in a `route` determine the name of the directory or path, relative to the root, where the `fields` module is located. `fields` defined in a step, are a list of the name of each field you want to use in the step.\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/postgresql","private":false,"url":"https://github.com/UKHomeOffice/postgresql","license":null,"readme":"PostgreSQL Docker image\n=======================\n\n## Acknowledgments\n\n* This repo is taken from https://github.com/openshift/postgresql/tree/master/9.4 \n\nIt has been modified to provide a secure base image and allow for files for secrets and configuration.\n\nEnvironment variables and volumes\n----------------------------------\n\nThe image recognizes the following environment variables that you can set during\ninitialization by passing `-e VAR=VALUE` to the Docker run command.\n\n|    Variable name             |    Description                                 |\n| :--------------------------- | ---------------------------------------------- |\n|  `POSTGRESQL_USER`           | User name for PostgreSQL account to be created |\n|  `POSTGRESQL_PASSWORD`       | Password for the user account                  |\n|  `POSTGRESQL_DATABASE`       | Database name                                  |\n|  `POSTGRESQL_ADMIN_PASSWORD` | Password for the `postgres` admin account (optional)     |\n\nThe following environment variables influence the PostgreSQL configuration file. They are all optional.\n\n|    Variable name              |    Description                                                          |    Default\n| :---------------------------- | ----------------------------------------------------------------------- | -------------------------------\n|  `POSTGRESQL_MAX_CONNECTIONS` | The maximum number of client connections allowed. This also sets the maximum number of prepared transactions. |  100\n|  `POSTGRESQL_SHARED_BUFFERS`  | Sets how much memory is dedicated to PostgreSQL to use for caching data |  32M\n|  `POSTGRESQL_EFFECTIVE_CACHE_SIZE`  | Set to an estimate of how much memory is available for disk caching by the operating system and within the database itself |  128M\n\nYou can also set the following mount points by passing the `-v /host:/container` flag to Docker.\n\n|  Volume mount point      | Description                           |\n| :----------------------- | ------------------------------------- |\n|  `/var/lib/pgsql/data`   | PostgreSQL database cluster directory |\n\nUsage\n----------------------\n\nFor this, we will assume that you are using the `centos/postgresql-94-centos7` image.\nIf you want to set only the mandatory environment variables and not store the database\nin a host directory, execute the following command:\n\n```\n$ docker run -d --name postgresql_database -e POSTGRESQL_USER=user -e POSTGRESQL_PASSWORD=pass -e POSTGRESQL_DATABASE=db -p 5432:5432 centos/postgresql-94-centos7\n```\n\nThis will create a container named `postgresql_database` running PostgreSQL with\ndatabase `db` and user with credentials `user:pass`. Port 5432 will be exposed\nand mapped to the host. If you want your database to be persistent across container\nexecutions, also add a `-v /host/db/path:/var/lib/pgsql/data` argument. This will be\nthe PostgreSQL database cluster directory.\n\nIf the database cluster directory is not initialized, the entrypoint script will\nfirst run [`initdb`](http://www.postgresql.org/docs/9.4/static/app-initdb.html)\nand setup necessary database users and passwords. After the database is initialized,\nor if it was already present, [`postgres`](http://www.postgresql.org/docs/9.4/static/app-postgres.html)\nis executed and will run as PID 1. You can stop the detached container by running\n`docker stop postgresql_database`.\n\nPostgreSQL auto-tuning\n--------------------\n\nWhen the PostgreSQL image is run with the `--memory` parameter set and if there\nare no values provided for `POSTGRESQL_SHARED_BUFFERS` and\n`POSTGRESQL_EFFECTIVE_CACHE_SIZE` those values are automatically calculated\nbased on the value provided in the `--memory` parameter.\n\nThe values are calculated based on the\n[upstream](https://wiki.postgresql.org/wiki/Tuning_Your_PostgreSQL_Server)\nformulas. For the `shared_buffers` we use 1/4 of given memory and for the\n`effective_cache_size` we set the value to 1/2 of the given memory.\n\nPostgreSQL admin account\n------------------------\nThe admin account `postgres` has no password set by default, only allowing local\nconnections.  You can set it by setting the `POSTGRESQL_ADMIN_PASSWORD` environment\nvariable when initializing your container. This will allow you to login to the\n`postgres` account remotely. Local connections will still not require a password.\n\n\nChanging passwords\n------------------\n\nSince passwords are part of the image configuration, the only supported method\nto change passwords for the database user (`POSTGRESQL_USER`) and `postgres`\nadmin user is by changing the environment variables `POSTGRESQL_PASSWORD` and\n`POSTGRESQL_ADMIN_PASSWORD`, respectively.\n\nChanging database passwords through SQL statements or any way other than through\nthe environment variables aforementioned will cause a mismatch between the\nvalues stored in the variables and the actual passwords. Whenever a database\ncontainer starts it will reset the passwords to the values stored in the\nenvironment variables.\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/json4s","private":false,"url":"https://github.com/UKHomeOffice/json4s","license":null,"readme":"# JSON4S [![Build Status](https://travis-ci.org/json4s/json4s.svg?branch=3.4)](https://travis-ci.org/json4s/json4s)\n\n[![Join the chat at https://gitter.im/json4s/json4s](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/json4s/json4s?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\nAt this moment there are at least 6 json libraries for scala, not counting the java json libraries.\nAll these libraries have a very similar AST. This project aims to provide a single AST to be used by other scala\njson libraries.\n\nAt this moment the approach taken to working with the AST has been taken from lift-json and the native package\nis in fact lift-json but outside of the lift project.\n\n## Lift JSON\n\nThis project also attempts to set lift-json free from the release schedule imposed by the lift framework.\nThe Lift framework carries many dependencies and as such it's typically a blocker for many other scala projects when\na new version of scala is released.\n\nSo the native package in this library is in fact verbatim lift-json in a different package name, this means that\nyour import statements will change if you use this library.\n\n```scala\nimport org.json4s._\nimport org.json4s.native.JsonMethods._\n```\n\nAfter that everything works exactly the same as it would with lift-json\n\n## Jackson\n\nIn addition to the native parser there is also an implementation that uses jackson for parsing to the AST.\nThe jackson module includes most of the jackson-module-scala functionality and the ability to use it with the\nlift-json AST.\n\nTo use jackson instead of the native parser:\n\n```scala\nimport org.json4s._\nimport org.json4s.jackson.JsonMethods._\n```\n\nBe aware that the default behavior of the jackson integration is to close the stream when it's done.\nIf you want to change that:\n\n```scala\nimport com.fasterxml.jackson.databind.SerializationFeature\norg.json4s.jackson.JsonMethods.mapper.configure(SerializationFeature.CLOSE_CLOSEABLE, false)\n```\n\n## Guide\n\nParsing and formatting utilities for JSON.\n\nA central concept in lift-json library is Json AST which models the structure of\na JSON document as a syntax tree.\n\n```scala\nsealed abstract class JValue\ncase object JNothing extends JValue // 'zero' for JValue\ncase object JNull extends JValue\ncase class JString(s: String) extends JValue\ncase class JDouble(num: Double) extends JValue\ncase class JDecimal(num: BigDecimal) extends JValue\ncase class JInt(num: BigInt) extends JValue\ncase class JLong(num: Long) extends JValue\ncase class JBool(value: Boolean) extends JValue\ncase class JObject(obj: List[JField]) extends JValue\ncase class JArray(arr: List[JValue]) extends JValue\n\ntype JField = (String, JValue)\n```\n\nAll features are implemented in terms of above AST. Functions are used to transform\nthe AST itself, or to transform the AST between different formats. Common transformations\nare summarized in a following picture.\n\n![Json AST](https://raw.github.com/json4s/json4s/3.4/core/json.png)\n\nSummary of the features:\n\n* Fast JSON parser\n* LINQ style queries\n* Case classes can be used to extract values from parsed JSON\n* Diff & merge\n* DSL to produce valid JSON\n* XPath like expressions and HOFs to manipulate JSON\n* Pretty and compact printing\n* XML conversions\n* Serialization\n* Low level pull parser API\n\nInstallation\n============\n\nYou can add the json4s as a dependency in following ways. Note, replace {latestVersion} with correct Json4s version.\n\nYou can find available versions here:\n\nhttp://search.maven.org/#search%7Cga%7C1%7Cg%3A%22org.json4s%22\n\n### SBT users\n\nFor the native support add the following dependency to your project description:\n\n```scala\nval json4sNative = \"org.json4s\" %% \"json4s-native\" % \"{latestVersion}\"\n```\n\nFor the Jackson support add the following dependency to your project description:\n\n```scala\nval json4sJackson = \"org.json4s\" %% \"json4s-jackson\" % \"{latestVersion}\"\n```\n\n### Maven users\n\nFor the native support add the following dependency to your pom:\n\n```xml\n<dependency>\n  <groupId>org.json4s</groupId>\n  <artifactId>json4s-native_${scala.version}</artifactId>\n  <version>{latestVersion}</version>\n</dependency>\n```\n\nFor the jackson support add the following dependency to your pom:\n\n```xml\n<dependency>\n  <groupId>org.json4s</groupId>\n  <artifactId>json4s-jackson_${scala.version}</artifactId>\n  <version>{latestVersion}</version>\n</dependency>\n```\n\nExtras\n------\n\n* [ext](https://github.com/json4s/json4s/tree/3.4/ext)\n\nSupport for Enum, Joda-Time, ...\n\n* [scalaz](https://github.com/json4s/json4s/tree/3.4/scalaz)\n\nApplicative style parsing with Scalaz\n\n* [native-lift](https://github.com/json4s/json4s/tree/3.4/native-lift)\n\nSupport for Box\n\nMigration from older versions\n=============================\n\n3.3.0 ->\n--------\n\njson4s 3.3 basically should be source code compatible with 3.2.x. Since json4s 3.3.0, We've started using [MiMa](https://github.com/typesafehub/migration-manager) for binary compatibility verification not to repeat the bin compatibility issue described [here](https://github.com/json4s/json4s/issues/225).\n\nThe behavior of `.toOption` on JValue has changed. Now both `JNothing` and `JNull` return None.\nFor the old behavior you can use `toSome` which will only turn a `JNothing` into a None.\n\nAll the merged pull requests:\nhttps://github.com/json4s/json4s/pulls?q=is%3Apr+is%3Aclosed+milestone%3A3.3\n\n3.0.0 ->\n--------\n\nJField is no longer a JValue. This means more type safety since it is no longer possible\nto create invalid JSON where JFields are added directly into JArrays for instance. Most\nnoticeable consequence of this change is that map, transform, find and filter come in\ntwo versions:\n\n```scala\ndef map(f: JValue => JValue): JValue\ndef mapField(f: JField => JField): JValue\ndef transform(f: PartialFunction[JValue, JValue]): JValue\ndef transformField(f: PartialFunction[JField, JField]): JValue\ndef find(p: JValue => Boolean): Option[JValue]\ndef findField(p: JField => Boolean): Option[JField]\n//...\n```\n\nUse *Field functions to traverse fields in the JSON, and use the functions without 'Field'\nin the name to traverse values in the JSON.\n\n2.2 ->\n------\n\nPath expressions were changed after 2.2 version. Previous versions returned JField which\nunnecessarily complicated the use of the expressions. If you have used path expressions\nwith pattern matching like:\n\n```scala\nval JField(\"bar\", JInt(x)) = json \\ \"foo\" \\ \"bar\"\n```\n\nIt is now required to change that to:\n\n```scala\nval JInt(x) = json \\ \"foo\" \\ \"bar\"\n```\n\nParsing JSON\n============\n\nAny valid json can be parsed into internal AST format.\nFor native support:\n\n```scala\nscala> import org.json4s._\nscala> import org.json4s.native.JsonMethods._\n\nscala> parse(\"\"\" { \"numbers\" : [1, 2, 3, 4] } \"\"\")\nres0: org.json4s.JsonAST.JValue =\n      JObject(List((numbers,JArray(List(JInt(1), JInt(2), JInt(3), JInt(4))))))\n\nscala> parse(\"\"\"{\"name\":\"Toy\",\"price\":35.35}\"\"\", useBigDecimalForDouble = true)\nres1: org.json4s.package.JValue = \n      JObject(List((name,JString(Toy)), (price,JDecimal(35.35))))\n```\n\nFor jackson support:\n\n```scala\nscala> import org.json4s._\nscala> import org.json4s.jackson.JsonMethods._\n\nscala> parse(\"\"\" { \"numbers\" : [1, 2, 3, 4] } \"\"\")\nres0: org.json4s.JsonAST.JValue =\n      JObject(List((numbers,JArray(List(JInt(1), JInt(2), JInt(3), JInt(4))))))\n\nscala> parse(\"\"\"{\"name\":\"Toy\",\"price\":35.35}\"\"\", useBigDecimalForDouble = true)\nres1: org.json4s.package.JValue = \n      JObject(List((name,JString(Toy)), (price,JDecimal(35.35))))\n```\n\nProducing JSON\n==============\n\nYou can generate json in 2 modes either in `DoubleMode` or in `BigDecimalMode`; the former will map all decimal values\ninto a JDouble the latter into a JDecimal.\n\nFor the double mode dsl use:\n\n```scala\nimport org.json4s.JsonDSL._\n// or\nimport org.json4s.JsonDSL.WithDouble._\n```\n\nFor the big decimal mode dsl use:\n\n```scala\nimport org.json4s.JsonDSL.WithBigDecimal._\n```\n\n\nDSL rules\n---------\n\n* Primitive types map to JSON primitives.\n* Any seq produces JSON array.\n\n```scala\nscala> val json = List(1, 2, 3)\n\nscala> compact(render(json))\nres0: String = [1,2,3]\n```\n\n* Tuple2[String, A] produces field.\n\n```scala\nscala> val json = (\"name\" -> \"joe\")\n\nscala> compact(render(json))\nres1: String = {\"name\":\"joe\"}\n```\n\n* ~ operator produces object by combining fields.\n\n```scala\nscala> val json = (\"name\" -> \"joe\") ~ (\"age\" -> 35)\n\nscala> compact(render(json))\nres2: String = {\"name\":\"joe\",\"age\":35}\n```\n\n* Any value can be optional. Field and value is completely removed when it doesn't have a value.\n\n```scala\nscala> val json = (\"name\" -> \"joe\") ~ (\"age\" -> Some(35))\n\nscala> compact(render(json))\nres3: String = {\"name\":\"joe\",\"age\":35}\n\nscala> val json = (\"name\" -> \"joe\") ~ (\"age\" -> (None: Option[Int]))\n\nscala> compact(render(json))\nres4: String = {\"name\":\"joe\"}\n```\n\n* Extending the dsl\n\nTo extend the dsl with your own classes you must have an implicit conversion in scope of signature:\n\n```scala\ntype DslConversion = T => JValue\n```\n\nExample\n-------\n\n```scala\nobject JsonExample extends App {\n  import org.json4s._\n  import org.json4s.JsonDSL._\n  import org.json4s.jackson.JsonMethods._\n\n  case class Winner(id: Long, numbers: List[Int])\n  case class Lotto(id: Long, winningNumbers: List[Int], winners: List[Winner], drawDate: Option[java.util.Date])\n\n  val winners = List(Winner(23, List(2, 45, 34, 23, 3, 5)), Winner(54, List(52, 3, 12, 11, 18, 22)))\n  val lotto = Lotto(5, List(2, 45, 34, 23, 7, 5, 3), winners, None)\n\n  val json =\n    (\"lotto\" ->\n      (\"lotto-id\" -> lotto.id) ~\n      (\"winning-numbers\" -> lotto.winningNumbers) ~\n      (\"draw-date\" -> lotto.drawDate.map(_.toString)) ~\n      (\"winners\" ->\n        lotto.winners.map { w =>\n          ((\"winner-id\" -> w.id) ~\n           (\"numbers\" -> w.numbers))}))\n\n  println(compact(render(json)))\n}\n```\n\n```scala\nscala> JsonExample\n{\"lotto\":{\"lotto-id\":5,\"winning-numbers\":[2,45,34,23,7,5,3],\"winners\":\n[{\"winner-id\":23,\"numbers\":[2,45,34,23,3,5]},{\"winner-id\":54,\"numbers\":[52,3,12,11,18,22]}]}}\n```\n\nExample produces following pretty printed JSON. Notice that draw-date field is not rendered since its value is None:\n\n```scala\nscala> pretty(render(JsonExample.json))\n\n{\n  \"lotto\":{\n    \"lotto-id\":5,\n    \"winning-numbers\":[2,45,34,23,7,5,3],\n    \"winners\":[{\n      \"winner-id\":23,\n      \"numbers\":[2,45,34,23,3,5]\n    },{\n      \"winner-id\":54,\n      \"numbers\":[52,3,12,11,18,22]\n    }]\n  }\n}\n```\n\nMerging & Diffing\n-----------------\n\nTwo JSONs can be merged and diffed with each other.\nPlease see more examples in [MergeExamples.scala](https://github.com/json4s/json4s/blob/3.4/tests/src/test/scala/org/json4s/MergeExamples.scala) and [DiffExamples.scala](https://github.com/json4s/json4s/blob/3.4/tests/src/test/scala/org/json4s/DiffExamples.scala).\n\n```scala\nscala> import org.json4s._\nscala> import org.json4s.jackson.JsonMethods._\n\nscala> val lotto1 = parse(\"\"\"{\n         \"lotto\":{\n           \"lotto-id\":5,\n           \"winning-numbers\":[2,45,34,23,7,5,3],\n           \"winners\":[{\n             \"winner-id\":23,\n             \"numbers\":[2,45,34,23,3,5]\n           }]\n         }\n       }\"\"\")\n\nscala> val lotto2 = parse(\"\"\"{\n         \"lotto\":{\n           \"winners\":[{\n             \"winner-id\":54,\n             \"numbers\":[52,3,12,11,18,22]\n           }]\n         }\n       }\"\"\")\n\nscala> val mergedLotto = lotto1 merge lotto2\n\nscala> pretty(render(mergedLotto))\nres0: String =\n{\n  \"lotto\":{\n    \"lotto-id\":5,\n    \"winning-numbers\":[2,45,34,23,7,5,3],\n    \"winners\":[{\n      \"winner-id\":23,\n      \"numbers\":[2,45,34,23,3,5]\n    },{\n      \"winner-id\":54,\n      \"numbers\":[52,3,12,11,18,22]\n    }]\n  }\n}\n\nscala> val Diff(changed, added, deleted) = mergedLotto diff lotto1\nchanged: org.json4s.JsonAST.JValue = JNothing\nadded: org.json4s.JsonAST.JValue = JNothing\ndeleted: org.json4s.JsonAST.JValue = JObject(List((lotto,JObject(List(JField(winners,\nJArray(List(JObject(List((winner-id,JInt(54)), (numbers,JArray(\nList(JInt(52), JInt(3), JInt(12), JInt(11), JInt(18), JInt(22))))))))))))))\n```\n\nQuerying JSON\n=============\n\n\"LINQ\" style\n------------\n\nJSON values can be extracted using for-comprehensions.\nPlease see more examples in [JsonQueryExamples.scala](https://github.com/json4s/json4s/blob/3.4/tests/src/test/scala/org/json4s/JsonQueryExamples.scala).\n\n```scala\nscala> import org.json4s._\nscala> import org.json4s.native.JsonMethods._\n\nscala> val json = parse(\"\"\"\n         { \"name\": \"joe\",\n           \"children\": [\n             {\n               \"name\": \"Mary\",\n               \"age\": 5\n             },\n             {\n               \"name\": \"Mazy\",\n               \"age\": 3\n             }\n           ]\n         }\n       \"\"\")\n\nscala> for {\n         JObject(child) <- json\n         JField(\"age\", JInt(age))  <- child\n       } yield age\nres0: List[BigInt] = List(5, 3)\n\nscala> for {\n         JObject(child) <- json\n         JField(\"name\", JString(name)) <- child\n         JField(\"age\", JInt(age)) <- child\n         if age > 4\n       } yield (name, age)\nres1: List[(String, BigInt)] = List((Mary,5))\n```\n\nXPath + HOFs\n------------\n\nJson AST can be queried using XPath like functions. Following REPL session shows the usage of\n'\\\\', '\\\\\\\\', 'find', 'filter', 'transform', 'remove' and 'values' functions.\n\nThe example json is:\n\n```javascript\n{\n  \"person\": {\n    \"name\": \"Joe\",\n    \"age\": 35,\n    \"spouse\": {\n      \"person\": {\n        \"name\": \"Marilyn\",\n        \"age\": 33\n      }\n    }\n  }\n}\n```\n\nTranslated to DSL syntax:\n\n```scala\nscala> import org.json4s._\nscala> import org.json4s.native.JsonMethods._\n```\n\nor \n\n```scala\nscala> import org.json4s.jackson.JsonMethods._\nscala> import org.json4s.JsonDSL._\n\nscala> val json: JObject =\n  (\"person\" ->\n    (\"name\" -> \"Joe\") ~\n    (\"age\" -> 35) ~\n    (\"spouse\" ->\n      (\"person\" ->\n        (\"name\" -> \"Marilyn\") ~\n        (\"age\" -> 33)\n      )\n    )\n  )\n\nscala> json \\\\ \"spouse\"\nres0: org.json4s.JsonAST.JValue = JObject(List(\n      (person,JObject(List((name,JString(Marilyn)), (age,JInt(33)))))))\n\nscala> compact(render(res0))\nres1: String = {\"person\":{\"name\":\"Marilyn\",\"age\":33}}\n\nscala> compact(render(json \\\\ \"name\"))\nres2: String = {\"name\":\"Joe\",\"name\":\"Marilyn\"}\n\nscala> compact(render((json removeField { _ == JField(\"name\", JString(\"Marilyn\")) }) \\\\ \"name\"))\nres3: String = \"Joe\"\n\nscala> compact(render(json \\ \"person\" \\ \"name\"))\nres4: String = \"Joe\"\n\nscala> compact(render(json \\ \"person\" \\ \"spouse\" \\ \"person\" \\ \"name\"))\nres5: String = \"Marilyn\"\n\nscala> json findField {\n         case JField(\"name\", _) => true\n         case _ => false\n       }\nres6: Option[org.json4s.JsonAST.JValue] = Some((name,JString(Joe)))\n\nscala> json filterField {\n         case JField(\"name\", _) => true\n         case _ => false\n       }\nres7: List[org.json4s.JsonAST.JField] = List(JField(name,JString(Joe)), JField(name,JString(Marilyn)))\n\nscala> json transformField {\n         case JField(\"name\", JString(s)) => (\"NAME\", JString(s.toUpperCase))\n       }\nres8: org.json4s.JsonAST.JValue = JObject(List((person,JObject(List(\n(NAME,JString(JOE)), (age,JInt(35)), (spouse,JObject(List(\n(person,JObject(List((NAME,JString(MARILYN)), (age,JInt(33)))))))))))))\n\nscala> json.values\nres8: scala.collection.immutable.Map[String,Any] = Map(person -> Map(name -> Joe, age -> 35, spouse -> Map(person -> Map(name -> Marilyn, age -> 33))))\n```\n\nIndexed path expressions work too and values can be unboxed using type expressions.\n\n```scala\nscala> val json = parse(\"\"\"\n         { \"name\": \"joe\",\n           \"children\": [\n             {\n               \"name\": \"Mary\",\n               \"age\": 5\n             },\n             {\n               \"name\": \"Mazy\",\n               \"age\": 3\n             }\n           ]\n         }\n       \"\"\")\n\nscala> (json \\ \"children\")(0)\nres0: org.json4s.JsonAST.JValue = JObject(List((name,JString(Mary)), (age,JInt(5))))\n\nscala> (json \\ \"children\")(1) \\ \"name\"\nres1: org.json4s.JsonAST.JValue = JString(Mazy)\n\nscala> json \\\\ classOf[JInt]\nres2: List[org.json4s.JsonAST.JInt#Values] = List(5, 3)\n\nscala> json \\ \"children\" \\\\ classOf[JString]\nres3: List[org.json4s.JsonAST.JString#Values] = List(Mary, Mazy)\n```\n\nExtracting values\n=================\n\nCase classes can be used to extract values from parsed JSON. Non-existing values can be extracted into scala.Option and strings can be automatically converted into java.util.Dates.\n\nPlease see more examples in [ExtractionExampleSpec.scala](https://github.com/json4s/json4s/blob/3.4/tests/src/test/scala/org/json4s/ExtractionExamplesSpec.scala).\n\n```scala\nscala> import org.json4s._\nscala> import org.json4s.jackson.JsonMethods._\n\nscala> implicit val formats = DefaultFormats // Brings in default date formats etc.\n\nscala> case class Child(name: String, age: Int, birthdate: Option[java.util.Date])\nscala> case class Address(street: String, city: String)\nscala> case class Person(name: String, address: Address, children: List[Child])\n\nscala> val json = parse(\"\"\"\n         { \"name\": \"joe\",\n           \"address\": {\n             \"street\": \"Bulevard\",\n             \"city\": \"Helsinki\"\n           },\n           \"children\": [\n             {\n               \"name\": \"Mary\",\n               \"age\": 5,\n               \"birthdate\": \"2004-09-04T18:06:22Z\"\n             },\n             {\n               \"name\": \"Mazy\",\n               \"age\": 3\n             }\n           ]\n         }\n       \"\"\")\n\nscala> json.extract[Person]\nres0: Person = Person(joe,Address(Bulevard,Helsinki),List(Child(Mary,5,Some(Sat Sep 04 18:06:22 EEST 2004)), Child(Mazy,3,None)))\n\nscala> val addressJson = json  \\ \"address\"  // Extract address object\nscala> addressJson.extract[Address]\nres1: Address = Address(Bulevard,Helsinki)\n\nscala> (json \\ \"children\").extract[List[Child]]  // Extract list of objects\nres2: List[Child] = List(Child(Mary,5,Some(Sat Sep 04 23:36:22 IST 2004)), Child(Mazy,3,None))\n```\n\nBy default the constructor parameter names must match json field names. However, sometimes json field names contain characters which are not allowed characters in Scala identifiers. There's two solutions for this (see [LottoExample.scala](https://github.com/json4s/json4s/blob/3.4/tests/src/test/scala/org/json4s/LottoExample.scala) for bigger example).\n\nUse back ticks.\n\n```scala\nscala> case class Person(`first-name`: String)\n```\n\nUse transform function to postprocess AST.\n\n```scala\nscala> case class Person(firstname: String)\nscala> json transformField {\n         case (\"first-name\", x) => (\"firstname\", x)\n       }\n```\n\nIf the json field names are snake case (i.e.: separated_by_underscores), but the case class uses camel case (i.e.: firstLetterLowercaseAndNextWordsCapitalized), you can convert the keys during the extraction using `camelizeKeys`:\n\n```scala\nscala> import org.json4s._\nscala> import org.json4s.native.JsonMethods._\nscala> implicit val formats = DefaultFormats\nscala> val json = parse(\"\"\"{\"first_name\":\"Mary\"}\"\"\")\nscala> case class Person(firstName: String)\n\nscala> json.camelizeKeys.extract[Person]\nres0: Person = Person(Mazy)\n```\nSee the \"Serialization\" section below for details on converting a class with camel case fields into json with snake case keys.\n\nExtraction function tries to find the best matching constructor when case class has auxiliary constructors. For instance extracting from JSON {\"price\":350} into the following case class will use the auxiliary constructor instead of the primary constructor.\n\n```scala\nscala> case class Bike(make: String, price: Int) {\n         def this(price: Int) = this(\"Trek\", price)\n       }\nscala> parse(\"\"\" {\"price\":350} \"\"\").extract[Bike]\nres0: Bike = Bike(Trek,350)\n```\n\nPrimitive values can be extracted from JSON primitives or fields.\n\n```scala\nscala> (json \\ \"name\").extract[String]\nres0: String = \"joe\"\n\nscala> ((json \\ \"children\")(0) \\ \"birthdate\").extract[Date]\nres1: java.util.Date = Sat Sep 04 21:06:22 EEST 2004\n```\n\nDateFormat can be changed by overriding 'DefaultFormats' (or by implmenting trait 'Formats').\n\n```scala\nscala> implicit val formats = new DefaultFormats {\n         override def dateFormatter = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\")\n       }\n```\n\nJSON object can be extracted to Map[String, _] too. Each field becomes a key value pair\nin result Map.\n\n```scala\nscala> val json = parse(\"\"\"\n         {\n           \"name\": \"joe\",\n           \"addresses\": {\n             \"address1\": {\n               \"street\": \"Bulevard\",\n               \"city\": \"Helsinki\"\n             },\n             \"address2\": {\n               \"street\": \"Soho\",\n               \"city\": \"London\"\n             }\n           }\n         }\"\"\")\n\nscala> case class PersonWithAddresses(name: String, addresses: Map[String, Address])\nscala> json.extract[PersonWithAddresses]\nres0: PersonWithAddresses(\"joe\", Map(\"address1\" -> Address(\"Bulevard\", \"Helsinki\"),\n                                     \"address2\" -> Address(\"Soho\", \"London\")))\n```\n\nSerialization\n=============\n\nCase classes can be serialized and deserialized. Please see other examples in [SerializationExamples.scala](https://github.com/json4s/json4s/blob/3.4/tests/src/test/scala/org/json4s/native/SerializationExamples.scala).\n\n```scala\nscala> import org.json4s._\nscala> import org.json4s.native.Serialization\nscala> import org.json4s.native.Serialization.{read, write}\n\nscala> implicit val formats = Serialization.formats(NoTypeHints)\n\nscala> val ser = write(Child(\"Mary\", 5, None))\n\nscala> read[Child](ser)\nres1: Child = Child(Mary,5,None)\n```\n\nIf you're using jackson instead of the native one: \n\n```scala\nscala> import org.json4s._\nscala> import org.json4s.jackson.Serialization\nscala> import org.json4s.jackson.Serialization.{read, write}\n\nscala> implicit val formats = Serialization.formats(NoTypeHints)\n\nscala> val ser = write(Child(\"Mary\", 5, None))\n\nscala> read[Child](ser)\nres1: Child = Child(Mary,5,None)\n```\n\nSerialization supports:\n\n* Arbitrarily deep case class graphs\n* All primitive types, including BigInt and Symbol\n* List, Seq, Array, Set and Map (note, keys of the Map must be strings: Map[String, _])\n* scala.Option\n* java.util.Date\n* Polymorphic Lists (see below)\n* Recursive types\n* Serialization of fields of a class (see below)\n* Custom serializer functions for types which are not supported (see below)\n \nIf the class contains camel case fields (i.e: firstLetterLowercaseAndNextWordsCapitalized) but you want to produce a json string with snake casing (i.e.: separated_by_underscores), you can use the `snakizeKeys` method:\n\n```scala\nscala> val ser = write(Person(\"Mary\"))\nser: String = {\"firstName\":\"Mary\"}\n\nscala> compact(render(parse(ser).snakizeKeys))\nres0: String = {\"first_name\":\"Mary\"}\n``` \n\nSerializing polymorphic Lists\n-----------------------------\n\nType hints are required when serializing polymorphic (or heterogeneous) Lists. Serialized JSON objects\nwill get an extra field named 'jsonClass' (the name can be changed by overriding 'typeHintFieldName' from Formats).\n\n```scala\nscala> trait Animal\nscala> case class Dog(name: String) extends Animal\nscala> case class Fish(weight: Double) extends Animal\nscala> case class Animals(animals: List[Animal])\n\nscala> implicit val formats = Serialization.formats(ShortTypeHints(List(classOf[Dog], classOf[Fish])))\n\nscala> val ser = write(Animals(Dog(\"pluto\") :: Fish(1.2) :: Nil))\nser: String = {\"animals\":[{\"jsonClass\":\"Dog\",\"name\":\"pluto\"},{\"jsonClass\":\"Fish\",\"weight\":1.2}]}\n\nscala> read[Animals](ser)\nres0: Animals = Animals(List(Dog(pluto), Fish(1.2)))\n```\n\nShortTypeHints outputs short classname for all instances of configured objects. FullTypeHints outputs full\nclassname. Other strategies can be implemented by extending TypeHints trait.\n\nSerializing fields of a class\n-----------------------------\n\nTo enable serialization of fields, a FieldSerializer can be added for some type:\n\n```scala\nimplicit val formats = DefaultFormats + FieldSerializer[WildDog]()\n```\n\nNow the type WildDog (and all subtypes) gets serialized with all its fields (+ constructor parameters).\nFieldSerializer takes two optional parameters which can be used to intercept the field serialization:\n\n```scala\ncase class FieldSerializer[A: Manifest](\n  serializer:   PartialFunction[(String, Any), Option[(String, Any)]] = Map(),\n  deserializer: PartialFunction[JField, JField] = Map()\n)\n```\n\nThose PartialFunctions are called just before a field is serialized or deserialized. Some useful PFs to rename and ignore fields are provided:\n\n```scala\nval dogSerializer = FieldSerializer[WildDog](\n  renameTo(\"name\", \"animalname\") orElse ignore(\"owner\"),\n  renameFrom(\"animalname\", \"name\"))\n\nimplicit val formats = DefaultFormats + dogSerializer\n```\n\nSerializing classes defined in traits or classes\n------------------------------------------------\n\nWe've added support for case classes defined in a trait. But they do need custom formats. I'll explain why and then how.\n\n##### Why?\n\nFor classes defined in a trait it's a bit difficult to get to their companion object, which is needed to provide default values.  We could punt on those but that brings us to the next problem, the compiler generates an extra field in the constructor of such case classes.  The first field in the constructor of those case classes is called `$outer` and is of type of the *defining trait*.  So somehow we need to get an instance of that object, naively we could scan all classes and collect the ones that are implementing the trait, but when there are more than one: which one to take?\n\n##### How?\n\nI've chosen to extend the formats to include a list of companion mappings for those case classes. So you can have formats that belong to your modules and keep the mappings in there. That will then make default values work and provide the much needed `$outer` field.\n\n```scala\ntrait SharedModule {\n  case class SharedObj(name: String, visible: Boolean = false)\n}\n\nobject PingPongGame extends SharedModule\nimplicit val formats: Formats =\n  DefaultFormats.withCompanions(classOf[PingPongGame.SharedObj] -> PingPongGame)\n\nval inst = PingPongGame.SharedObj(\"jeff\", visible = true)\nval extr = Extraction.decompose(inst)\nextr must_== JObject(\"name\" -> JString(\"jeff\"), \"visible\" -> JBool(true))\nextr.extract[PingPongGame.SharedObj] must_== inst\n```\n\nSerializing non-supported types\n-------------------------------\n\nIt is possible to plug in custom serializer + deserializer functions for any type.\nNow, if we have a non case class Interval (thus, not supported by default), we can still serialize it\nby providing following serializer.\n\n```scala\nscala> class Interval(start: Long, end: Long) {\n         val startTime = start\n         val endTime = end\n       }\n\nscala> class IntervalSerializer extends CustomSerializer[Interval](format => (\n         {\n           case JObject(JField(\"start\", JInt(s)) :: JField(\"end\", JInt(e)) :: Nil) =>\n             new Interval(s.longValue, e.longValue)\n         },\n         {\n           case x: Interval =>\n             JObject(JField(\"start\", JInt(BigInt(x.startTime))) ::\n                     JField(\"end\",   JInt(BigInt(x.endTime))) :: Nil)\n         }\n       ))\n\nscala> implicit val formats = Serialization.formats(NoTypeHints) + new IntervalSerializer\n```\n\nCustom serializer is created by providing two partial functions. The first evaluates to a value\nif it can unpack the data from JSON. The second creates the desired JSON if the type matches.\n\nExtensions\n----------\n\nModule json4s-ext contains extensions to extraction and serialization. Following types are supported.\n\n```scala\n// Lift's box\nimplicit val formats = org.json4s.DefaultFormats + new org.json4s.native.ext.JsonBoxSerializer\n\n// Scala enums\nimplicit val formats = org.json4s.DefaultFormats + new org.json4s.ext.EnumSerializer(MyEnum)\n// or\nimplicit val formats = org.json4s.DefaultFormats + new org.json4s.ext.EnumNameSerializer(MyEnum)\n\n// Joda Time\nimplicit val formats = org.json4s.DefaultFormats ++ org.json4s.ext.JodaTimeSerializers.all\n```\n\nXML support\n===========\n\nJSON structure can be converted to XML node and vice versa.\nPlease see more examples in [XmlExamples.scala](https://github.com/json4s/json4s/blob/3.4/tests/src/test/scala/org/json4s/XmlExamples.scala).\n\n```scala\nscala> import org.json4s.Xml.{toJson, toXml}\nscala> val xml =\n         <users>\n           <user>\n             <id>1</id>\n             <name>Harry</name>\n           </user>\n           <user>\n             <id>2</id>\n             <name>David</name>\n           </user>\n         </users>\n\nscala> val json = toJson(xml)\nscala> pretty(render(json))\nres3: String =\n{\n  \"users\":{\n    \"user\":[{\n      \"id\":\"1\",\n      \"name\":\"Harry\"\n    },{\n      \"id\":\"2\",\n      \"name\":\"David\"\n    }]\n  }\n}\n```\n\nNow, the above example has two problems. First, the id is converted to String while we might want it as an Int. This is easy to fix by mapping JString(s) to JInt(s.toInt). The second problem is more subtle. The conversion function decides to use JSON array because there's more than one user-element in XML. Therefore a structurally equivalent XML document which happens to have just one user-element will generate a JSON document without JSON array. This is rarely a desired outcome. These both problems can be fixed by following transformation function.\n\n```scala\nscala> json transformField {\n         case (\"id\", JString(s)) => (\"id\", JInt(s.toInt))\n         case (\"user\", x: JObject) => (\"user\", JArray(x :: Nil))\n       }\n```\n\nOther direction is supported too. Converting JSON to XML:\n\n```scala\nscala> toXml(json)\nres5: scala.xml.NodeSeq = NodeSeq(<users><user><id>1</id><name>Harry</name></user><user><id>2</id><name>David</name></user></users>)\n```\n\nLow level pull parser API\n=========================\n\nPull parser API is provided for cases requiring extreme performance. It improves parsing performance by two ways. First, no intermediate AST is generated. Second, you can stop parsing at any time, skipping rest of the stream. Note, this parsing style is recommended only as an optimization. Above mentioned functional APIs are easier to use.\n\nConsider following example which shows how to parse one field value from a big JSON.\n\n```scala\nscala> val json = \"\"\"\n  {\n    ...\n    \"firstName\": \"John\",\n    \"lastName\": \"Smith\",\n    \"address\": {\n      \"streetAddress\": \"21 2nd Street\",\n      \"city\": \"New York\",\n      \"state\": \"NY\",\n      \"postalCode\": 10021\n    },\n    \"phoneNumbers\": [\n      { \"type\": \"home\", \"number\": \"212 555-1234\" },\n      { \"type\": \"fax\", \"number\": \"646 555-4567\" }\n    ],\n    ...\n  }\"\"\"\n\nscala> val parser = (p: Parser) => {\n         def parse: BigInt = p.nextToken match {\n           case FieldStart(\"postalCode\") => p.nextToken match {\n             case IntVal(code) => code\n             case _ => p.fail(\"expected int\")\n           }\n           case End => p.fail(\"no field named 'postalCode'\")\n           case _ => parse\n         }\n\n         parse\n       }\n\nscala> val postalCode = parse(json, parser)\npostalCode: BigInt = 10021\n```\n\nPull parser is a function `Parser => A`, in this example it is concretely `Parser => BigInt`. \nConstructed parser recursively reads tokens until it finds `FieldStart(\"postalCode\")` token. \nAfter that the next token must be `IntVal`, otherwise parsing fails. It returns parsed integer and stops parsing immediately.\n\nFAQ\n===\n\nQ1: I have a JSON object and I want to extract it to a case class:\n\n```scala\nscala> case class Person(name: String, age: Int)\nscala> val json = \"\"\"{\"name\":\"joe\",\"age\":15}\"\"\"\n```\n\nBut extraction fails:\n\n```scala\nscala> parse(json).extract[Person]\norg.json4s.MappingException: Parsed JSON values do not match with class constructor\n```\n\nA1:\n\nExtraction does not work for classes defined in REPL. Compile the case class definitions\nwith scalac and import those to REPL.\n\nKudos\n=====\n\n* The original idea for DSL syntax was taken from Lift mailing list ([by Marius](http://markmail.org/message/lniven2hn22vhupu)).\n\n* The idea for AST and rendering was taken from [Real World Haskell book](http://book.realworldhaskell.org/read/writing-a-library-working-with-json-data.html).\n","travis":true,"contributing":"## json4s Contributers' Guide\n\n### Issues\n\n- Questions should be posted to [stackoverflow.com](http://stackoverflow.com/questions/tagged/json4s)\n- Please describe about your issue in detail (verison, situation, examples)\n- We may close your issue when we have no plan to take action right now. We appreciate your understanding.\n\n### Pull Requests\n\n- Pull requests basically should be sent toward \"3.4\" branch\n- Source/binary compatibility always must be kept as far as possible\n- Prefer creating scala source code for each class/object/trait (of course, except for sealed trait)\n- json4s build checks binary compatibility by using [MiMa](https://github.com/typesafehub/migration-manager/wiki/Sbt-plugin) for maintenance releases (e.g. 3.3.x).\n\n#### Branches\n\n##### 3.4 (the default branch)\n\n- The latest stable version\n- This branch must be able to build against Scala 2.10 and 2.11\n\n##### 3.3\n\n- The version 3.3 series maintainance branch\n- All the backports must be source/binary compatibility\n- This branch must be able to build against Scala 2.10 and 2.11\n\n#### Testing your pull request\n\nAll the pull requests must pass the Travis CI jobs before merging them.\n\nhttps://travis-ci.org/json4s/json4s\n\nTesting with default settings is required when push changes:\n\n```sh\nsbt test\n```\n","masterBranchProtection":false},{"name":"UKHomeOffice/docker-ruby","private":false,"url":"https://github.com/UKHomeOffice/docker-ruby","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# Ruby Base Container\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-ruby.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-ruby)\n\nThis is a base container for projects that require ruby.\n\n## Usage  \n\nPut `FROM quay.io/ukhomeofficedigital/ruby` in the top of your Dockerfile\n\n### Useful Directories\n\n* `/app` - Where you app will be copied to on build\n\n## Contributing\n\nFeel free to submit pull requests and issues. If it's a particularly large PR, you may wish to\ndiscuss it in an issue first.\n\nPlease note that this project is released with a\n[Contributor Code of Conduct](https://github.com/UKHomeOffice/docker-ruby/blob/master/CODE_OF_CONDUCT.md).\nBy participating in this project you agree to abide by its terms.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for the version tags available See the tags on this repository.\n\n\n## Authors\n\n* **Jay Keshur** - *Initial work* - [jaykeshur](https://github.com/jaykeshur)\n\nSee also the list of\n[contributors](https://github.com/UKHomeOffice/docker-ruby/graphs/contributors) who participated\nin this project.\n\n## License\n\nThis project is licensed under the GPL v2 License - see the\n[LICENSE.md](https://github.com/UKHomeOffice/docker-ruby/blob/master/LICENSE.md) file for details\n\n## Acknowledgments\n\n* [RVM](https://rvm.io/)\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/scala-sbt","private":false,"url":"https://github.com/UKHomeOffice/scala-sbt","license":null,"readme":"# scala-sbt\n\nSimple Scala project with `sbt` and support for both `ScalaTest` and `specs2`.","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-ruby-firefox-chrome","private":false,"url":"https://github.com/UKHomeOffice/docker-ruby-firefox-chrome","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# Ruby Base Container\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-ruby-firefox-chrome.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-ruby-firefox-chrome)\n\nThis is a container that includes Ruby, Firefox and Chrome, intended to be used for running cucumber tests.\n\n## Usage  \n\nPut `FROM quay.io/ukhomeofficedigital/ruby-firefox-chrome` in the top of your Dockerfile\n\n### Useful Directories\n\n* `/app` - Where you app will be copied to on build\n\n## Contributing\n\nFeel free to submit pull requests and issues. If it's a particularly large PR, you may wish to\ndiscuss it in an issue first.\n\nPlease note that this project is released with a\n[Contributor Code of Conduct](https://github.com/UKHomeOffice/docker-ruby-firefox-chrome/blob/master/CODE_OF_CONDUCT.md).\nBy participating in this project you agree to abide by its terms.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for the version tags available See the tags on this repository.\n\n\n## Authors\n\n* **Jay Keshur** - *Initial work* - [jaykeshur](https://github.com/jaykeshur)\n\nSee also the list of\n[contributors](https://github.com/UKHomeOffice/docker-ruby-firefox-chrome/graphs/contributors) who participated\nin this project.\n\n## License\n\nThis project is licensed under the GPL v2 License - see the\n[LICENSE.md](https://github.com/UKHomeOffice/docker-ruby-firefox-chrome/blob/master/LICENSE.md) file for details\n\n## Acknowledgments\n\n* [Firefox](https://www.mozilla.org/firefox)\n* [Chrome](https://www.google.com/chrome/)\n","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/firearms","private":false,"url":"https://github.com/UKHomeOffice/firearms","license":{"key":"gpl-3.0","name":"GNU General Public License v3.0","spdxId":"GPL-3.0","url":"https://api.github.com/licenses/gpl-3.0","featured":true},"readme":"Firearms Licensing Application\n------------------------------\n\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/saru","private":false,"url":"https://github.com/UKHomeOffice/saru","license":null,"readme":"# saru\nSubject Access Request Unit\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-postgres-patroni-not-tracking","private":false,"url":"https://github.com/UKHomeOffice/docker-postgres-patroni-not-tracking","license":null,"readme":false,"travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/dolores-landingham-bot","private":false,"url":"https://github.com/UKHomeOffice/dolores-landingham-bot","license":null,"readme":"# Dolores Landingham Bot\n\n[![Build Status](https://travis-ci.org/18F/dolores-landingham-bot.svg?branch=master)](https://travis-ci.org/18F/dolores-landingham-bot)\n\n![Dolores](http://seattletimes.nwsource.com/ABPub/2006/05/11/2002987603.jpg)\n\nThis is a Slack bot that helps onboard new hires at 18F through scheduled Slack\nmessages about topics relevant to 18F and GSA employees. Messages will be\nscheduled once per day and will trickle out to employees over the course of 60\ndays.\n\nMrs. Landingham will teach 18F employees about working in the federal\ngovernment, how to set up travel, how to add their biographical information and\npictures to our website, and other facts that will help them get acclimated to\nboth 18F and the federal government.\n\nPlease file an issue if you have any questions about Mrs. Landingham.\n\n## Usage instructions for 18F employees\n\n**To add new users**\n\n1. Go https://dolores-app.18f.gov/\n2. Click https://dolores-app.18f.gov/employees/new\n3. Write their Slack username without the @ symbol\n4. Select the date that they started\n5. Select the time zone that they reside in\n6. Click https://dolores-app.18f.gov/employees to make sure they’re on the list\n\n**To add new messages**\n\n1. Draft the message in this [issue](https://github.com/18F/dolores-landingham-bot/issues/115)\n2. Admins can copy the message and paste it in the message body here: https://dolores-app.18f.gov/scheduled_messages/new\n3. Add a title to your message to be able to identify the message\n4. Add the number of days after an employee starts. (Add 1 to the last message in this Google Doc)\n5. Select a time that the message should be sent (the message will be sent at each employee's local time)\n6. Add tags to be able to surface the message\n\n## Installing and contributing\n\nIf you're interested in setting up a version of this bot or contributing to this one, our [contribution guidelines](CONTRIBUTING.md) explain how to set up and deploy this app, find potential tasks to work on, and submit pull requests.\n\n## Using Dolores\n\n18F employees can view the scheduled messages that Dolores sends employees by visiting\nhttps://dolores-app.18f.gov/.\n\nAny 18F employee with a Slack handle can add themselves as a Dolores Landingham\nmessage recipient [here](https://dolores-app.18f.gov/).\n\nOnly admin users can add and update scheduled messages. If you would like to\nadd or update scheduled messages, please DM Melody Kramer on Slack or open an\nIssue on this repo.\n\nAdmin users can add scheduled messages\n[here](https://dolores-app.18f.gov/scheduled_messages/new).\n\nScheduled messages include a \"day count\" attribute. Messages to be sent on the\nday an employee starts have a day count of 0, messages to be sent the next day\nshould have a day count of 1, and so on.\n\n## Questions?\n\nIf you have any questions about the Dolores Bot project and are internal to 18F,\nyou can chat with us in the [#bots](https://18f.slack.com/messages/bots/) Slack\nchannel.\n\nIf you are not internal to 18F and have a question, we would be delighted to\nhelp. Please [open a GitHub\nissue](https://github.con/18F/dolores-landingham-bot/issues/new) and we will get back to\nyou as soon as we can.\n\n## Public domain\n\nThis project is in the public domain within the United States, and\ncopyright and related rights in the work worldwide are waived through\nthe [CC0 1.0 Universal public domain dedication](https://creativecommons.org/publicdomain/zero/1.0/).\n\nFor more information, see [license](LICENSE.md).\n","travis":true,"contributing":"## Contributing\n\n### Code of conduct\n\nWe aspire to create a welcoming environment for collaboration on this project.\nTo that end, we follow the [18F Code of\nConduct](https://github.com/18F/code-of-conduct/blob/master/code-of-conduct.md)\nand ask that all contributors do the same.\n\n### Not sure what to work on?\n\nIssues that are ready for contributions are tagged with [help\nwanted](https://github.com/18F/dolores-landingham-bot/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22).\n\nComment on the issue you're working on so we all know who is working on what.\n\nIf you're thinking about working on a feature unrelated to an existing issue,\nconsider creating an issue before you start work to get feedback from the team.\nWe are always happy to receive pull requests but don't want anyone to feel like\nthey wasted time if a pull request is submitted but not merged.\n\n### Git Protocol\n\nTo contribute to this project, people internal to 18F can create a branch and\nsubmit a pull request. If you are external to 18F, you can fork the repository\nand submit a pull request that way.\n\nWe are minimizing commits on the `master` branch by rebasing and squashing\ncommits on branches before merging them into `master`. This will require you to\nforce push on your branch (but not to `master`...please don't force push\n`master`).\n\nFor a more detailed walk through on how to do this, you can read thoughtbot's\n[Git\nProtocol](https://github.com/thoughtbot/guides/tree/master/protocol/git#write-a-feature)\ndocument.\n\n18F-ers can merge their changes into master after getting approval from another\ncontributor. PRs can be merged manually by merging the branch into `master`\nlocally and pushing `master` or by using the merge button on GitHub.\n\n### Managing time / Updating holidays\nEach message created will send a specified number of **business days** after an employee joins 18F.\nWhat constitutes a business day is managed by the gem `business_time` and is configured [here](config/initializers/business_time.rb) and [here](config/business_time.yml). To add days that dolores will skip, add that date to the `holidays` field in [this yaml config file](config/business_time.yml).\n\n### App setup\n\nBefore running bin/setup, ensure that 'foreman' is removed from the Gemfile.  \n\nPrior to running 'bin/setup', it may be necessary to launch the postgres server using \n```postgres -D /usr/local/var/postgres``` You can also use the OS X app.\n\nTo get started, run `bin/setup`\n\nAfter setting up, you can run the application using [foreman]:\n\n    foreman start\n\nIf you don't have `foreman`, see [Foreman's install instructions][foreman]. It\nis [purposefully excluded from the project's `Gemfile`][exclude].\n\n[foreman]: https://github.com/ddollar/foreman\n[exclude]: https://github.com/ddollar/foreman/pull/437#issuecomment-41110407\n\nThe application will run locally at http://localhost:5000/.\n\nIf you have previously run a project on a different port, a `.foreman` file\nmay be generated at the root of your directory. If so, make sure that this\nfile is set to port `5000` or you will be unable to authenticate locally with MyUSA.\n\nIf your server isn't defaulting to Port 5000, you may have to add a .foreman file to root directory. In the file, add \"port: 5000\". \n\n### Testing\nTesting is done using `capybara-poltergeist`, which requires a local install of [phantomjs](https://github.com/jonleighton/poltergeist#installing-phantomjs).\nYou can run the entire test suite using:\n\n`rake`\n\n### Required Keys\n\nThe setup script creates a `.env` file with a dummy environment configuration\nvariables.  If you are internal to 18F and would like access to these configs,\nyou can contact Jessie Young. Otherwise, you can create a Slack bot\n[here](https://18f.slack.com/services/new/bot).\n\n### Authentication\n\nYou will need to be on the developer list to authenticate locally via MyUSA.\n\nIf you are internal to 18F, contact Brian Hedberg to be added to the developer\nlist.  If you are on the list, `dolores-local` will be one of your [Authorized\nApplications](https://alpha.my.usa.gov/authorizations) on MyUSA.\n\nIf `dolores-local` is on your MyUSA list for Authorized Applications and you\nare still unable to authenticate, check with Brian to make sure that the `MYUSA_KEY`\nand `MYUSA_SECRET` keys listed in `.env` are up to date.\nFor more on environmental variables and keys, refer to [Required Keys](#required-keys) above.\n\nIf you are not part of 18F and would like to run the application locally, you can\nfollow these steps:\n\n1. Create a [MyUSA Account](https://alpha.my.usa.gov/) and create an application for\ndevelopment with the following:\n\n  For Url:\n\n  `http://localhost:5000/`\n\n  For Redirect uri:\n\n  `http://localhost:5000/auth/myusa/callback`\n\n2. Under `Select the API Scopes that your Application will use`: select `Email\n   Address`.\n\n3. Generate a set of keys by clicking `New Api Key` next to your application in MyUSA.\n   They will be called `Consumer Public Key` and `Consumer Secret Key` on MyUSA but will\n   map to `MYUSA_KEY` and `MYUSA_SECRET`, in your local `.env` file.\n\n4. Edit the `AUTH_DOMAIN` value in your local `.env` file such that the `is_permitted` method in\n   `/app/controllers/auth_controller` will accept the email address you used in your MyUSA\n   application.\n  For example, if you use gmail, change the AUTH_DOMAIN to \"gmail.com\"\n\n```ruby\n  # Invocation\n  if is_permitted?(auth_email)\n\n  # Method\n  def is_permitted?(auth_email)\n    /#{ENV['AUTH_DOMAIN']}/.match(auth_email)\n  end\n```\n\n## Granting Yourself Admin Access\n\nOnce you've created an account with MyUSA, open the Rails console and change your admin status to \"true\". This will allow you to create and schedule messages.\n\nNote: scheduled messages may not send if you're using over the weekend, which is due to the business_time gem referenced above.\n\n## Deployment\n\nDolores is configured to be deployed with Cloud Foundry as an 18f-er.\n\nRefer to [docs.18f.gov](https://docs.18f.gov/getting-started/setup/) for getting\nset up with Cloud Foundry.\n\nThe Dolores Landingham bot is deployed within the `18f` Cloud Foundry org. To\nsee if you have access to the `18f` do the following in the root of your repo:\n\n`cf orgs`\n\nIf `18f` does not show up as an available org, you can request access by\nposting an issue to the [DevOps repo](https://github.com/18F/DevOps/issues/new)\non GitHub.\n\nOnce you have access to the org, you can target the Cloud Foundry organization\nand space for this project:\n\n`cf target -o 18f -s dolores`\n\nOnce your target is set, you can push the application. We have two Cloud Foundry\ninstances: `dolores-app` and `dolores-staging`. Test your changes by pushing to\n`dolores-staging` before pushing to the `dolores-app` instance.\n\n`cf push <app-instance-name>`\n\nNew migrations will be run automatically. See the [manifest](manifest.yml) for\nmore details on the Cloud Foundry setup.\n\nTo see existing environment variables:\n\n`cf env <app-instance-name>`\n\nTo set or change the value of an environment variable:\n\n`cf set-env <app-instance-name> <env-name> <env-value>`\n","masterBranchProtection":false},{"name":"UKHomeOffice/sheff-gradle","private":false,"url":"https://github.com/UKHomeOffice/sheff-gradle","license":null,"readme":"# sheff-gradle","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/UKVI-Complaints","private":false,"url":"https://github.com/UKHomeOffice/UKVI-Complaints","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# UKVI-Complaints [![Docker Repository on Quay](https://quay.io/repository/ukhomeofficedigital/ukvi-complaints/status \"Docker Repository on Quay\")](https://quay.io/repository/ukhomeofficedigital/ukvi-complaints) [![Build Status](https://drone.digital.homeoffice.gov.uk/api/badges/UKHomeOffice/UKVI-Complaints/status.svg)](https://drone.digital.homeoffice.gov.uk/UKHomeOffice/UKVI-Complaints)\nA form for UKVI complaints\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/evw-self-serve","private":false,"url":"https://github.com/UKHomeOffice/evw-self-serve","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"[![Build Status](https://travis-ci.org/UKHomeOffice/evw-self-serve.svg?branch=master)](https://travis-ci.org/UKHomeOffice/evw-self-serve)\n[![Dependency Status](https://david-dm.org/UKHomeOffice/evw-self-serve.svg)](https://david-dm.org/UKHomeOffice/evw-self-serve)\n[![devDependency Status](https://david-dm.org/UKHomeOffice/evw-self-serve/dev-status.svg)](https://david-dm.org/UKHomeOffice/evw-self-serve#info=devDependencies)\n\n# EVW Self serve\n\nA tiny, HOF-based form to allow Electronic Visa Waiver users to update their travel details.\n\n### Prerequisities\n\nWhat things you need to install the software and how to install them\n- [NodeJS](https://nodejs.org/en/)\n- npm (bundled with node)\n- [Redis server](http://redis.io/topics/quickstart) running on the default port\n\n### Installing\n\n```bash\n$ redis-server &\n$ npm install\n$ npm run dev\n```\n\nGo to http://localhost:8080/update-journey-details\n\n## Running the tests\nYou will need the server running to run the cucumber tests against.\n\n```bash\n$ node_modules/.bin/nightwatch\n$ # or run in chrome and firefox in parallel 🤘🏽😝🤘🏽\n$ node_modules/.bin/nightwatch  -e chrome,firefox\n$ # or via npm scripts\n$ npm run test:acceptance\n```","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/evw-self-serve/branches/master/protection","requiredStatusChecks":{"url":"https://api.github.com/repos/UKHomeOffice/evw-self-serve/branches/master/protection/required_status_checks","strict":false,"includeAdmins":true,"contextsUrl":"https://api.github.com/repos/UKHomeOffice/evw-self-serve/branches/master/protection/required_status_checks/contexts"}}},{"name":"UKHomeOffice/passports-templates","private":false,"url":"https://github.com/UKHomeOffice/passports-templates","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# hmpo-templates\n\nCommon page layouts and partials. Inherits from [hmpo-govuk-template](https://github.com/UKHomeOffice/govuk-template-compiler).\n\n## Installation\n\n```\nnpm install [--save] hmpo-templates\n```\n\n## Setup\n\nInstall [hogan-express-strict](https://github.com/lennym/hogan-express) and [express-partial-templates](https://github.com/UKHomeOffice/express-partial-templates) as part of your project.\n```\nvar app = require('express')();\n\napp.set('view engine', 'html');\napp.use(require('hmpo-templates'));\napp.engine('html', require('hogan-express-strict'));\napp.use(require('express-partial-templates')(app));\n```\n\n## Basic usage\n\nmy-page.html\n```\n{{< hmpo-layout}}\n    {{$pageTitle}}...page title...{{/pageTitle}}\n\n    {{$header}}\n        <h1>...heading...</h1>\n    {{/header}}\n\n    {{$content}}\n        <p>...intro content...</p>\n        {{< hmpo-partials-form}}\n            {{$form}}\n                ...form inputs...\n                ...form submit button...\n            {{/form}}\n        {{/ hmpo-partials-form}}\n    {{/content}}\n{{/ hmpo-layout}}\n```\n\n## Templates\n\nThe templates are added to `res.locals` with `hmpo` as a prefix to the template names.\n\nLayout:\n+ maincontent (sets maincontent-left as the default and provides a block to override)\n+ maincontent-left\n+ maincontent-right\n+ maincontent-full\n+ flash-card\n\nPartials:\n+ analytics\n+ back-link\n+ back\n+ betatag\n+ body-end\n+ cookies\n+ form\n+ head\n+ new-window\n+ sidebar\n+ validation-summary\n\n### Changing a page layout\n\nCreate layout.html in your views directory.\n```\n{{< hmpo-layout}}\n    {{$pageTitle}}...page title...{{/pageTitle}}\n\n    {{$main-content}}\n        {{< hmpo-partials-maincontent-right}}\n            {{$header}}...heading...{{/header}}\n            {{$content}}...content...{{/content}}\n        {{/ hmpo-partials-maincontent-right}}\n    {{/main-content}}\n{{/ hmpo-layout}}\n```\nThis changes the main page layout to maincontent-right. In your custom pages you can now inherit from layout.html.\n\n## Compatibility\n\nUse with [hmpo-template-mixins](https://github.com/UKHomeOffice/passports-template-mixins) for form inputs and view formatters. When used with [hmpo-form-wizard](https://github.com/UKHomeOffice/passports-form-wizard) you'll get a validation summary appearing at the top of your page when a form error occurs.\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/pttg-fs-api","private":false,"url":"https://github.com/UKHomeOffice/pttg-fs-api","license":null,"readme":"# pttg-financial-status-service-api\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/ukvicomplaints-prototype","private":false,"url":"https://github.com/UKHomeOffice/ukvicomplaints-prototype","license":null,"readme":"# Unofficial Static Government Digital Prototype kit\nSimple prototyping kit for GOV.UK service designers. This kit does not contain all of the functionality of the express kit, however, you will not need node.js or git experience, and you will not need to run anything in command line.\n\nCreated internally at Home Office Digital - not supported, not created by GDS, supplied as-is\n\nThis is not finished! It's Alpha Alpha!\n\n## Getting Started\n\n#### You will need:\n- A mac (sorry, this isn't tested on PCs yet)\n\n#### Nice to have:\n- _Some_ HTML knowledge\n\nFirst, either:\n\n- Download a zip of this repository from https://github.com/tjharrop/simple_prototype_kit/archive/master.zip and unzip it to your computer\n\n*- OR -*\n\n- If you're comfortable with git, either clone the repo in the git desktop client or via command line (`git clone https://github.com/tjharrop/simple_prototype_kit.git`)\n\nOnce you have the folder on your computer, you will see the index.html and example files. The example files contain demonstrations of various pieces of functionality. index.html has buttons to guide you through each page. Full instructions on each demo to follow.\n\n## Running the thing\n\nThere are 2 options here. You can either open index.html in Safari or Firefox directly or you can run a small script which will allow you to use chrome.\n\n#### Using Safari or Firefox\n1. Cmd + click index.html in Finder\n2. Open With\n3. Select Safari or Firefox\n\n#### Using Chrome (recommended)\n\n_You may see an unauthorised developer warning message. If you do, cmd + click and click \"open\" instead (thanks Joe)_\n\n1. Double click run.command (see above if you get a warning)\n2. In chrome, go to http://localhost:1987/index.html\n\n## Working on it\n\nA good place to start in index.html.\n\n1. Open this in your chosen HTML editor (if you don't have one, see https://atom.io/).\n2. Hack away! Change some content, add some buttons or form fields according to your design\n3. Press refresh in your browser.\n\n#### Changing the service name\n\nThere is a file called service-name.txt which looks like this:\n\n```Digital Service Name```\n\n1. Open it\n2. Change it to your service name\n3. Save it\n\n#TODO\n\n1. Full instructions on the examples pages\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/research-resources","private":false,"url":"https://github.com/UKHomeOffice/research-resources","license":null,"readme":false,"travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/posters","private":false,"url":"https://github.com/UKHomeOffice/posters","license":null,"readme":"# posters\nHome Office Digital repository of posters covering different topics - research, access needs, accessibility, design.\n\n**Contributions**\n\nIf you've got a poster you've created and would like to commit it here, please do!\n\n**Access needs**\n\nThese posters cover the following access needs:\n* Autism (https://github.com/UKHomeOffice/posters/blob/master/accessibility/autistic-spectrum.pdf)\n* Dyslexia (https://github.com/UKHomeOffice/posters/blob/master/accessibility/dyslexia.pdf)\n* Visually impaired - low vision users (https://github.com/UKHomeOffice/posters/blob/master/accessibility/low-vision.pdf)\n* Visually impaired - screenreader users (https://github.com/UKHomeOffice/posters/blob/master/accessibility/screenreader.pdf)\n\n**User research and design**\n\n* User research is a team sport (https://github.com/UKHomeOffice/posters/blob/master/gds/research-teamsport.pdf)\n* 2 hours of user research every six weeks (https://github.com/UKHomeOffice/posters/blob/master/gds/two-hours-every-six-weeks.pdf)\n* GDS design principles (https://github.com/UKHomeOffice/posters/blob/master/gds/design-principles-poster.pdf)\n* GDS \"It's OK to..\" (https://github.com/UKHomeOffice/posters/blob/master/gds/its-ok-to.pdf)\n\n\n**Contact**\n\nBest is to open a message in Issues, and we'll get in touch. Otherwise you can contact Bernard Tyers, @bernardtyers on Twitter.\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/pttg-gradle-common","private":false,"url":"https://github.com/UKHomeOffice/pttg-gradle-common","license":null,"readme":"## Gradle plugin that applies PTTG team standards and conventions.\n\n### Use this plugin in your gradle build by:\n\n1. Adding a buildscript dependency\n\n```\nbuildscript {\n       repositories{\n            maven { url \"https://github.com/UKHomeOffice/pttg-gradle-repo/raw/master/releases\" }\n            maven { url \"https://plugins.gradle.org/m2/\" }\n       }\n       dependencies {\n           classpath 'pttg-gradle-common:pttgCommonGradle:1.2.RELEASE'\n       }\n}\n```\n\n2. Applying the plugin\n\n```\napply plugin: 'pttgCommonGradle'\n```\n\n3. User guide\nSee the following documentation. In your project you can also execute the 'pttgCommonGradlePluginUsage' task to\nsee usage instructions and version information etc.\n\n\n### What this plugin gives your build automatically\n\n1. Applies our commonly used plugins \n - java\n - groovy\n - application\n - checkstyle\n - git properties\n\n2. Applies the standard repositories that we use\n\n3. Sets our standard gradle / gradle wrapper version\n\n4. Sets our standard Java version\n\n5. Applies our convention for test reporting: All tasks with a type of 'Test' will generate report HTML into \nbuild/reporting/task-name, eg build/reporting/acceptanceTest or build/reporting/test or build/reporting/myCustomTest\n\n6. Includes commonly used dependencies at our standard versions, eg\n - junit\n - mockito\n - groovy\n - json\n \n7. Applies property expansion to application.properties so that you can use eg ${version} to receive the version\nproperty from build.gradle\n \n8. If the project uses the 'com.moowork.gulp' plugin, then the build is changed to depned on the gulp_test task, and \nthe gulp_test task is added to the verification group\n \n9. Adds checkstyleTest task to the verification group, and adds Checkstyle to the 'check' task, \nconfigured to report on the following errors (but not fail the build):\n - Unused imports\n  \n  NB You can choose to have Checkstyle violations fail the build by adding this configuration:\n  \n  ```\n  checkstyle {\n    ignoreFailures = true\n  }\n  ```\n  NB You can use your own Checkstyle rules using the following configuration to point to your checkstyle.xml\n  \n  ```\n  checkstyle {\n    configFile = <path-to-checkstyle.xml>\n  }\n  ```\n \n### What this plugin allows you to use in your build\n\n1. The plugin creates libraries of dependency groupings at our standard versions\n\neg the plugin defines a standard dependency grouping for Cucumber BDD support, including the following dependencies\n```\n\"info.cukes:cucumber-java:$cucumberVersion\",\n\"info.cukes:cucumber-junit:$cucumberVersion\",\n\"info.cukes:gherkin:2.12.2\",\n\"net.serenity-bdd:serenity-core:$serenityVersion\",\n\"net.serenity-bdd:serenity-cucumber:$serenityCucumberVersion\",\n\"net.serenity-bdd:serenity-junit:$serenityVersion\"\n```\nYou can use this library in your build as follows:\n\n```\ndependencies{\n    testCompile libraries.cucumber\n}\n```\n\nThe following libraries are defined:\n\n- groovy\n- json\n- testUtils\n- logging\n- jackson\n- jacksonJsonProviders\n- mongo    \n- springboot \n- springbootActuator\n- springrestdocs\n- restassured \n- spock    \n- cucumber\n\nYou can override versions of common dependency libraries using the commonLibraries extension block, specifying\nnew version number for the library you wish to override.\n\nThis example shows the current version properties and values that can be overridden:\n\n```\ncommonLibraries{\n    cucumberVersion = '1.2.4'\n    groovyVersion = '2.4.3'\n    jsonVersion = '20160212'\n    jacksonVersion = '2.7.4'\n    logbackVersion = '1.1.3'\n    mongoVersion = '3.0.4'\n    restAssuredVersion = '2.9.0'\n    serenityCucumberVersion = '1.1.6'\n    serenityVersion = '1.1.31'\n    spockVersion = '1.0-groovy-2.4'\n    springBootVersion = '1.3.3.RELEASE'\n    springRestDocsVersion = '1.1.0.RC1'\n    springVersion = '4.2.5.RELEASE'\n}\n```\n\n### Deploying this plugin to the GitHub gradle repository\n\n1. Set the version number in build.gradle (and update this readme)\n2. Execute the tasks clean, build, publishToGitHub\n3. IntelliJ will ask you for your github login the first time\n\nThis relies on the [gradle-git-repo-plugin](https://github.com/layerhq/gradle-git-repo-plugin)\n\n\n\n### Development\n\n1. Increment the minor version number (still needs to be RELEASE because I can't figure out how to make the git-repo plugin support snapshots)\n2. Make your changes\n3. You can use publishMavenJavaPublicationToMavenLocal to deploy the change to your local maven repo\n   1. Note however that this won't work if your changes add new transitive third-party dependencies\n4. Test consumption of the plugin from another project by\n   1. Adding mavenLocal() to your buildscript repositories to consume form local repo\n   2. using the new version number for the plugin in your buildscript dependencies\n   3. You may well need to execute ``` ./gradlew --refresh-dependencies``` to pick up changes, then refresh your IDE\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/pttg-gradle-springboot","private":false,"url":"https://github.com/UKHomeOffice/pttg-gradle-springboot","license":null,"readme":"## Gradle plugin that adds Spring Boot and supporting utilitiy tasks to your build.\n\n### Use this plugin in your gradle build by:\n\n1. Adding a buildscript dependency\n\n```\nbuildscript {\n       repositories{\n            maven { url \"https://github.com/UKHomeOffice/pttg-gradle-repo/raw/master/releases\" }\n       }\n       dependencies {\n           classpath 'pttg-gradle-common:pttgSpringBootGradle:1.1.RELEASE'\n       }\n}\n```\n\n2. Applying the plugin\n\n```\napply plugin: 'pttgSpringBootGradle'\n```\n\n! NOTE - This plugin expects the java plugin to be applied first.\nIf you are using the pttgCommonGradlePlugin, ensure it is applied above this one.\n\n3. User guide\nSee the following documentation. In your project you can also execute the 'pttgSpringBootGradlePluginUsage' task to\nsee usage instructions and version information etc.\n\n3. Configuring the plugin\n\nCustomise configuration using the 'springboot' extension block and override any properties.\nThe available properties and their defaults are shown in this sample:\n\n```\nspringboot{\n    port = 8081 // the port where your spring boot app is running. Required by the bootStop task\n}\n```\n\n### What this plugin gives your build automatically\n\n1. Applies the spring boot plugin\n\n2. Adds the spring boot dependencies\n\n3. Adds a bootStop task alongside the standard bootRun task (defaults to use port 8081)\n\n4. Adds the spring boot actuator support running with the bootRun task\nsee [spring-boot-actuator endpoints](http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#production-ready-endpoints)\n\n5. Adds startSever and stopServer tasks which use a separate process so that other gradle tasks such as acceptanceTest\ncan start and stop the server automatically \n\n### Springboot Actuator support\ntodo tune config for production\n\nActuator support exposes (amongst other things) the following useful endpoints\n\n  * /mappings\n  * /health\n  * /metrics\n  * /info\n  * /trace \n\nTry them and see.\n\n### Development\n\n1. Increment the minor version number (still needs to be RELEASE because I can't figure out how to make the git-repo plugin support snapshots)\n2. Make your changes\n3. You can use publishMavenJavaPublicationToMavenLocal to deploy the change to your local maven repo\n   1. Note however that this won't work if your changes add new transitive third-party dependencies\n4. Test consumption of the plugin from another project by\n   1. Adding mavenLocal() to your buildscript repositories to consume form local repo\n   2. using the new version number for the plugin in your buildscript dependencies\n   3. You may well need to execute ``` ./gradlew --refresh-dependencies``` to pick up changes, then refresh your IDE\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/pttg-fs-stub","private":false,"url":"https://github.com/UKHomeOffice/pttg-fs-stub","license":null,"readme":"Financial Status Service Stub\n=============================\n\n**Overview**\n\n\nA stub to represent a banking interface for the Finanical Status Service. Also provides a central repository for acceptance \ntest data. \n\n-\n\n**Demo Data**\n\nAdd any data files to be automatically inserted,  to the src/test/resources folder with the prefix **demoData**\n\n-\n\n**Technical Notes**\n\nThe API is implemented using Spring Boot, Spring data (MongoDB)\n\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/pttg-gradle-apidocs","private":false,"url":"https://github.com/UKHomeOffice/pttg-gradle-apidocs","license":null,"readme":"## Gradle plugin that adds Spring Rest API documentation support\n\n### Use this plugin in your gradle build by:\n\n1. Adding a buildscript dependency\n\n```\nbuildscript {\n       repositories{\n            maven { url \"https://github.com/UKHomeOffice/pttg-gradle-repo/raw/master/releases\" }\n            jcenter()\n       }\n       dependencies {\n           classpath 'pttg-gradle-common:pttgApiDocsGradle:1.1.RELEASE'\n       }\n}\n```\n\n2. Applying the plugin\n\n```\napply plugin: 'pttgApiDocsGradle'\n```\n! NOTE - This plugin expects the java plugin to be applied first.\nIf you are using the pttgCommonGradlePlugin, ensure it is applied above this one.\n\n3. User guide\nSee the following documentation. In your project you can also execute the 'pttgApiDocsGradlePluginUsage' task to\nsee usage instructions and version information etc.\n\n4. Configuring the plugin\n\nCustomise configuration using the 'apidocs' extension block and override any properties you wish to change.\nThe available properties and their defaults are shown in this sample:\n\n```\napidocs{\n    testSrcPattern = 'apidocs/**'\n    sourceDocsDir = 'src/doc'\n    jarDocsDir = 'static/docs'\n    snippetsDir = 'build/generated-snippets'\n    jarAppendix = 'docs'\n}\n```\n\nwhere\n * testSrcPattern = pattern for the api test classes eg this is for tests under src/test/java/apidocs\n * sourceDocsDir = location of your 'asciidoc' and 'resources' folders containing asciidoc files (eg your index.adoc) and template overrides\n * jarDocsDir = location to put the generated documentation (HTML and PDF) in the project jar\n * snippetsDir = working directory where spring-rest-docs will generate adoc fragments from your test cases\n * jarAppendix = appendix to append to the jar name\n \n5. Using the plugin in conjunction with SpringBoot\n\nThe buildWithApiDocs task generates a jar containing the project outputs and the generated api docs.\nTo produce a Spring Boot executable jar, you must then execute the bootRepackage task.\nThese steps can be combined with a custom task such as the following:\n\n```\ntask buildSpringBootWithApiDocs(type: BootRepackage, dependsOn: buildWithApiDocs) {\n    group 'build'\n    description 'Builds the jar as a Spring Boot executable jar containing the api docs'\n}\n```\n\n6. Modifying the jar manifest\n\nThe buildWithApiDocs task generates a default jar manifest. If you have customised the project's jar manifest then those\ncustomisations should be passed to the buildWithApiDocs task by extracting a shared manifest such as:\n\n```\nversion = blah\n\next.sharedManifest = manifest {\n    attributes(\n        'Implementation-Title': \"${jar.baseName}\",\n        'Implementation-Version': version\n    )\n}\n```\n\nwhich can then be re-used in your jar task or the buildWithApiDocs task as follows:\n\n```\nbuildWithApiDocs{\n    manifest = project.manifest {\n        from sharedManifest\n    }\n}\n```\n \n\n### What this plugin gives your build automatically\n\n1. Applies the spring-rest-doc and asciidoctor plugins\n\n2. Applies the spring-rest-docs dependencies and repositories\n\n3. Creates a new source set, 'doc', to hold your asciidoc files\n\n4. Excludes api doc tests from the regular unit test task\n\n5. Creates the following new tasks for working with spring rest docs\n   1. verification / apiDocTest : run the api doc test cases\n   2. documentation / generateApiDocs : run the api doc test cases and generate the final HTML and PDF documentation\n   3. build / buildWithApiDocs : perform a full build including the api doc tests, adding the generated documentation to a copy of the final jar \n\n\n### Development\n\n1. Increment the minor version number (still needs to be RELEASE because I can't figure out how to make the git-repo plugin support snapshots)\n2. Make your changes\n3. You can use publishMavenJavaPublicationToMavenLocal to deploy the change to your local maven repo\n   1. Note however that this won't work if your changes add new transitive third-party dependencies\n4. Test consumption of the plugin from another project by\n   1. Adding mavenLocal() to your buildscript repositories to consume form local repo\n   2. using the new version number for the plugin in your buildscript dependencies\n   3. You may well need to execute ``` ./gradlew --refresh-dependencies``` to pick up changes, then refresh your IDE\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/pttg-gradle-repo","private":false,"url":"https://github.com/UKHomeOffice/pttg-gradle-repo","license":null,"readme":"Maven repository for gradle artifacts.\n\nConsume artifacts from this repository into your gradle build using the following repository configuration:\n\n```\nmaven { url \"https://github.com/UKHomeOffice/pttg-gradle-repo/raw/master/releases\" }\n```\n\nPublish artifacts to this repository using the following configuration, and use the publishToGitHub task:\n\n```\nbuildscript {\n    repositories {\n        mavenCentral()\n    }\n    dependencies {\n        classpath 'com.layer:gradle-git-repo-plugin:2.0.2'\n    }\n}\n\napply plugin: 'git-repo'\n\ngitPublishConfig {\n    org = \"UKHomeOffice\"\n    repo = \"pttg-gradle-repo\"\n    gitUrl = \"https://github.com/UKHomeOffice/pttg-gradle-repo.git\"\n}\n\npublishing {\n    repositories {\n        maven {\n            url \"file://${gitPublishConfig.home}/${gitPublishConfig.org}/${gitPublishConfig.repo}/releases\"\n        }\n    }\n    publications {\n        mavenJava(MavenPublication) {\n            from components.java\n        }\n    }\n}\n```\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/pttg-fs-ui","private":false,"url":"https://github.com/UKHomeOffice/pttg-fs-ui","license":null,"readme":"Financial Status Service UI\n=\n\nOverview\n-\n\nThis is an overview of the financial status service UI.\nThe financial status service UI is a UI for the financial status service.\nThat was an overview of the financial status service UI.\n\n\nSuggestions\n-\n\nAdded a demo of the Spring Boot actuator support and healthchecks\n\nsee eg (or use JConsole to view via JMX)\n\nhttp://localhost:8001/info\n\n> Gives application version and git version details.\n> Perhaps useful when we have a deployment pipeline\n  \n  \nhttp://localhost:8001/health\n\n> Reports healthcheck results\n> Hit refresh a few times to see different results\n\n\nhttp://localhost:8001/mappings\n\n> Shows all known path mappings \n\nhttp://localhost:8001/metrics\n\n> Metrics including hit counts and response times\n> Also including custom metrics eg use the UI a few times to do some queries, then look at the metrics for\n> counter.greetings.accountNumber\n\nhttp://localhost:8001/trace\n\n> Request log traces\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/rtp-sqs-producer","private":false,"url":"https://github.com/UKHomeOffice/rtp-sqs-producer","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"rtp-sqs-producer [![npm version](https://badge.fury.io/js/rtp-sqs-producer.svg)](https://badge.fury.io/js/rtp-sqs-producer) [![Build Status](https://travis-ci.org/UKHomeOffice/rtp-sqs-producer.svg)](https://travis-ci.org/UKHomeOffice/rtp-sqs-producer)\n-----------------\n\nVery thin wrapper around amazon sqs. Provides little more than a friendly interface to publish messages to the sqs queue, and\nretry in case of failure.\nCurrently doesn't support receiving, but only publishing.\n\nUse\n---\n\n    var producer = new (require('rtp-sqs-connector'))(config)\n    \nThe module assumes that you have injected your amazon sqs credentials into `process.env`.\n\nAnyone (internal or external) can report concerns with published code by emailing evw-contactus@homeoffice.gsi.gov.uk.\n\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/sbt-mustache","private":false,"url":"https://github.com/UKHomeOffice/sbt-mustache","license":null,"readme":"#SBT {{mustache}}\n\n[![Build Status]](https://travis-ci.org/michaeldfallen/sbt-mustache)\n[![Bintray Release]](https://bintray.com/michaelallen/sbt-plugins/sbt-mustache/0.2)\n\n[Build Status]: https://travis-ci.org/michaeldfallen/sbt-mustache.svg?branch=master\n[Bintray Release]: http://img.shields.io/badge/bintray-v0.2-blue.svg \n\nAn SBT plugin for integrating Mustache templates into Scala projects.\n\nWe take the same philosophy as the Play Frameworks [Twirl] plugin, generating\nScala sources that are preconfigured to access your templates during compile.\n\nThis plugin was inspired by [@julienba]'s [play2-mustache] plugin, which we used\non the [Register to vote] exemplar project. Sadly since Play migrated to\n[SBT-Web], in it's recent [play-2.3], the [play2-mustache] plugin has been\ndeprecated.\n\n##Installation\n\nTo your projects `plugins.sbt` add the following:\n\n```\nresolvers += Resolver.url(\n  \"bintray-sbt-plugin-michaelallen\",\n  url(\"https://dl.bintray.com/michaelallen/sbt-plugins/\")\n)(Resolver.ivyStylePatterns)\n\nresolvers += \"bintray-maven-michaelallen\" at \"https://dl.bintray.com/michaelallen/maven/\"\n\naddSbtPlugin(\"io.michaelallen.mustache\" %% \"sbt-mustache\" % \"0.2\")\n```\n\nDone. SBT 0.13 added AutoPlugins which allows plugins to handle their default\nconfiguration themselves.\n\n##Usage\n\nThere's two ways to use this plugin, which I'll call *The Hogan way* and *The\nTwirl way*. Whichever you choose is up to you.\n\n####Source Directories\n\nIn most Scala apps Mustache templates are stored in `src/main/mustache`.\nIn Play apps you should put your templates in `app/mustache`.\n\nIf you would like to add further directories to look for Mustache templates you\ncan edit the key `sourceDirectories in mustacheTemplate`.\n\nAdding a new source directory for Mustache templates:\n```\nlazy val root = (project in file(\".\")).settings(\n  sourceDirectories in mustacheTemplate :+ baseDirectory / \"mySpecialMustaches\"\n)\n```\n\n####The Hogan way\n\nIn Hogan.js you call off to a Mustache compiler to compile your template then\nrender that template with a set of data. This can be done in Sbt-Mustache.\n\nOn compile Sbt-Mustache will generate a few source files. One of them is the\n`io.michaelallen.mustache.MustacheFactory` object, which is configured to look\nfor the Mustache templates in your source directories.\n\nYou can simply call `MustacheFactory.compile` to ask the factory to compile you\na template, like you would in Hogan.js\n\nWith a template sitting in `src/main/mustache/foo/bar.mustache`:\n```\n<h1>{{message}}</h1>\n```\n\nWe can ask the MustacheFactory to compile it:\n\n```\nval template = MustacheFactory.compile(\"foo/bar.mustache\")\n```\n\nThen execute the template to render it's html:\n\n```\nval writer = new StringWriter()\ntemplate.execute(writer, Map(\"message\" -> \"Hello World!\"))\n\nwriter.flush().toString == \"<h1>Hello World!</h1>\"\n```\n\n####The Twirl way\n\nTwirl models your templates as Scala files, by generating Scala objects that\nunderstand how to render the html of the template.\n\nThis is a nice feature and something I wanted to bring to Sbt-Mustache.\n\nIf you have a template at `src/main/mustache/foo/bar.mustache`:\n```\n<h1>{{message}}</h1>\n```\n\nThen Sbt-Mustache will generate a Scala trait at `mustache.foo.bar` which\nunderstands how to render the `bar.mustache` template.\n\nWe can then mix that trait into a class or case class to provide the backing\nobject to render based off:\n\n```\ncase class Bar(message:String) extends mustache.foo.bar\n```\n\nThen newing that class up and calling render will generate our html:\n\n```\nBar(message = \"Hello World!\").render == \"<h1>Hello World!</h1>\"\n```\n\n####Play Support\n\nThe plugin provides native support for Play Frameworks [custom content types].\nWe do this by generating a trait into source_managed that provides the implicit\n`Writeable` and `ContentType` that play Results need to render arbitrary types\nas HTML. We then piggy back off your version of the Play Framework jars to compile\nthose sources.\n\nTo turn on Play support set `MustacheKeys.playSupport` in your build.sbt:\n\n```\nlazy val root = (project in file(\".\"))\n  .enablePlugins(PlayScala)\n  .settings(MustacheKeys.playSupport := true)\n```\n\nAssuming you have a Presenter in views.Foo:\n\n```\npackage views\n\ncase class Foo() extends mustache.foo\n```\n\nThen mix in the PlayImplicits trait in your controller:\n\n```\nimport io.michaelallen.mustache.PlayImplicits\n\nobject MyController extends Controller with PlayImplicits {\n  def index = Ok(views.Foo())\n}\n```\n\n##Work in progress\n\nThis plugin is a work in progress. Currently you can checkout the code, build it\n, publish it locally and make use of it to do basic Mustache compilation and\nrendering.\n\n [SBT-Web]: https://github.com/sbt/sbt-web\n [Twirl]: https://github.com/playframework/twirl\n [@julienba]: https://github.com/julienba\n [play2-mustache]: https://github.com/julienba/play2-mustache\n [Register to vote]: https://www.gov.uk/transformation/register-to-vote\n [play-2.3]: http://www.playframework.com/documentation/2.3.x/Highlights23\n [custom content types]: http://www.playframework.com/documentation/2.3.x/ScalaCustomTemplateFormat\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/pttg-gradle-common-ui","private":false,"url":"https://github.com/UKHomeOffice/pttg-gradle-common-ui","license":null,"readme":"## Gradle plugin that applies PTTG team standards and conventions for UI projects\n\n### Use this plugin in your gradle build by:\n\n1. Adding a buildscript dependency\n\n```\nbuildscript {\n       repositories{\n            maven { url \"https://github.com/UKHomeOffice/pttg-gradle-repo/raw/master/releases\" }\n       }\n       dependencies {\n           classpath 'pttg-gradle-common:pttgCommonUIGradle:1.0.RELEASE'\n       }\n}\n```\n\n2. Applying the plugin\n\n```\napply plugin: 'pttgCommonUIGradle'\n```\n\n\n### What this plugin does:\n\n1. Applies commonly used plugins for UI projects \n - gulp\n\n2. Sets the build task to depend on the gulp_build task\n\n3. Instructs the jar task to copy src/main/webapp into the jar under 'static'\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/pttg-ip-api","private":false,"url":"https://github.com/UKHomeOffice/pttg-ip-api","license":null,"readme":"Income Proving API\n=\n\n[![Docker Repository on Quay](https://quay.io/repository/ukhomeofficedigital/pttg-income-proving-api/status \"Docker Repository on Quay\")](https://quay.io/repository/ukhomeofficedigital/pttg-income-proving-api)\n\nOverview\n-\n\nThis is the Income Proving API.\n\nTechnical Notes\n-\n\nThe API is implemented using Spring Boot.  It is intended to allow the team to compare and contrast with\nthe API previously built using Spark Java.\n\n\n\n### Infrastructure\n\nBuilds are triggered by Jenkins.\n\nApps are packaged as Docker images and stored on quay.io.\n\nApps are run on AWS managed by kubernetes.\n\n### Philosophy\n\nEverything runs in a Docker container.\n\nBuilds are portable, it should be possible to check the code out, build and run the tests without any constraints.\n\nNo dependence on Jenkins for plugins, etc.\n\n## Building\n\n### Everything in Docker\n\nThere is a requirement to not use any non-vanilla feature in Jenkins nor to use any plugins.  This is\nseen as polluting Jenkins.  This will allow Jenkins to be replaced at any time without difficulty.\n\nJenkins runs in a Docker container on AWS.\n\nFollowing this approach Jobs execute a shell script that carries out the build within a Docker Container.  This\nis implemented by the build.sh script which does the following:\n\n\t1. Create Docker image to execute build in\n\t2. Run docker image\n\t3. Build docker image to run jar from artifacts\n\t4. Push image to quay.io\n\n#### Pros of this approach\n\n* There will be no port conflicts as the only thing running in the container is the app.  During the\nspike we found that Jenkins was running on port 8080 which is the port used by the app which meant the\n app had to be run a different port for testing.  This is different to how it will run in production.\n* Jenkins can be easily replaced with another tool.  [Not sure why this would be neccessary given that\nit is only used to poll git and then execute a shell script - essentially doing the job chron does but\nusing git changes instead to time event.]\n\n#### Cons of this approach:\n\n* Running the build inside a container adds overhead in terms of both build duration and scripting.\n* Build scripts are more complex, have to cater for situation such as running a docker container\nwith a docker container.\n* Running the build inside a container is slower than building directly on the Jenkins server as\nall the dependent jar files have to be downloaded for each build as does Gradle.\n* Cannot use Jenkins plugins to publish the Serenity BDD reports they would have to be extracted and\npublished. [The docker cp command does not support wildcards or recursive folder copying so it cannot\nbe used.]\n* Jenkins cannot be used to view unit test coverage reports. They would need to be extracted and published.\n\n### Build on Jenkins server using Gradle\n\nThe usual approach is to define a Job that executes the build steps on the Jenkins\nserver in a local workspace.  For this example a simple build step that executes various Gradle tasks\nhas been implemented.  The Gradle script uses a plugin that builds the docker image and a custom task\nto push the image to quay.io.\n\n#### Pros of this approach\n\n* No need to create a short lived container to execute the build in.  This reduces the amount of\nshell scripting.\n* Gradle can be used for all build steps, same as for development as same as anyone who wanted to take\nadvantage of the project as open source.\n* Builds are faster as Jenkins maintains a local cache for jar dependencies.\n* Gradle only downloaded once, not for every build.\n* The example Job that builds the project does not make use of any non-vanilla Jenkins features or\nplugins so Jenkins could be swapped out.\n\n#### Cons of this approach\n\n* Port conflicts\n\n### Other points\n\nThe 'Build on Jenkins server using Gradle' approach would allow some Jenkins plugins to be used to, for example, publish\nthe test reports.  Proving things uses BDD approach and the Serenity BDD tool to report the state of\nthe executable specification (cucumber feature files).  Publishing these reports would be more complex\nusing the 'Everything in Docker' approach.\n\nEach image pushed to quay.io must have a unique tag.  This is achieved by appending the Jenkins build\nnumber to the version number:\n\n\tquay.io/ukhomeofficedigital/uk.gov.digital.ho.proving.income.api:1.0.29\n\nIt is unlikely that every build on Jenkins should be pushed to quay.io.\n\nNeither approach offers a method for easily automating a software release.  Solving this issue in\nGradle will most likely be easier.\n\n## Deploy\n\n### Overview\n\nContainers are deployed and managed by Kubernetes running on AWS.\nImages are pulled from quay.io.\nLogging is via stdout.\n\n### Kubernetes on AWS\n\nKubernetes is used for deploying, running and managing the Docker containers.  Simply put\nKuberentes is configured declaratively, you tell it what you want deploying (i.e. docker image), and\nwhat you want running (i.e. number of docker containers).  Kubernetes then takes the appropriate\nsteps to achieve this.\n\nA framework, kb8or (https://github.com/UKHomeOffice/kb8or), has been built to assist in this process.\n\nThe services folder contains all the files neccessary to carry out the deployment.  Following the\npreviously stated philosophy the deployment is executed from inside a Dcoker container.\n\nThe characteristics of the app are defined in the ReplicationController\n\n\tservices/k8resoruces/pt-income-rc.yaml\n\nThis file declares the required number of running instances; how much cpu and memory each instance\ngets; which port is exposed to the proxy; and any runtime configuration items that are to be passed\ninto the container as environment variables.\n\n### Summary\n\nIn addition to run capacity and performance he only items that need to be considered from an\napplication delivery team perspective are:\n\n* Provisioning the token used to authenticate to k8s\n* Providing the correct version of the image to be deployed\n\nAll the other configuration should be boiler plate that only needs to be set up when a new application\ndevelopment is started.\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/pttg-test-ip-mongodb","private":false,"url":"https://github.com/UKHomeOffice/pttg-test-ip-mongodb","license":null,"readme":"# Overview\n\nThis project creates some test data in a MongoDB instance\n\nStart mongo as per usual:\n\n mongod --dpath <path to your data directoy>\n \n optional - override Mongodb host and port with environment variables  - MONGO_HOST and MONGO_PORT","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/pttg-ip-gt-ui","private":false,"url":"https://github.com/UKHomeOffice/pttg-ip-gt-ui","license":null,"readme":"Generic UI\n=\n\nOverview\n-\n\nTODO\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/pttg-ip-fm-ui","private":false,"url":"https://github.com/UKHomeOffice/pttg-ip-fm-ui","license":null,"readme":"Income Proving API\n=\n\n[![Docker Repository on Quay](https://quay.io/repository/ukhomeofficedigital/pttg-ip-fm-ui/status \"Docker Repository on Quay\")](https://quay.io/repository/ukhomeofficedigital/pttg-ip-fm-ui)\n\nOverview\n-\n\nThis is the Income Proving API.\n\nTechnical Notes\n-\n\nThe API is implemented using Spring Boot.  It is intended to allow the team to compare and contrast with\nthe API previously built using Spark Java.\n\nAPI Notes\n-\n* The API will only return enough information to support the current UI tools needs\n* The API will NOT return the search parameters used by the client\n* The API will use resources and restful ideas as much as possible\n* The API will only support accepting and returning JSON data\n\nExamples will follow once the API redesign is done.\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-centos-tomcat","private":false,"url":"https://github.com/UKHomeOffice/docker-centos-tomcat","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# tomcat\n\n## Description\nApache Tomcat Container\n\n## Usage\n\nTo build this container you need to run:\n\n```\nmake build\n```\n\nIf you want TLS configured then you need to put your ca.crt, crt.pem and key.pem into the ssl directory for these to be mounted into the image (with those specific names). If you would like to enable Basic Auth as well then you need to rename and edit ssl/tomcat-users.xml.template to ssl/tomcat-user.xml adding any users as required. The SSL directory should then be mounted into the container to /opt/tomcat/ssl. To run the Tomcat container run which will dynamically start with SSL/Basic Auth if it finds the correct files:\n\n```\nmake run\n```\n\nThis will startup a Tomcat container running Catalina\n\n\n## Tests\n\nAs part of the build process the docker file will run the OpenSSL and Tomcat test exiting and failing the build if these fail.\n\n\n### Credits\n\nThis package was created with Cookiecutter_ and the `audreyr/cookiecutter-pypackage`_ project template.\n\n[Cookiecutter](https://github.com/audreyr/cookiecutter)\n[audreyr/cookiecutter-pypackage](https://github.com/audreyr/cookiecutter-pypackage)\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/kube-pttg-income-mongodb","private":false,"url":"https://github.com/UKHomeOffice/kube-pttg-income-mongodb","license":null,"readme":"# Proving things - mongodb database - test data\n\n### Kubernetes Deployment\n\nThis is the kubernetes deployment files for Proving Things mongo db (non production test data)\n\nrun deployment\n\n\t./scripts/deploy_kd\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/kube-pttg-ip-gt-ui","private":false,"url":"https://github.com/UKHomeOffice/kube-pttg-ip-gt-ui","license":null,"readme":"# pttg-income-ui\nProving Things - Income UI\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/kube-pttg-ip-api","private":false,"url":"https://github.com/UKHomeOffice/kube-pttg-ip-api","license":null,"readme":"## Proving Things - Income API -  Kubernetes Resources\n\n### Kubernetes Deployment\n\nThis is the kubernetes deployment files for Proving Things Income API\n\nAs it stands this is using [KB8OR for deployments](https://github.com/UKHomeOffice/kb8or)\n\nrun deployment\n\n\t./scripts/deploy -e dev ./pttg-ip-api.yaml\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-vault","private":false,"url":"https://github.com/UKHomeOffice/docker-vault","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Vault in Kubernetes\n\n[![Build Status](https://drone.digital.homeoffice.gov.uk/api/badges/UKHomeOffice/docker-vault/status.svg)](https://drone.digital.homeoffice.gov.uk/UKHomeOffice/docker-vault)\n\nVault in a docker image with all the necessary scripts to run vault in\nkubernetes cluster.\n\nThere are two main components in this setup:\n- Vault container - main vault process which listens in a tcp socket\n- overlord container - bash script which takes care of unsealing vault,\n  creating admin user and persisting vault unseal key if `KUBERNETES_NAMESPACE` is set.\n\n\n## Getting Started\n\nFirst of all, you need to make sure that your kubernetes cluster supports\nservice accounts and that either the default or vault specific service account\nhas access to create kubernetes secrets in the namespace. However this is only\nneeded if you're bootstrapping vault.\n\nWe are going assume that vault is being deployed into a namespace called vault.\n\nIn the below example we will use AWS DynamoDB as a backend. So for that, you\nneed to create a DynamoDB table and an IAM user with required permissions. Then\nchange environment variables accordingly in [vault deployment file](kube/vault-deployment.yaml).\n\n\n### Configuration\n\n* `VAULT_BACKEND` - defaults to `inmem`.\n* `TLS_DISABLE` - defaults to 1.\n* `VAULT_ADMIN_PASSWORD` - admin password that overlord sets when creating an\n  admin user. If unset, overlord will generate a random one, which will be\n  logged, so changing it is advisable.\n* `KUBERNETES_NAMESPACE` - if service account is present, then the namespace\n  name will be taken from there and vault unseal key will be persisted as\n  kubernetes secret.\n\nAny other environment variables, which are supported by vault, can be set.\n\n\n### Deployment\n\n* Deploy an empty vault-unseal secret (will be updated by overlord script)\n```\nkubectl --namespace=vault create -f kube/vault-secrets.yaml\n```\n\n* Deploy vault pod (vault itself and overlord container)\n```\nkubectl --namespace=vault create -f kube/vault-deployment.yaml\n```\n\n* Deploy a kubernetes service endpoint for vault\n```\nkubectl --namespace=vault create -f kube/vault-svc.yaml\n```\n\n\n### Other\n\n#### TLS\n\nIf you want to provide TLS certs, you can place them in `/vault/certs/cert.pem`\nand `/vault/certs/key.pem`.\n\n\n## Contributing\n\nContributions are most certainly welcome. If you want to introduce a breaking\nchange or any other major change, please raise an issue first to discuss.\n\n## License\n\n[MIT](LICENSE)\n","travis":false,"contributing":false,"masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/docker-vault/branches/master/protection","requiredStatusChecks":{"url":"https://api.github.com/repos/UKHomeOffice/docker-vault/branches/master/protection/required_status_checks","strict":true,"includeAdmins":false,"contextsUrl":"https://api.github.com/repos/UKHomeOffice/docker-vault/branches/master/protection/required_status_checks/contexts"}}},{"name":"UKHomeOffice/hadiscover","private":false,"url":"https://github.com/UKHomeOffice/hadiscover","license":null,"readme":"# hadiscover\n\nThis tool generates a [HAproxy](www.haproxy.org) configuration file based on [etcd](https://coreos.com/using-coreos/etcd/), and then reloads gracefully HAproxy.\n\nhadiscover is listening on a specific directory in etcd, and for each changes it  re-generates the configuration and reloads graceully the server (using the `-sf` HAproxy flag).\n\nIt have been created to be used in parallel of my [Dockreg](https://github.com/adetante/dockreg) tool which does Docker container registration in etcd (see [my blog post](http://adetante.github.io/articles/service-discovery-with-docker-2)).\n\nFor more information and for build instruction, please read my post about [Service Discovery with HAproxy](http://adetante.github.io/articles/service-discovery-haproxy).\n\n## Config file\n\nhadiscover uses a [go text template](http://golang.org/pkg/text/template) to generate the haproxy configuration. For example:\n\n```\nglobal\n    maxconn 4096\n\ndefaults\n    log global\n    mode    http\n    option  httplog\n    option  dontlognull\n    retries 3\n    redispatch\n    maxconn 2000\n    contimeout  5000\n    clitimeout  50000\n    srvtimeout  50000\n\nfrontend http-in\n    bind *:8000\n    default_backend http\n\nbackend http\n{{range .}}     server {{.Name}} {{.Ip}}:{{.Port}} maxconn 32\n{{end}}\n```\n\nThe `backend http` part will be replaced by the list of available services retrieved in etcd.\n\nThe key name in etcd must have be formatted with the form `host:port`, for example:\n`http://my-etcd-server:4001/keys/services/192.168.0.1:8000`\n\n\n## Command line usage\n\n```\nhadiscover --config templatePath --etcd etcdServersList --ha pathToHAcommand --key etcdKey\n```\n\nWhere:\n\n* **templatePath** is the path to the configuration template\n* **etcdServersList** is the list of etcd servers, like `--etcd http://localhost:4001`\n* **pathToHAcommand** is the path to the HAproxy executable\n* **etcdKey** is the key to watch changes for\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/workshops","private":false,"url":"https://github.com/UKHomeOffice/workshops","license":null,"readme":"# workshops\nA Collection of Developer Workshop &amp; Presentation Documents\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-postgresql-patroni","private":false,"url":"https://github.com/UKHomeOffice/docker-postgresql-patroni","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"|Build Status| |Coverage Status|\n\nPatroni: A Template for PostgreSQL HA with ZooKeeper, etcd or Consul\n------------------------------------------------------------\nThere are many ways to run high availability with PostgreSQL; for a list, see the `PostgreSQL Documentation <https://wiki.postgresql.org/wiki/Replication,_Clustering,_and_Connection_Pooling>`__.\n\nPatroni is a template for you to create your own customized, high-availability solution using Python and — for maximum accessibility — a distributed configuration store like `ZooKeeper <https://zookeeper.apache.org/>`__, `etcd <https://github.com/coreos/etcd>`__ or `Consul <https://github.com/hashicorp/consul>`__. Database engineers, DBAs, DevOps engineers, and SREs who are looking to quickly deploy HA PostgreSQL in the datacenter—or anywhere else—will hopefully find it useful.\n\nWe call Patroni a \"template\" because it is far from being a one-size-fits-all or plug-and-play replication system. It will have its own caveats. Use wisely.\n\n.. contents::\n    :local:\n    :depth: 1\n    :backlinks: none\n\n==============\nHow Patroni Works\n==============\n\nPatroni originated as a fork of `Governor <https://github.com/compose/governor>`__, the project from Compose. It includes plenty of new features. \n\nFor an example of a Docker-based deployment with Patroni, see `Spilo <https://github.com/zalando/spilo>`__, currently in use at Zalando.\n\nFor additional background info, see:\n\n* `PostgreSQL HA with Kubernetes and Patroni <https://www.youtube.com/watch?v=iruaCgeG7qs>`__, talk by Josh Berkus at KubeCon 2016 (video)\n* `Feb. 2016 Zalando Tech blog post <https://tech.zalando.de/blog/zalandos-patroni-a-template-for-high-availability-postgresql/>`__\n\n===================\nRunning the service\n===================\nThe docker container has a number of environment variables that are available for use:\nMost can be seen in the Dockerfile, the most common are described below\n- SYNCHRONOUS - set to on to make replication synchronous\n- ADMINUSER - the main admin user for the database\n- ADMINPASS - the password for the admin user\n- ETCD_TTL - the period before a postgres master election occurs after the current master dies\n- ETCD_TIMEOUT - the period before the call to etcd times out, this is described as a string eg. \"2s - 2 seconds, 1m - 1 minute\"\n\nExample usage:\n```\ndocker run -t -i -e ADMINUSER=\"postgres\" -e ADMINPASS=\"password\" patroni-dev --etcd=192.168.99.100\n```\n\n================\nDevelopment Status\n================\n\nPatroni is in active development and accepts contributions. See our `Contributing <https://github.com/zalando/patroni/blob/master/README.rst#contributing>`__ section below for more details. \n\n===========================\nTechnical Requirements/Installation\n===========================\n\n**For Mac**\n\nTo install requirements on a Mac, run the following:\n\n::\n\n    brew install postgresql etcd haproxy libyaml python\n    pip install psycopg2 pyyaml\n\n===================\nRunning and Configuring\n===================\n\nTo get started, do the following from different terminals:\n::\n\n    > etcd --data-dir=data/etcd\n    > ./patroni.py postgres0.yml\n    > ./patroni.py postgres1.yml\n\nYou will then see a high-availability cluster start up. Test different settings in the YAML files to see how the cluster’s behavior changes. Kill some of the components to see how the system behaves.\n\nAdd more ``postgres*.yml`` files to create an even larger cluster.\n\nPatroni provides an `HAProxy <http://www.haproxy.org/>`__ configuration, which will give your application a single endpoint for connecting to the cluster's leader. To configure,\nrun:\n\n::\n\n    > haproxy -f haproxy.cfg\n\n::\n\n    > psql --host 127.0.0.1 --port 5000 postgres\n\n===============\nYAML Configuration\n===============\n\nGo `here <https://github.com/zalando/patroni/blob/master/SETTINGS.rst>`__ for comprehensive information about settings for etcd, consul, and ZooKeeper. And for an example, see `postgres0.yml <https://github.com/zalando/patroni/blob/master/postgres0.yml>`__. \n\n===============\nReplication Choices\n===============\n\nPatroni uses Postgres' streaming replication, which is asynchronous by default. For more information, see the `Postgres documentation on streaming replication <http://www.postgresql.org/docs/current/static/warm-standby.html#STREAMING-REPLICATION>`__.\n\nPatroni's asynchronous replication configuration allows for ``maximum_lag_on_failover`` settings. This setting ensures failover will not occur if a follower is more than a certain number of bytes behind the follower. This setting should be increased or decreased based on business requirements.\n\nWhen asynchronous replication is not optimal for your use case, investigate Postgres's `synchronous replication <http://www.postgresql.org/docs/current/static/warm-standby.html#SYNCHRONOUS-REPLICATION>`__. Synchronous replication ensures consistency across a cluster by confirming that writes are written to a secondary before returning to the connecting client with a success. The cost of synchronous replication: reduced throughput on writes. This throughput will be entirely based on network performance. \n\nIn hosted datacenter environments (like AWS, Rackspace, or any network you do not control), synchronous replication significantly increases the variability of write performance. If followers become inaccessible from the leader, the leader effectively becomes read-only.\n\nTo enable a simple synchronous replication test, add the follow lines to the ``parameters`` section of your YAML configuration files:\n\n.. code:: YAML\n\n        synchronous_commit: \"on\"\n        synchronous_standby_names: \"*\"\n\nWhen using synchronous replication, use at least three Postgres data nodes to ensure write availability if one host fails.\n\nChoosing your replication schema is dependent on your business considerations. Investigate both async and sync replication, as well as other HA solutions, to determine which solution is best for you.\n\n===============================\nApplications Should Not Use Superusers\n===============================\n\nWhen connecting from an application, always use a non-superuser. Patroni requires access to the database to function properly. By using a superuser from an application, you can potentially use the entire connection pool, including the connections reserved for superusers, with the ``superuser_reserved_connections`` setting. If Patroni cannot access the Primary because the connection pool is full, behavior will be undesirable.\n\n================\nContributing\n================\nPatroni accepts contributions from the open-source community; see the `Issues Tracker <https://github.com/zalando/patroni/issues>`__ for current needs. \n\nBefore making a contribution, please let us know by posting a comment to the relevant issue. \nIf you would like to propose a new feature, please first file a new issue explaining the feature you’d like to create.\n\n.. |Build Status| image:: https://travis-ci.org/zalando/patroni.svg?branch=master\n   :target: https://travis-ci.org/zalando/patroni\n.. |Coverage Status| image:: https://coveralls.io/repos/zalando/patroni/badge.svg?branch=master\n   :target: https://coveralls.io/r/zalando/patroni?branch=master\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/ckan","private":false,"url":"https://github.com/UKHomeOffice/ckan","license":{"key":"other","name":"Other","spdxId":null,"url":null,"featured":false},"readme":"CKAN: The Open Source Data Portal Software\n==========================================\n\n.. image:: https://secure.travis-ci.org/ckan/ckan.png?branch=master\n    :target: http://travis-ci.org/ckan/ckan\n    :alt: Build Status\n\n.. image:: https://coveralls.io/repos/ckan/ckan/badge.png?branch=master\n    :target: https://coveralls.io/r/ckan/ckan\n    :alt: Coverage Status\n\n**CKAN is the world’s leading open-source data portal platform**.\nCKAN makes it easy to publish, share and work with data. It's a data management\nsystem that provides a powerful platform for cataloging, storing and accessing\ndatasets with a rich front-end, full API (for both data and catalog), visualization\ntools and more. Read more at `ckan.org <http://ckan.org/>`_.\n\n\nInstallation\n------------\n\nSee the `CKAN Documentation <http://docs.ckan.org>`_ for installation instructions.\n\n\nSupport\n-------\n\nIf you need help with CKAN or want to ask a question about CKAN, use either the\n`ckan-discuss`_ mailing list or the `CKAN tag on Stack Overflow`_ (try\nsearching the Stack Overflow and ckan-discuss archives for an answer to your\nquestion first).\n\nIf you've found a bug in CKAN, open a new issue on CKAN's `GitHub Issues`_ (try\nsearching first to see if there's already an issue for your bug).\n\n\n.. _CKAN tag on Stack Overflow: http://stackoverflow.com/questions/tagged/ckan\n.. _ckan-discuss: http://lists.okfn.org/mailman/listinfo/ckan-discuss\n.. _GitHub Issues: https://github.com/ckan/ckan/issues\n\n\nContributing to CKAN\n--------------------\n\nFor contributing to CKAN or its documentation, see\n`CONTRIBUTING <https://github.com/ckan/ckan/blob/master/CONTRIBUTING.rst>`_.\n\nIf you want to talk about CKAN development say hi to the CKAN developers on the\n`ckan-dev`_ mailing list or in the `#ckan`_ IRC channel on irc.freenode.net.\n\nIf you've figured out how to do something with CKAN and want to document it for\nothers, make a new page on the `CKAN wiki`_, and tell us about it on\n`ckan-dev`_.\n\n.. _ckan-dev: http://lists.okfn.org/mailman/listinfo/ckan-dev\n.. _#ckan: http://webchat.freenode.net/?channels=ckan\n.. _CKAN Wiki: https://github.com/ckan/ckan/wiki\n\n\nCopying and License\n-------------------\n\nThis material is copyright (c) 2006-2014 Open Knowledge Foundation.\n\nIt is open and licensed under the GNU Affero General Public License (AGPL) v3.0\nwhose full text may be found at:\n\nhttp://www.fsf.org/licensing/licenses/agpl-3.0.html\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/opensource-by-default","private":false,"url":"https://github.com/UKHomeOffice/opensource-by-default","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# opensource-by-default","travis":false,"contributing":false,"masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/opensource-by-default/branches/master/protection","requiredStatusChecks":{"url":"https://api.github.com/repos/UKHomeOffice/opensource-by-default/branches/master/protection/required_status_checks","strict":true,"includeAdmins":true,"contextsUrl":"https://api.github.com/repos/UKHomeOffice/opensource-by-default/branches/master/protection/required_status_checks/contexts"},"restrictions":{"url":"https://api.github.com/repos/UKHomeOffice/opensource-by-default/branches/master/protection/restrictions","users":[],"usersUrl":"https://api.github.com/repos/UKHomeOffice/opensource-by-default/branches/master/protection/restrictions/users","teams":[{"name":"Opensource by Default","id":2055180,"slug":"opensource-by-default","description":"Works with HOD teams to make sure we are contributing to the community","privacy":"closed","url":"https://api.github.com/teams/2055180","repositoriesUrl":"https://api.github.com/teams/2055180/repos","permission":"pull"}],"teamsUrl":"https://api.github.com/repos/UKHomeOffice/opensource-by-default/branches/master/protection/restrictions/teams"}}},{"name":"UKHomeOffice/docker-neo4j","private":false,"url":"https://github.com/UKHomeOffice/docker-neo4j","license":null,"readme":"## Running Clustered Neo4j on Kubernetes.\n\n#### Cluster the Nodes\n\nOnce you've decided how many nodes you want to have then first create your services for each of your nodes to join the cluster like so.\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    name: neo4j-<cluster-number>\n  name: neo4j-<cluster-number>\nspec:\n  ports:\n    -\n      name: cluster\n      port: 5001\n      targetPort: 5001\n    -\n      name: transaction\n      port: 6001\n      targetPort: 6001\n  selector:\n    name: neo4j-<cluster-number>\n```\n\nThis will mean that each pod will have their own static ip.\n\nThen from there you can spin up your pods. \n\n```yaml\napiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    app: neo4j-<cluster-number>\n  name: neo4j-<cluster-number>\nspec:\n  replicas: 1\n  selector:\n    name: neo4j-<cluster-number>\n  template:\n    metadata:\n      labels:\n        name: neo4j-<cluster-number>\n        app: neo4j-<cluster-number>\n    spec:\n      containers:\n        -\n          imagePullPolicy: Always\n          image: neo4j:3.0.2-enterprise\n          name: neo4j-<cluster-number>\n          resources:\n            limits:\n              memory: \"2G\"\n              cpu: \"500m\"\n          ports:\n          - containerPort: 7474\n            name: \"http\"\n          - containerPort: 5001\n            name: \"cluster\"\n          - containerPort: 6001\n            name: \"transaction\"\n          env:\n          - name: \"NEO4J_dbms_mode\"\n            value: \"HA\"\n          - name: NEO4J_ha_host_coordination\n            value: 0.0.0.0:5001\n          - name: NEO4J_ha_host_data\n            value: neo4j-1:6001\n          - name: \"NEO4J_HA_ADDRESS\"\n            value: \"0.0.0.0\"\n          - name: \"NEO4J_ha_serverId\"\n            value: \"<cluster-number>\"\n          - name: \"NEO4J_ha_initialHosts\"\n            value: \"neo4j-1:5001,neo4j-2:5001,neo4j-3:5001\"\n      restartPolicy: Always\n```\n\n\nNote the environment variables:\n\n* `NEO4J_HA_ADDRESS` must be 0.0.0.0 to allow the pods ip's in as they can be any ip. \n* `NEO4J_ha_initialHosts` a comma separated list of your nodes using the service ips, or dns names if you have them.\n* `NEO4J_ha_serverId` id of a server must be unique within a cluster.\n* `NEO4J_ha_host_coordination` same as `NEO4J_HA_ADDRESS` but with the port added.\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/hubpress.io","private":false,"url":"https://github.com/UKHomeOffice/hubpress.io","license":null,"readme":":toc: macro\n:toclevels: 4\n:sectnums:\n\n= HubPress\n\ntoc::[]\n\nA free, open source tool you can use to build a blog using GitHub Pages and http://asciidoctor.org/docs/user-manual/[AsciiDoc].\n\nhttps://gratipay.com/hubpress/[HubPress] on Gratipay image:https://avatars1.githubusercontent.com/u/1744073?v=3&s=24[].\n\n== What Is HubPress?\nimage::http://hubpress.io/img/editor.png[]\n\nHubPress is a web application that makes it easy for you to maintain a blog. It provides the following features:\n\n* WYSIWYG editor for writing blog posts.\n* Backed by the power of http://asciidoctor.org/docs/user-manual/[AsciiDoc markup] for tight control of content presentation to your requirements.\n* Administration console to customise many aspect of your blog's content.\n* Disqus integration for blog comments.\n* Google Analytics integration to track visitor activity. \n* A number of different themes shipped with the product, ready to use.\n\nHosting for your blog is provided by GitHub Pages.\n\nIf you see something wrong with the documentation, please raise an issue. Your help with improving every aspect of HubPress is greatly appreciated. Pull Requests are *always* welcome. \n\nSee the link:CONTRIBUTING.adoc[Contributors Guide] for more information about being a successful HubPress contributor.\n\n== Browser Compatibility\n\nHubPress is compatible with Chrome Desktop, Firefox Desktop, and Chrome for Android.\n\n== Getting Started\n\n=== Fork the Repository\n\nClick the Fork icon image:http://hubpress.io/img/fork-icon.png[Fork,80] to create a copy of this repository within your GitHub account.\n\n=== Use the github.io Domain\n\nIf you have never used your GitHub Pages domain before, you can use this procedure to quickly set up HubPress. With this method, only a few steps are required to get HubPress deployed and ready for use.\n\nIMPORTANT: If you are currently using your `username.github.io` GitHub Pages domain for another project, or if you want to use a custom domain name, skip to the next procedure for instructions.\n\n. Rename your repository to `<username>.github.io`\n\n. Set values in `hubpress/config.json`\n+\nimage:http://hubpress.io/img/edit-config.png[Edit config]\n+\nThe following parameters are mandatory:\n+\n* `username`, which is your GitHub user name,\n* `repositoryName`, which is the new name of the repository fork, `<username>.github.io`.\n. Commit the changes, and open the GitHub Pages domain:  `https://<username>.github.io/`.\n. The following screen indicates you have correctly configured HubPress\n+\nimage:http://hubpress.io/img/home-install.png[Install complete,300]\n\n=== Use a Custom Domain or GitHub Page Domain Already In Use\n\nIf you want your blog to be available on a custom domain, or you are already using your GitHub Pages domain to host another project, some extra configuration is required.\n\n. In the repository settings, set the default branch to `gh-pages`:\n+\nimage:http://hubpress.io/img/settings-gh-pages.png[Settings gh-pages,400]\n. Switch your repository to the `gh-pages` branch.\n+\nimage:http://hubpress.io/img/switch-gh-pages.png[Install complete,300]\n+\n. Set the required values in `hubpress/config.json`\n+\nimage:http://hubpress.io/img/edit-config-gh-pages.png[Edit config]\n+\nThe following parameters are mandatory:\n+\n* `username`, which is your GitHub user name,\n* `repositoryName`, which is the repository fork. For example, `hubpress.io` if you did not rename it.\n. Commit the changes, and open the GitHub Pages domain:  `https://<username>.github.io/<repositoryName>/`.\n. The following screen indicates you have correctly configured HubPress\n+\nimage:http://hubpress.io/img/home-install.png[Install complete,300]\n\nNow you have successfully configured HubPress, you can customise it by adding social network information, experiment with different themes, and make your HubPress blog your own. \n\nSee the link:Administration.adoc[Administration Guide] for the next steps you need to take in setting up your HubPress blog.\n\nOnce you've completed the configuration aspects, you can write your first blog post. Follow the guidelines in the link:Writers_Guide.adoc[Writer's Guide] to write a sucessful first blog post.\n\n== HubPress Team\n\nCode by http://github.com/anthonny[Anthonny Quérouil] (Twitter - http://twitter.com/anthonny_q[@anthonny_q]).\n\nEnglish Docs by http://github.com/jaredmorgs[Jared Morgan]  (Twitter - http://twitter.com/jaredmorgs[@jaredmorgs]).\n\nTranslations (Japanese) by:\n\n* https://github.com/takkyuuplayer[takkyuuplayer], \n* https://github.com/hinaloe[hinaloe].\n\n== Donations\n\nHubPress is now on https://gratipay.com/hubpress/[Gratipay]! \n\nimage::https://cloud.githubusercontent.com/assets/2006548/12901016/7b09da22-ceb9-11e5-93f7-16ab135b2e2e.png[]\n\nIt's not the only way you can help us, but it is certainly a welcome one. \nDonations are a great way to show your appreciation for the platform: it inspires us to dedicate extra time away from our families and day jobs to make HubPress an awesome blogging platform for you.\n\nimage::https://cloud.githubusercontent.com/assets/2006548/12901085/cc5ee908-ceb9-11e5-9d8b-c526f081f1e9.png[]\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/firearms-prototype","private":false,"url":"https://github.com/UKHomeOffice/firearms-prototype","license":null,"readme":"# Unofficial Static Government Digital Prototype kit\nSimple prototyping kit for GOV.UK service designers. This kit does not contain all of the functionality of the express kit, however, you will not need node.js or git experience, and you will not need to run anything in command line.\n\nCreated internally at Home Office Digital - not supported, not created by GDS, supplied as-is\n\nThis is not finished! It's Alpha Alpha!\n\n## Getting Started\n\n#### You will need:\n- A mac (sorry, this isn't tested on PCs yet)\n\n#### Nice to have:\n- _Some_ HTML knowledge\n\nFirst, either:\n\n- Download a zip of this repository from https://github.com/tjharrop/simple_prototype_kit/archive/master.zip and unzip it to your computer\n\n*- OR -*\n\n- If you're comfortable with git, either clone the repo in the git desktop client or via command line (`git clone https://github.com/tjharrop/simple_prototype_kit.git`)\n\nOnce you have the folder on your computer, you will see the index.html and example files. The example files contain demonstrations of various pieces of functionality. index.html has buttons to guide you through each page. Full instructions on each demo to follow.\n\n## Running the thing\n\nThere are 2 options here. You can either open index.html in Safari or Firefox directly or you can run a small script which will allow you to use chrome.\n\n#### Using Safari or Firefox\n1. Cmd + click index.html in Finder\n2. Open With\n3. Select Safari or Firefox\n\n#### Using Chrome (recommended)\n\n_You may see an unauthorised developer warning message. If you do, cmd + click and click \"open\" instead (thanks Joe)_\n\n1. Double click run.command (see above if you get a warning)\n2. In chrome, go to http://localhost:1987/index.html\n\n## Working on it\n\nA good place to start in index.html.\n\n1. Open this in your chosen HTML editor (if you don't have one, see https://atom.io/).\n2. Hack away! Change some content, add some buttons or form fields according to your design\n3. Press refresh in your browser.\n\n#### Changing the service name\n\nThere is a file called service-name.txt which looks like this:\n\n```Digital Service Name```\n\n1. Open it\n2. Change it to your service name\n3. Save it\n\n#TODO\n\n1. Full instructions on the examples pages\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/evw-integration-stub","private":false,"url":"https://github.com/UKHomeOffice/evw-integration-stub","license":null,"readme":"# EVW Integration Stub\n\nA stub service to mock RESTful communication between Electronic Visa Waiver Customer and Caseworker applications. Built using [Dyson](https://www.npmjs.com/package/dyson)\n\n[![npm version](https://img.shields.io/npm/v/evw-integration-stub.svg?style=flat-square)](https://www.npmjs.com/package/evw-integration-stub)\n\n## Run\n\n```\nINTEGRATION_SERVICE_URL={$someURL} ./node_modules/.bin/evw-interation-stub\n```","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/hof-template-partials","private":false,"url":"https://github.com/UKHomeOffice/hof-template-partials","license":null,"readme":"# HOF-template-partials\n\nHome Office Forms template partials is a collection of mustache partials commonly used in HOF applications.  It also contains a collection of i18n translations used within the template partials. All contents are designed to be extended in your individual applications.\n\n## installation\n\n```bash\n$ npm install --save hof-template-partials\n```\n\n## Usage\n\n### Template partials\n\n#### Standalone\n\nTemplate partials can be used by adding the route to the views directory to your express application views setting. You will need to be using the HTML view engine with Hogan and Mustache.\n\n```js\nvar app = require('express')();\n\napp.set('view engine', 'html');\napp.set('views', [\n  // your application shared views\n  path.resolve(__dirname, './path/to/views'),\n  // the module exports paths to views and translations directories\n  require('hof-template-partials').views\n]);\n```\n\nThe views are now available when calling `res.render('view-name')` from express.\n\n#### HOF Application\n\nWhen used in a hof application in conjunction with [express-partial-templates](https://github.com/UKHomeOffice/express-partial-templates) the contents of the views directory are added to `res.locals.partials`. These are added right to left so conflicting views are resolved from the left-most directory.\n\n```js\nvar app = require('express')();\n\napp.set('view engine', 'html');\napp.set('views', [\n  path.resolve(__dirname, './path/to/views'),\n  require('hof-template-partials').views\n]);\napp.use(require('express-partial-templates')(app));\n\napp.use(function (req, res, next) {\n  // res.locals.partials contains all views from the views dir in this repo\n  // which are extended by any local views in ./path/to/views\n  next();\n});\n```\n\n### Translations\n\n#### Standalone\n\nThe provided translations are designed to be used in conjunction with a translations library such as [i18n-future](https://github.com/lennym/i18n-future). The source files are compiled automatically post-install. If you need to re-compile run the following:\n\n```bash\n$ npm run transpile\n```\n\nThe compiled translations file can be found at `hof-template-partials/translations/{lang}/default.json.`\n\nTo use with i18n-future:\n\napp.js\n```js\nvar i18n = require('i18n-future')({\n  path: require('hof-template-partials').translations\n});\n\ni18n.on('ready', function () {\n  var lookedup = i18n.translate('key');\n});\n```\n\n#### HOF Application\n\nThe provided translations can be combined with your application shared and route specific translations by using [hof-transpiler](https://github.com/UKHomeOffice/hof-transpiler). You can run the following script:\n\n```bash\n$ npm install hof-transpiler\n$ ./node_modules/.bin/hof-transpiler path/to/translations/src -w --shared path/to/shared/translations/src --shared node_modules/hof-template-partials/translations/src\n```\n\nor add the following to `scripts` in `package.json`\n```json\n\"scripts\": {\n  \"transpile\": \"hof-transpiler path/to/translations/src -w --shared path/to/shared/translations/src --shared node_modules/hof-template-partials/translations/src\"\n}\n```\n\nand run with:\n\n```bash\n$ npm run transpile\n```\n\nThis will extend from right to left so any duplicate keys will be overwritten by the left-most source.\n\n### Rendering Terms & Conditions and Cookies\n\nThese templates are scoped to their respective translation files so you would render them in the following way:\n\napp.js\n```js\napp.get('/terms', function (req, res, next) {\n  i18n.on('ready', function () {\n    // express will look for a terms.html template in the\n    // directories defined earlier\n    res.render('terms', i18n.translate('terms'))\n  });\n});\n```\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/hof-boilerplate","private":false,"url":"https://github.com/UKHomeOffice/hof-boilerplate","license":{"key":"gpl-3.0","name":"GNU General Public License v3.0","spdxId":"GPL-3.0","url":"https://api.github.com/licenses/gpl-3.0","featured":true},"readme":"HOF-Boilerplate\n---------------\n\nBoilerplate is a template for HOF services. Copy the repository, update the package and configure the forms.\n\n## Quick start\n\nGet it `git clone git@github.com:UKHomeOffice/hof-boilerplate.git`\n\nOpen `package.json` and edit the `name` and `description` and `repository` fields.\n\n__Hint__: Those fields need to describe elements of the service you are building.\n\nInstall everything: `npm install`\n\nOpen `app.js` in you editor of choice and start configuring your service.\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/centralteam_ci","private":false,"url":"https://github.com/UKHomeOffice/centralteam_ci","license":null,"readme":"# centralteam_ci\nLooking at CI solutions centrally as a strategic goal for HO\n\n## Open source\n\n* [Buildbot](http://buildbot.net/) - Python-based toolkit for continuous integration.\n* [Drone](https://github.com/drone/drone) - Continuous integration server built on Docker and configured using YAML files.\n* [Go](http://www.go.cd/) - Open source continuous delivery server.\n* [Jenkins](http://jenkins-ci.org/) - An extendable open source continuous integration server.\n* [Concourse](https://concourse.ci) Rather than a myriad of checkboxes, pipelines are defined as a single declarative config file\n* [ElectricFlow](http://electric-cloud.com/products/electricflow/)  ElectricFlow/ElectricCommander gives distributed teams shared control and visibility into infrastructure, tool chains and processes. It accelerates and automates the software delivery process to enable agility, predictability and security across many build-test-deploy pipelines\n* [rundesk](http://rundeck.org) Rundeck features fine-grain access controls, a built-in job scheduler, and the ability to define workflows that dispatch commands and scripts to your nodes.\n* [strider](http://stridercd.com) Strider is an Open Source Continuous Deployment / Continuous Integration platform. It is written in Node.JS / JavaScript and uses MongoDB as a backing store.\n\n## Services\n\n* [Buildkite](https://buildkite.io/)\n* [CircleCI](https://circleci.com/)\n* [Cloudbees](http://www.cloudbees.com/)\n* [Codeship](https://codeship.io/)\n* [Drone.io](https://drone.io/)\n* [Shippable](http://www.shippable.com/)\n* [Snap-CI](https://www.snap-ci.com/)\n* [Travis-CI](https://travis-ci.org/)\n* [Wrecker](https://app.wercker.com/)\n* [Solano CI](https://www.solanolabs.com)  Faster Continuous Integration and Deployment with patented auto-parallelization. See results 10 to 80x faster. 14-day free trial. No credit card required.\n* [Teamcity](http://www.jetbrains.com/teamcity/index.html)  Ready to work, extensible\n* [bamboo](https://www.atlassian.com/software/bamboo)  Bamboo does more than just run builds and tests. It connects issues, commits, test results, and deploys so the whole picture is available to your entire product team and developer-friendly build server out of the box\n* [quickbuild](http://www.pmease.com/)  GitHub integration. Perforce shelve support. Coverity report rendering. Subversion external change retrieval. Resource access info. Display reasons for waiting steps. Custom build and request columns. Favorite dash board list. Inheritable environment variables.And much more...\n* [pulse](http://zutubi.com) no free version.\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-nginx","private":false,"url":"https://github.com/UKHomeOffice/docker-nginx","license":null,"readme":"# docker-nginx\nMinimal bare nginx docker image\n\n\n### Configuration\nThere are two ways to pass nginx configuration.\n\n#### Config block via env variable\nRead in a config block preserving new lines, etc.\n\n```\nread -r -d '' NGINX_CONFIG <<'EOF'\nuser nginx;\nworker_processes auto;\nerror_log /dev/stderr error;\n\nevents {\n    worker_connections 1024;\n}\n\nhttp {\n    sendfile            on;\n    tcp_nopush          on;\n    tcp_nodelay         on;\n    keepalive_timeout   65;\n    types_hash_max_size 2048;\n\n    include             /etc/nginx/mime.types;\n    default_type        application/octet-stream;\n\n    server {\n        listen       80 default_server;\n        server_name  _;\n\n        location / {\n            default_type text/plain;\n            return 200 \"Everything is OK.\\n\";\n        }\n    }\n}\nEOF\n```\n\n```\nexport NGINX_CONFIG\ndocker run -ti --rm -e NGINX_CONFIG quay.io/ukhomeofficedigital/nginx:v0.0.1\n```\n\n#### Config file via env variable\nYou can provide a config file inside a container instead.\n\n```\ndocker run -ti --rm -e NGINX_CONFIG_FILE=/config/nginx.conf quay.io/ukhomeofficedigital/nginx:v0.0.1\n```\n\n\n### Extra Configs\n\nExtra config snippets can be found in [conf.d](conf.d) directory. You can\ninclude specific files or all by adding the following to the main `nginx.conf`\nfile:\n\n```\ninclude /etc/nginx/conf.d/logging.conf;\n\n```\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/drt-passenger-splits","private":false,"url":"https://github.com/UKHomeOffice/drt-passenger-splits","license":{"key":"apache-2.0","name":"Apache License 2.0","spdxId":"Apache-2.0","url":"https://api.github.com/licenses/apache-2.0","featured":true},"readme":"Voygage Passenger Splits\n====================\n\nService reads data from Advance Passenger Information (API) which is posted to an S3 bucket,\nperforms some data crunching, and then provides a rest query endpoint so that other parts of DRT can ask\n\n?) What is the paxSplit (passenger desk distribution) for flight BA123 @  2016-06-03 14:45 (i.e.\n  http://service:port/flight-pax-splits/port-LHR/BA123/scheduled-arrival-time-20160603T1445\n\n?) What are the paxSplits for flights a port, between 20160612T1231 and 201607T1830 (i.e.\n  http://service:port/flight-pax-splits/port-LHR?from=20160612T1231&to=2016071830\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-postgres-exec","private":false,"url":"https://github.com/UKHomeOffice/docker-postgres-exec","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Docker Postgres executor\n\nDocker container for initialising and manipulating external postgres\ndatabases by executing postgres SQL scripts.\n\n## Usage\n\nTo use this image you will need to either mount in your SQL scripts when\nyou run this image or you will need to derive a new image from this one\nand copy your scripts across in your `Dockerfile`.\n\nThe scripts should be placed in `/docker-entrypoint-initdb.d/`.\n\nAn example of executing an image built in this way can be found below:\n\n```\ndocker run \\\n       -e POSTGRES_HOST=your-postgres-server \\\n       -e POSTGRES_DB=your-db-name \\\n       -e POSTGRES_USER=your-postgres-user \\\n       -e POSTGRES_PASSWORD=your-password \\\n       your-image\n```\n\nThe login credentials can also be mounted into the image rather than\nprovided as environment variables.\n\n### Environment Variables\n\nThe variables and the defaults are shown below.\n\n* `POSTGRES_HOST` The host to connect to.\n* `POSTGRES_PORT=5432` The port to connect to.\n* `POSTGRES_DB_SECRET=/etc/postgres/db` The location in which to look for the database name.\n* `POSTGRES_USER_SECRET=/etc/postgres/user` The location in which to look for the postgres username.\n* `POSTGRES_PASSWORD_SECRET=/etc/postgres/password` The location in which to look for the postgres password.\n* `POSTGRES_DB` The database name (overrides the secret).\n* `POSTGRES_USER` The postgres username (overrides the secret).\n* `POSTGRES_PASSWORD` The postgres password (overrides the secret).\n\n## Contributing\n\nFeel free to submit pull requests and issues. If it's a particularly large PR, you may wish to discuss\nit in an issue first.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions\navailable, see the [tags on this repository](https://github.com/UKHomeOffice/docker-postgres-exec/tags).\n\n## Authors\n\n* **Daniel Martin** - *Initial work* - [Daniel A.C. Martin](https://github.com/daniel-ac-martin)\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.\n","travis":false,"contributing":false,"masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/docker-postgres-exec/branches/master/protection"}},{"name":"UKHomeOffice/docker-taurus","private":false,"url":"https://github.com/UKHomeOffice/docker-taurus","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Docker Gradle\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-taurus.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-taurus)\n\nBlazemeter Tuarus in a docker image, the version of the image / tag will match the version of Taurus and SemVer. \n\nFor more information on this please refer to: [Docker Tuarus](https://github.com/Blazemeter/taurus)\n\n## Getting Started\n\nThis is to provide the performance testing tool as part of a CI pipeline / local delivery development pipeline\nfor a service. It's to make sure that CI can operate in a complete containerised world.\n\nBlazemeter test yaml data is mounted into the container under /code where that becomes the WORKDIR and then bzt is run\nfrom that directory on the code\n\n### Environment Variables\n\n* `TAURUS_VERSION` - the version of Taurus BZT to pip install\n\n### Volumes\n\n* `/bzt` - This is where the blazmeter tests are mounted and is also the WORKDIR\n\n### Usage\n\ndocker run -v \"${PWD}\":/bzt quay.io/ukhomeofficedigital/taurus:v0.8.3\n\n## Contributing\n\nContributions are most certainly welcome. If you want to introduce a breaking\nchange or any other major change, please raise an issue first to discuss.\n\n## License\n\n[MIT](LICENSE)\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-tuf","private":false,"url":"https://github.com/UKHomeOffice/docker-tuf","license":null,"readme":"# docker-tuf\nDocker The Update Framework\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-python","private":false,"url":"https://github.com/UKHomeOffice/docker-python","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# Docker Gradle\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/docker-python.svg?branch=master)](https://travis-ci.org/UKHomeOffice/docker-python)\n\nThis is a docker python image with pip installed\n\n## Getting Started\n\nThis is a base image for python, this can be used by python projects as the base image\n\n### Environment Variables\n\n### Volumes\n\n### Other\n\n## Contributing\n\nContributions are most certainly welcome. If you want to introduce a breaking\nchange or any other major change, please raise an issue first to discuss.\n\n## License\n\n[MIT](LICENSE)\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-toolbox","private":false,"url":"https://github.com/UKHomeOffice/docker-toolbox","license":null,"readme":"# Docker Toolbox\n\n\n## Summary\n\nThis is a simple toolbox of tools for use within docker including sysdig.\n\n\n\n## Usage\n\nTo build this container or run it in your local environment use the Makefile by running:\n\n```\nmake build\n```\n\nor to run it do:\n\n```\nmake shell\n```\n\n\nTo run this container on a CoreOS node then you need to mount specific paths into the container and run it under priviledged mode to allow Sysdig to work correctly. This can be done with the following command:\n\n```\ndocker run -it --rm -v /var/run/docker.sock:/host/var/run/docker.sock -v /dev:/host/dev -v /proc:/host/proc:ro -v /boot:/host/boot:ro -v /lib/modules:/host/lib/modules:ro -v /usr:/host/usr:ro --privileged --name NAME quay.io/ukhomeofficedigital/toolbox\n```\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/hmpo-enquiries","private":false,"url":"https://github.com/UKHomeOffice/hmpo-enquiries","license":null,"readme":"# hmpo-enquiries\nA form for HMPO Passport enquiries\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/security-guide-for-developers","private":false,"url":"https://github.com/UKHomeOffice/security-guide-for-developers","license":null,"readme":"# Security Guide for Developers\n\n[Important stuff](../../wiki#really-important-stuff)\n\n[Development Process](../../wiki#development-process)\n\n[Application Design](../../wiki#application-design)\n\n[General protection](../../wiki#general-protection)\n\n[Cookies](../../wiki#cookies)\n\n[Testing](../../wiki#testing)\n\n[Running Application](../../wiki#running-application)\n\n[Validation](../../wiki#validation)\n\n[Error Handling and Logging](../../wiki#error-handling-and-logging)\n\n[Data protection](../../wiki#data-protection)\n\n[Authentication and Authorisation](../../wiki#authentication--authorisation)\n\n[Session Management](../../wiki#session-management)\n\n[Integration](../../wiki#integration)\n\n[Communication security](../../wiki#communication-security)\n\n[File uploads](../../wiki#file-uploads)\n\n[Resources](../../wiki#useful-resources-and-books)\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/pttg-acceptance","private":false,"url":"https://github.com/UKHomeOffice/pttg-acceptance","license":null,"readme":"pttg-acceptance\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/passports-prototype","private":false,"url":"https://github.com/UKHomeOffice/passports-prototype","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# passports-prototype\n\nPassport journeys\n\n# Setup\n\nClone/download this repo and run `npm install` then `npm start`.\n\nVisit <a href=\"http://localhost:3001/\" target=\"_blank\">http://localhost:3000/</a> in your browser.\n\n# View the prototype online\n\n<a href=\"http://passports-prototype.herokuapp.com/\" target=\"_blank\">http://passports-prototype.herokuapp.com/</a>\n\nIt may take a few seconds to load.\n\n# Deploying to Heroku\n\nGet yourself a Heroku account and get yourself added to the prototype app.\n\nAdd Heroku remote (that you will push to, to deploy) `heroku git:remote -a passports-prototype`\n\nUse `git push heroku master` to deploy the master branch. To deploy another branch use `git push heroku <branch-name>:master`, where <branch-name> is the branch you want to push.\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-kubectl","private":false,"url":"https://github.com/UKHomeOffice/docker-kubectl","license":null,"readme":"# kubectl\nKubernetes kubectl\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/kube-pttg-ip-fm-ui","private":false,"url":"https://github.com/UKHomeOffice/kube-pttg-ip-fm-ui","license":null,"readme":"# pttg-ip-fm-ui\nProving Things - Family Migration Income UI\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/pttg-angular","private":false,"url":"https://github.com/UKHomeOffice/pttg-angular","license":null,"readme":"# pttg-angular\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/python-sdc-client","private":false,"url":"https://github.com/UKHomeOffice/python-sdc-client","license":null,"readme":"Sysdig Cloud python client library\n===\n\n[![Build Status](https://travis-ci.org/draios/python-sdc-client.png?branch=master)](https://travis-ci.org/draios/python-sdc-client)\n[![Current version on PyPI](http://img.shields.io/pypi/v/sdcclient.svg)](https://pypi.python.org/pypi/sdcclient)\n\nA python client API for Sysdig Cloud.\n\nThis module is a wrapper around the Sysdig Cloud API, which is documented [here](http://support.sysdigcloud.com/hc/en-us/articles/205233166-The-Sysdig-Cloud-API-Specification). It exposes most of the sysdig REST API functionality as an easy to use and easy to install python interface. The repository includes a rich set of examples (in the [examples](examples/) subdir) that quickly address several use cases.\n\nInstallation\n------------\n#### Automatic w/ PyPI ([virtualenv](http://virtualenv.readthedocs.org/en/latest/) is recommended.)\n    pip install sdcclient\n\n#### Manual\n    git clone https://github.com/draios/python-sdc-client.git\n    pip install\n\nQuick start\n-----------\n- If you are interested in exporting metrics data from Sysdig Cloud, take a look at [examples/get_data_simple.py](examples/get_data_simple.py) and [examples/get_data_advanced.py](examples/get_data_advanced.py).\n- If you want to programmatically create an alert, refer to [examples/create_alert.py](examples/create_alert.py)\n- If you want to programmatically create a dashboard, refer to [examples/create_dashboard.py](examples/create_dashboard.py)\n\nUsage\n-----\n\n_Note:_ in order to use this API you must obtain a Sysdig Cloud token. You can get your user's token in the _Sysdig Cloud API_ section of the [settings](https://app.sysdigcloud.com/#/settings/user) page.\n\nThe library exports a single class, `SdcClient`, that is used to connect to Sysdig Cloud and execute actions. It can be instantiated like this:\n\n``` python\nfrom sdcclient import SdcClient\n\nsdc_token = \"MY_API_TOKEN\"\n\n#\n# Instantiate the SDC client\n#\nsdclient = SdcClient(sdc_token)\n```\n\nOnce instantiated, all the methods documented below can be called on the object.\n\n####Return Values\nEvery method in the SdcClient class returns **a list with two entries**. The first one is a boolean value indicating if the call was successful. The second entry depends on the result:\n- If the call was successful, it's a dictionary reflecting the json returned by the underlying REST call\n- If the call failed, it's a string describing the error\n\nFor an example on how to parse this output, take a look at a simple example like [get_data_simple.py](examples/get_data_simple.py) \n\nFunction List\n-------\n\nPlease Refer to the [Python Script Library documentation page](https://sysdig.gitbooks.io/sysdig-cloud-api/content/python/function_list.html) for the list of functions available.\n","travis":true,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-scala-sbt","private":false,"url":"https://github.com/UKHomeOffice/docker-scala-sbt","license":null,"readme":"# docker-scala-sbt\nEnables build of Scala apps.\n\nThis has:\n- Oracle Java\n- JCE Unlimited Security Policy\n- sbt\n- activator\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/so-acceptance","private":false,"url":"https://github.com/UKHomeOffice/so-acceptance","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"# SO Acceptance\n\nSO Acceptance is a NodeJS acceptance testing framework build on top of [CodeceptJS](https://github.com/Codeception/CodeceptJS) and is designed to be used in SO applications\n\n## Installation\n\n```bash\n$ npm install so-acceptance --save-dev\n```\n\n## Application configuration\n\n### Simple usage\n\n#### Setup\n\nFor quickstart usage you can simply npm install the library and add the following script to your package.json.\n> note - this assumes you are using NPM@3. If you are using a previous version of NPM you will need to point to the relative path of the codeceptjs exectuable. This will be located at ./node_modules/so-acceptance/.bin/codeceptjs\n\npackage.json\n```json\n\"scripts\": {\n  \"test:acceptance\": \"codeceptjs run ./node_modules/so-acceptance --steps\"\n}\n```\n\nThe root of your acceptance tests will need to be located in a folder called `acceptance_tests` in the root of your app, features are located in a subdirectory named `features`.\n\n```\n<service name>\n  |__acceptance_tests/\n       |__features/\n          |__your tests go here.\n```\n\n#### Running\n\n```bash\n$ npm run test:acceptance\n```\n\n### Session Mocking\n\n#### Setup\n\nSO Acceptance comes with session mocking so you are able to test steps independently of one another. This assumes you are using  [hof-bootstrap](https://github.com/UKHomeOffice/hof-bootstrap/) and redis for session storage.\n\n#### API\n\nThe `I` actor in CodeceptJS has been extended with the following session manipulation methods:\n\n* `getSession(route_name)`: returns the session data for the given route_name (defined in bootstrap config).\n* `setSessionData(route_name, {data})`: sets the key: value pairs in data to session for given route_name.\n* `setSessionSteps(route_name, [steps])`: sets the visited steps to session for given route name.\n\nAs these API methods all return promises, they should be used within generator functions to ensure code execution is paused while the session is manipulated:\n\n```js\nScenario('I set session steps', function *(I) {\n  yield I.setSessionSteps('journey-name', ['/', '/step-1']);\n  I.amOnPage('/step-2');\n});\n```\n\n### Extensions to the actor (`I`)\n\nThe following methods have been added to `I`:\n\n* `submitForm()`: clicks the submit button `input[type=\"submit\"]`\n* `visitPage(page, [journey], [prereqs])`: visits `'/'`, then page, prepending journey if present, and setting prereq steps. Page and Prereqs are expected to be [PageObjects](https://github.com/Codeception/CodeceptJS/blob/master/docs/pageobjects.md) with a `url` property.\n* `seeErrors(errors)`: accepts either an array of keys or a single key, and checks for validation errors related to the element.\n* `seeElements(elements)`: accepts either an array of selectors or a single selector and checks all elements are present on the page.\n* `refreshPage()`: refreshes the page - async, should be called within a generator.\n* `seeEach(texts)`: accepts an array of text and checks all texts are present on the page`.\n\n### Customisation\n\nYou can add any customisation options in `acceptance_tests/codecept.conf.js`. The default options are extended with overrides defined here.\n\ncodecept.conf.js\n```js\nvar path = require('path');\n\nmodule.exports = {\n  name: 'name of your app',\n  include: {\n    customPage: path.resolve(__dirname, './pages/custom.js')\n  }\n}\n```\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/nginx-statsd","private":false,"url":"https://github.com/UKHomeOffice/nginx-statsd","license":null,"readme":"nginx-statsd\n============\n\nAn nginx module for sending statistics to statsd.\n\nThis is how to use the nginx-statsd module:\n\n\thttp {\n\t\t\n\t\t# Set the server that you want to send stats to.\n\t\tstatsd_server your.statsd.server.com;\n\n\t\t# Randomly sample 10% of requests so that you do not overwhelm your statsd server.\n\t\t# Defaults to sending all statsd (100%). \n\t\tstatsd_sample_rate 10; # 10% of requests\n\n\n\t\tserver {\n\t\t\tlisten 80;\n\t\t\tserver_name www.your.domain.com;\n\t\t\t\t\n\t\t\t# Increment \"your_product.requests\" by 1 whenever any request hits this server. \n\t\t\tstatsd_count \"your_product.requests\" 1;\n\n\t\t\tlocation / {\n\t\t\t\t\n\t\t\t\t# Increment the key by 1 when this location is hit.\n\t\t\t\tstatsd_count \"your_product.pages.index_requests\" 1;\n\n\t\t\t\t# Increment the key by 1, but only if $request_completion is set to something.\n\t\t\t\tstatsd_count \"your_product.pages.index_responses\" 1 \"$request_completion\";\n\n\t\t\t\t# Send a timing to \"your_product.pages.index_response_time\" equal to the value\n\t\t\t\t# returned from the upstream server. If this value evaluates to 0 or empty-string,\n\t\t\t\t# it will not be sent. Thus, there is no need to add a test.\n\t\t\t\tstatsd_timing \"your_product.pages.index_response_time\" \"$upstream_response_time\";\n\n\t\t\t\t# Increment a key based on the value of a custom header. Only sends the value if\n\t\t\t\t# the custom header exists in the upstream response.\n\t\t\t\tstatsd_count \"your_product.custom_$upstream_http_x_some_custom_header\" 1 \n\t\t\t\t\t\"$upstream_http_x_some_custom_header\";\n\n\t\t\t\tproxy_pass http://some.other.domain.com;\n\t\t\t}\n\t\t}\n\t}\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/drone-trigger","private":false,"url":"https://github.com/UKHomeOffice/drone-trigger","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# drone-trigger\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/drone-trigger.svg?branch=master)](https://travis-ci.org/UKHomeOffice/drone-trigger) [![Docker Repository on Quay](https://quay.io/repository/ukhomeofficedigital/drone-trigger/status \"Docker Repository on Quay\")](https://quay.io/repository/ukhomeofficedigital/drone-trigger)\n\nDrone plugin for triggering downstream builds with custom parameters\n\nThis plugin allows for triggering remote or local builds. You can specify\nvarious filters, like `tag`, `branch`, `number`, `commit`, etc. It will find an\nexisting build which matches specified filters and trigger the build restart or\ndeployment, in addition, custom parameters can also be set.\n\n## Build\n\nDependencies are located in the vendor directory and managed using\n[govendor](https://github.com/kardianos/govendor) cli tool.\n\n```\ngo test -v -cover\n\nmkdir -p bin\nGOOS=linux GOARCH=amd64 CGO_ENABLED=0 go build -ldflags \"-X main.Version=dev+git\" -o bin/drone-trigger_linux_amd64\n```\n\n## Configuration\n\nThe following parameters are used to configure the plugin:\n\n- `drone_server`: full URL to the drone server, it can be a remote drone server as well\n- `drone_token` or `${DRONE_TOKEN}`: drone user secret token. Just create a `DRONE_TOKEN` secret, the plugin will pick it up\n- `repo`: git repository in owner/name format\n- `status`: build status filter, default is `success`\n- `event`: build event type filter. If unset, no event filter will be done\n- `deploy_to`: sends a deployment trigger, which also sets a `DRONE_DEPLOY_TO` environment variable in the target job\n- `params`: list of custom parameters that will be passed into a build environment as environment variables\n- `fork`: create a new build and a build number instead of restarting an existing build. Please note that a deployment trigger always spawns a new build\n- `verbose`: displays a more verbose output\n\nOnly one filter from the below list can be specified.\n- `number`: filter by specific build number\n- `commit`: filter by long commit sha\n- `branch`: filter by branch name\n- `tag`: filter by tag name. Please note that event type will be `tag`.\n\n\n### Drone configuration\n\n```yaml\npipeline:\n  build:\n    image: golang\n    commands:\n      - go get -v\n      - ...\n\n  docker_build:\n    image: docker:1.11\n    commands:\n      - docker login ...\n      - docker build -t foo/bar:${DRONE_COMMIT_SHA} .\n      - docker push foo/bar:${DRONE_COMMIT_SHA}\n\n  trigger_deploy:\n    image: quay.io/ukhomeofficedigital/drone-trigger:latest\n    drone_server: https://drone.example.com\n    repo: owner/go-deploy-scripts\n    branch: master\n    deploy_to: prod\n    params:\n      - IMAGE_NAME=foo/bar:${DRONE_COMMIT_SHA}\n```\n\n\nSince drone-trigger can be run as a standalone tool, configuration can be\nprovided via cli flags and arguments as well as environment variables.\n\n```bash\ndrone-trigger --help\nNAME:\n   drone-trigger - trigger drone builds or deployments\n\nUSAGE:\n   drone-trigger_linux_amd64 [global options] command [command options] [arguments...]\n\nCOMMANDS:\n     help, h  Shows a list of commands or help for one command\n\nGLOBAL OPTIONS:\n   --verbose                      verbose output [$VERBOSE, $PLUGIN_VERBOSE]\n   --fork                         fork an existing build - drone assigns a new build number [$FORK, $PLUGIN_FORK]\n   --drone-server URL, -s URL     drone server URL [$DRONE_SERVER, $PLUGIN_DRONE_SERVER]\n   --drone-token TOKEN, -t TOKEN  drone auth TOKEN [$DRONE_TOKEN, $PLUGIN_DRONE_TOKEN]\n   --repo REPO, -r REPO           REPO, eg. foo/bar [$REPO, $PLUGIN_REPO]\n   --commit value, -c value       filter by commit sha [$FILTER_COMMIT, $PLUGIN_COMMIT]\n   --tag value                    filter by tag [$FILTER_TAG, $PLUGIN_TAG]\n   --branch value, -b value       filter by branch [$FILTER_BRANCH, $PLUGIN_BRANCH]\n   --status value                 filter by build status (default: \"success\") [$FILTER_STATUS, $PLUGIN_STATUS]\n   --number value                 filter by build number (default: 0) [$FILTER_NUMBER, $PLUGIN_NUMBER]\n   --event value                  filter by trigger event [$FILTER_EVENT, $PLUGIN_EVENT]\n   --deploy-to value, -d value    environment to deploy to, if set a deployment event will be triggered [$DEPLOY_TO, $PLUGIN_DEPLOY_TO]\n   --param value, -p value        custom parameters to include in the trigger in KEY=value format [$PARAMS, $PLUGIN_PARAMS]\n   --help, -h                     show help\n   --version, -v                  print the version\n\n```\n\n## Release process\n\nPush / Merge to master will produce a docker\n[image](https://quay.io/repository/ukhomeofficedigital/drone-trigger?tab=tags) with a tag `latest`.\n\nTo create a new release, just create a new tag off master.\n\n## Contributing\n\nWe welcome pull requests. Please check issues and existing PRs before submitting a patch.\n\n## Author\n\nVaidas Jablonskis [vaijab](https://github.com/vaijab)\n\n","travis":true,"contributing":false,"masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/drone-trigger/branches/master/protection","requiredStatusChecks":{"url":"https://api.github.com/repos/UKHomeOffice/drone-trigger/branches/master/protection/required_status_checks","strict":true,"includeAdmins":true,"contextsUrl":"https://api.github.com/repos/UKHomeOffice/drone-trigger/branches/master/protection/required_status_checks/contexts"},"restrictions":{"url":"https://api.github.com/repos/UKHomeOffice/drone-trigger/branches/master/protection/restrictions","users":[],"usersUrl":"https://api.github.com/repos/UKHomeOffice/drone-trigger/branches/master/protection/restrictions/users","teams":[],"teamsUrl":"https://api.github.com/repos/UKHomeOffice/drone-trigger/branches/master/protection/restrictions/teams"}}},{"name":"UKHomeOffice/court-flagging","private":false,"url":"https://github.com/UKHomeOffice/court-flagging","license":{"key":"gpl-3.0","name":"GNU General Public License v3.0","spdxId":"GPL-3.0","url":"https://api.github.com/licenses/gpl-3.0","featured":true},"readme":"<<<<<<< HEAD\n# CFN (Court Flagging Notification)\n\n## Getting Started\n\n### Prerequisities\n\n- [Node.js](https://nodejs.org/en/) - Tested against LTS\n- NPM (installed with Node.js) - Works with versions 2 and 3.\n- [Redis server](http://redis.io/download) running on the default port\n\n### Up & Running\n\n```bash\n$ cd cfn\n$ npm install\n$ npm run dev\n```\n\nThen visit: [http://localhost:8080/](http://localhost:8080/)\n\n## Testing\n\n### Acceptance Tests\nWith the server running in development mode (`npm run dev`), start the acceptance tests:\n\n```bash\n$ npm run test:acceptance\n```\nPhantomjs is required to run the acceptance tests (`npm install phantomjs`), or alternatively, export `IN_BROWSER=true` to run the tests in Firefox.\n\n### Unit Tests\n```bash\n$ npm t\n```\n\n## Contributing\n\nPlease read [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct, and the process for submitting pull requests to us.\n\n## Versioning\n\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see the [tags on this repository](https://github.com/your/project/tags).\n\n## License\n\nThis project is licensed under the GPLv2 License - see the [LICENSE.md](LICENSE.md) file for details\n=======\n# court-flagging\nWeb service for Court Flag Notifications\n>>>>>>> 85953f3c21d587096fbb21dfa64aa043b1625ed2\n","travis":false,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/rtp-monitoring-metrics","private":false,"url":"https://github.com/UKHomeOffice/rtp-monitoring-metrics","license":null,"readme":"# RTP monitoring and metrics\n\nThis module is intended to be used with node.js web apps using Express. It exports an express router which provides useful endpoints.\n \n### Endpoints provided\n\nThe following endpoints are provided:\n\n##### GET `/metrics`\n\nThis will return metrics in the following JSON format, with HTTP 200:\n\n``` json\n{\n  \"cpu\": 5.5,\n  \"memory\": {\n    \"rss\": 92643328,\n    \"heapTotal\": 71131392,\n    \"heapUsed\": 40280776\n  }\n}\n```\n\n*Note: if an error occurs attempting to generate the metrics HTTP 500 will be returned with JSON containing the error*\n\n##### GET `/healthz`\n\nThis will check that a session store is available and return HTTP 200 all is ok. The JSON response will be in the following format:\n \n``` json\n{\n  \"app\": \"OK\",\n  \"session\": \"OK\"\n}\n```\n\nIf the request to the endpoint times out then the app is not alive. Also if there is not a session store available HTTP 500 will be returned and it will state \"unavailable\".\n\n##### GET `/readiness`\n\nThe readiness endpoint operates exactly the same as the `/healthz` endpoint.\n\n### How to use\n\n1. Add this module to your application using `npm install --save rtp-monitoring-metrics`\n2. Add the exported router to you app: `app.use(require('rtp-monitoring-metrics'));`\n\n### Additional configuration\n\nIf you would like to mount the middleware functions under a sub-route, you can do so using express out the box\n\n```\napp.use('/path-to-mount-at', require('rtp-monitoring-metrics'));\n```\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/kube-pttg-fs-ui","private":false,"url":"https://github.com/UKHomeOffice/kube-pttg-fs-ui","license":null,"readme":"# kube-pttg-fs-ui\nFinanical Status service UI\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/kube-pttg-fs-stub","private":false,"url":"https://github.com/UKHomeOffice/kube-pttg-fs-stub","license":null,"readme":"## Proving Things - Income Barclays stub -  Kubernetes Resources\n\n### Kubernetes Deployment\n\nThis is the kubernetes deployment files for Proving Things Financial Status Barclays Stub\n\nrun deployment\n\n\t./scripts/deploy_kd\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/kube-pttg-fs-api","private":false,"url":"https://github.com/UKHomeOffice/kube-pttg-fs-api","license":null,"readme":"## Proving Things - Income API -  Kubernetes Resources\n\n### Kubernetes Deployment\n\nThis is the kubernetes deployment files for Proving Things Financial Status API\n\nrun deployment\n\n\t./scripts/deploy_kd\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/evw-customer-hof","private":false,"url":"https://github.com/UKHomeOffice/evw-customer-hof","license":{"key":"gpl-2.0","name":"GNU General Public License v2.0","spdxId":"GPL-2.0","url":"https://api.github.com/licenses/gpl-2.0","featured":false},"readme":"[![Build Status](https://travis-ci.org/UKHomeOffice/evw-customer-hof.svg?branch=master)](https://travis-ci.org/UKHomeOffice/evw-customer-hof)\n[![Dependency Status](https://david-dm.org/UKHomeOffice/evw-customer-hof.svg)](https://david-dm.org/UKHomeOffice/evw-customer-hof)\n[![devDependency Status](https://david-dm.org/UKHomeOffice/evw-customer-hof/dev-status.svg)](https://david-dm.org/UKHomeOffice/evw-customer-hof#info=devDependencies)\n\n# EVW Customer HOF\n\nA HOF version of the EVW Customer form.\n\n### Prerequisities\n\nThings you need to install the software and how to install them\n- [NodeJS](https://nodejs.org/en/)\n- npm (bundled with node)\n- [MongoDB](https://www.mongodb.com) running on the default port\n\n### Installing\n\n```bash\n$ mongod &\n$ npm install\n$ npm run dev\n```\n\nGo to http://localhost:8080/start\n\n## Running the tests\nYou will need the server running to run the cucumber tests against.\n\n```bash\n$ node_modules/.bin/nightwatch\n$ # or run in chrome and firefox in parallel 🤘🏽😝🤘🏽\n$ node_modules/.bin/nightwatch  -e chrome,firefox\n$ # or via npm scripts\n$ npm run test:acceptance\n```","travis":true,"contributing":"# Contributing\n\nWhen contributing to this repository, please first discuss the change you wish to make via issue,\nemail, or any other method with the owners of this repository before making a change. \n\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\n\n## Pull Request Process\n\n1. Ensure any install or build dependencies are removed before the end of the layer when doing a \n   build.\n2. Update the README.md with details of changes to the interface, this includes new environment \n   variables, exposed ports, useful file locations and container parameters.\n3. Increase the version numbers in any examples files and the README.md to the new version that this\n   Pull Request would represent. The versioning scheme we use is [SemVer](http://semver.org/).\n4. You may merge the Pull Request in once you have the sign-off of two other developers, or if you \n   do not have permission to do that, you may request the second reviewer to merge it for you.\n\n## Contributor Code of Conduct\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and \nwelcoming community, we pledge to respect all people who contribute through reporting issues, \nposting feature requests, updating documentation, submitting pull requests or patches, and other \nactivities.\n\nWe are committed to making participation in this project a harassment-free experience for everyone, \nregardless of level of experience, gender, gender identity and expression, sexual orientation, \ndisability, personal appearance, body size, race, ethnicity, age, religion, or nationality.\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery\n* Personal attacks\n* Trolling or insulting/derogatory comments\n* Public or private harassment\n* Publishing other's private information, such as physical or electronic addresses, without explicit\n  permission\n* Other unethical or unprofessional conduct.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, \ncode, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. By \nadopting this Code of Conduct, project maintainers commit themselves to fairly and consistently \napplying these principles to every aspect of managing this project. Project maintainers who do not \nfollow or enforce the Code of Conduct may be permanently removed from the project team.\n\nThis code of conduct applies both within project spaces and in public spaces when an individual is \nrepresenting the project or its community.\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by opening an \nissue or contacting one or more of the project maintainers.\n\nThis Code of Conduct is adapted from the [Contributor Covenant](http://contributor-covenant.org), \nversion 1.2.0, available at \n[http://contributor-covenant.org/version/1/2/0/](http://contributor-covenant.org/version/1/2/0/)\n","masterBranchProtection":false},{"name":"UKHomeOffice/kd","private":false,"url":"https://github.com/UKHomeOffice/kd","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# kd - Kubernetes resources deployment tool\n\n[![Build Status](https://travis-ci.org/UKHomeOffice/kd.svg?branch=master)](https://travis-ci.org/UKHomeOffice/kd) [![Docker Repository on Quay](https://quay.io/repository/ukhomeofficedigital/kd/status \"Docker Repository on Quay\")](https://quay.io/repository/ukhomeofficedigital/kd)\n\nThis is a very minimalistic tool for deploying kubernetes resources.\n\n## Features\n\n- Go template engine support\n- Supports any kubernetes resource type\n- Polls deployment resources for completion\n\n\n## Getting Started\n\nThe is only requirement and that is a kubectl binary in your `${PATH}`. You\ncan use the docker image or download the binary for your OS from\n[releases](https://github.com/UKHomeOffice/kd/releases) page.\n\nFirst, let's create a simple deployment template. Templating data comes from\nthe environment, so in this example we'll use `NGINX_IMAGE_TAG` environment\nvariable to set nginx image tag.\n\nCreate a `nginx-deployment.yaml` with the following content:\n\n```yaml\n---\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: nginx\nspec:\n  replicas: 5\n  template:\n    metadata:\n      labels:\n        name: nginx\n    spec:\n      containers:\n        - name: nginx\n          image: nginx:{{.NGINX_IMAGE_TAG}}\n          ports:\n            - containerPort: 80\n          resources:\n            limits:\n              cpu: \"0.1\"\n          livenessProbe:\n            httpGet:\n              path: /\n              port: 80\n            initialDelaySeconds: 10\n            timeoutSeconds: 1\n```\n\n```bash\n$ export NGINX_IMAGE_TAG=1.11-alpine\n$ kd --context=mykube --namespace=testing --file nginx-deployment.yaml\n[INFO] 2016/09/21 14:06:37 main.go:153: deploying deployment/nginx\n[INFO] 2016/09/21 14:06:38 main.go:157: deployment \"nginx\" submitted\n[INFO] 2016/09/21 14:06:41 main.go:194: deployment \"nginx\" in progress. Unavailable replicas: 5.\n[INFO] 2016/09/21 14:06:56 main.go:194: deployment \"nginx\" in progress. Unavailable replicas: 5.\n[INFO] 2016/09/21 14:07:11 main.go:190: deployment \"nginx\" is complete. Available replicas: 5\n```\n\nYou can fail an ongoing deployment if there's been a new deployment by adding `--fail-superseded` flag.\n\n## Configuration\n\nConfiguration can be provided via cli flags and arguments as well as\nenvironment variables.\n\n```bash\n$ kd --help\n\nNAME:\n   kd - simple kubernetes resources deployment tool\n\nUSAGE:\n   kd [global options] command [command options] [arguments...]\n   \nVERSION:\n   v0.2.0\n\nAUTHOR(S):\n   Vaidas Jablonskis <jablonskis@gmail.com> \n   \nCOMMANDS:\n     help, h  Shows a list of commands or help for one command\n\nGLOBAL OPTIONS:\n   --debug                              debug output [$DEBUG, $PLUGIN_DEBUG]\n   --insecure-skip-tls-verify           if true, the server's certificate will not be checked for validity [$INSECURE_SKIP_TLS_VERIFY, $PLUGIN_INSECURE_SKIP_TLS_VERIFY]\n   --kube-server URL, -s URL            kubernetes api server URL [$KUBE_SERVER, $PLUGIN_KUBE_SERVER]\n   --kube-token TOKEN, -t TOKEN         kubernetes auth TOKEN [$KUBE_TOKEN, $PLUGIN_KUBE_TOKEN]\n   --context CONTEXT, -c CONTEXT        kube config CONTEXT [$KUBE_CONTEXT, $PLUGIN_CONTEXT]\n   --namespace NAMESPACE, -n NAMESPACE  kubernetes NAMESPACE [$KUBE_NAMESPACE, $PLUGIN_KUBE_NAMESPACE]\n   --fail-superseded                    fail deployment if it has been superseded by another deployment. WARNING: there are some bugs in kubernetes. [$FAIL_SUPERSEDED, $PLUGIN_FAIL_SUPERSEDED]\n   --file value, -f value               list of kubernetes resources FILE [$FILES, $PLUGIN_FILES]\n   --retries value                      number of deployment status check retries (default: 10) [$RETRIES, $PLUGIN_RETRIES]\n   --check-interval value               deployment status check interval (default: 15s) [$CHECK_INTERVAL, $PLUGIN_CHECK_INTERVAL]\n   --help, -h                           show help\n   --version, -v                        print the version\n```\n\n\n## Build\n\nDependencies are located in the vendor directory and managed using\n[govendor](https://github.com/kardianos/govendor) cli tool.\n\n```\ngo test -v -cover\n\nmkdir -p bin\nGOOS=linux GOARCH=amd64 CGO_ENABLED=0 go build -ldflags \"-X main.Version=dev+git\" -o bin/kd_linux_amd64\n```\n\n\n## Release process\n\nPush / Merge to master will produce a docker\n[image](https://quay.io/repository/ukhomeofficedigital/kd?tab=tags) with a tag `latest`.\n\nTo create a new release, just create a new tag off master.\n\n\n## Contributing\n\nWe welcome pull requests. Please raise an issue to discuss your changes before\nsubmitting a patch.\n\n\n## Author\n\nVaidas Jablonskis [vaijab](https://github.com/vaijab)\n\n","travis":true,"contributing":false,"masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/kd/branches/master/protection","requiredStatusChecks":{"url":"https://api.github.com/repos/UKHomeOffice/kd/branches/master/protection/required_status_checks","strict":true,"includeAdmins":true,"contextsUrl":"https://api.github.com/repos/UKHomeOffice/kd/branches/master/protection/required_status_checks/contexts"}}},{"name":"UKHomeOffice/docker-pentest","private":false,"url":"https://github.com/UKHomeOffice/docker-pentest","license":null,"readme":false,"travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/development_environment","private":false,"url":"https://github.com/UKHomeOffice/development_environment","license":null,"readme":"# Generic Secure Development Environment\n\nThese ansible scripts are free to use and follow where possible best practice guidence from the security community. Please feel free to fork this repository for your own needs and also submit pull requests to enhance or harden where approptiate.\n\nAll modules included here should work as a minimum under xfce4 with either an Ubuntu or RedHat/CentOS base image. For Ubuntu the compatability checks start at 16.04 where as for RedHat/CentOS it also supports 6.7 along with 7 and above however, continuing support for 6.7 is not required so long as the module checks to only install on OS's of a higher version.\n\n\n## Bits on the list to add\n\n* blackbox - Stackexchange\n* DNSMasq \n* aide - filesystem monitoring\n\n?? how to require a password for debian single user mode and disable interactive boot mode\n\n\n## Usage\n\n### Production\n\nTo bootstrap this job please run:\n\n```\ncurl https://raw.githubusercontent.com/UKHomeOffice/development_environment/master/install.sh | bash\n```\n\n### Development\n\nThis will install the latest tagged release, if you are developing and need a development version (not to be used on live machines but within Vagrant or test boxes) then you can run the following to pull and built the lastest development release:\n\n```\ncurl https://raw.githubusercontent.com/UKHomeOffice/development_environment/develop/install.sh | TAG=develop bash\n```\n\n\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/sheff-hub-dev-wiki","private":false,"url":"https://github.com/UKHomeOffice/sheff-hub-dev-wiki","license":null,"readme":false,"travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/evw-versions","private":false,"url":"https://github.com/UKHomeOffice/evw-versions","license":null,"readme":"# evw-versions\nA way of generating a dashboard of all deployed evw software\n\n### install\n\n`npm i`\n\n### collect\n\n`node index.js`\n\n### run\n\nuse something like [supervisor](https://github.com/petruisfan/node-supervisor)\n\n```\nsupervisor -e js,hbs app.js\n```\n\n### aspirations\n\n* [x] collect versions from application published endpoints\n* [x] enqueue all http requests using e.g. [async parallel](http://caolan.github.io/async/docs.html#.parallel)\n* [ ] loudly highlight when versions mismatch between machines\n* [ ] less loudly highlight differences between environments\n* [ ] check versions of `rtp-worldpay-stub` and `mock-integration-service`\t\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/drt-scalajs-spa-exploration","private":false,"url":"https://github.com/UKHomeOffice/drt-scalajs-spa-exploration","license":{"key":"apache-2.0","name":"Apache License 2.0","spdxId":"Apache-2.0","url":"https://api.github.com/licenses/apache-2.0","featured":true},"readme":"# Scala.js SPA-tutorial\n\n[![Gitter](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/ochrons/scalajs-spa-tutorial?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n[![Scala.js](https://www.scala-js.org/assets/badges/scalajs-0.6.8.svg)](https://www.scala-js.org)\n\nTutorial for creating a simple (but potentially complex!) Single Page Application with\n[Scala.js](http://www.scala-js.org/) and [Play](https://www.playframework.com/).\n\n## Purpose\n\nThis project demonstrates typical design patterns and practices for developing SPAs with Scala.js with special focus on\nbuilding a complete application. It started as a way to learn more about Scala.js and related libraries, but then I\ndecided to make it more tutorial-like for the greater good :)\n\nThe code covers typical aspects of building a SPA using Scala.js but it doesn't try to be an all-encompassing example\nfor all the things possible with Scala.js. Before going through this tutorial, it would be helpful if you already know\nthe basics of Scala.js and have read through the official [Scala.js tutorial](http://www.scala-js.org/doc/tutorial.html)\nand the great e-book [Hands-on Scala.js](http://lihaoyi.github.io/hands-on-scala-js/#Hands-onScala.js) by \n[Li Haoyi (@lihaoyi)](https://github.com/lihaoyi).\n\n# Documentation\n\nTutorial [documentation](https://ochrons.github.io/scalajs-spa-tutorial) is now presented as a GitBook.\n\nあなたは日本語を話せますか？Scala.js is Big in Japan, so I'm looking for help to translate the tutorial documentation into Japanese.\nContact me on twitter (@ochrons) or via email (otto@chrons.me) if you're interested!\n\n# Scala IDE users\n\nIf you are using Scala IDE, you need to set additional settings to get your Eclipse project exported from SBT.\n\n```\nset EclipseKeys.skipParents in ThisBuild := false\neclipse\n```\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/home-office-pattern-library","private":false,"url":"https://github.com/UKHomeOffice/home-office-pattern-library","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# GOV.UK Prototype kit\n\n## News\n\n**Upgrading from version 1 to 2:** the latest version of the kit (2.0.0 and later) is not compatible with previous versions. If you update your old prototypes you'll need to [convert them as well](https://github.com/alphagov/govuk_prototype_kit/blob/master/docs/updating-the-kit.md).\n\n## About the prototype kit\n\nThe prototype kit provides a simple way to make interactive prototypes that look like pages on GOV.UK. These prototypes can be used to show ideas to people you work with, and to do user research.\n\nRead the [project principles](docs/principles.md).\n\n## Security\n\nIf you publish your prototypes online, they **must** be protected by a [username and password](docs/guides/publishing-on-heroku.md). This is to prevent members of the public finding prototypes and thinking they are real services.\n\nYou must protect user privacy at all times, even when using prototypes. Prototypes made with the kit look like GOV.UK, but do not have the same security provisions. Always make sure you are handling user data appropriately. \n\n## Installation instructions\n\n- [Installation guide for new users (non technical)](docs/install/introduction.md)\n- [Installation guide for developers (technical)](docs/developer-install-instructions.md)\n\n## Guides\n\n1. [Setting up git](docs/guides/setting-up-git.md)\n2. [Publishing on the web (Heroku)](docs/guides/publishing-on-heroku.md)\n3. [Using GOV.UK Verify](docs/guides/using-verify.md)\n\n## Other documentation\n\n- [Prototype kit principles](docs/principles.md)\n- [Making pages](docs/making-pages.md)\n- [Writing CSS](docs/writing-css.md)\n- [Updating the kit to the latest version](docs/updating-the-kit.md)\n- [Tips and tricks](docs/tips-and-tricks.md)\n- [Creating routes (server-side programming)](docs/creating-routes.md)\n\n## Community\n\nWe have two Slack channels for the Prototype kit. You'll need a government email address to join them.\n\n* [Slack channel for users of the prototype kit](https://ukgovernmentdigital.slack.com/messages/prototype-kit/)\n* [Slack channel for developers of the prototype kit](https://ukgovernmentdigital.slack.com/messages/prototype-kit-dev/)\n","travis":false,"contributing":"# Contribution guidelines\n\nWe really like contributions and bug reports, in fact the project wouldn't have got to this stage without them.\nWe do have a few guidelines to bear in mind.\n\n## Community\n\nWe have two Slack channels for the Prototype kit. You'll need a government email address to join them.\n\n* [Slack channel for users of the prototype kit](https://ukgovernmentdigital.slack.com/messages/prototype-kit/)\n* [Slack channel for developers of the prototype kit](https://ukgovernmentdigital.slack.com/messages/prototype-kit-dev/)\n\n## Raising bugs\n\nWhen raising bugs please explain the issue in good detail and provide a guide to how to replicate it.\nWhen describing the bug it's useful to follow the format:\n\n- what you did\n- what you expected to happen\n- what happened\n\n## Suggesting features\n\nPlease raise feature requests as issues before contributing any code.\n\nThis ensures they are discussed properly before any time is spent on them.\n\n## GOV.UK Elements\n\nThe project contains code taken from the [GOV.UK Elements](https://github.com/alphagov/govuk_elements/) project.\nPlease check that any issues related to that code are raised with that project, not this one.\n\n## Contributing code\n\n### Indentation and whitespace\n\n2-space, soft-tabs only please. No trailing whitespace.\n\n### Versioning\n\nFollow the guidelines on [semver.org](http://semver.org/) for assigning version\nnumbers.\n\nVersions should only be changed in a commit of their own, in a pull request of\ntheir own. This alerts team members to the new version and allows for\nlast-minute scrutiny before the new version is released. Also, by raising a\nseparate pull request, we avoid version number conflicts between feature\nbranches.\n\n### Commit hygiene\n\nPlease see our [git style guide](https://github.com/alphagov/styleguides/blob/master/git.md)\nwhich describes how we prefer git history and commit messages to read.\n","masterBranchProtection":false},{"name":"UKHomeOffice/lev-api-mock","private":false,"url":"https://github.com/UKHomeOffice/lev-api-mock","license":{"key":"gpl-3.0","name":"GNU General Public License v3.0","spdxId":"GPL-3.0","url":"https://api.github.com/licenses/gpl-3.0","featured":true},"readme":"# lev-api-mock\nA mock version of the LEV API (and downstream) backend systems\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-drone","private":false,"url":"https://github.com/UKHomeOffice/docker-drone","license":null,"readme":"# Drone docker image\n\n[![Docker Repository on Quay](https://quay.io/repository/ukhomeofficedigital/drone/status \"Docker Repository on Quay\")](https://quay.io/repository/ukhomeofficedigital/drone)\n\nThis image trusts [DSP CA](https://github.com/UKHomeOffice/dsp-root-ca).\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/dsp-root-ca","private":false,"url":"https://github.com/UKHomeOffice/dsp-root-ca","license":null,"readme":"# Digital Services Platform Public CA certificates\n\nThis repository contains Root and Intermediate CA certificates for DSP platform.\n\n\n## How to install\n\n### Alpine Linux\n\n```bash\napk add ca-certificates curl\ncurl -s https://raw.githubusercontent.com/UKHomeOffice/dsp-root-ca/master/root-ca.pem > /usr/local/share/ca-certificates/dsp_root_ca.crt\ncurl -s https://raw.githubusercontent.com/UKHomeOffice/dsp-root-ca/master/intermediate-ca.pem > /usr/local/share/ca-certificates/dsp_intermediate_ca.crt\nupdate-ca-certificates\n```\n\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/scala-skeleton-project","private":false,"url":"https://github.com/UKHomeOffice/scala-skeleton-project","license":{"key":"gpl-3.0","name":"GNU General Public License v3.0","spdxId":"GPL-3.0","url":"https://api.github.com/licenses/gpl-3.0","featured":true},"readme":"# scala-skeleton-project\nSkeleton project used for scala programming exercises\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/api-guide-for-developers","private":false,"url":"https://github.com/UKHomeOffice/api-guide-for-developers","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"Home Office API Guide for Developers\n====================================\n:toc:\n:numbered:\n:toc-placement!:\n\ntoc::[]\n\n== Introduction\nThis document is intended to help developers in the Home Office understand our current and recommended approaches for developing APIs\n\n== Authentication\nHow consumers authenticate with an API is important for many APIs. Whilst we've not settled on a standard the following approaches have been tried.\n\n=== Mutual TLS\nMutual TLS means that connecting clients need to have a client certificate before using the service. Typically the system terminating the mutual TLS will add headers to identify the client. The could allow your application to use these for example for granular permissions.\n\n.Pros and Cons of Mutual TLS\n|===\n|Pros | Cons\n|Can use standard nginx or similar for this purpose, so your application doesn't need to worry about auth\n|Client certificates will expire, and hence need to recreate these for all clients periodically, which introduces a lot of overhead and potential for errors\n\n|\n|Have to maintain a CA for signing client certs\n|===\n\n=== OAuth2 with keycloak\nOAuth2 is very commonly used for user authentication, but less frequently for API authentication. This is reflected by fewer client auth libraries available than you may expect. However the logic is trivial to implement.\n\nWe can implement OAuth2 authentication trivially using keycloak-proxy in front of an API, authenticating to a centralised keycloak server. This is especially beneficial as keycloak-proxy combined with a centralised keycloak give many capabilities for free such as role and user management, brute force prevention.\n\n.Pros and Cons of OAuth2 with keycloak\n|===\n|Pros | Cons\n|Can implement trivially using keycloak-proxy and keycloak\n|Client auth is slightly more complicated\n\n|Get a lot of capabilities for free with keycloak\n|\n\n|Possibility for consumers to rotate their own credentials, reducing administrative overhead\n|\n\n|Creds are only sent to the system on first auth or when the authentication token expires\n|===\n\n=== Basic HTTP Auth with username and password\nBasic HTTP auth requires a username and password to be sent with every request.\n\n.Pros and Cons of Basic HTTP Auth\n|===\n|Pros | Cons\n|Very simple to set up initially\n|Doing anything beyond basic auth is difficult\n\n|\n|User accounts have to be managed by your application, introducing complexity\n|===\n\n== Acceptance tests, documentation, and creating a mock of your API\nThese topics all go hand in hand - frequently one document can be the basis for tests, documentation, and for generating a mock. Here we will cover the common approaches we favour, and when each is appropriate.\n\n=== Recommended approach - Rest-assured tests with Spring RestDocs (you don't need Spring!), and Wiremock\n\n*Why we like this approach*\n\n* It enables one set of tests to generate docs and mock, helping to make sure everything ties together\n* The mock generated is flexible - it can have multiple canned responses per endpoint depending on the request params, whereas many other automatically generated mocks only allow one canned response per endpoint\n* The docs generated are flexible - A person writes the overall documentation, meaning it can be structured however makes most sense for your API, with as much detail as you like. The generated snippets then give real examples that you can embed into sections. This allows you to put much more context around the documentation than you may otherwise have been able to do\n* Allows testing and documentation of a json schema for your API\n\n*Example application using this approach* +\nhttps://ukhomeoffice.github.io/lev-api-docs/[Example docs] and https://github.com/UKHomeOffice/lev-api-docs/tree/master/mock[mock] for the LEV project are available here.\n\nhttps://gitlab.digital.homeoffice.gov.uk/lev/lev-api-scala[Code] is available here (you may need to ask a member of the LEV team for access).\n\nIf you have any questions ask in the developers slack channel and one of us will get back to you.\n\n*https://github.com/rest-assured/rest-assured[Rest-assured]* +\nRest assured is a library designed for making testing APIs straightforward. We recommend it here as it works out the box with Spring RestDocs.\n\n*http://projects.spring.io/spring-restdocs/[Spring Restdocs]* +\nSpring Restdocs allows you to generate documentation snippets for each of your tests. It records the request and the response and creates snippets for each of these. You can then embed these snippets into a master document that describes your whole API.\n\nDocumentation snippets are recorded in asciidoctor format, which is like a more advanced version of markdown. The main readme asciidoc file can then embed snippets from other files\n\n*http://wiremock.org/[Wiremock]* +\nWiremock is a mock API that allows you to record a series of requests and responses (by proxying requests through wiremock). When running your rest-assured tests you should proxy requests through a wiremock instance in record mode. It will then generate a number of files that represent the requests and responses. These files can then be used to run wiremock as a mock, where it will then respond with the recorded responses.\n\n=== Alternative approach - http://swagger.io/[Swagger]\nSwagger is a very common way to document APIs. It does a reasonable job of getting some API documentation available. The shortcomings are that it can become out of sync (it relies heavily on annotations which can get out of date), the mock you can generate from a swagger spec is very inflexible, and the docs are also very inflexible. The major benefits are that it is a common format that you can put together very quickly.\n\n=== Alternative approach - https://apiblueprint.org/[API Blueprint]\nAPI blueprint allows you to have one markdown file which is a specification of your API. From this file you can generate html docs, run tests, and generate a mock version of your API. The shortcomings are that the mock you can generate from an API Blueprint is very inflexible, and the docs are also very inflexible. The major benefits are that it is a common format that you can put together very quickly.\n\n== Technologies for building APIs\nThis will never be a conclusive list, but just says what technologies we have found good and bad for building APIs, and when we would recommend each of them.\n\n== API Versioning\nThis section will detail our approach to API versioning. Please note though having to version an API is never a desirable thing and should be avoided if possible using the strategy of expanding and contracting APIs (contracting once all clients have migrated away from old functionality).\n\n== API Gateways\nCurrently still something we are looking into, so consider this a placeholder for thoughts on API Gateways\n","travis":false,"contributing":false,"masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/api-guide-for-developers/branches/master/protection"}},{"name":"UKHomeOffice/application-pattern-library","private":false,"url":"https://github.com/UKHomeOffice/application-pattern-library","license":null,"readme":"# Application Pattern Library\n\nA library of patterns developed for Home Office applications by researchers, designers and developers within Home Office Digital, Data and Technology.\n","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-nginx-proxy-govuk","private":false,"url":"https://github.com/UKHomeOffice/docker-nginx-proxy-govuk","license":{"key":"mit","name":"MIT License","spdxId":"MIT","url":"https://api.github.com/licenses/mit","featured":true},"readme":"# GovUK-branded NGINX reverse proxy\n\n[![Docker Repository on Quay](https://quay.io/repository/ukhomeofficedigital/nginx-proxy-govuk/status \"Docker Repository on Quay\")](https://quay.io/repository/ukhomeofficedigital/nginx-proxy-govuk)\n\nSimply a version of [docker-nginx-proxy] with GovUK-branded error\npages. - Please read [the documentation for that image].\n\n**Warning:** This also adds debugging information to 418 (Teapot) pages.\n             You might not want this if you want to take the small\n             advantage of 'security through obscurity'. Feel free to\n             mount in your own SSI 'partial' to remove this information.\n\n## Find Us\n\n* [GitHub]\n* [Quay.io]\n\n## Versioning\n\nThis image will be versioned alongside the version of\n[docker-nginx-proxy] it consumes, with a minor build number taggen on\nthe end. For the versions available, see the [tags on this repository].\n\n## Authors\n\n* **Daniel A.C. Martin** - *Initial work* - [daniel-ac-martin]\n\nSee also the list of [contributors] who participated in this project.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md]\nfile for details.\n\n[contributors]:                     https://github.com/UKHomeOffice/docker-nginx-proxy-govuk/graphs/contributors\n[daniel-ac-martin]:                 https://github.com/daniel-ac-martin\n[docker-nginx-proxy]:               https://github.com/UKHomeOffice/docker-nginx-proxy\n[GitHub]:                           https://github.com/UKHomeOffice/docker-nginx-proxy-govuk\n[LICENSE.md]:                       LICENSE.md\n[Quay.io]:                          https://quay.io/repository/ukhomeofficedigital/nginx-proxy-govuk\n[tags on this repository]:          https://github.com/UKHomeOffice/docker-nginx-proxy-govuk/tags\n[the documentation for that image]: https://github.com/UKHomeOffice/docker-nginx-proxy/blob/master/README.md\n","travis":false,"contributing":false,"masterBranchProtection":{"url":"https://api.github.com/repos/UKHomeOffice/docker-nginx-proxy-govuk/branches/master/protection","restrictions":{"url":"https://api.github.com/repos/UKHomeOffice/docker-nginx-proxy-govuk/branches/master/protection/restrictions","users":[],"usersUrl":"https://api.github.com/repos/UKHomeOffice/docker-nginx-proxy-govuk/branches/master/protection/restrictions/users","teams":[],"teamsUrl":"https://api.github.com/repos/UKHomeOffice/docker-nginx-proxy-govuk/branches/master/protection/restrictions/teams"}}},{"name":"UKHomeOffice/evw-validation-rules","private":false,"url":"https://github.com/UKHomeOffice/evw-validation-rules","license":null,"readme":"# evw-validation-rules\n\nA collection of validation rules for all Electronic Visa Wavier applications to use","travis":false,"contributing":false,"masterBranchProtection":false},{"name":"UKHomeOffice/docker-node-hello-world","private":false,"url":"https://github.com/UKHomeOffice/docker-node-hello-world","license":null,"readme":"# Docker + Node \"Hello World\" Example\n\nThis repository gives you a quick introduction to getting docker running with Node. It is intended for the Docker beginner.\n\nYou can adapt the same approach to other languages but I chose Node because it's what I use most often.\n\n\n## Setup\n\nFirst, checkout this project locally and then follow these steps:\n\n0. Go through the Docker [installation](https://docs.docker.com/installation/) and [getting started guide](https://docs.docker.com/mac/started/) before you start.\n1. Install the [Docker Toolbox](https://www.docker.com/docker-toolbox).\n2. Start a \"Quickstart Terminal\" session (see the getting started guide).\n3. Build the Docker image: `docker build -t hello-world .`\n4. Run the image in a container: `docker run -d -p 4001:4000 hello-world`\n  - The `-d` flag says to run the container in the background (daemon mode).\n  - The `-p` flag maps port 4000 from the container to port 4001 on the docker machine.\n5. View your new container: `docker ps -a`\n6. Check the logs for your container: `docker logs <container-id>`\n7. Check the port of the container: `docker port <container-id>`\n8. Open the app running on the docker machine: `open http://$(docker-machine ip default):4001`\n\n\n\n## Notes & Tips\n\n- If you make changes to your application, you will need to rebuild your image and restart your container.\n- The `docker-machine` command controls the virtual machine that is running Docker on your machine.\n- View logs for a docker container: `docker logs <container-id>`\n- List the running containers: `docker ps -a`\n- List all local images: `docker images`\n- Remove an image: `docker rmi <image-id>`\n- Remove a container: `docker rm <container-id>`\n\n\n## Further Reading\n\n- Checkout [Tutum](http://tutum.co) for hosting private docker registries and managing your infrastructure.\n  - Check out the [Tutum CLI](https://github.com/tutumcloud/cli): `brew install tutum`\n- Check out this [Docker + Tutum hello world repo](https://github.com/tutumcloud/hello-world)\n\n\n## Credits and License\n\nPut together by [Dana Woodman](mailto:dana@danawoodman.com) and released under the MIT license. Have fun!\n","travis":false,"contributing":false,"masterBranchProtection":false}]